@article{attention:2017,
title = {{Attention Is All You Need}},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and N. Gomez, Aidan and Kaiser, Lukasz and Polosukhin, Illia},
journal = {arXiv:1607.06450},
year = {2017}
}

@article{bert:2018,
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
journal = {arXiv:1810.04805},
year = {2018}
}

@article{depthscore:2021,
title = {{Improving Unsupervised Dialogue Topic Segmentation with Utterance-Pair Coherence Scoring}},
author = {Linzi, Xing and Carenini, Giuseppe},
journal = {arXiv:2106.06719},
year = {2021}
}

@article{mistral:2023,
title = {{Mistral 7B}},
author = {Jiang, Albert and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris},
journal = {arXiv:2310.06825},
year = {2023}
}

@article{llama:2023,
title = {{Llama 2: Open Foundation and Fine-Tuned Chat Models}},
author = {Touvron, Hugo and Martin, Louis and Stone Kevin},
journal = {arXiv:2307.09288},
year = {2023}
}

@article{prompttopic:2023,
title = {{Prompting Large Language Models for Topic Modeling}},
author = {Wang, Han and Prakash, Nirmalendu and Hoang, Nguyen and Hee, Ming},
journal = {arXiv:2312.09693},
year = {2023}
}

@article{qmsum:2021,
title = {{QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization}},
author = {Zhong, Ming and Yin, Da and Yu, Tao and Zaidi, Ahmad},
journal = {arXiv:2104.05938},
year = {2021}
}

@article{qmsum:2021,
title = {{QMSum: A New Benchmark for Query-based Multi-domain Meeting Summarization}},
author = {Zhong, Ming and Yin, Da and Yu, Tao and Zaidi, Ahmad},
journal = {arXiv:2104.05938},
year = {2021}
}

@article{rotary:2021,
title = {{RoFormer: Enhanced Transformer with Rotary Position Embedding}},
author = {Jianlin Su and
            Yu Lu and
            Shengfeng Pan and
            Bo Wen and
            Yunfeng Liu},
journal = {CoRR},
year = {2021}
}
