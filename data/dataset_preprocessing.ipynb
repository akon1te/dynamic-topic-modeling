{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keybert import KeyBERT\n",
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "superseg, tiage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, 1)\n",
    "top_n = 5\n",
    "superseg_path = './datasets/superseg'\n",
    "splits = ['train', 'validation', 'test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6948/6948 [05:12<00:00, 22.25it/s]\n",
      "100%|██████████| 1322/1322 [00:58<00:00, 22.73it/s]\n",
      "100%|██████████| 1322/1322 [00:55<00:00, 23.73it/s]\n",
      "100%|██████████| 3/3 [07:06<00:00, 142.16s/it]\n"
     ]
    }
   ],
   "source": [
    "for split in tqdm(splits):\n",
    "    with open(os.path.join(superseg_path, f'segmentation_file_{split}.json')) as f:\n",
    "        data = json.load(f)\n",
    "    dataset = {'data' : []}\n",
    "    for idx, current_dialog in enumerate(tqdm(data['dial_data']['superseg-v2'])):\n",
    "        current_topic_utterances = [] \n",
    "        current_topic_id = 0\n",
    "        for item in current_dialog['turns']:\n",
    "            if item['topic_id'] == current_topic_id:\n",
    "                current_topic_utterances.append(item['utterance'].strip())\n",
    "            else:\n",
    "                keywords = kw_model.extract_keywords(' '.join(current_topic_utterances), top_n=top_n,  keyphrase_ngram_range=ngram_range, stop_words='english') \n",
    "                keywords = [word[0] for word in keywords]\n",
    "                dataset['data'].append({\"text\": \"\\n\".join(current_topic_utterances),\n",
    "                                        \"topic_id\": current_topic_id,\n",
    "                                        \"keywords\": ', '.join(keywords),\n",
    "                                        \"dialogue_id\": idx})\n",
    "                current_topic_id += 1\n",
    "                current_topic_utterances = [item['utterance'].strip()]\n",
    "\n",
    "    with open(f'./data/superseg_{split}.json', 'w') as f:\n",
    "        json.dump(dataset, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, 1)\n",
    "top_n = 5\n",
    "superseg_path = './datasets/tiage'\n",
    "splits = ['train', 'validation', 'test']\n",
    "bad_chars = [symbol for symbol in \"<>:/\\|?!*\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:11<00:00, 26.56it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 24.87it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 24.79it/s]\n",
      "100%|██████████| 3/3 [00:19<00:00,  6.46s/it]\n"
     ]
    }
   ],
   "source": [
    "for split in tqdm(splits):\n",
    "    with open(os.path.join(superseg_path, f'segmentation_file_{split}.json')) as f:\n",
    "        data = json.load(f)\n",
    "    dataset = {'data' : []}\n",
    "    for idx, current_dialog in enumerate(tqdm(data['dial_data']['tiage'])):\n",
    "        current_topic_utterances = [] \n",
    "        current_topic_id = 0\n",
    "        for item in current_dialog['turns']:\n",
    "            if item['topic_id'] == current_topic_id:\n",
    "                text = ''.join(i for i in item['utterance'].strip() if not i in bad_chars)\n",
    "                current_topic_utterances.append(text)\n",
    "            else:\n",
    "                keywords = kw_model.extract_keywords(' '.join(current_topic_utterances), top_n=top_n,  keyphrase_ngram_range=ngram_range, stop_words='english') \n",
    "                keywords = [word[0] for word in keywords]\n",
    "                dataset['data'].append({\"text\": \"\\n\".join(current_topic_utterances),\n",
    "                                        \"topic_id\": current_topic_id,\n",
    "                                        \"keywords\": ', '.join(keywords),\n",
    "                                        \"dialogue_id\": idx})\n",
    "                current_topic_id += 1\n",
    "                current_topic_utterances = [item['utterance'].strip()]\n",
    "\n",
    "    with open(f'./data/tiage_{split}.json', 'w') as f:\n",
    "        json.dump(dataset, f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_range = (1, 1)\n",
    "top_n = 5\n",
    "qmsum_path = './datasets/QMSum'\n",
    "splits = ['train', 'validation', 'test']\n",
    "acadenic_ds = {'train' : [], 'validation': [], 'test': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(qmsum_path, 'Academic', 'train'))\n",
    "with open(os.path.join(qmsum_path, 'Academic', 'train', files[0])) as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic': 'Technical issues', 'relevant_text_span': [['0', '171']]},\n",
       " {'topic': 'Transcription pipeline', 'relevant_text_span': [['172', '372']]},\n",
       " {'topic': 'Options for carrying out transcription',\n",
       "  'relevant_text_span': [['373', '877']]},\n",
       " {'topic': 'Transcription conventions and interfaces',\n",
       "  'relevant_text_span': [['878', '1156']]},\n",
       " {'topic': 'Time cost of annotation and website',\n",
       "  'relevant_text_span': [['1157', '1341']]},\n",
       " {'topic': 'Electronics', 'relevant_text_span': [['1342', '1744']]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['topic_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_topic_utterances = []\n",
    "text = [utter['content'] for utter in data['meeting_transcripts']]\n",
    "new_dialog = []\n",
    "for idx, topics in enumerate(data['topic_list']):\n",
    "    #topic_idx = \n",
    "    topic_start_idx, topic_end_idx = int(topics['relevant_text_span'][0][0]), int(topics['relevant_text_span'][0][1]) + 1\n",
    "    keywords = kw_model.extract_keywords(' '.join(text[topic_start_idx:topic_end_idx]).strip(), \n",
    "                                         top_n=top_n,  \n",
    "                                         keyphrase_ngram_range=ngram_range, \n",
    "                                         stop_words='english') \n",
    "    keywords = [word[0] for word in keywords]\n",
    "    new_dialog.append({'text': text[topic_start_idx:topic_end_idx],\n",
    "                        'topic_id': idx,\n",
    "                        'keywords': keywords})\n",
    "    break\n",
    "\n",
    "acadenic_ds['train'].append(new_dialog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [[{'text': ['OK , this is one channel . Can you uh , say your name and talk into your mike one at a time ?',\n",
       "     'This is Eric on channel three , I believe .',\n",
       "     \"OK . Uh , I don't think it 's on there , Jane .\",\n",
       "     'Tasting one two three , tasting .',\n",
       "     'OK , this is Jane on channel five .',\n",
       "     \"Uh , I still don't see you Jane .\",\n",
       "     'Oh , darn , what am I doing wrong ?',\n",
       "     'Can you see me on channel four ? Really ?',\n",
       "     'Yeah , I s',\n",
       "     'My lucky day .',\n",
       "     'Uh , screen no , {disfmarker} it is , oh , maybe it just warmed up ?',\n",
       "     'No .',\n",
       "     \"Oh , darn , can you can't see channel five yet ?\",\n",
       "     \"Uh , well , the mike isn't close enough to your mouth , so .\",\n",
       "     'Oh , this would be k OK , is that better ?',\n",
       "     'S uh , try speaking loudly ,',\n",
       "     'I like the high quality labelling .',\n",
       "     'so ,',\n",
       "     'Hello ,',\n",
       "     'OK , good .',\n",
       "     'David , can we borrow your labelling machine to improve the quality of the labelling a little bit here ?',\n",
       "     'hello . Alright .',\n",
       "     'Thank you .',\n",
       "     'One t',\n",
       "     'How {disfmarker} how many are there , one to five ?',\n",
       "     'One five , yeah .',\n",
       "     'Yeah , please .',\n",
       "     'Would you like to join the meeting ?',\n",
       "     \"Well , we don't wanna renumber them ,\",\n",
       "     'I bet {disfmarker}',\n",
       "     \"cuz we 've already have like , forms filled out with the numbers on them . So , let 's keep the same numbers on them .\",\n",
       "     \"Yeah , OK , that 's a good idea .\",\n",
       "     'OK , Dan , are you on ?',\n",
       "     \"I 'm on {disfmarker} I 'm on two and I should be on .\",\n",
       "     'Good .',\n",
       "     'Yeah .',\n",
       "     'Want to join the meeting , Dave ? Do we {disfmarker} do {disfmarker} do we have a spare , uh {disfmarker}',\n",
       "     \"And I 'm getting lots of responses on different ones , so I assume {pause} the various and assorted P Z Ms are on .\",\n",
       "     \"We ' r we 're {disfmarker} we ' r This is {disfmarker} this {disfmarker} this is a meeting meeting .\",\n",
       "     \"This is abou we 're {disfmarker} we 're mainly being taped but we 're gonna talk about , uh , transcription for the m future meeting meetings .\",\n",
       "     'Stuff . Yeah , this is not something you need to attend . So .',\n",
       "     'Yeah . e OK .',\n",
       "     \"You 're always having one of those days , Dave .\",\n",
       "     \"Y you 'd be welcome .\",\n",
       "     \"Besides , I don't want anyone who has a weird accent .\",\n",
       "     \"You 'd be welcome .\",\n",
       "     'Right , Dan ?',\n",
       "     \"So , I don't understand if it 's neck mounted you don't get very good performance .\",\n",
       "     \"It 's not neck mounted . It 's supposed to be h head mounted .\",\n",
       "     'Yeah . It {disfmarker} it should be head mounted . Right ?',\n",
       "     'Well , then put it on your head .',\n",
       "     \"I don't know .\",\n",
       "     'Right .',\n",
       "     'What are you doing ?',\n",
       "     'Cuz when you do this , you can {disfmarker} Rouww - Rouww .',\n",
       "     \"Why didn't I {disfmarker} you were saying that but I could hear you really well on the {disfmarker} on the transcription {disfmarker} on the , uh , tape .\",\n",
       "     'Well , I m I would prefer that people wore it on their head',\n",
       "     \"I {disfmarker} I don't know .\",\n",
       "     'i',\n",
       "     \"but they were complaining about it . Because it 's not {disfmarker} it doesn't go over the ears .\",\n",
       "     'Why ?',\n",
       "     \"It 's badly designed .\",\n",
       "     \"It 's very badly designed so it 's {disfmarker}\",\n",
       "     \"It 's very badly designed ?\",\n",
       "     \"What do you mean it doesn't go over the ears ?\",\n",
       "     \"Why ? It 's not s It 's not supposed to cover up your ears .\",\n",
       "     \"Yeah but , there 's nowhere to put the pad so it 's comfortable .\",\n",
       "     \"I mean , it 's only badly {disfmarker}\",\n",
       "     \"So that 's what you 're d He 's got it on his temples so it cuts off his circulation .\",\n",
       "     \"Oh , that 's strange .\",\n",
       "     \"Yeah , that 's {disfmarker} that 's what I have .\",\n",
       "     'And it feels so good that way .',\n",
       "     'It feels so good when I stop .',\n",
       "     'So I {disfmarker} I again would like to do some digits .',\n",
       "     'Somebody wanna {disfmarker}',\n",
       "     'Try it .',\n",
       "     'Um .',\n",
       "     'Somebody wanna close the door ?',\n",
       "     'Sure .',\n",
       "     'OK .',\n",
       "     'We could do it with noise .',\n",
       "     'So let me {disfmarker}',\n",
       "     \"You 're always doing digits .\",\n",
       "     \"Well , you know , I 'm just that sort of {disfmarker} digit - y g sorta guy . OK . So this is Adam .\",\n",
       "     'Uh , this is the same one I had before .',\n",
       "     'I doubt it .',\n",
       "     \"It 's still the same words .\",\n",
       "     \"I think we 're session four by the way . Or m it might be five .\",\n",
       "     \"Psss ! Oh , that 's good .\",\n",
       "     'No',\n",
       "     \"I didn't bring my previous thing .\",\n",
       "     \"We didn't {disfmarker}\",\n",
       "     'Now , just to be sure , the numbers on the back , this is the channel ?',\n",
       "     \"That 's the microphone number .\",\n",
       "     \"That 's the microphone number .\",\n",
       "     'Yeah , d leave the channel blank .',\n",
       "     'Uh - oh . OK , good .',\n",
       "     'But number has to be {disfmarker} ? So we have to look up the number .',\n",
       "     'Five {disfmarker}',\n",
       "     'Right .',\n",
       "     'OK , good .',\n",
       "     'Good . OK . Well , this is Jane , on mike number five . Um . I just start ? Do I need to say anything more ?',\n",
       "     'Uh , transcript number .',\n",
       "     'Transcript number {disfmarker}',\n",
       "     'OK , this is Eric on microphone number three ,',\n",
       "     'This is Beck on mike four .',\n",
       "     'Thanks . Should I turn off the VU meter Dan ? Do you think that makes any difference ?',\n",
       "     'Oh , God . No , let me do it .',\n",
       "     'Why ? Are you gonna do something other than hit \" quit \" ?',\n",
       "     \"No , but I 'm gonna look at the uh , logs as well .\",\n",
       "     'Oh . Should have done it before .',\n",
       "     'Uh , you said turn off the what ?',\n",
       "     'The VU meter which tells you what the levels on the various mikes are and there was one hypothesis that perhaps that {disfmarker} {vocalsound} the act of recording the VU meter was one of the things that contributed to the errors .',\n",
       "     'Oh . Oh , I see .',\n",
       "     \"Yeah , but Eric , uh , you didn't think that was a reasonable hypothesis , right ?\",\n",
       "     'I See .',\n",
       "     'That was me ,',\n",
       "     \"Oh , I 'm sorry y\",\n",
       "     'I thought that was {disfmarker}',\n",
       "     'That was malarkey .',\n",
       "     \"Well , the only reason that could be is if the driver has a bug . Right ? Because the machine just isn't very heavily loaded .\",\n",
       "     'No chance of that .',\n",
       "     \"No chance of that . Just because it 's beta . Look OK ?\",\n",
       "     'Yeah , there {disfmarker} there {disfmarker} there was {disfmarker} there was a {disfmarker} there was a bug . There was a glitch last time we ran .',\n",
       "     'Are - are yo are you recording where the table mikes are by the way ?',\n",
       "     'No .',\n",
       "     'Do you know which channels {disfmarker}',\n",
       "     'Yeah , we usually do that .',\n",
       "     \"No , we don't .\",\n",
       "     'Yeah .',\n",
       "     'But we {disfmarker} we ought to st we ought to standardize .',\n",
       "     'Why not ?',\n",
       "     'I think , {vocalsound} uh , I s I spoke to somebody , Morgan , {comment} about that . I think {disfmarker} I think we should put mar Well , no , w we can do that .',\n",
       "     \"Why don't you just do this ?\",\n",
       "     \"I mean , that 's what we 've done before .\",\n",
       "     \"I know what they {disfmarker} they 're {disfmarker} they 're four , three , two , one . In order now .\",\n",
       "     'Four .',\n",
       "     'Three , two , {vocalsound} and one .',\n",
       "     'Three .',\n",
       "     'But I think {disfmarker} I think we should put them in standard positions . I think we should make little marks on the table top .',\n",
       "     \"Which means we need to move this thing , and sorta decide how we 're actually going to do things .\",\n",
       "     'So that we can put them {disfmarker}',\n",
       "     'Oh , OK .',\n",
       "     \"I guess that 's the point .\",\n",
       "     'So .',\n",
       "     \"It 'll be a lot easier if we have a {disfmarker} if we have them permanently in place or something like that .\",\n",
       "     'Right .',\n",
       "     'I do wish there were big booms coming down from the ceiling .',\n",
       "     'You do ?',\n",
       "     'Yeah .',\n",
       "     'Would it make you feel more important ?',\n",
       "     'Mmm .',\n",
       "     'Yeah , yeah , yeah .',\n",
       "     'I see .',\n",
       "     'Wait till the projector gets installed .',\n",
       "     'You know .',\n",
       "     \"That 'll work .\",\n",
       "     \"Oh , that 'll be good .\",\n",
       "     \"That 'll work .\",\n",
       "     'Oh , gosh .',\n",
       "     \"Cuz it 's gonna hang down , make noise .\",\n",
       "     'OK .',\n",
       "     \"When 's it gonna be installed ?\",\n",
       "     'OK .',\n",
       "     'Well , {vocalsound} it depends on',\n",
       "     'I see .',\n",
       "     'Is this b is this being recorded ?',\n",
       "     \"That 's right .\",\n",
       "     'Uh , I think Lila actually is almost getting r pretty close to even getting ready to put out the purchase order .',\n",
       "     'OK . Cool .',\n",
       "     'I handed it off to her about a month ago .',\n",
       "     'I see .'],\n",
       "    'topic_id': 0,\n",
       "    'keywords': ['channel', 'labelling', 'channels', 'disfmarker', 'mike']}]],\n",
       " 'validation': [],\n",
       " 'test': []}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acadenic_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
