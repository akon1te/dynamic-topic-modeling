{"data": [{"text": "Channel one .\nTest .\nHello .\nChannel three .\nTest .\nUh - oh .\nSo you think we 're going now , yes ? OK , good . Alright Going again Uh  So we 're gonna go around as before , and uh do  do our digits . Uh transcript one three one one dash one three three zero .  three two three  four seven six five  five three one six two four one  six seven  seven  eight  nine zero nine four zero zero three  zero one five eight  one seven three five three  two six eight zero  three six two four three zero seven  four  five zero six nine four  seven four  eight five seven  nine six one five  O seven eight O two  zero nine six zero four zero zero  one  two  Uh  Yeah , you don't actually n need to say the name .\nOK ,  this is Barry Chen and I am reading transcript\nThat 'll probably be bleeped out .\nOK .\nSo . That 's if these are anonymized , but  Yeah\nOh .  OK .\nuh  I mean  not that there 's anything defamatory about uh  eight five seven or  or anything , but\nOK .\nUh , anyway . Uh  so here 's what I have for  I  I was just jotting down things I think th w that we should do today . Uh  This is what I have for an agenda so far Um , We should talk a little bit about the plans for the uh  the field trip next week . Uh  a number of us are doing a field trip to uh Uh  OGI And uh  mostly uh First though about the logistics for it . Then maybe later on in the meeting we should talk about what we actually you know , might accomplish . Uh\nOK .\nUh , in and  kind of go around  see what people have been doing  talk about that ,  a r progress report . Um , Essentially . Um  And then uh  Another topic I had was that uh  uh  Uh  Dave here had uh said uh \" Give me something to do . \" And I  I have  I have uh  failed so far in doing that . And so maybe we can discuss that a little bit . If we find some holes in some things that  that  someone could use some help with , he 's  he 's volunteering to help .\nI 've got to move a bunch of furniture .\nOK , always count on a  serious comment from that corner . So , um , uh , and uh , then uh , talk a little bit about  about disks and resource  resource issues that  that 's starting to get worked out . And then , anything else anybody has that isn't in that list ? Uh\nI was just wondering , does this mean the battery 's dying and I should change it ?\nUh I think that means the battery 's O K .\nLet me see .\nd  do you\nOh OK , so th\nYeah , that 's good . You 're alright ?\nCuz it 's full .\nYeah . Yeah .\nAlright .\nYeah . Yeah . It looks full of electrons . OK . Plenty of electrons left there . OK , so , um , uh . OK , so , uh , I wanted to start this with this mundane thing . Um  Uh  I  I  it was  it was kind of my bright idea to have us take a plane that leaves at seven twenty in the morning .\nOh , yeah , that 's right .\nUm . Uh  this is uh  The reason I did it uh was because otherwise for those of us who have to come back the same day it is really not much of a  of a visit . Uh  So um the issue is how  how  how would we ever accomplish that ? Uh  what  what  what part of town do you live in ?\nUm , I live in , um , the corner of campus . The , um , southeast corner .\nOK . OK , so would it be easier  those of you who are not , you know , used to this area , it can be very tricky to get to the airport at  at uh , you know , six thirty . Um . So . Would it be easier for you if you came here and I drove you ? Yeah ? Yeah , yeah , OK .\nYeah , perhaps , yeah .\nYeah . Sure .\nYeah .\nOK , so if  if everybody can get here at six .\nAt six .\nYeah , I 'm afraid we need to do that to get there on time .\nSix , OK .\nYeah , so . Oh boy . Anyway , so .\nWill that  be enough time ?\nYeah . Yeah , so I 'll just pull up in front at six and just be out front . And , uh , and yeah , that 'll be plenty of time . It 'll take  it  it  it won't be bad traffic that time of day and  and uh\nI guess once you get past the bridge  that that would be the worst .\nYeah , Oakland .\nGoing to Oakland .\nYeah .\nOakland .\nOnce you get past the turnoff to the  Bay Bridge .\nBridge oh , the turnoff to the bridge\nYeah .\nWon't even do that .\nYeah .\nI mean , just go down Martin Luther King .\nYeah . OK . Mm - hmm .\nAnd then Martin Luther King to nine - eighty to eight - eighty ,\nYeah .\nand it 's  it 'd take us , tops uh thirty minutes to get there .\nOh , I\nSo that leaves us fifty minutes before the plane  it 'll just  yeah . So Great , OK so that 'll It 's  I mean , it 's still not going to be really easy but  well Particularly for  for uh  for Barry and me , we 're not  we 're not staying overnight so we don't need to bring anything particularly except for  uh  a pad of paper and   So , and , uh you , two have to bring a little bit\nOK .\nbut uh  you know , don't  don't bring a footlocker and we 'll be OK So .\ns So just\nW you 're staying overnight . I figured you wouldn't need a great big suitcase , yeah .\nOh yeah . Yeah .\nThat 's sort of   one night . So . Anyway . OK .\nSo , s six AM , in front .\nSix AM in front .\nOK .\nUh , I 'll be here . Uh  I 'll  I 'll  I 'll  I 'll give you my phone number , If I 'm not here for a few m after a few minutes then\nWake you up .\nNah , I 'll be fine . I just , uh  it  for me it just means getting up a half an hour earlier than I usually do . Not  not  not a lot ,\nOK . Wednesday .\nso OK , that was the real real important stuff . Um , I  I  I figured maybe wait on the potential goals for the meeting uh  until we talk about wh what 's been going on . So , uh , what 's been going on ? Why don't we start  start over here .\nUm .  Well , preparation of the French test data actually .\nOK .\nSo ,  it means that um , well , it is , uh , a digit French database of microphone speech , downsampled to eight kilohertz and I 've added noise to one part , with the  actually the Aurora - two noises . And , @ @ so this is a training part . And then  the remaining part , I use for testing and  with other kind of noises . So we can  So this is almost ready . I 'm preparing the  the HTK baseline for this task . And , yeah .\nOK Uh , So the HTK base lines  so this is using mel cepstra and so on , or  ? Yeah . OK .\nYeah .\nAnd again , I guess the p the plan is , uh , to uh  then given this  What 's the plan again ?\nThe plan with  these data ?\nWith  So  So  Does i Just remind me of what  what you were going to do with the  what  what  what  what 's  y You just described what you 've been doing . So if you could remind me of what you 're going to be doing .\nYeah .\nOh , this is  yeah , yeah .\nUh , yeah .\nTell him about the cube .\nWell . The cube ? I should tell him about the cube ?\nYeah .\nOh ! Cube . Yeah .\nYeah .\nFill in the cube .\nUh we  actually we want to , mmm , Uh ,  uh , analyze three dimensions , the feature dimension , the  training data dimension , and the test data dimension . Um . Well , what we want to do is first we have number for each  uh task . So we have the um , TI - digit task , the Italian task , the French task  and the Finnish task .\nYeah ?\nSo we have numbers with  uh  systems  I mean  I mean neural networks trained on the task data . And then to have systems with neural networks trained on ,  uh , data from the same language , if possible , with , well , using a more generic database , which is phonetically  phonetically balanced , and . Um .\nSo - so we had talked  I guess we had talked at one point about maybe , the language ID corpus ?\nYeah . So .\nIs that a possibility for that ?\nYe - uh   Yeah , but , uh these corpus , w w there is a CallHome and a CallFriend also , The CallFriend is for language ind identification . Well , anyway , these corpus are all telephone speech . So , um .  This could be a   a problem for  Why ? Because uh , uh , the  the SpeechDat databases are not telephone speech . They are downsampled to eight kilohertz but  but they are not  uh with telephone bandwidth .\nYeah . That 's really funny isn't it ? I mean cuz th this whole thing is for  developing new standards for the telephone .\nTelephone .\nYeah .\nYeah , but the  the idea is to compute the feature before  the  before sending them to the  Well ,  you don't  do not send speech , you send features , computed on th the   the device ,\nMm - hmm . Yeah , I know , but the reason\nor  Well .\nOh I see , so your point is that it 's  it 's  it 's uh  the features are computed locally , and so they aren't necessarily telephone bandwidth , uh or telephone distortions .\nSo you  Yeah . Yeah .\nDid you  happen to find out anything about the OGI multilingual database ?\nYeah , that 's wh that 's wh that 's what I meant .\nYeah , it 's\nI said  @ @ , there 's  there 's  there 's an OGI language ID , not the  not the , uh  the CallFriend is a  is a , uh , LDC w thing , right ?\nYea - Yeah , there are also two other databases . One they call the multi - language database , and another one is a twenty - two language , something like that . But it 's also telephone speech .\nOh , they are ? OK .\nUh . Well , nnn .\nBut I 'm not sure\nSo\nI mean , we ' r e e The bandwidth shouldn't be such an issue right ? Because e e this is downsampled and  and filtered , right ? So it 's just the fact that it 's not telephone . And there are so many other differences between these different databases . I mean some of this stuff 's recorded in the car , and some of it 's  I mean there 's  there 's many different acoustic differences . So I 'm not sure if  . I mean , unless we 're going to include a bunch of car recordings in the  in the training database , I 'm not sure if it 's  completely rules it out\nYeah .\nif our  if we  if our major goal is to have phonetic context and you figure that there 's gonna be a mismatch in acoustic conditions does it make it much worse f to sort of add another mismatch , if you will .\nMmm .\nUh , i i I  I guess the question is how important is it to  for us to get multiple languages uh , in there .\nYeah , but  Mm - hmm .  Um . Yeah . Well , actually , for the moment if we w do not want to use these phone databases , we  we already have uh  English , Spanish and French uh , with microphone speech .\nMm - hmm . Yeah .\nSo .\nSo that 's what you 're thinking of using is sort of the multi the equivalent of the multiple ?\nWell . Yeah , for the multilingual part we were thinking of using these three databases .\nAnd for the difference in phonetic context  that you  ? Provide that .\nWell , this  Uh , actually , these three databases are um generic databases .\nYeah .\nSo w f for  for uh Italian , which is close to Spanish , French and , i i uh , TI - digits we have both uh , digits  training data and also  more general training data . So . Mmm .\nWell , we also have this Broadcast News that we were talking about taking off the disk , which is   is microphone data for  for English .\nYeah . Yeah , perhaps  yeah , there is also TIMIT .\nYeah .\nWe could use TIMIT .\nRight . Yeah , so there 's plenty of stuff around . OK , so anyway , th the basic plan is to , uh , test this cube . Yes .\nYeah .\nTo fill in the cube .\nTo fill i fill it in , yeah . OK .\nYeah , and perhaps , um   We were thinking that perhaps the cross - language issue is not , uh , so big of a issue . Well , w w we  perhaps we should not focus too much on that cross - language stuff . I mean , uh , training  training a net on a language and testing a for another language .\nUh - huh . But that 's\nMmm . Perhaps the most important is to have neural networks trained on the target languages . But , uh , with a general database  general databases . u So that th Well , the  the guy who has to develop an application with one language can use the net trained o on that language , or a generic net ,\nUh , depen it depen it depends how you mean \" using the net \" .\nbut not trained on a\nSo , if you 're talking about for producing these discriminative features  that we 're talking about  you can't do that .\nMmm .\nBecause  because the  what they 're asking for is  is a feature set . Right ? And so , uh , we 're the ones who have been weird by  by doing this training . But if we say , \" No , you have to have a different feature set for each language , \" I think this is ver gonna be very bad .\nYeah .\nOh .\nYou think so .\nThat 's\nOh .\nSo  Oh yeah .\nMmm .\nYeah . I mean , in principle , I mean conceptually , it 's sort of like they want a re @ @  well , they want a replacement for mel cepstra .\nMmm .\nSo , we say \" OK , this is the year two thousand , we 've got something much better than mel cepstra . It 's , you know , gobbledy - gook . \" OK ? And so  we give them these gobbledy - gook features but these gobbledy - gook features are supposed to be good for any language .\nHmm .\nCuz you don't know who 's gonna call , and you know , I mean so it 's  it 's  it 's , uh , uh  how do you know what language it is ? Somebody picks up the phone . So thi this is their image . Someone picks up the phone , right ?\nWell , I  chh\nAnd  and he  he picks up the ph\nYeah , but the  the application is  there is a target language for the application .\nYeah . y y y\nSo , if a\nWell . But , no but , y you  you pick up the phone ,\nWell .\nyou talk on the phone ,\nYeah ?\nand it sends features out . OK , so the phone doesn't know what a  what  what your language is .\nYeah , if  Yeah . If it 's th in the phone , but\nBut that 's the image that they have .\nwell , it  that  that could be th at the server 's side ,\nIt could be ,\nand , well . Mmm , yeah .\nbut that 's the image they have , right ? So that 's  that 's  I mean , one could argue all over the place about how things really will be in ten years . But the particular image that the cellular industry has right now is that it 's distributed speech recognition , where the , uh , uh , probabilistic part , and  and s semantics and so forth are all on the servers , and you compute features of the  uh , on the phone . So that 's  that 's what we 're involved in . We might  might or might not agree that that 's the way it will be in ten years , but that 's  that 's  that 's what they 're asking for . So  so I think that  th th it is an important issue whether it works cross - language . Now , it 's the OGI , uh , folks ' perspective right now that probably that 's not the biggest deal . And that the biggest deal is the , um envir acoustic - environment mismatch . And they may very well be right , but I  I was hoping we could just do a test and determine if that was true . If that 's true , we don't need to worry so much . Maybe  maybe we have a couple languages in the training set and that gives us enough breadth uh , uh , that  that  that the rest doesn't matter . Um , the other thing is , uh , this notion of training to uh  which I  I guess they 're starting to look at up there ,  training to something more like articulatory features . Uh , and if you have something that 's just good for distinguishing different articulatory features that should just be good across , you know , a wide range of languages .\nYeah .\nUh , but  Yeah , so I don't th I know  unfortunately I don't  I see what you 're comi where you 're coming from , I think , but I don't think we can ignore it .\nSo we  we really have to do test with a real cross - language . I mean , tr for instance training on English and testing on Italian , or  Or we can train  or else , uh , can we train a net on , uh , a range of languages and  which can include the test  the test @ @ the target language ,\nTest on an unseen .\nor\nYeah , so , um , there 's  there 's , uh  This is complex . So , ultimately , uh , as I was saying , I think it doesn't fit within their image that you switch nets based on language . Now , can you include , uh , the  the target language ?\nYeah .\nUm , from a purist 's standpoint it 'd be nice not to because then you can say when  because surely someone is going to say at some point , \" OK , so you put in the German and the Finnish .\nMmm .\nUh , now , what do you do , uh , when somebody has Portuguese ? \" you know ? Um , and  Uh , however , you aren't  it isn't actually a constraint in this evaluation . So I would say if it looks like there 's a big difference to put it in , then we 'd make note of it , and then we probably put in the other , because we have so many other problems in trying to get things to work well here that  that , you know , it 's not so bad as long as we  we note it and say , \" Look , we did do this \" .\nMmm ?\nAnd so , ideally , what you 'd wanna do is you 'd wanna run it with and without the target language and the training set for a wide range of languages .\nUh . Yeah .\nYeah , perhaps . Yeah .\nAnd that way you can say , \" Well , \" you know , \" we 're gonna build it for what we think are  the most common ones \" ,\nYeah .\nYeah .\nbut if that  somebody uses it with a different language , you know , \" here 's what 's you 're l here 's what 's likely to happen . \"\nYeah , cuz the truth is , is that it 's  it 's not like there are  I mean , al although there are thousands of languages , uh , from uh , uh , the point of view of cellular companies , there aren't .\nRight .\nThere 's   you know , there 's fifty or something , you know ? So , uh , an and they aren't  you know , with the exception of Finnish , which I guess it 's pretty different from most  most things . uh , it 's  it 's , uh  most of them are like at least some of the others . And so , our guess that Spanish is like Italian , and  and so on . I guess Finnish is a  is  is a little bit like Hungarian , supposedly , right ?\nI don't know anything about Finnish .\nOr is  I think  well , I kn oh , well I know that H uh , H I mean , I 'm not a linguist , but I guess Hungarian and Finnish and one of the  one of the languages from the former Soviet Union are in this sort of same family .\nHmm .\nBut they 're just these , you know , uh  countries that are pretty far apart from one another , have  I guess , people rode in on horses and brought their\nHmm .\nOK .\nThe  Yeah .", "topic_id": 0, "keywords": "transcript, defamatory, channel, digits, phonetic", "dialogue_id": 0}, {"text": "Oh , my turn .\nYour turn .\nOh , OK . Um , Let 's see , I  I spent the last week , uh , looking over Stephane 's shoulder . And   and understanding some of the data . I re - installed , um , um , HTK , the free version , so , um , everybody 's now using three point O , which is the same version that , uh , OGI is using .\nOh , good .\nYeah . So , without  without any licensing big deals , or anything like that . And , um , so we 've been talking about this  this , uh , cube thing , and it 's beginning more and more looking like the , uh , the Borge cube thing . It 's really gargantuan . Um , but I I 'm  Am I\nSo are  are you going to be assimilated ?\nResistance is futile .\nExactly . Um , yeah , so I I 've been looking at , uh , uh , TIMIT stuff . Um , the  the stuff that we 've been working on with TIMIT , trying to get a , um  a labels file so we can , uh , train up a  train up a net on TIMIT and test , um , the difference between this net trained on TIMIT and a net trained on digits alone . Um , and seeing if  if it hurts or helps .\nMm - hmm .\nAnyway .\nAnd again , when y just to clarify , when you 're talking about training up a net , you 're talking about training up a net for a tandem approach ?\nYeah , yeah . Um . Mm - hmm .\nAnd  and the inputs are PLP and delta and that sort of thing ,\nWell , the inputs are one dimension of the cube ,\nor  ?\nwhich , um , we 've talked about it being , uh , PLP , um , M F C Cs , um , J - JRASTA , JRASTA - LDA\nHmm .\nYeah , but your initial things you 're making one choice there ,\nYeah ,\nright ?\nright .\nWhich is PLP , or something ?\nUm , I  I haven't  I haven't decided on  on the initial thing .\nYeah .\nProbably  probably something like PLP . Yeah .\nHmm .\nYeah . Um , so  so you take PLP and you  you , uh , do it  uh , you  you , uh , use HTK with it with the transformed features using a neural net that 's trained . And the training could either be from Digits itself or from TIMIT .\nRight .\nAnd that 's the  and , and th and then the testing would be these other things which  which  which might be foreign language .\nRight . Right .\nI see . I  I  I get in the picture about the cube .\nYeah . Maybe\nOK .\nOK . Uh - huh .\nOK . Um , I mean , those listening to this will not have a picture either , so , um , I guess I 'm  I 'm not any worse off . But but at some point  somebody should just show me the cube . It sounds s I  I get  I think I get the general idea of it ,\nYeah , yeah ,\nyeah .\nSo , when you said that you were getting the labels for TIMIT ,  um , are y what do you mean by that ?\nb May Mm - hmm . Oh , I 'm just  I 'm just , uh , transforming them from the , um , the standard TIMIT transcriptions into  into a nice long huge P - file to do training .\nMmm . Were the digits , um , hand - labeled for phones ?\nUm , the  the digits\nOr were they  those labels automatically derived ?\nOh yeah , those were  those were automatically derived by  by Dan using , um , embedded  embedded training and alignment .\nMmm .\nAh , but which Dan ?\nUh , Ellis . Right ?\nOK . OK .\nYeah . So .\nI was just wondering because that test you 're t\nUh - huh .\nI  I think you 're doing this test because you want to determine whether or not , uh , having s general speech performs as well as having specific  speech .\nThat 's right .\nWell , especially when you go over the different languages again , because you 'd  the different languages have different words for the different digits ,\nMm - hmm . And I was\nso it 's\nyeah , so I was just wondering if the fact that TIMIT  you 're using the hand - labeled stuff from TIMIT might be  confuse the results that you get .\nI  I think it would , but  but on the other hand it might be better .\nRight , but if it 's better , it may be better because  it was hand - labeled .\nOh yeah , but still @ @ probably use it .\nYeah . OK .\nI mean , you know , I  I  I guess I 'm sounding cavalier , but I mean , I think the point is you have , uh , a bunch of labels and  and they 're han hand uh  hand - marked . Uh , I guess , actually , TIMIT was not entirely hand - marked . It was automatically first , and then hand  hand - corrected .\nOh , OK .\nBut  but , um , uh , it  it , um , it might be a better source . So , i it 's  you 're right . It would be another interesting scientific question to ask , \" Is it because it 's a broad source or because it was , you know , carefully ? \"\nMm - hmm .\nuh . And that 's something you could ask , but given limited time , I think the main thing is if it 's a better thing for going across languages on this training tandem system ,\nYeah . Right .\nthen it 's probably\nWhat about the differences in the phone sets ?\nUh , between languages ?\nNo , between TIMIT and the  the digits .\nOh , um , right . Well , there 's a mapping from the sixty - one phonemes in TIMIT to  to fifty - six , the ICSI fifty - six .\nSixty - one .\nOh , OK . I see .\nAnd then the digits phonemes , um , there 's about twenty twenty - two or twenty - four of them ? Is that right ?\nOut of that fifty - six ?\nYep .\nOut of that fifty - six .\nOh , OK .\nYeah . So , it 's  it 's definitely broader , yeah .\nBut , actually , the issue of phoneti phon uh phone phoneme mappings will arise when we will do severa use several languages\nYeah .\nbecause you  Well , some phonemes are not , uh , in every languages , and  So we plan to develop a subset of the phonemes , uh , that includes , uh , all the phonemes of our training languages ,\nMm - hmm .\nand use a network with kind of one hundred outputs or something like that .\nMm - hmm . You mean a superset , sort of .\nUh , yeah ,\nYeah .  Yeah .\nsuperset ,\nYeah . I th I looks the SAMPA SAMPA phone .\nyeah .\nSAMPA phone ? For English  uh American English , and the  the  the language who have more phone are the English .\nYeah .\nMmm .\nOf the  these language . But n for example , in Spain , the Spanish have several phone that d doesn't appear in the E English and we thought to complete . But for that , it needs  we must r h do a lot of work  because we need to generate new tran transcription for the database that we have .\nMm - hmm . Mm - hmm .\nOther than the language , is there a reason not to use the TIMIT phone set ? Cuz it 's larger ? As opposed to the ICSI  phone set ?\nOh , you mean why map the sixty - one to the fifty - six ?\nYeah .\nI don't know . I have\nUm , I forget if that happened starting with you , or was it  o or if it was Eric , afterwards who did that . But I think , basically , there were several of the phones that were just hardly ever there .\nYeah , and I think some of them , they were making distinctions between silence at the end and silence at the beginning , when really they 're  both silence .\nOh .\nI th I think it was things like that that got it mapped down to fifty - six .\nOK .\nYeah , especially in a system like ours , which is a discriminative system . You know , you 're really asking this net to learn .\nYeah .\nYeah .\nIt 's  it 's kind of hard .\nThere 's not much difference , really . And  the ones that are gone , I think are  I think there was  they also in TIMIT had like a glottal stop , which was basically a short period of silence ,\nMm - hmm .\nand so .\nWell , we have that now , too , right ?\nI don't know .\nYeah .\nSo .\ni It 's actually pretty common that a lot of the recognition systems people use have things like  like , say thirty - nine , phone symbols , right ? Uh , and then they get the variety by  by bringing in the context , the phonetic context . Uh . So we actually have an unusually large number in  in what we tend to use here . Um . So , a a actually  maybe  now you 've got me sort of intrigued . What  there 's  Can you describe what  what 's on the cube ?\nYeah , w I th I think that 's a good idea\nI mean\nto  to talk about the whole cube\nYeah , yeah .\nYeah . Yeah .\nand maybe we could sections in the cube for people to work on .\nYeah . Yeah .\nUm , OK . Uh , do you wanna do it ?\nOK , so even  even though the meeting recorder doesn't  doesn't , uh  and since you 're not running a video camera we won't get this , but if you use a board it 'll help us anyway .\nOK .\nUh , point out one of the limitations of this  medium ,\nOK .\nbut you 've got the wireless on ,\nYeah , I have the wireless .\nright ? Yeah , so you can walk around .\nOK . Can y can you walk around too ? No . OK , well , um ,\nUh , he can't , actually , but\ns basically , the  the cube will have three dimensions .\nHe 's tethered .\nThe first dimension is the  the features that we 're going to use . And the second dimension , um , is the training corpus . And that 's the training on the discriminant neural net . Um and the last dimension happens to be\nYeah and again  Yeah . So the  the training for HTK is always  that 's always set up for the individual test , right ? That there 's some training data and some test data . So that 's different than this .\nRight , right . This is  this is for  for ANN only . And , yeah , the training for the HTK models is always , uh , fixed for whatever language you 're testing on .\nRight .\nAnd then , there 's the testing corpus . So , then I think it 's probably instructive to go and  and  and show you the features that we were talking about . Um , so , let 's see . Help me out with\nPLP .\nWith what ?\nPLP .\nPLP ? OK .\nMSG .\nMSG .\nUh , JRASTA .\nJRASTA .\nAnd JRASTA - LDA .\nJRASTA - LDA .\nUm , multi - band .\nMulti - band .\nSo there would be multi - band before , um  before our network , I mean .\nYeah , just the multi - band features , right ?\nAnd\nYeah .\nYeah .\nUh - huh . Ah . Ah .\nSo , something like , uh , s TCT within bands and  Well . And then multi - band after networks . Meaning that we would have , uh , neural networks , uh , discriminant neural networks for each band . Uh , yeah . And using the  the outputs of these networks or the linear outputs or something like that . Uh , yeah .\nWhat about mel cepstrum ? Or is that\nOh , um\nyou don't include that because it 's part of the base or something ?\nYeah databases .\nWell , y you do have a baseline system that 's m that 's mel cepstra ,\nYeah .\nright ?\nMm - hmm .\nSo .\nBut , uh , well , not for the  the ANN . I mean\nOK .\nSo , yeah , we could  we could add  MFCC also .\nWe could add\nProbably should . I mean at least  at least conceptually , you know , it doesn't meant you actually have to do it ,\nYeah .\nYeah .\nbut conceptually it makes sense as a  as a base line .\nIt 'd be an interesting test just to have  just to do MFCC with the neural net\nWithout the\nand everything else the same .\nYeah .\nCompare that with just M - MFCC without the  the net .\nYeah .\nMm - hmm .\nI think  I think Dan did some of that .\nOh .\nUm , in his previous Aurora experiments . And with the net it 's  it 's wonderful . Without the net it 's just baseline .\nUm , I think OGI folks have been doing that , too . D Because I think that for a bunch of their experiments they used , uh , mel cepstra , actually .\nYeah . Yeah .\nUm , of course that 's there and this is here and so on . OK ?", "topic_id": 1, "keywords": "cube, ogi, borge, instructive, embedded", "dialogue_id": 0}, {"text": "OK . Um , for the training corpus  corpus , um , we have , um , the  the d  digits {nonvocalsound} from the various languages . Um , English Spanish um , French What else do we have ?\nAnd the  Finnish .\nFinnish .\nWhere did th where did that come from ?\nAnd Italian .\nDigits ?\nUh , no , Italian no . Italian no .\nOh .\nOh . Italian .\nI Italian yes . Italian ?\nItalian .\nIs that  Was that distributed with Aurora , or  ?\nOne L or two L 's ?\nWhere did that  ?\nThe newer one .\nSo English , uh , Finnish and Italian are Aurora .\nYeah .\nAnd Spanish and French is something that we can use in addition to Aurora . Uh , well .\nYeah , so Carmen brought the Spanish , and Stephane brought the French .\nOK . And , um , oh yeah , and\nIs it French French or Belgian French ? There 's a\nIt 's , uh , French French .\nFrench French .\nLike Mexican Spain and Spain .\nYeah .\nOr Swiss .\nI think that is more important ,\nSwiss - German .\nMexican Spain . Because more people\nYeah . Yeah , probably so .\nYeah .\nYeah . Yeah , Herve always insists that Belgian is  i is absolutely pure French , has nothing to do with  but he says those  those  those Parisians talk funny .\nYeah , yeah , yeah . They have an accent .\nYeah they  they do , yeah . Yeah .  But then he likes Belgian fries too , so . OK .\nAnd then we have , uh , um , broader  broader corpus , um , like TIMIT . TIMIT so far ,\nAnd Spanish too .\nright ? Spanish  Oh , Spanish stories ?\nAlbayzin is the name .\nWhat about TI - digits ?\nUm , TI - digits  uh all these Aurora f d data p data is from  is derived from TI - digits .\nUh - huh . Oh . Oh OK .\nUm , basically , they  they corrupted it with , uh , different kinds of noises at different SNR levels .\nAh . I see .\nYeah .\ny And I think Stephane was saying there 's  there 's some broader s material in the French also ?\nYeah , we cou we could use\nOK .\nYeah . The French data .\nSpanish stories ?\nNo .\nNo .\nSp - Not Spanish stories ?\nNo . No . Albayz\nSpanish\nSpanish something .\nYeah .\nOK .\nDid the Aurora people actually corrupt it themselves , or just specify the signal and the signal - t\nThey  they corrupted it , um , themselves ,\nOK .\nbut they also included the  the noise files for us , right ? Or\nYeah .\nso we can go ahead and corrupt other things .\nI 'm just curious , Carmen  I mean , I couldn't tell if you were joking or  i Is it  is it Mexican Spanish ,\nNo no no no .\nor is it\nNo no no no .\nOh , no , no . It 's  it 's Spanish from Spain , Spanish .\nSpanish from Spain .\nYeah , OK .\nFrom Spain .\nAlright . Spanish from Spain . Yeah , we 're really covered there now . OK .\nOK .\nAnd the French from France .\nYeah , the  No , the French is f yeah , from , uh , Paris ,\nOh , from Paris , OK .\nYeah .\nAnd TIMIT 's from  lots of different places .\nOK .\nFrom TI . From  i It 's from Texas . So may maybe it 's\nFrom the deep South .\nSo - s so it 's not really from the US either .\nYeah .\nIs that  ? OK .\nYeah . OK . And , um , with within the training corporas um , we 're , uh , thinking about , um , training with noise . So , incorporating the same kinds of noises that , um , Aurora is in incorporating in their , um  in their training corpus . Um , I don't think we we 're given the , uh  the unseen noise conditions , though , right ?\nI think what they were saying was that , um , for this next test there 's gonna be some of the cases where they have the same type of noise as you were given before hand and some cases where you 're not .\nLike  Mm - hmm . OK .\nMm - hmm .\nSo , presumably , that 'll be part of the topic of analysis of the  the test results , is how well you do when it 's matching noise and how well you do where it 's not .\nRight .\nI think that 's right .\nSo , I guess we can't train on  on the  the unseen noise conditions .\nWell , not if it 's not seen ,\nRight . If  Not if it 's unseen .\nyeah .\nYeah .\nOK . I mean , i i i i it does seem to me that a lot of times when you train with something that 's at least a little bit noisy it can  it can help you out in other kinds of noise even if it 's not matching just because there 's some more variance that you 've built into things . But , but , uh ,\nMm - hmm .\nuh , exactly how well it will work will depend on how near it is to what you had ahead of time . So . OK , so that 's your training corpus ,\nMm - hmm .\nand then your testing corpus  ?\nUm , the testing corporas are , um , just , um , the same ones as Aurora testing . And , that includes , um , the English Spa - um , Italian . Finnish .\nFinnish .\nUh , we ' r we 're gonna get German , right ? Ge -  At the final test will have German .\nWell , so , yeah , the final test , on a guess , is supposed to be German and Danish ,\nUh , yeah .\nright ?\nRight .\nThe s yeah , the Spanish , perhaps ,\nSpanish . Oh yeah , we can  we can test on s Spanish .\nwe will have . Yeah . But the  the Aurora Spanish , I mean .\nOh yeah . Mm - hmm .\nOh , there 's a  there 's Spanish testing in the Aurora ?\nUh , not yet , but , uh , yeah , uh , e\nYeah , it 's preparing .\npre they are preparing it ,\nThey are preparing .\nand , well , according to Hynek it will be  we will have this at the end of November , or  Um .\nOK , so , uh , something like seven things in each , uh  each column .\nYeah\nSo that 's , uh , three hundred and forty - three , uh ,  different systems that are going to be developed . There 's three of you .\nYeah . One hundred each , about .\nUh , so that 's hundred and   hundred and fourteen each .\nWhat a what about noise conditions ?\nWhat ?\nw Don't we need to put in the column for noise conditions ?\nAre you just trying to be difficult ?\nNo , I just don't understand .\nWell , th uh , when  when I put these testings on there , I 'm assumi\nI 'm just kidding . Yeah .\nThere - there 's three  three tests . Um , type - A , type - B , and type - C . And they 're all  they 're all gonna be test tested , um , with one training of the HTK system . Um , there 's a script that tests all three different types of noise conditions . Test - A is like a matched noise . Test - B is a  is a slightly mismatched . And test - C is a , um , mismatched channel .\nAnd do we do all our  training on clean data ?\nUm , no , no ,\nAlso , we can clean that .\nwe 're  we 're gonna be , um , training on the noise files that we do have .\nNo .\nSo , um  Yeah , so I guess the question is how long does it take to do a  a training ? I mean , it 's not totally crazy t I mean , these are  a lot of these are built - in things and we know  we have programs that compute PLP , we have MSG , we have JRA you know , a lot of these things will just kind of happen , won't take uh a huge amount of development , it 's just trying it out . So , we actually can do quite a few experiments .\nMm - hmm .\nBut how  how long does it take , do we think , for one of these   trainings ?\nThat 's a good question .\nWhat about combinations of things ?\nOh yeah , that 's right . I mean , cuz , so , for instance , I think the major advantage of MSG\nOh !\nYeah ,\nOch !\ngood point . A major advantage of MSG , I see , th that we 've seen in the past is combined with PLP .\nYeah .\nUm .\nNow , this is turning into a four - dimensional cube ?\nWell , you just select multiple things on the one dimension .\nOr you just add it to the features .\nNo .\nJust\nHere .\nOh , yeah . OK .\nYeah , so , I mean , you don't wanna , uh  Let 's see , seven choose two would    be , uh , twenty - one different combinations . Um .\nIt 's not a complete set of combinations , though ,\nProbably\nright ? It 's not a complete set of combinations , though ,\nWhat ?\nright ?\nNo .\nYeah , I hope not . Yeah , there 's\nThat would be\nUh , yeah , so PLP and MSG I think we definitely wanna try cuz we 've had a lot of good experience with putting those together .\nMm - hmm .\nUm . Yeah .\nWhen you do that , you 're increasing the size of the inputs to the net . Do you have to reduce the hidden layer , or something ?\nWell , so  I mean , so i it doesn't increase the number of trainings .\nNo , no , I 'm  I 'm just wondering about number of parameters in the net . Do you have to worry about keeping that the same , or  ?\nUh , I don't think so .\nThere 's a computation limit , though , isn't there ?\nYeah , I mean , it 's just more compu Excuse me ?\nIsn't there like a limit  on the computation load , or d latency , or something like that for Aurora task ?\nOh yeah , we haven't talked about any of that at all , have we ?\nNo .\nYeah , so , there 's not really a limit . What it is is that there 's  there 's , uh  it 's just penalty , you know ? That  that if you 're using , uh , a megabyte , then they 'll say that 's very nice , but , of course , it will never go on a cheap cell phone .\nOK .\nUm . And , u uh , I think the computation isn't so much of a problem . I think it 's more the memory . Uh , and , expensive cell phones , exa expensive hand - helds , and so forth , are gonna have lots of memory . So it 's just that , uh , these people see the  the cheap cell phones as being still the biggest market , so .\nMm - hmm .\nUm . But , yeah , I was just realizing that , actually , it doesn't explode out , um  It 's not really two to the seventh . But it 's  but  but  i i it doesn't really explode out the number of trainings cuz these were all trained individually . Right ? So , uh , if you have all of these nets trained some place , then , uh , you can combine their outputs and do the KL transformation and so forth\nMm - hmm .\nand  and , uh  So , what it  it blows out is the number of uh testings . And , you know  and the number of times you do that last part . But that last part , I think , is so  has gotta be pretty quick , so . Uh . Right ? I mean , it 's just running the data through\nOh .\nBut wh what about a net that 's trained on multiple languages , though ?\nWell , you gotta do the KL transformation ,\nEight  y\nbut\nIs that just separate nets for each language then combined , or is that actually one net trained on ?\nNecessary to put in .\nGood question .\nUh , probably one net . Well . Uh .\nOne would think one net ,\nSo .\nbut we 've  I don't think we 've tested that . Right ?\nSo , in the broader training corpus we can  we can use , uh , the three , or , a combination of  of two  two languages .\nDatabase three .\nIn one net . Mm - hmm .", "topic_id": 2, "keywords": "french, languages, language, corpus, spanish", "dialogue_id": 0}, {"text": "Yeah .\nYeah , so , I guess the first thing is if w if we know how much a  how long a  a training takes , if we can train up all these  these combinations , uh , then we can start working on testing of them individually , and in combination . Right ?\nMm - hmm .\nBecause the putting them in combination , I think , is not as much computationally as the r training of the nets in the first place . Right ?\nYeah .\nSo y you do have to compute the KL transformation . Uh , which is a little bit , but it 's not too much .\nIt 's not too much ,\nYeah .\nno .\nSo it 's\nBut  Yeah . But there is the testing also , which implies training , uh , the HTK models\nThe  the model  the HTK model .\nand , well ,\nUh , right .\nit 's\nRight . So if you do have lots of combinations , it 's\nyeah . But it 's  it 's  it 's not so long . It @ @  Yeah .\nHow long does it take for an , uh , HTK training ?\nIt 's around six hours , I think .\nIt depends on the\nFor training and testing , yeah .\nMore than six hours .\nMore .\nFor the Italian , yes . Maybe one day .\nOne day ?\nYeah .\nFor HTK ?\nWell .\nReally ? Running on what ?\nUh , M  MFCC .\nNo , I 'm sorry , ru running on what machine ?\nUh , Ravioli .\nUh , I don't know what Ravioli is . Is it  is it an Ultra - five , or is it a  ?\nmmm Um . Who is that ?\nI don't know .\nI don't know .\nI don't know .\nI don't know what a Ravioli is .\nI don't know .\nI don't know .\nWe can check really quickly , I guess .\nYeah , I I think it 's - it 's - it 's not so long because , well , the TI - digits test data is about , uh how many hours ? Uh , th uh , thirty hours of speech , I think ,\nIt 's a few hours .\nHmm .\nYeah .  Right ,\nsomething like that . And it p Well .\nso , I mean , clearly , there  there 's no way we can even begin to do an any significant amount here unless we use multiple machines .\nIt 's six hours .\nRight ? So  so  w we  I mean there 's plenty of machines here and they 're n they 're often not in  in a great  great deal of use . So , I mean , I think it 's  it 's key that  that the  that you look at , uh , you know , what machines are fast , what machines are used a lot  Uh , are we still using P - make ? Is that  ?\nOh , I don't know how w how we would P - make this , though . Um .\nWell , you have a  I mean , once you get the basic thing set up , you have just all the  uh , a all these combinations ,\nYeah .\nright ?\nMm - hmm .\nUm . It 's  it 's  let 's say it 's six hours or eight hours , or something for the training of HTK . How long is it for training of  of , uh , the neural net ?\nThe neural net ? Um .\nI would say two days .\nDepends on the corpuses , right ?\nIt depends .\nIt s also depends on the net .\nYeah .\nYeah .\nDepends on the corpus .\nHow big is the net ?\nFor Albayzin I trained on neural network , uh , was , um , one day also .\nUh , but on what machine ?\nOn a SPERT board .\nUh . I  I think the neural net SPERT .\nY you did a  you did it on a SPERT board .\nYes .\nOK , again , we do have a bunch of SPERT boards .\nYeah .\nAnd I think there  there  there 's  I think you folks are probably go the ones using them right now .\nIs it faster to do it on the SPERT , or  ?\nUh , don't know .\nIt 's  it 's still a little faster on the\nUsed to be .\nIs it ?\nYeah , yeah . Ad - Adam  Adam did some testing . Or either Adam or  or Dan did some testing and they found that the SPERT board 's still  still faster .\nMm - hmm .\nAnd the benefits is that , you know , you run out of SPERT and then you can do other things on your  your computer ,\nMm - hmm .\nMm - hmm .\nand you don't\nYeah . So you could be  we have quite a few SPERT boards . You could set up , uh , you know , ten different jobs , or something , to run on SPERT  different SPERT boards and  and have ten other jobs running on different computers . So , it 's got to take that sort of thing , or  or we 're not going to get through any significant number of these .\nYeah .\nSo this is  Yeah , I mean , I kind of like this because what it  No\nOK .\nuh , no , what I like about it is we  we  we do have a problem that we have very limited time . You know , so , with very limited time , we actually have really quite a  quite a bit of computational resource available if you , you know , get a look across the institute and how little things are being used . And uh , on the other hand , almost anything that really i you know , is  is new , where we 're saying , \" Well , let 's look at , like we were talking before about , uh , uh , voiced - unvoiced - silence detection features and all those sort  \" that 's\nYeah .\nI think it 's a great thing to go to . But if it 's new , then we have this development and  and  and learning process t to  to go through on top of  just the  the  all the  all the work . So , I  I  I don't see how we 'd do it . So what I like about this is you basically have listed all the things that we already know how to do .\nYeah .\nAnd  and all the kinds of data that we , at this point , already have . And , uh , you 're just saying let 's look at the outer product of all of these things and see if we can calculate them . a a Am I  am I interpreting this correctly ? Is this sort of what  what you 're thinking of doing in the short term ?\nMmm .\nOK .\nYeah .\nSo  so then I think it 's just the  the missing piece is that you need to , uh , you know  you know , talk to  talk to , uh , Chuck , talk to , uh , Adam , uh , sort out about , uh , what 's the best way to really , you know , attack this as a  as a  as a mass problem in terms of using many machines . Uh , and uh , then , you know , set it up in terms of scripts and so forth , and  uh , in  in kind o some kind of structured way . Uh . Um , and , you know , when we go to , uh , OGI next week , uh , we can then present to them , you know , what it is that we 're doing . And , uh , we can pull things out of this list that we think they are doing sufficiently ,\nMmm . Mm - hmm .\nthat , you know , we 're not  we won't be contributing that much . Um . And , uh  Then , uh , like , we 're there .\nHow big are the nets you 're using ?\nUm , for the  for nets trained on digits ,  um , we have been using , uh , four hundred order hidden units . And , um , for the broader class nets we 're  we 're going to increase that because the , um , the digits nets only correspond to about twenty phonemes .\nUh - huh .\nSo .\nBroader class ?\nUm , the broader  broader training corpus nets like TIMIT . Um , w we 're gonna\nOh , it 's not actually broader class , it 's actually finer class , but you mean  y You mean  more classes .\nRight . Right . Yeah . More classes . Right , right . More classes .\nYeah .\nThat 's what I mean .\nYeah . Yeah .\nMm - hmm . And . Yeah .", "topic_id": 3, "keywords": "htk, computational, computationally, training, hours", "dialogue_id": 0}, {"text": "Carmen , did you  do you have something else to add ? We  you haven't talked too much , and\nD I begin to work with the Italian database to  nnn , to  with the f front - end and with the HTK program and the @ @ . And I trained eh , with the Spanish two neural network with PLP and with LogRASTA PLP . I don't know exactly what is better if  if LogRASTA or JRASTA .\nWell , um , JRASTA has the potential to do better , but it doesn't always . It 's  i i JRASTA is more complicated . It 's  it 's , uh  instead of doing RASTA with a log , you 're doing RASTA with a log - like function that varies depending on a J parameter , uh , which is supposed to be sensitive to the amount of noise there is . So , it 's sort of like the right transformation to do the filtering in , is dependent on how much noise there is .\nHm - hmm .\nAnd so in JRASTA you attempt to do that . It 's a little complicated because once you do that , you end up in some funny domain and you end up having to do a transformation afterwards , which requires some tables . And , uh ,\nHm - hmm .\nso it 's  it 's  it 's a little messier , uh , there 's more ways that it can go wrong , uh , but if  if  if you 're careful with it , it can do better .\nIt 's a bit  I 'll do better .\nSo , it 's  So .\nUm , and I think to  to  to recognize the Italian digits with the neural netw Spanish neural network , and also to train another neural network with the Spanish digits , the database of Spanish digits . And I working that .\nYeah .\nBut prepa to prepare the  the database are difficult . Was for me , n it was a difficult work last week with the labels because the  the program with the label obtained that I have , the Albayzin , is different w to the label to train the neural network . And   that is another work that we must to do , to  to change .\nI  I didn't understand .\nUh , for example Albayzin database was labeled automatically with HTK . It 's not hand  it 's not labels by hand .\nOh , \" l labeled \" .\nLabels .\nI 'm sorry ,\nI 'm sorry ,\nI have a p I had a problem with  the pronunciation .\nI 'm sorry . The labels . I 'm sorry . The labels .\nYeah , OK .\nOh , also that\nSo , OK , so let 's start over .\nYes .\nSo , TI TIMI TIMIT 's hand - labeled , and  and you 're saying about the Spanish ?\nThe Spanish labels ? That was in different format , that the format for the em  the program to train the neural network .\nOh , I see .\nI necessary to convert . And someti well\nSo you 're just having a problem converting the labels .\nIt 's  it 's  Yeah . Yeah , but n yes , because they have one program , Feacalc , but no , l LabeCut , l LabeCut , but don't  doesn't , eh , include the HTK format to convert .\nMm - hmm .\nHmm .\nAnd , I don't know what . I ask  e even I ask to Dan Ellis what I can do that , and h they  he say me that h he does doesn't any  any s any form to  to do that . And at the end , I think that with LabeCut I can transfer to ASCII format , and HTK is an ASCII format . And I m do another , uh , one program to put ASCII format of HTK to ase ay ac ASCII format to Exceed\nMm - hmm .\nand they used LabCut to   to pass .\nOK , yeah .\nActually that was complicated ,\nSo you\nbut well , I know how we can did that  do that .\nSure . So it 's just usual kind of uh  sometimes say housekeeping , right ? To get these  get these things sorted out .\nYeah .\nSo it seems like there 's  there 's some peculiarities of the , uh  of each of these dimensions that are getting sorted out . And then , um , if  if you work on getting the , uh , assembly lines together , and then the  the pieces sort of get ready to go into the assembly line and gradually can start , you know , start turning the crank , more or less . And , uh , uh , we have a lot more computational capability here than they do at OGI , so I think that i if  What 's  what 's great about this is it sets it up in a very systematic way , so that , uh , once these  all of these , you know , mundane but real problems get sorted out , we can just start turning the crank\nMm - hmm .\nand  and push all of us through , and then finally figure out what 's best .\nYeah . Um , I  I was thinking two things . Uh , the first thing was , um  we  we actually had thought of this as sort of like , um  not  not in stages ,  but more along the  the time axis . Just kind of like one stream at a time ,\nMm - hmm .\nje - je - je - je - je  check out the results and  and go that way .\nOh , yeah , yeah , sure . No , I 'm just saying , I 'm just thinking of it like loops ,\nUh - huh .\nright ? And so , y y y if you had three nested loops , that you have a choice for this , a choice for this , and a choice for that ,\nYeah . Mm - hmm .\nright ? And you 're going through them all . That  that 's what I meant .\nRight , right .\nAnd , uh , the thing is that once you get a better handle on how much you can realistically do , uh , um ,  concurrently on different machines , different SPERTs , and so forth , uh , and you see how long it takes on what machine and so forth , you can stand back from it and say , \" OK , if we look at all these combinations we 're talking about , and combinations of combinations , and so forth , \" you 'll probably find you can't do it all .\nMm - hmm . OK .\nOK , so then at that point , uh , we should sort out which ones do we throw away .\nMm - hmm .\nWhich of the combinations across  you know , what are the most likely ones , and  And , uh , I still think we could do a lot of them . I mean , it wouldn't surprise me if we could do a hundred of them or something . But , probably when you include all the combinations , you 're actually talking about a thousand of them or something , and that 's probably more than we can do . Uh , but a hundred is a lot . And  and , uh , um\nOK .\nYeah .\nYeah , and the  the second thing was about scratch space . And I think you sent an email about , um , e scratch space for  for people to work on . And I know that , uh , Stephane 's working from an NT machine , so his  his home directory exists somewhere else .\nHis  his stuff is somewhere else , yeah . Yeah , I mean , my point I  I want to  Yeah , thanks for bring it back to that . My  th I want to clarify my point about that  that  that Chuck repeated in his note . Um . We 're  over the next year or two , we 're gonna be upgrading the networks in this place ,\nMm - hmm .\nbut right now they 're still all te pretty much all ten megabit lines . And we have reached the  this  the machines are getting faster and faster . So , it actually has reached the point where it 's a significant drag on the time for something to move the data from one place to another .\nMm - hmm .\nSo , you  you don't w especially in something with repetitive computation where you 're going over it multiple times , you do  don't want to have the  the data that you 're working on distant from where it 's being  where the computation 's being done if you can help it .\nMm - hmm .\nUh . Now , we are getting more disk for the central file server , which , since it 's not a computational server , would seem to be a contradiction to what I just said . But the idea is that , uh , suppose you 're working with , uh , this big bunch of multi multilingual databases . Um , you put them all in the central ser at the cen central file server .\nMm - hmm .\nThen , when you 're working with something and accessing it many times , you copy the piece of it that you 're working with over to some place that 's close to where the computation is and then do all the work there . And then that way you  you won't have the  the network  you won't be clogging the network for yourself and others .\nMmm .\nThat 's the idea . So , uh , it 's gonna take us  It may be too late for this , uh , p precise crunch we 're in now , but , uh , we 're , uh  It 's gonna take us a couple weeks at least to get the , uh , uh , the amount of disk we 're gonna be getting . We 're actually gonna get , uh , I think four more , uh , thirty - six gigabyte drives and , uh , put them on another  another disk rack . We ran out of space on the disk rack that we had , so we 're getting another disk rack and  four more drives to share between , uh  primarily between this project and the Meetings  Meetings Project . Um . But , uh , we 've put another  I guess there 's another eighteen gigabytes that 's  that 's in there now to help us with the immediate crunch . But , uh , are you saying  So I don't know where  you 're  Stephane , where you 're doing your computations . If  i so , you 're on an NT machine , so you 're using some external machine\nYeah , it , uh  Well , to  It 's Nutmeg and Mustard , I think ,\nDo you know these yet ?\nI don't know what kind .\nNuh - uh .\nYeah , OK . Uh , are these  are these , uh , computational servers , or something ? I 'm  I 've been kind of out of it .\nYeah , I think , yeah . I think so .\nUnfortunately , these days my idea of running comput of computa doing computation is running a spread sheet .\nMmm .\nSo .\nMmm .\nUh , haven't been  haven't been doing much computing personally , so . Um . Yeah , so those are computational servers . So I guess the other question is what disk there i space there is there on the computational servers .\nRight . Yeah , I 'm not sure what 's available on  is it  you said Nutmeg and what was the other one ?\nMustard .\nMustard . OK .\nHuh .\nYeah , Well , you 're the  you 're the disk czar now .\nRight , right .\nSo\nWell , I 'll check on that .\nYeah . Yeah , so basically , uh , Chuck will be the one who will be sorting out what disk needs to be where , and so on , and I 'll be the one who says , \" OK , spend the money . \" So .  Which , I mean , n these days , uh , if you 're talking about scratch space , it doesn't increase the , uh , need for backup , and , uh , I think it 's not that big a d and the  the disks themselves are not that expensive . Right now it 's\nWhat you can do , when you 're on that machine , is , uh , just go to the slash - scratch directory , and do a DF minus K , and it 'll tell you if there 's space available .\nYeah .\nUh , and if there is then , uh\nBut wasn't it , uh  I think Dave was saying that he preferred that people didn't put stuff in slash - scratch . It 's more putting in d s XA or XB or ,\nWell , there 's different  there , um , there 's\nright ?\nRight . So there 's the slash - X - whatever disks , and then there 's slash - scratch . And both of those two kinds are not backed up . And if it 's called \" slash - scratch \" , it means it 's probably an internal disk to the machine . Um . And so that 's the kind of thing where , like if  um , OK , if you don't have an NT , but you have a  a  a Unix workstation , and they attach an external disk ,  it 'll be called \" slash - X - something \" uh , if it 's not backed up and it 'll be \" slash - D - something \" if it is backed up . And if it 's inside the machine on the desk , it 's called \" slash - scratch \" . But the problem is , if you ever get a new machine , they take your machine away . It 's easy to unhook the external disks , put them back on the new machine , but then your slash - scratch is gone . So , you don't wanna put anything in slash - scratch that you wanna keep around for a long period of time . But if it 's a copy of , say , some data that 's on a server , you can put it on slash - scratch because , um , first of all it 's not backed up , and second it doesn't matter if that machine disappears and you get a new machine because you just recopy it to slash - scratch . So tha that 's why I was saying you could check slash - scratch on those  on  on , um , Mustard and  and Nutmeg to see if  if there 's space that you could use there .\nI see .\nYou could also use slash - X - whatever disks on Mustard and Nutmeg .\nYeah , yeah .\nUm . Yeah , and we do have  I mean , yeah , so  so you  yeah , it 's better to have things local if you 're gonna run over them lots of times so you don't have to go to the network .\nRight , so es so especially if you 're  right , if you 're  if you 're taking some piece of the training corpus , which usually resides in where Chuck is putting it all on the  on the , uh , file server , uh , then , yeah , it 's fine if it 's not backed up because if it g g gets wiped out or something , y I mean it is backed up on the other disk . So ,\nMm - hmm .\nyeah , OK .\nYeah , so ,  one of the things that I need to  I 've started looking at  Uh , is this the appropriate time to talk about the disk space stuff ?\nSure .\nI 've started looking at , um , disk space . Dan  David , um , put a new , um , drive onto Abbott , that 's an X disk , which means it 's not backed up . So , um , I 've been going through and copying data that is , you know , some kind of corpus stuff usually , that  that we 've got on a CD - ROM or something , onto that new disk to free up space  on other disks . And , um , so far , um , I 've copied a couple of Carmen 's , um , databases over there . We haven't deleted them off of the slash - DC disk that they 're on right now in Abbott , um , uh , but we  I would like to go through  sit down with you about some of these other ones and see if we can move them onto , um , this new disk also . There 's  there 's a lot more space there ,\nYeah , OK .\nand it 'll free up more space for doing the experiments and things . So , anything that  that you don't need backed up , we can put on this new disk . Um , but if it 's experiments and you 're creating files and things that you 're gonna need , you probably wanna have those on a disk that 's backed up , just in case something  goes wrong . So . Um So far I 've  I 've copied a couple of things , but I haven't deleted anything off of the old disk to make room yet . Um , and I haven't looked at the  any of the Aurora stuff , except for the Spanish . So I  I guess I 'll need to get together with you and see what data we can move onto the new disk .\nYeah , OK .\nUm , yeah , I  I just  an another question occurred to me is  is what were you folks planning to do about normalization ?\nUm . Well , we were thinking about using this systematically for all the experiments . Um .\nThis being  ?\nSo , but  Uh . So that this could be another dimension , but we think perhaps we can use the  the best , uh , um , uh , normalization scheme as OGI is using , so , with parameters that they use there ,\nYeah , I think that 's a good idea .\nu  u\nI mean it 's i i we  we seem to have enough dimensions as it is . So probably if we  sort of take their\nYeah , yeah , yeah .\nprobably the on - line  line normalization because then it   it 's  if we do anything else , we 're gonna end up having to do on - line normalization too , so we may as well just do on - line normalization .\nMm - hmm .\nSo . Um . So that it 's plausible for the final thing . Good . Um . So , I guess , yeah , th the other topic  I  maybe we 're already there , or almost there , is goals for the  for next week 's meeting . Uh . i i i it seems to me that we wanna do is flush out what you put on the board here . Uh . You know , maybe , have it be somewhat visual , a little bit .\nOK . Like a s like a slide ?\nUh , so w we can say what we 're doing ,\nOK .\nyeah . And , um , also , if you have  sorted out , um , this information about how long i roughly how long it takes to do on what and , you know , what we can  how many of these trainings , uh , uh , and testings and so forth that we can realistically do , uh , then one of the big goals of going there next week would be to  to actually settle on which of them we 're gonna do . And , uh , when we come back we can charge in and do it . Um . Anything else that  I a a Actually  started out this  this field trip started off with  with , uh , Stephane talking to Hynek , so you may have  you may have had other goals , uh , for going up , and any anything else you can think of would be  we should think about  accomplishing ? I mean , I 'm just saying this because  maybe there 's things we need to do in preparation .\nOh , I think basically , this is  this is , uh , yeah .\nOK . OK . Uh . Alright . And uh  and the other  the  the last topic I had here was , um , uh d Dave 's fine offer to  to , uh , do something   on this . I mean he 's doing    he 's working on other things , but to  to do something on this project . So the question is , \" Where  where could we , uh , uh , most use Dave 's help ? \"\nUm , yeah , I was thinking perhaps if , um , additionally to all these experiments , which is not really research , well I mean it 's , uh , running programs\nYeah .\nand , um ,  trying to have a closer look at the  perhaps the , um ,  speech , uh , noise detection or , uh , voiced - sound - unvoiced - sound detection and  Which could be important in  i for noise  noise\nI think that would be a  I think that 's a big  big deal . Because the  you know , the thing that Sunil was talking about , uh , with the labels , uh , labeling the database when it got to the noisy stuff ? The  That  that really throws things off . You know , having the noise all of a sudden , your  your , um , speech detector , I mean the  the , um  What was it ? What was happening with his thing ?\nHe was running through these models very quickly . He was getting lots of , uh , uh insertions , is what it was , in his recognitions .\nThe only problem  I mean , maybe that 's the right thing  the only problem I have with it is exactly the same reason why you thought it 'd be a good thing to do . Um , I  I think that  Let 's fall back to that . But I think the first responsibility is sort of to figure out if there 's something  that , uh , an  an additional  Uh , that 's a good thing you  remove the mike . Go ahead , good . Uh , uh . What an additional clever person could help with when we 're really in a crunch for time . Right ? Cuz Dave 's gonna be around for a long time ,\nYeah .\nright ? He 's  he 's gonna be here for years . And so , um ,\nYeah .\nover years , if he 's  if he 's interested in , you know , voiced - unvoiced - silence , he could do a lot . But if there  if in fact there 's something else  that he could be doing , that would help us when we 're  we 're sort of uh strapped for time  We have  we  we 've , you know , only ,  uh , another  another month or two  to  you know , with the holidays in the middle of it , um , to  to get a lot done . If we can think of something  some piece of this that 's going to be  The very fact that it is sort of just work , and i and it 's running programs and so forth , is exactly why  it 's possible that it  some piece of could be handed to someone to do , because it 's not  Uh , yeah , so that  that 's the question . And we don't have to solve it right this s second , but if we could think of some  some piece that 's  that 's well defined , that he could help with , he 's expressing a will willingness to do that .\nWhat about training up a , um , a multilingual net ?\nUh .\nYes , maybe to , mmm , put together the  the label  the labels between TIMIT and Spanish or something like that .\nYeah . Yeah , so defining the superset ,\nYes .\nand , uh , joining the data and  Mmm .\nYeah .\nYeah .\nUh . Yeah , that 's something that needs to be done in any event .\nYeah .\nSo what we were just saying is that  that , um  I was arguing for ,  if possible , coming up with something that  that really was development and wasn't research because we  we 're  we have a time crunch . And so , uh , if there 's something that would  would save some time that someone else could do on some other piece , then we should think of that first . See the thing with voiced - unvoiced - silence is I really think that  that it 's  to do  to do a  a  a  a poor job is  is pretty quick , uh , or , you know , a so - so job . You can  you can  you can throw in a couple fea we know what  what kinds of features help with it .\nHmm .\nYou can throw something in . You can do pretty well . But I remember , in fact , when you were working on that , and you worked on for few months , as I recall , and you got to , say ninety - three percent , and getting to ninety - four   really really hard .\nMm - hmm . Another year .\nYeah , yeah . So , um  And th th the other tricky thing is , since we are , uh , even though we 're not  we don't have a strict prohibition on memory size , and  and computational complexity , uh , clearly there 's some limitation to it . So if we have to  if we say we have to have a pitch detector , say , if we  if we 're trying to incorporate pitch information , or at least some kind of harmonic  harmonicity , or something , this is another whole thing , take a while to develop . Anyway , it 's a very very interesting topic . I mean , one  I think one of the  a lot of people would say , and I think Dan would also , uh , that one of the things wrong with current speech recognition is that we  we really do throw away all the harmonicity information . Uh , we try to get spectral envelopes . Reason for doing that is that most of the information about the phonetic identity is in the spectral envelopes are not in the harmonic detail . But the harmonic detail does tell you something . Like the fact that there is harmonic detail is  is real important . So . Um . So , uh . So I think  Yeah . So  wh that  so the  the other suggestion that just came up was , well what about having him  work on the , uh ,  multilingual super f superset  kind of thing . Uh , coming up with that and then , you know , training it  training a net on that , say , um , from  from , uh  from TIMIT or something . Is that  or uh , for multiple databases . What  what would you  what would you think it would  wh what would this task consist of ?\nYeah , it would consist in , uh , well , um , creating the  the superset , and , uh , modifying the lab labels for matching the superset . Uh .\nUh , creating a superset from looking at the multiple languages ,\nWell , creating the mappings , actually .\nand then creating i m changing labels on TIMIT ?\nYeah .\nOr on  or on multiple language   multiple languages ?\nNo . The multiple language .\nYeah , yeah , with the @ @ three languages ,\nMaybe for the other language because TIMIT have more phone .\nYeah .\nSo you 'd have to create a mapping from each language to the superset .\nUh .\nYeah . Mm - hmm .\nFrom each language to the superset ,\nYeah .\nyeah .\nThere 's , um  Carmen was talking about this SAMPA thing , and it 's , um ,  it 's an effort by linguists to come up with , um , a machine readable IPA , um , sort of thing , right ? And , um , they  they have a web site that Stephane was showing us that has , um  has all the English phonemes and their SAMPA correspondent , um , phoneme ,\nYeah .\nand then , um , they have Spanish , they have German , they have all  all sorts of languages , um , mapping  mapping to the SAMPA phonemes , which\nYeah , the tr the transcription , though , for Albayzin is n the transcription are of SAMPA the same , uh , how you say , symbol that SAMPA appear .\nSAMPA ? What does \" SAMPA \" mean ?\nMm - hmm . Hmm .\nBut I don't know if TIMIT o how is TIMIT .\nSo , I mean\nWhat\nI 'm sorry .\nGo ahead .\nI was gonna say , does that mean IPA is not really international ?\nNo , it 's  it 's saying\nIt uses special diacritics and stuff , which you can't do with ASCII characters .\ny can't print on ASCII .\nYeah .\nSo the SAMPA 's just mapping those .\nOh , I see . Got it .\nWhat , uh  Has OGI done anything about this issue ? Do they have  Do they have any kind of superset that they already have ?\nI don't think so . Well , they  they  they 're going actually the  the other way , defining uh , phoneme clusters , apparently . Well .\nAha . That 's right . Uh , and that 's an interesting  way to go too .\nSo they just throw the speech from all different languages together , then cluster it into sixty or fifty or whatever clusters ?\nI think they 've not done it , uh , doing , uh , multiple language yet , but what they did is to training , uh , English nets with all the phonemes , and then training it in English nets with , uh , kind of seventeen , I think it was  seventeen , uh , broad classes .\nAutomatically derived  Mm - hmm . Automatically derived broad classes , or  ?\nYeah . Yeah , I think so .\nUh - huh .\nUh , and , yeah . And the result was that apparently , when testing on cross - language it was better . I think so . But Hynek didn't add  didn't have all the results when he showed me that , so , well .\nSo that does make an interesting question , though .\nBut\nIs there 's some way that we should tie into that with this . Um . Right ? I mean , if  if in fact that is a better thing to do ,  should we leverage that , rather than doing ,  um , our own . Right ? So , if i if  if they s I mean , we have   i we have the  the trainings with our own categories . And now we 're saying , \" Well , how do we handle cross - language ? \" And one way is to come up with a superset , but they are als they 're trying coming up with clustered , and do we think there 's something wrong with that ?\nI think that there 's something wrong\nOK . What w\nor  Well , because  Well , for the moment we are testing on digits , and e i perhaps u using broad phoneme classes , it 's  it 's OK for um , uh classifying the digits , but as soon as you will have more words , well , words can differ with only a single phoneme , and  which could be the same , uh , class .\nI see .\nWell . So .\nRight . Although , you are not using this for the\nSo , I 'm\nYou 're using this for the feature generation , though , not the\nYeah , but you will ask the net to put one for th th the phoneme class\nYeah .\nand  So .\nSo you 're saying that there may not be enough information coming out of the net to help you discriminate the words ?\nYeah .\nWell . Yeah , yeah . Mmm .\nFact , most confusions are within the phone  phone classes , right ? I think , uh , Larry was saying like obstruents are only confused with other obstruents , et cetera , et cetera .\nYeah .\nHmm .\nYeah . Yeah .\nYeah , this is another p yeah , another point .\nYeah .\nSo  so , maybe we could look at articulatory type stuff ,\nBut that 's what I thought they were gonna\nright ?\nDid they not do that , or  ?\nI don't think so . Well ,\nSo\nthey were talking about , perhaps , but they d\nThey 're talking about it ,\nI d\nbut that 's sort of a question whether they did\nw Yeah .\nbecause that 's  that 's the other route to go .\nMm - hmm .\nInstead of this , you know\nSuperclass .\nInstead of the  the  the  the superclass thing , which is to take  So suppose y you don't really mark arti To really mark articulatory features , you really wanna look at the acoustics and  and see where everything is , and we 're not gonna do that . So , uh , the second class way of doing it is  to look at the , uh , phones that are labeled and translate them into acoustic  uh , uh  articulatory , uh , uh , features . So it won't really be right . You won't really have these overlapping  things and so forth ,\nSo the targets of the net  are these  ?\nbut\nArticulatory features .\nArticulatory feature .\nBut that implies that you can have more than one on at a time ?\nRight . That 's right .\nAh . OK .\nYou either do that or you have multiple nets .\nI see .\nUm . And , um I don't know if our software  this  if the qu versions of the Quicknet that we 're using allows for that . Do you know ?\nAllows for  ?\nMultiple targets being one ?\nOh , um , we have gotten soft targets to  to work .\nOK . So that  that 'll work , yeah .\nYeah .\nOK . So , um , that 's another thing that could be done\nUm .\nis that we could  we could , uh , just translate  instead of translating to a superset ,  just translate to articulatory features , some set of articulatory features and train with that . Now the fact  even though it 's a smaller number ,  it 's still fine because you have the  the , uh , combinations . So , in fact , it has every , you know  it had  has  has every distinction in it that you would have the other way .\nYeah .\nBut it should go across languages better .\nWe could do an interesting cheating experiment with that too . We could  I don't know , if you had uh the phone labels , you could replace them by their articulatory features and then feed in a vector with those uh , things turned on based on what they 're supposed to be for each phone to see if it  if you get a big win . Do you know what I 'm saying ?\nNo .\nSo , um , I mean , if your net is gonna be outputting , uh , a vector of  basically of  well , it 's gonna have probabilities , but let 's say that they were ones and zeros , then y and you know for each , um , I don't know if you know this for your testing data , but if you know for your test data , you know , what the string of phones is and  and you have them aligned , then you can just  instead of going through the net , just create the vector for each phone and feed that in to see if that data helps . Eh , eh , what made me think about this is , I was talking with Hynek and he said that there was a guy at A T - andT who spent eighteen months working on a single feature . And because they had done some cheating experiments\nThis was the guy that we were just talking a that we saw on campus . So , this was Larry Saul who did this  did this .\nOh , OK .\nHe used sonorants .\nRight , OK ,\nWas what he was doing .\nright . And they  they had done a cheating experiment or something , right ?\nYeah .\nand determined that\nHe  he di he didn't mention that part .\nWell , Hynek said that  that , I guess before they had him work on this , they had done some experiment where if they could get that one feature right , it dramatically improved the result .\nBut . I see . OK .\nSo I was thinking , you know  it made me think about this , that if  it 'd be an interesting experiment just to see , you know , if you did get all of those right .\nShould be . Because if you get all of them in there , that defines all of the phones . So that 's  that 's equivalent to saying that you 've got   got all the phones right .\nRight .\nSo , if that doesn't help , there 's\nYeah .\nAlthough , yeah , it would be  make an interesting cheating experiment because we are using it in this funny way ,\nYeah .\nwhere we 're converting it into features .\nAnd then you also don't know what error they 've got on the HTK side . You know ? It sort of gives you your  the best you could hope for , kind of .\nYeah .\nMmm . Mmm , I see .\nThe soft training of the nets still requires the vector to sum to one , though , right ?\nTo sum up to one .\nSo you can't really feed it , like , two articulatory features that are on at the same time with ones cuz it 'll kind of normalize them down to one half or something like that , for instance .\nBut perhaps you have the choice of the  final nonl\nRight . Nonlinearity ?\nuh , nonlinearity ,\nUm ,\nyeah . Is it always softmax\nit 's sig No , it 's actually sigmoid - X\nor  ? Yeah .\nfor the\nSo if you choose sigmoid it 's o it 's OK ?\nYou , um\nDid we just run out of disk ,\nI think  I think apparently , the , uh\nor  ?\nWhy don't you just choose linear ? Right ?\nWhat 's that ?\nLinear outputs ?\nLinear outputs ?\nIsn't that what you 'll want ?\nUm .\nIf you 're gonna do a KL Transform on it .\nRight , right . Right , but during the training , we would train on sigmoid - X\nOh , you  Yeah ?\nand then at the end just chop off the final nonlinearity .\nHmm .\nSo , we 're  we 're  we 're off the air , or  ? About to be off the air .", "topic_id": 4, "keywords": "lograsta, rasta, jrasta, softmax, log", "dialogue_id": 0}, {"text": "What channel am I on ?\nChannel .\nOh , channel two .\nMake sure to turn your microphone on .\nChannel .\nThere 's a battery .\nThere we go .\nOK . Your channel number 's already on this blank sheet .\nYeah .\nSo you just  If you can\nChannel five ? Channel five .\nChannel whatever .\nI 'm on channel five .\nCamera one , camera two .\nWhat am I ?\nLittle low ?\nChannel four ?\nChannel five .\nThis number four ? OK .\nChannel five . OK .\nThe gai the gain 's up at it  what it usually is ,\nIs it ?\nbut if you think it 's  Yeah . It 's sort of a default . But I can set it higher if you like .\nOh . Maybe it should be a little higher .\nYeah ?\nIt 's not showing much . Test , test , test , test , test , test , test , test , test , test . OK , that  that seems better ? Yeah ? OK , good . Ah , that 's good , that 's good . That 's Ahh . Mmm . So I  I had a question for Adam . Have we started already ?\nWell , we started recording , but  Yeah .\nYeah . Is Jane around or  ?\nI saw her earlier .\nUh .\nI think\nShe can just walk in , I guess , or\nYeah . She 'll probably come up .\nRight .\nSince we 're starting late I figured we 'd better just start .\nYeah . Great idea . I was gonna ask Adam to , uh , say if he thought anymore about the demo stuff because  it occurred to me that this is late May and the DARPA meeting is in  mid July . Uh , but  I don't remember w what we  I know that we were gonna do something with the transcriber interface is one thing , but I thought there was a second thing . Anybody remember ?\nWell , we were gonna do a mock - up , like , question answering or something , I thought , that was totally separate from the interface . Do you remember ? Remember , like , asking questions and retrieving ,  but in a pre - stored fashion .\nMm - hmm . Right .\nThat was the thing we talked about , I think , before the transcriber\nYeah .\nCome on in .\nAlright . So anyway , you have to sort out that out and get somebody going on it cuz we 're  got a  got a month left basically . So .\nYou like these . Right ? OK , good .\nOK . Um OK . So , what are we g else we got ? You got  you just wrote a bunch of stuff .\nNo . That was all , um , previously here .\nOh .\nI was writing  the digits and then I realized I could xerox them ,\nOh , oh .\nbecause I didn't want people to turn their heads from these microphones . So . We all , by the way , have the same digit form , for the record . So .\nThat 's cool .\nYeah .\nSo , the choice is , uh , which  which do we want more , the  the  the comparison , uh ,  of everybody saying them at the same time or the comparison of people saying the same digits at different times that  ?\nIt 's just cuz I didn't have any more digit sheets .\nI know that . But , you know , which opportunity should we\nSo . Yeah .\nUnison .\nexploit ?  Unison .\nI mean , it  Actually it might be good to have them separately and have the same exact strings . I mean , we could use them for normalizing or something , but it of course goes more quickly doing them in unison .\nI guess we 'll see\nI don't know .\ni I guess it 's dependent on\nSee how long we go .\nhow long we go and how good the snack is out there .\nBut anyway , they won't be identical as somebody is saying zero in some  sometimes , you know , saying O , and so , it 's not i not identical .\nYeah . Hmm . Get some advance intelligence .\nRight . Right .\nYeah . We 'd have to train .\nWe 'd be like a chorus .\nOK .\nYeah . We 'd have to get s get some experience .\nGreek chorus .\nYeah .\nYes .\nYeah . Really  boring chorus . Um . Do we  have an agenda ? Adam usually tries to put those together , but he 's ill .\nI 've got a couple of things to talk about .\nSo . Yeah . Uh ju what  what might those be ?\nUh , IBM stuff and , um , just getting  uh , meeting information organized .\nMeeting info organized . OK . Um .\nAre you implying that it 's currently disorganized ?\nIn my mind .\nIs there stuff that 's happened about , um , uh , the  SRI recognizer et cetera , tho those things that were happening before with  ?\nWell .\nY y you guys were doing a bunch of experiments with different front - ends and then with  Is  is that still sort of where it was , uh , the other day ?\nWe 're improving .\nWe 're improving .\nYeah .\nNow the  the  You saw the note that the PLP now is getting basically the same as the MFCC .\nRight .\nRight ?\nYeah . Actually it looks like it 's getting better .\nRight . Oh .\nSo . But  but it 's not\nJust with  with age , kind of .\nWith age . Yeah .\nYeah . Yeah .\nBut , uh , that 's not d directly related to me . Doesn't mean we can't talk about it . Um , it seems  It looks l I haven't  The  It 's  The experiment is still not complete , but , um , it looks like the vocal tract length normalization is working beautifully , actually , w using the warp factors that we computed for the SRI system and just applying them to the  ICSI front - end .\nMm - hmm . That 's pretty funny .", "topic_id": 0, "keywords": "channel, recording, microphone, record, camera", "dialogue_id": 1}, {"text": "Yeah .\nOK .\nSo you just need to  copy over to this one .\nJust had to take the reciprocal of the number because they have different meanings in the two systems .\nOK .\nAh ! Yeah . Well , that 's always good to do .\nYeah .\nOK . OK . Uh\nBut one issue actually that just came up in discussion with Liz and  and Don was , um , as far as meeting recognition is concerned , um , we would really like to , uh , move , uh , to , uh , doing the recognition on automatic segmentations .\nYeah .\nBecause in all our previous experiments , we had the  uh , you know , we were essentially cheating by having the , um , you know , the h the hand - segmentations as the basis of the recognition .\nMm - hmm .\nAnd so now with Thilo 's segmenter working so well , I think we should  consider doing a\nMmm . So .\nCome on .\nuh , doing\nYeah . We  But\nY think  you think we should increase the error rate .\nAnyway . Yeah .\nYeah .\nYeah .\nGood .\nYeah .\nYeah .\nThat - that 's what I wanted to do anyway ,\nYeah .\nso we should just get together and\nYeah .\nYeah .\nAnd even  The good thing is that since you , um , have high recall ,  even if you have low precision cuz you 're over - generating , that 's good because we could train noise models in the recognizer for these kinds of , uh , transients and things that come from the microphones ,\nRight .\nYeah . Yeah .\nbut  I know that if we run recognition unconstrained on a whole waveform , we do very poorly because we 're  we 're getting insertions in places what  that you may well be cutting out .\nWell\nYeah .\nMm - hmm .\nSo we do need some kind of pre - segmentation .\nWe should  we should consider doing some extra things , like , um , you know , retraining or adapting the   the models for background noise to the  to this environment , for instance .\nMmm . Yeah .\nYeah .\nAnd , yeah , using Thilo 's , you know , posteriors or some kind of  or\nSo .\nright now they 're  they 're discrete ,\nYeah .\nyes or no for a speaker , to consider those particular speaker background models .\nRight .\nSo . There 's lots of ins interesting things that could be done .\nYeah . Yeah . We should do that .\nSo .\nGood . So , uh , why don't we , uh , do the IBM stuff ?\nYeah . So , um , talked with Brian and gave him the alternatives to the single beep at the end of each utterance that we had generated before .\nYou had some  thing about that ? Right .\nAnd so\nThe , uh , Chuck chunks .\nYeah . The Chuck chunks .\nHmm .\nRight . And so he talked it over with the transcriber and the transcriber thought that the easiest thing for them would be if there was a beep and then the nu a number , a digit , and then a beep , uh , at the beginning of each one\nYeah . Yeah .\nand that would help keep them from getting lost . And , um ,  so Adam wrote a little script to generate those style , uh , beeps\nWhere 'd you get the digits from ?", "topic_id": 1, "keywords": "meeting, segmenter, recognizer, segmentations, recognition", "dialogue_id": 1}, {"text": "and so we 're  I came up here and just recorded the numbers one through ten .\nThey sound really good .\nSo . Does it sound OK ?\nThat 's a great idea .\nYeah .\nSo , um  Yeah . We just used those .\nAnd do you splice them into the  waveform ? Or  ?\nYeah . He  then he d I recorded  Actually , I recorded one through ten three times at three different speeds and then he picked .\nRight . Mm - hmm .\nHe liked the fastest one , so he just cut those out  and spliced them in between , uh , two beeps .\nIt sounds like a radio announcer 's voice . Really .\nIt will be funny uh\nYeah , yeah .\nDoes it ?\nIt will be funny when you 're really reading digits , and then there are the chunks with  with your  digits in ?\nYeah . With my\nOh that 's right .\nOh , right .\nYeah .\nNow actually ,\nThat 'll throw them ,\nwe 're  Are we handling  ?\nhuh ?\nUh , maybe we should have you record A , B , C for those or something .\nYeah .  Huh ! Maybe . And she said it wasn't gonna  the transcriber said it wouldn't be a problem cuz they can actually make a template , uh , that has beep , number , beep . So for them it 'll be very quick\nOK .\nto  to put those in there  when they 're transcribing .\nYeah .\nSo , um , we  We 're gonna send them one more sample meeting , uh , and Thilo has run his segmentation . Adam 's gonna generate the chunked file . And then , um , I 'll give it to Brian and they can try that out . And when we get that back we 'll see if that sort of fixes the problem we had with , uh , too many beeps in the last transcription .\nOK . Do w do  what  Do you have any idea of the turn - around on  on those steps you just said ?\nGreat .\nUh . Our s our  On our side ?\nUh .\nor including IBM 's ?\nIncluding IBM 's .\nWell , I don't know . The last one seemed like it took a couple of weeks . Um , maybe even three .\nOK .\nUh , that 's just the I B M side . Our side is quick . I mean , I  I don't know . How long does your  ?\nIt should @ @ be finished today or something . Yeah .\nWell , I meant the overall thing .\nYeah .\ne e u u  The reason I 'm asking is because , uh , Jane and I have just been talking , and she 's just been doing .  Uh , e a , you know , further hiring of transcribers .\nMm - hmm . Mm - hmm .\nAnd so we don't sort of really know exactly what they 'll be doing , how long they 'll be doing it , and so forth , because right now she has no choice but to operate in the mode that we already have working .\nRight .\nAnd , uh , so it 'd be  It 'd be good to sort of get that resolved , uh , soon as we could ,\nYeah . I  Yeah , I  I hope @ @  we can get a better estimate from this  one that we send them .\nand then\nSo . Um .\nMm - hmm .\nI  I don't know yet how long that 'll take .\nYeah . Um  I mean in particular I would  I would really hope that when we do this DARPA meeting in July that we sort of have  we 're  we 're into production mode , somehow\nMm - hmm .\nYou know , that we  we actually  have a stream going and we know how  how well it does and how  and how it operates .\nYeah .\nI think that would  that would certainly be a  a very good thing to know .\nRight . Right .\nOK . Uh . Maybe before we do the meeting info organize thing , maybe you could say relevant stuff about where we are in transcriptions .\nOK . So , um , we   Uh , the transcribers have continued to work past what I 'm calling \" set one \" , which was the s the set that I 've been , uh  OK , talking about up to this point , but , uh , they 've gotten five meetings done in that set . Right now they 're in the process of being edited . Um , the , um  Let 's see , I hired two transcribers today . I 'm thinking of hiring another one , which will  because we 've had a lot of attrition . And that will bring our total to\nThey die off after they do this for a while .\nYeah . Well , you know , it 's  it 's various things .\nBurn - out .\nYeah .\nSo , one of them had a baby . Um , you know , one of them really w wasn't planning\nOh , that was an unfor unforeseen side effect of\nEh , one of them , um , had never planned to work past January . I mean , it 's th all these various things , cuz we , you know , we presented it as possibly a month project back in January and  and  and  and  Um , so it makes sense . Uh , through attrition we  we 've  we 're down to  to two , but they 're really solid . We 're really lucky the two that we kept . And , um  Well , I don't mean  I don't mean anything against the others .  What I mean is we 've got a good cause  a good core . No . We had a good core\nWell , they won't hear this since they 're going . They won't be transcribing this meeting .\nYeah , but still . I mean , I d it 's just a matter of we  w we 're  we 've got , uh ,\nNo backs .\ntwo of the ones who  who , um , ha had been putting in a lot of hours up to this point and they 're continuing to put in a  a lot of hours , which is wonderful , and excellent work . And so , then , in addition , um , I hired two more today and I 'm planning to h hire a third one with this  within this coming week , but   but the plan is  just as , uh , Morgan was saying we discussed this , and the plan right now is to keep the staff on the  on the leaner side , you know , rather than hiring , like , eight to ten right now ,\nMm - hmm .\nbecause if the IBM thing comes through really quickly , then , um , we wouldn't wanna have to , uh , you know , lay people off and stuff . So . And this way it 'll  I mean , I got really a lot of response for  for my notice and I think I could hire additional people if I  wish to .\nYeah . An - and the other thing is , I mean , in the unlikely event  and since we 're so far from this , it 's a little hard to plan this way  in the unlikely event that we actually find  that we have , uh , transcribers on staff who are twiddling their thumbs because , you know , there 's , you know ,  all the stuff that  that was sitting there has been transcribed and they 're  and they 're faster  the  the pipeline is faster than   uh , than the generation , um , eh , i in  in the day  e event that that day actually dawns , uh , I  I bet we could find some other stuff for them to do .\nOh , yes .\nSo I  I think  that , eh , eh , a as we were talking , if we  if we hire twelve , then we could , you know , run into a problem later . I mean , we also just couldn't sustain that forever . But  but , um  for all sorts of reasons  but if we hire f you know , f we have five on staff  five or six on staff at any given time , then  it 's a small enough number so we can be flexible either way .\nGood . OK .\nGood .\nIt 'd be great , too , if , um , we can  we might need some help again getting the tighter boundaries or some hand  to experiment with , um   you know , to have a ground truth for this segmentation work , which  I guess you have some already that was really helpful , and we could probably use more .\nMmm , yeah . That was a thing I  I planned working on , is , uh , to use the  the transcriptions which are done by now , and to  to use them as , uh\nOh . Oh , the new ones\nYeah .\nwith the tighter boundaries . Yeah .\nYeah . And to use them for  for training a  or for  fo whatever . Yeah . To  to create some speech - nonspeech labels out of them , and  Yeah , but that  that 's a thing w was  w what I 'm just looking into .\nOK .\nThe  the  the pre - segmentations are so much  are s so extremely helpful . Now there was , uh , I g guess  So , a couple weeks ago I needed some new ones and it happened to be during the time that he was on vacation  f for just very few days you were away . But it happened to be during that time I needed one ,\nYeah .\nso I   so I started them on the non - pre - segmented and then switched them over to yours and , um , they , um  you know , they always appreciate that when they have that available . And he 's , uh , usually , eh , uh , um  Um . So they really appreciate it . But I was gonna say that they do adjust it once in a while . You know , once in a while there 's something like ,\nYeah , sure .\num , and e Actually you talked to them . Didn't you ? Did you ? Have you  ?\nYeah . I talked to Helen .\nAnd  and  and she was  And so , I asked her  I mean , They 're very perceptive . I really want to have this meeting of the transcribers . I haven't done it yet , but I wanna do that and she 's out of town , um , for a couple of weeks , but I wanna do that when she returns . Um , cuz she was saying , you know , in a  in a span of very short period  we asked  It seems like the ones that need to be adjusted are these  these  these things , and she was saying the short utterances , uh , the , um\nHmm .\nMmm . Yeah .\nyou know , I mean , you 're  You 're aware of this . But  but actually i it 's so correct for so much of the time , that it 's an enormous time saver\nYeah .\nand it just gets tweaked a little around the boundaries . So .\nThat 's great .\nUm . Yeah . I think it 'd be interesting to combine these .\nYeah .\nIs there actually a record of where they change ? I mean , you can compare , do a diff on the  just so that we  knew\nYou could do it . It 's  it 's complicated in that  um ,  hhh , i hhh , i\nYeah . Actually , when  when they create new  yeah , new segments or something , it will be , uh , not that easy but  hmm . I think  one could do that .\nI mean , if we keep a old copy of the old time marks\nYeah .\njust so that if we run it we know whether we 're  which ones were cheating\nYeah . Yeah . That would be great , yeah , to know that .\nand\nThere is a  there is one problem with that and that is when they start part way through then what I do is I merge what they 've done with the pre - segmented version .\nwhich one would be good .\nYeah .\nSo it 's not a pure  it 's not a pure condition . Wha - what you 'd really like is that they started with pre - segmented and were pre - segmented all the way through .\nMm - hmm .\nAnd , um  @ @   I , uh  the  it wasn't possible for about four of the recent ones . But , it will be possible in the future\nYeah .\nbecause we  we 're , um .\nIt would .\nMmm , that 's great .\nYeah .\nYeah . As long as we have a record , I guess , of the original  automatic one , we can always find out how well  we would do fr from the recognition side by using those boundaries .\nYeah . Yeah .\nUm .\nYeah .\nYou know , a completely non - cheating version .\nYeah .\nAlso if you need someone to record this meeting , I mean , I 'm happy to  for the transcribers  I could do it , or Chuck or Adam .\nThank you .\nOK . So , uh , u you were saying something about organizing the meeting info ?\nYeah . So , um , uh , Jane and Adam and I had a meeting where we talked about the reorganization of the  directory structure for all of the meeting\nDid you record it ?\nNo . For all the Meeting Recorder data . We should have . Um . And so we 've got a plan for what we 're gonna do there . And then , Jane also s prepared a  um , started getting all of the  the meetings organized , so she prepared a   a spreadsheet , which I spent the last couple of days adding to . So I went through all of the data that we have collected so far , and have been putting it into , uh , a spreadsheet  with start time , the date , the old meeting name , the new meeting name , the number of speakers , the duration of the meeting , comments , you know , what its transcription status is , all that kind of stuff . And so , the idea is that we can take this and then export it as HTML and put it on the Meeting Recorder web page so we can keep people updated about what 's going on .\nOh , great .\nUm , I 've gotta get some more information from Jane cuz I have some  some gaps here that I need to get her to fill in , but  so far , um ,  as of Monday , the fourteenth , um , we 've had a total number of meeting sixty - two hours of meetings that we have collected . And , um  Uh , some other interesting things , average number of speakers per meeting is six . Um , and I 'm gonna have on here the total amount that 's been transcribed so far , but I 've got a bunch of  uh , that 's what I have to talk to Jane about , figuring out exactly which ones have  have been completed and so forth . But , um ,  this 'll be a nice thing that we can put up on the  the web site and people can  be informed of the status of various different ones . And  it 'll also list , uh , like under the status , if it 's at IBM or if it 's at ICSI , uh , or if it 's completed or which ones we 're excluding and  and there 's a place for comments , so we can ,  um , say why we 're excluding things and so forth . So .\nNow would the ones that , um , are already transcribed  we h we have enough there that c you know , we 've already done some studies and so forth and  um , shouldn't we go through and do the business - es u of  of having the , um , uh , participants approve it , uh , for  approve the transcriptions for distribution and so forth ?\nUm , interesting idea . In principle , I  I would say yes , although I still am doing some  the final - pass editing , trying to convert it over to the master file as the  being the channelized version and it 's  Yeah , it seems like I get into that a certain way and then something else intervenes  and I have to stop . Cleaning up the things like the , uh , uh , places where the transcriber was uncertain , and  and doing spot - checking here and there . So , um , uh , I guess it would make sense to wait until th that 's done , um , but  but\nWell , le let me put in another sort of a milestone kind of  as  as I did with the , uh , uh  the  the pipeline .\nYeah .\nUm , we are gonna have this DARPA  meeting in the middle of July ,\nYes .\nand I think it w it 'd be  given that we 've been  we 've given a couple public talks about it already , spaced by months and months , I think it 'd be pretty bad if we continued to say none of this is available . Um .\nIt 'll certainly be done by then . Yeah .\nRight . So we can s we  we wanna be able to say \" here is a subset that is available right now \"\nMm - hmm . That 's right .\nand that 's has been through the legal issues and so forth .\nThat 's right .\nSo .\nYeah . That 's right . So that\nOK ?\nOK .\nSo , by  before July .\nAnd they don't have to approve , you know , th an edited version , they can just give their approval to whatever version\nWell , maybe\nWell , in principle , yes . But , I mean , i if  if  if somebody actually did get into some legal issue with it then we\nBu Yeah . But th I mean , the editing will continue . Presumably if  if s errors are found , they will be fixed , but they won't change the  the content of the meetings .\nContent , really .\nWell , see , this is the  this is the issue . Subtleties .\nSo .\nWell , i if Jane is clarifying question question , then , you know , how can they agree to it before they know her final version ?\nThe other thing , too , is there can be subtleties where a person uses this word instead of that word , which @ @  could 've been transcribed in the other way .\nYeah .\nThing\nAnd no and they wouldn't have  been slanderous if it had been this other word . You know ?\nI it  you know , there there is a point at which I agree it becomes ridiculous because , you know , you could do this final thing and then a year from now somebody could say , you know , that should be a period and not a question mark . Right ? And you don't  you  there 's no way that we 're gonna go back and ask everybody \" do you approve this , uh , you know  this document now ? \" So  So I think what it is is that the  the  the  the thing that they sign  I  I haven't looked at it in a while , but it has to be open enough that it sort of says \" OK , from now on  you know , now that I 've read this , you can use  do anything you want with these data . \"\nMm - hmm .\nAnd , uh  But , i I think we wanna  So , assuming that it 's in that kind of wording , which I don't remember ,  um , I think i we just wanna have enough confidence ourselves that it 's so close to the final form it 's gonna be in , a year from now that they 're\nMm - hmm . I agree . Mmm . I totally agree . It 's just , uh , a question of ,  uh , if  if the person is using the transcript as the way of them judging what they said and whether it was slanderous ,  then it seems like it 's  it 's  i it needs to be more correct than if we could count on them re - listening to the meeting .\nUh .\nBecause it becomes , eh , in a way a  a f uh , a legal document i if they 've agreed to that .\nWell , I forget how we end Right . I forget how we ended up on this , but I remember my taking the position  of not making it so  so easy for everybody to observe everything and Adam was taking the position of  of having it be really straightforward for people to check every aspect of it including the audio . And I don't remember who won , Adam or me , but\nWell ,  if it 's only the transcript , though  I mean , th this  this is my point , that  that\nuh , the  Uh , that that 's why I 'm bringing this up again , because I can't remember how we ended up .\nthen it becomes\nThat it was the transcrip He wanted to do a web interface that would make it\nWell , if it 's just the audio  Well .\nthat would give you access to the transcript and the audio . That 's what Adam wanted .\nMm - hmm .\nAnd I don't remember how we ended up .\nI mean , with the web interface it 's interesting , because you could allow the person who signs to be informed when their transcript changes , or something like that . And , I mean , I would say \" no \" . Like , I don't wanna know , but some people might be really  interested and then y In other words , they would be informed if there was some significant change other than typos and things like that .\nYou decided you were whispering Satanic incantations under your breath when you were\nWell ,  I don't know what happened to the small heads thing , but I j  Um , I 'm just saying that , like , you know , you can sort of say that any things that are deemed\nThey disappeared from view .\nAnyway . I mean , I agree that at some point people  probably won't care about typos but they would care about significant meaning changes and then they could be asked for their consent , I guess , if  if those change . Cuz assumi  assuming we  we don't really distribute things that have any significant changes from what they sign anyway .\nTha That 's  How about having them approve the audio and not the transcripts ?\nOh , my God .\nThat would be simpler ,\nUh .\nif we could count on them listening .\nBut no one will listen to the hours and hours of\nTalk .\nWell , that 's O K .\nThat 's\nWe just have to give them a chance to listen to it , and if they don't , that 's their problem .\nhmm , hmm .\nYou  you d That 's like\nUnfortunately , uh , in  in the sign thing that they signed , it says \" transcripts \" .\nNo , I 'm serious .\n\" You 'll be  you 'll be provided the transcripts when they 're available . \"\nReally ?\nMmm .\nMmm .\nYeah .\nYeah .\nI I  I think\nYeah .\nthat 's a lot to ask for people that have been in a lot of meetings .\nYeah .\nW anyway , haven't we  we 've gone down this path a number of times . I know this can lead to extended conversations and  and not really get anywhere , so let  let me just suggest that   uh , off - line that , uh , the people involved figure it out and take care of it before it 's July .\nYes .\nOK . So  so that in July we can tell people  \" yes , we have this and you can use it \" .\nYes . It 's done , ready , available . Good .\nUh . So , let 's see . What else we got ? Uh . Don did  did a report about his project in class and , uh  an oral and written  written version .\nWell .\nSo that was stuff he was doing with you . Yeah .\nI mean , it 's  I guess one thing we 're learning is that the amount  We have eight meetings there because we couldn't use the non - native  all non - native meetings and  it 's , well , probably below threshold on enough data for us for the things we 're looking at because the  prosodic features are  very noisy and so you  you need a lot of data in order to model them . Um , so we 're starting to see some patterns and we 're hoping that maybe with ,  I don't know , double or triple the data  with twenty meetings or so , that we would start to get better results . But we did find that some of the features that , I gue Jane would know about , that are expressing sort of the  distance of , um ,  boundaries from peaks in the utterance and  some  local , um , range  pitch range effects , like how close people are to their floor , are showing up in these classifiers , which are also being given some word features that are cheating , cuz they 're true words . Um , so these are based on forced alignment . Word features like , um , word frequency and whether or not something 's a backchannel and so forth . So , we 're starting to see , I think , some interesting patterns .\nSo the dominant features , including everything , were those  those quasi - cheating things . Right ? Where these are\nSometimes not .\nI think it depends what you 're looking at , a actually .\nYeah . Sometimes  positions in sentences obviously , or in spurts , was helpful . I don't know if that 's cheating , too .\nRight . Um ,\nSpurts wouldn't be . Right ?\nspurts is not cheating except that of course you know the real words ,\nRight .\nbut roughly speaking , the recognized words are gonna give you a similar type of position .\nRight . Would they give you the same number of words , though ?\nRight .\nIt 's either early or late .\nNo\nNot exactly , but i\nBut ra somewhat ?\nOn the average .\nY yeah it should be . Well , we don't know and actually that 's one of the things we 're interested in doing , is a sort of\nUh - huh .\nHave you tried using just time , as opposed to number of words ?\nSo .\nI think ti uh  Just p time position , like when the word starts ?\nYeah .\nI don't know if that was in the\nWell , no , I mean t time  time position relative to the beginning of the spurt .\nEh  You know , uh\nStart .\nYeah ,\nYeah . There 's all these things to do .\nuh , we didn't try it , but it 's s\nLike , there 's a lot of different features you could just pull out .\nYeah . I mean that wouldn't be cheating because you can detect pause  pretty well within the time .\nRight .\nRight .\nHow about time position normalized by speak\nAnd it depends on speaking rate\nYeah .  Yeah .\nspeaking rate . Yeah .\nYeah .\nYeah . That 's actually why I didn't use it at first .\nYeah .\nMm - hmm .\nBut we  one of the interesting things was I guess you reported on some te punctuation type\nYeah .\nfinding sentence boundaries , finding disfluency boundaries , and then I had done some work on finding from the foreground speech whether or not someone was likely to interrupt , so where  you know , if I 'm talking now and someone  and  and Andreas is about to interrupt me , is he gonna choose a certain place in my speech , either prosodically or word - based . And there the prosodic features actually showed up and a neat thing  even though the word features were available . And a neat thing there too is I tried some   putting the speaker  So , I gave everybody  a short version of their name . So the real names are in there , which we couldn't use . Uh , we should use I Ds or something . And those don't show up . So that means that overall , um , it wasn't just modeling Morgan , or it wasn't just modeling a single person ,\nMm - hmm .\num , but was sort of trying to ,  uh , get a general idea  the model  the tree classifier was trying to find general locations that were applicable to different speakers , even though there are huge speaker effects . So . The  but the main limitation now is I  because we 're only looking at things that happen every  ten words or every twenty words , we need more  more data and more data per speaker . So . It 'd also be interesting to look at the EDU meetings because we did include meeting type as a feature , so whether you were in a r Meeting Recorder meeting or a Robustness meeting did matter  to  interrupts because there are just fewer interrupts in the Robustness meetings .\nMm - hmm .\nAnd so the classifier learns more about Morgan than it does about sort of the average person ,\nMm - hmm .\nwhich is  not bad . It 'd probably do better than   Um , but it wasn't generalizing .\nYeah .\nSo it 's  And I think Don , um  Well , we have a long list of things he 's starting to look at now over the summer , where we can  And he 'll be able to report on more things  in the future . But it was great that we could at least go from the   you know , Jane 's transcripts and the ,  uh , recognizer output and get it  to this point . And I think it 's something Mari can probably use in her preliminary report  like , \" yeah , we 're at the point where we 're training these classifiers and we 're just  reporting very preliminary but suggestive results that  some features , both word and pro prosodic , work . \" The other thing that was interesting to me is that the pitch features are better than in Switchboard . And I think that really is from the close - talking mikes , cuz the pitch processing that was done has much cleaner behavior than  than the Switchboard telephone bandwidth .\nW wh wh wh Better in what sense ?\nUm . Well , first of all , the pitch tracks are m have less , um , halvings and doublings than  than Switchboard and there 's a lot less dropout , so if you ask how many regions where you would normally expect some vowels to be occurring  are completely devoid of pitch information ,\nMm - hmm .\nin other words the pitch tracker just didn't get a high enough probability of voicing for words  for  for , you know , five word\nHmm .\nthere are much fewer than in Switchboard . So the missing   We had a big missing data problem in Switchboard and , so the features weren't as reliable cuz they were often just not available .\nCould it have to do with the  the lower frequency cut - off on the Switchboard ?\nSo that 's actually good . Ma - maybe . I mean , the tele we had telephone bandwidth for Switchboard and we had the an annoying sort of telephone handset movement problem that I think may also affect it .\nHmm .\nSo we 're just getting better signals in  in this data . Which is nice . So .\nYeah .\nAnyway , Don 's been doing a great job and we hope to continue with , um , Andreas 's help and also some of Thilo 's help on this ,\nGreat .\nY\nto  to try to get a non - cheating version of how all this would work .\nYeah . Sure . Yeah .\nHas  has , uh  ? We just  I think , just talked about this the other day , but h has  has anybody had a chance to try changing , uh , insertion penalty sort of things with the  with the , uh   uh , using the tandem system input for the  ?\nOh , yeah . I tried that . It didn't , um , help dramatically . The\nWere they out of balance ? I didn't  I didn't notice .\nThere were a little  the relative number of  I think there were a higher number of deletions , actually .\nOh .\nSo , you , uh  So , actually it  it preferred to have a positive  er , negative insertion penalty ,\nDeletions ?\nwhich means  that , um\nUh - huh .\nBut , you know , it didn't change  th the  by adjusting that  the , um\nOK .\nYeah . The error changed by probably one percent or so . But , you know , given that that word error rate is so high , that 's not a\nOK . So that  So that 's  So that 's not the problem .\nThat 's not the problem . No .\nYeah .\nBut , uh , we s just , um , uh  you know , Chuck and I talked and the  @ @  next thing to do is probably to tune the  um , the size of the Gaussian system , um , @ @  to  to this  to this feature vector , which we haven't done at all . We just used the same  configuration as we used for the   for the standard system .\nHmm .\nAnd ,  for instance , uh , Dan  @ @  Dan just sent me a message saying that CMU used , um ,  something like ten Gaussians per cluster  You know , each  each mixture has ten  Gaussians\nMm - hmm . Hmm . We 're using sixty - four ,\nand  and we 're using sixty - four ,\nright ?\nso that 's  obviously a big difference\nYeah .\nand it might be way off and give very poorly trained , uh , you know , Gaussians that way ,\nHmm .\nuh , an and poorly trained mixture weights . So  so , we have  The turn - around time on the training when we train only the  a male system with , uh , you know , our small training set , is  less than twenty - four hours , so we can run lots of   uh , basically just brute force , try a whole bunch of different um , settings .\nOK .\nAnd , uh , with the new machines it 'll be even better . So .\nYeah . We get twelve of those ,\nYeah .\nhuh ?\nBut the PLP features work  um , uh , you know , continue to improve the ,\nOK .\num  As I said before , the  uh using Dan 's , uh , uh , vocal tract normalization option works very well . So , um , @ @  I ran one experiment where we 're just  did the vocal tract le normalization only in the test data ,\nMm - hmm .\nso I didn't bother to retrain  the models at all , and it improved by one percent , which is about what we get with   uh , with , you know , just @ @  actually doing both training and test normalization , um , with , um ,  the , uh   uh , with the standard system . So , in a few hours we 'll have the numbers for the  for retraining everything with vocal tract length normalization and  So , that might even improve it further .\nGreat .\nSo , it looks like the P L - fea P features  do very well now with  after having figured out all these little tricks to  to get it to work .\nYeah .\nSo .\nGood .\nWait . So you mean you improve one percent over a system that doesn't have any V T L in it already ?\nExactly . Yeah .\nOK .\nYeah . OK . So then  then we 'll have our baseline to  to compare the currently hideous , uh , uh , new thing with .\nRight . a Right . And  and what that suggests also is of course that the current Switchboard  MLP isn't trained on very good features .\nBut  Yeah .\nUh , because it was trained on whatever , you know , was used , uh , last time you did Hub - five stuff , which didn't have any of the\nRight . But all of these effects were j like a couple percent .\nUh .\nRight ? I mean , y the\nWell , but if you add them all up you have , uh , almost five percent difference now .\nAdd  all of them . I thought one was one point five percent and one was point eight .\nYeah . And now we have another percent with the V T\nThat 's three point three .\nUm , actually , and it 's , um , What 's actually qu interesting is that with  um , well , you m prob maybe another half percent if you do the VTL in training , and then interestingly , if you optimize you get more of a win out of rescoring the , um ,  uh , the N best lists , uh , and optimizing the weights , um , uh than\nThan you do with the standard ?\nYeah . So\nYeah . But the part that 's actually adjustment of the front - end per se as opposed to doing  putting VTLN in or something is  it was a couple percent .\nRight .\nRight ? It was  it was  there was   there was one thing that was one and a half percent and one that was point eight . So  and  and  let me see if I remember what they were . One of them  was , uh , the change to , uh  because it did it all at once ,  to  uh , from bark scale to mel scale ,\nMm - hmm .\nwhich I really feel like saying in quotes , because @ @  they 're essentially the same scale but the  but  but  but any i individual particular implementation of those things puts things in a particular place .\nYeah . Why did that cha ?\nMm - hmm .\nSo that 's why I wanted to look  I still haven't looked at it yet . I  I wanna look at exactly where the filters were in the two ,\nMm - hmm .\nand it   it 's probably something like there 's one fewer or one more filter in the sub  one kilohertz band\nMm - hmm .\nand for whatever reason with this particular experiment it was better one way or the other .\nHmm .\nUm , it could be there 's something more fundamental but it  you know , I  I don't know it yet . And the other  and the other  that was like one and a half or something , and then there was point eight percent , which was  what was the other thing ?\nWell , that was combined with the triangular . Right ?\nYeah . Those  those two were together .\nYeah . Right .\nWe d weren't able to separate them out cuz it was just done in one thing . But then there was a point eight percent which was something else .\nThe low - frequency cut - off .\nDo you remember the  ? Oh , yeah . So that was  that was , uh  that one I can claim credit for , uh , i in terms of screwing it up in the first place . So that someone e until someone else fixed it , which is that , um , I never put  when I u We had some problems before with offsets . This inf this went back to , uh , I think Wall Street Journal .\nHmm .\nSo we  we had , uh  ea everybody else who was doing Wall Street Journal knew that there were big DC offsets in th in these data  in those data and  and  and nobody happened to mention it to us ,\nHmm .\nand we were getting these , like , really terrible results , like two , three times the error everybody else was getting . And then in casual conversation someone ment mentioned \" uh , well , I guess , you know , of course you 're taking care of the offsets . \" I said \" what offsets ? \"\nMm - hmm .\nAnd at that point , you know , we were pretty new to the data and we 'd never really , like , looked at it on a screen and then when we just put it on the screen  and wroop !\nMm - hmm .\nthere 's this big DC offset . So , um , in PLP\nThere was a  like a hum or some or  when they recorded it ?\nNo . It 's just , it  it 's  it 's not at all uncommon for  for recorded electronics to have different , um , DC offsets .\nOr just  ? Huh .\nIt 's  it 's , you know , no big deal . It 's  you know , you could have ten , twenty , maybe thirty millivolts , whatever , and it 's consistently in there . The thing is , most people 's front - ends have pre - emphasis with it , with zero at zero frequency , so that it 's irrelevant . Uh , but with P L P , we didn't actually have that . We had  we had the equivalent of pre - emphasis in a  a , uh , Fletcher - Munson style weighting that occurs in the middle of P L but it doesn't actually have a zero at zero frequency ,\nHmm .\nlike , eh , uh , typical simple fr pre - emphasis does . We had something more fancy . It was later on it didn't have that . So at that point I reali \" oh sh we better have a  have a high - pass filter \" just , you know   just take care of the problem . So I put in a high - pass filter at , uh , I think ninety  ninety hertz or so  uh , for a sixteen kilohertz sampling rate . And I never put anything in to adjust it for different  different sampling rates . And so  well , so , you know , the code doesn't know anything about that and so this is all at eight kilohertz and so it was at forty - five hertz instead of at   instead of at ninety .\nHmm .\nSo , um , I don't know if Dan fixed it or  or , uh , what he\nWell , he made it a parameter .\nHe made it a parameter . So . Yeah , I guess if he did it right , he did fix it and then  and then it 's taking care of sampling rate , which is great .\nWhat  what is the parameter ?\nHe had a\nIs it , uh , just the f lower cut - off that you want ?\nIt 's called , uh ,  H - HPF .\nH  Yeah . Does HPF on  on his feat feature .\nu And  but HPF , you know , when you put a number after it , uses that as the hertz value of the cut - off .\nMm - hmm . Oh , OK .\nYeah .\nSo .\nI mean , frankly , we never did that with the RASTA filter either ,\nMm - hmm .\nso the RASTA filter is actually doing a different thing in the modulation spectral domain depending on what sampling rate you 're doing , which is  another old  old bug of mine .\nMm - hmm .\nBut , um  Um . So that  that was the problem there was th we  we  we had always intended to cut off below a hundred hertz\nMm - hmm .\nand it just wasn't doing it , so now it is . So ,  that hep that helped us by , like , eight tenths of a percent . It  still wasn't a big deal .\nOK . Well , but , um  Well , uh , again , after completing the  current experiments , we 'll   we can add up all the uh differences\nOh , yeah .\nand   and  an\nBut  but , I guess my  my point was that  that , um , the hybrid system thing that we did was , uh , primitive in many ways .\nY Right .\nAnd I think I agree with you that if we fixed lots of different things and they would all add up , we would probably have a  a  a competitive system . But I think not that much of it is due to the front - end per se . I think maybe a couple percent of it is , as far as I can see from this .\nMm - hmm .\nUh , unless you call  well , if you call VTL the front - en front - end , that 's , uh , a little more . But that 's sort of more both , kind of .\nOne experiment we should  we 'll probably need to do though when  um , at some point , is , since we 're using that same  the net that was trained on PLP without all these things in it , for the tandem system , we may wanna go back and retrain ,\nRight ? But .\nWell , that 's what I meant , in fact . Yeah .\nyeah , yeah , for the tandem . You know , so we can see if it  what effect it has on the tandem processing .\nSo  so , the thing is  is do we expect  ?\nMm - hmm .\neh At this point I 'm as I mean , you know  e I 'm wondering is it  Can we expect , uh , a tandem system to do better than a properly trained  you know , a Gaussian system trained directly on the features with , you know , the right ch choice of  parameters ?\nWell , that 's what we 're seeing in other areas . Yes . Right ? So , it 's  so , um , um\nSo , we  But  but we may not . I mean , if it doesn't perform as well , we may not know why . Right ? Cuz we need to do the exact experiment .\nRight .\nI mean , the reason to think it should is because you 're putting in the same information and you 're transforming it to be more discriminative . So . Um . Now the thing is , in some databases I wouldn't expect it to necessarily give you much and  and part of what I view as the real power of it is that it  gives you a transformational capability  for taking all sorts of different wild things that we do , not just th the standard front - end , but other things , like with multiple streams and so forth ,\nMm - hmm .\nand allows you to feed them to the other system with this  through this funnel . Um , so I think  I think that 's the real power of it . I wouldn't expect huge in huge improvements . Um , but it should at least be roughly the same and maybe a little better .\nMm - hmm .\nIf it 's , you know , like way way worse then , you know\nRight .\nSo , Morgan , an another thing that Andreas and I were talking about was , so @ @  in the first experiment that he did  we just took the whole fifty - six , uh , outputs and that 's , um , basically compared to a thirty - nine input feature vector from either MFCC or PLP .\nMm - hmm . Mm - hmm .\nBut one thing we could do is\nLet  let me  let me just ask you something . When you say take the fifty - six outputs , these are the pre final nonlinearity  outputs\nYeah . Through the regular tandem outputs .\nand they 're  and  through the KLT .\nThrough the KLT . All that kinda stuff .\nOK . And so  so then you u Do you use all fifty - six of the KLT\nThat 's what we did .\nor  ?\nRight ? So one thing we were wondering is , if we did principal components and , say , took out just thirteen , and then did deltas and double - deltas on that\nOK . Yes .\nso we treated the th first thirteen as though they were  standard features .\nYes . Yeah .\nI mean , did Dan do experiments like that to  ?\nUh . Talk with Stephane . He did some things like that . It was either him or Carmen . I forget .\nMm - hmm .\nMmm .\nI mean these were all different databases and different  you know , in HTK and all that ,\nYeah .\nso i it  it may not apply . But my recollection of it was that it didn't make it better but it didn't make it worse .\nHmm .\nBut , again , given all these differences , maybe it 's more important in your case that you not take a lot of these low - variance , uh , components .\nCuz in a sense , the net 's already got quite a bit of context in those features ,\nYeah .\nso if we did deltas and double - deltas on top of those , we 're getting sort of even more .\nWhich could be good or not .\nYeah .\nYeah . Yeah . Worth trying .\nBut there the main point is that , um , you know , it took us a while but we have the procedure for coupling the two systems  debugged now and  I mean , there 's still conceivably some bug somewhere in the way we 're feeding the tandem features  uh , either generating them or feeding them to this  to the  SRI system ,\nMm - hmm . Yeah .\nbut it 's\nThere might be , cuz that 's a pretty big difference .\nYeah . And I 'm wondering how we can  how we can debug that .\nBut\nYeah .\nI mean how  Um .\nHmm .\nI 'm actually f quite sure that the  feeding the  features into the system and training it up ,\nWhat if  ?\nthat  that  I think that 's  this  that 's essentially the same as we use with the ce with the P L P fe features . And that 's obviously working great . So . I um .\nYeah . There could be a bug in  in the  somewhere before that .\nThere  we could  the  another degree of freedom is how do you generate the K L T transform ?\nMm - hmm .\nRight ? We to\nThat 's\nRight .\nwell , and another one is the normalization of the inputs to the net .\nYeah .\nThese nets are trained with particular normalization and when that gets screwed up it  it can really hurt it .\nI 'm doing what Eric  E Eric coached me through then  that part of it , so I 'm pretty confident in that .\nOK .\nI mean , the only slight difference is that I use normalization values that , um , Andreas calculated from the original  PLP ,\nRight .\nwhich is right .\nRight .\nN Yeah . So , I u I do  Oh , we actually don't do that normalization for the PLP , do we ? For the st just the straight PLP features ?\nNo . The  the SRI system does it .\nS R I system does that . Right .\nYeah .\nRight . Well , you might e e\nSo , there 's  there is  there is room for bugs that we might not have discovered ,\nSo that 's  that 's another  Yeah .\nYeah .\nMm - hmm .\nYeah .  I  I would actually double check with Stephane at this point ,\nbut\ncuz he 's probably the one here  I mean , he and Dan are the ones who are at this point most experienced with the tandem\nMm - hmm .\nthing and there may  there may be some little bit here and there that is not  not being handled right .\nYeah . It 's hard with features , cuz you don't know what they should look like . I mean , you can't just , like , print the  the values out in ASCII and , you know , look at them , see if they 're\nNot unless you had a lot of time\nWell\nand\neh , and also they 're not  I mean , as I understand it , you  you don't have a way to optimize the features for the final word error . Right ?\nRight .\nI mean , these are just discriminative , but they 're not , um , optimized for the final\nThey 're optimized for phone discrimination , not for\nRight . So it  there 's always this question of whether you might do better with those features if there was a way to train it for the word error metric that you 're actually  that you 're actually\nThat 's right . Well , the other  Yeah , th the\nMm - Mmm .\nWell , you actually are . But  but it  but in an indirect way .\nWell , right . It 's indirect , so you don't know\nSo wha w what  an and you may not be in this case , come to think of it , because , uh , you 're just taking something that 's trained up elsewhere . So , what  what you  what you do in the full procedure  is you , um , uh , have an embedded training . So in fact you  the  the net is trained on , uh , uh , a , uh , Viterbi alignment of the training data that comes from your full system . And so that 's where the feedback comes all around , so that it is actually discriminant . You can prove that it 's  it 's a , uh  If you believe in the Viterbi assumption that , uh , getting the best path , uh , is almost equivalent to getting the best , uh , total probability , um , then you actually do improve that by , uh  by training up on local  local , uh  local frames . But , um , we aren't actually doing that here , because we did  we did that for a hybrid system , and now we 're plugging it into another system and so it isn't   i i i it wouldn't quite apply here .\nDo y\nSo another huge experiment we could do would be to take the tandem features , uh , do SRI forced alignments using those features , and then re - do the net with those .\nMm - hmm .\nMmm , uh  Exactly . Exactly .\nYeah .\nSo that you can optimize it for the word error .\nBut\nYeah . Another thing is since you 're not using the net for recognition per se but just for this transformation , it 's probably bigger than it needs to be .\nYeah .\nSo that would save a lot of time .\nAnd there 's a mismatch in the phone sets . So , you 're using a l a long a larger phone set than what\nMmm .\nYeah . Actually all those things could  could  could  could , uh  could affect it as well .\nYeah . Yeah .\nThe other thing , uh , just to mention that Stephane  this was an innovation of Stephane 's , which was a pretty neat one , uh , and might particularly apply  here , given all these things we 're mentioning . Um , Stephane 's idea was that , um , discriminant , uh , approaches are great . Even the local ones , given , you know , these potential outer loops which , you know , you can convince yourself turn into the global ones . Um , however , there 's times when it  is not good . Uh , when  something about the test set is different enough from the training set that  that , uh , the discrimination that you 're learning is  is  is not a good one .\nMm - hmm .\nSo , uh , his idea was to take as the input feature vector to the , uh , Gaussian mixture system ,  uh , a concatenation of the neural net outputs and the regular features .\nOh , we already talked about that .\nYeah . That\nYeah .\nEl\nMm - hmm .\nDidn't you  did you  do that already\nYeah . No , but we  we  when  when we  when I first started corresponding with Dan about how to go about this , I think that was one of the things that we definitely went there .\nor  ? Oh . That makes a lot of sense . Huh .\nYeah . Yeah . I mean , I 'm sure that Stephane wasn't the first to think of it ,\nYeah .\nbut actually Stephane did it\nUh - huh . And i does it help ?\nand   and  and it helped a lot .\nOh , OK .\nYeah . So that 's  that  that 's our current best  best system in the , uh   uh , in the Aurora thing .\nOh . OK .\nYeah . That makes sense .\nAnd do you do a KLT transform on the con on the combined feature vector ?\nYeah .\nAs  you should never do worse .\nI  I , uh , missed what you said .\nDo you  d you do a KLT transform on the combined feature vector ?\nYeah .\nOK .\nWell , actually , I , uh  you should check with him , because he tried several different combinations .\nBecause you end up with this huge feature vector , so that might be a problem , a unless you do some form of dimensionality reduction .\nYeah . I , uh , th what I don't remember is which came out best . So he did one where he put o put e the whole thing into one KLT , and another one , since the  the PLP things are already orthogonalized , he left them alone and  and just did a KLT on the  on the  on the net outputs\nMm - hmm . Mmm .\nand then concatenated that . And I don't remember which was better .\nDid he  did he try to  ? So he always ended up with a feature vector that was  twice as long as either one of the  ?\nNo . I don't know , i I  I don't know . You have to check with him .\nYeah .\nOK . Actually , I have to run .\nI 'm into big ideas these days .\nYeah .\nUh .\nWe need to close up cuz I need to save the data and , um , get a call .\nNot to mention the fact that we 're missing snacks . Yeah .\nRight .\nUh\nDid people wanna do the digits\nUm .\nor , um , do them together ?\nI  I g I think , given that we 're in a hurry for snacks , maybe we should do them together .\nI don't know . Should we just  ? OK . I mean , are we trying to do them {nonvocalsound} in synchrony ? That might be fun .\nWell , it 's   it 's  it 's not  You know , it 's not gonna work out\nAdam 's not here , so he 's not here to tell me no .\nbut we could  we could just , uh , uh , see if we find a rhythm , you know , what\nSure .\nUh , O 's or zeroes , we wanna agree on that ?\nMaybe just whatever people would naturally do ? I don't know .\nOh , but if we were a singing group , we would wanna decide . Right ?\nBe harmony . Yeah .  Yeah .\nMine 's identical to yours .\nWe might wa\nIs that correct ?\nSorry . So I set up and we didn't have  enough digit forms\nOh . I see .\nSo these are excellent .\nso I xeroxed the same one seven times .\nOh . I see .\nWhy don't we do zer i Anyone have a problem with saying zero ? Is zero OK ?\nNo .\nYeah .\nOK . One and a two and three .\ne\nOnce more with feeling .\nAnd th\nNo , just k just kidding . Oh , yeah . It was .", "topic_id": 2, "keywords": "recorder, transcribers, audio, waveform, transcriber", "dialogue_id": 1}, {"text": "OK , we 're on .\nOK .\nSo , I mean , everyone who 's on the wireless check that they 're on .\nC we\nAlright .\nI see . Yeah .\nYeah .\nOK , our agenda was quite short .\nOh , could you  close the door , maybe ? Yeah .\nSure . Two items , which was , uh , digits and possibly stuff on  on , uh , forced alignment , which Jane said that Liz and Andreas had in information on ,\nbut they didn't ,\nMm - hmm .\nI guess the only other thing , uh , for which I\nso .\nWe should do that second , because Liz might join us in time for that .\nOK .\nUm . OK , so there 's digits , alignments , and , um , I guess the other thing ,  which I came unprepared for , uh ,  is , uh , to dis s s see if there 's anything anybody wants to discuss about the Saturday meeting .\nRight .\nSo . Any  I mean , maybe not .\nDigits and alignments . But\nUh .\nTalk about aligning people 's schedules .\nYeah .\nYeah .\nMm - hmm .\nYeah . I mean  Right . Yeah , I mean , it was\nYeah , it 's forced alignment of people 's schedules .\nYeah .\nForced align .\nIf we 're very\nYeah .\nYeah .\nWith  with  whatever it was , a month and a half or something ahead of time , the only time we could find in common  roughly in common , was on a Saturday .\nYeah .\nUgh .\nYep .\nIt 's pretty sad .\nYeah .\nYeah .\nHave  Have we thought about having a conference call to include him in more of   in more of the meeting ? I  I mean , I don't know , if we had the  if we had the telephone on the table\nNo . But , h I mean , he probably has to go do something .\nNo , actually I  I have to  I have to shuttle  kids from various places to various other places .\nRight ?\nI see . OK .\nYeah .\nSo . And I don't have  and I don't , um , have a cell phone\nA cell phone ?\nso I can't be having a conference call while driving .\nR r right .\nNo .  It 's not good .\nSo we have to  we\nThat 's not good .\nPlus , it would make for interesting noise  background noise .\nYep .\nUh\nSo we have to equip him with a  with a   with a head - mounted , uh , cell phone\nYe - we and we 'd have to force you to read lots and lots of digits ,\nand\nso it could get real   real car noise .\nOh , yeah .\nYeah .\nOh , yeah .\nTake advantage .\nAnd with the kids in the background .\nI 'll let  I 'd let\nYeah .\nI let , uh , my five - year - old have a try at the digits , eh .\nYeah .\nSo , anyway , I can talk about digits . Um , did everyone get the results or shall I go over them again ? I mean that it was basically  the only thing that was even slightly surprising was that the lapel did so well . Um , and in retrospect that 's not as surprising as maybe i it shouldn't have been as surprising as I  as  as I felt it was . The lapel mike is a very high - quality microphone . And as Morgan pointed out , that there are actually some advantages to it in terms of breath noises and clothes rustling  if no one else is talking .\nYeah .\nExactly .\nUm , so , uh\nMm - hmm .\nWell , it 's  Yeah , sort of the bre the breath noises and the mouth clicks and so forth like that , the lapel 's gonna be better on .\nIt 's g it\nOr the cross - talk . Yeah .\nThe lapel is typically worse on the  on clothes rustling , but if no one 's rustling their clothes ,\nRight . I mean , a lot of people are just sort of leaning over and reading the digits ,\nit 's  it 's\nso it 's  it 's a very different task than sort of the natural .\nYeah . You don't move much during reading digits , I think .\nYeah .\nSo .\nYeah .\nRight .\nProbably the fact that it picks up other people 's speakers  other people 's talking is an indication of that it  the fact it is a good microphone .\nYeah .\nRight . So in the digits , in most  most cases , there weren't other people talking .\nRight . Right .\nSo .\nSo .\nD do the lapel mikes have any directionality to them ?\nThere typically don't , no .\nBecause I  I suppose you could make some that have sort of  that you have to orient towards your mouth ,\nThey have a little bit ,\nand then it would\nbut they 're not noise - cancelling . So , uh\nThey 're  they 're intended to be omni - directional .\nRight .\nAnd th it 's  and because you don't know how people are gonna put them on , you know .\nMm - hmm .\nRight . So , also , Andreas , on that one the  the back part of it should be right against your head . And that will he keep it from flopping aro up and down as much .\nIt is against my head .\nOK .\nYeah . Um . Yeah , we actually talked about this in the , uh , front - end meeting this morning , too . Much the same thing ,\nUh - huh .\nand  and it was  uh , I mean , there the point of interest to the group was primarily that , um ,  the , uh  the system that we had that was based on H T K , that 's used by , you know ,  all the participants in Aurora ,  was so much worse  than the  than the S R\nEverybody .\nAnd the interesting thing is that even though ,  yes , it 's a digits task and that 's a relatively small number of words and there 's a bunch of digits that you train on ,  it 's just not as good as having a  a l very large amount of data and training up a  a  a nice good big  HMM . Um , also you had the adaptation in the SRI system , which we didn't have in this . Um . So . Um .\nAnd we know  Di - did I send you some results without adaptation ?\nNo .\nI s I think Stephane , uh , had seen them .\nOr if you did , I didn't include them , cuz it was\nSo\nYeah , I think I did , actually . So there was a significant loss from not doing the adaptation .\nYeah .\nUm . A  a  a couple percent or some I mean  Well , I don't know it  Overall  Uh , I  I don't remember , but there was  {nonvocalsound} there was a significant , um , loss or win  from adaptation  with  with adaptation . And , um , that was the phone - loop adaptation . And then there was a very small  like point one percent on the natives  uh , win from doing , um , you know , adaptation to  the recognition hypotheses . And  I tried both means adaptation and means and variances , and the variances added another  or subtracted another point one percent . So ,  it 's , um  that 's the number there . Point six , I believe , is what you get with both , uh , means and variance adaptation .\nRight .\nBut I think one thing is that , uh , I would presume  Hav - Have you ever t  Have you ever tried this exact same recognizer out on the actual TI - digits test set ?\nThis exact same recognizer ? No .\nIt might be interesting to do that . Cuz my  my  cuz my sense , um\nBut  but , I have  I mean , people  people at SRI are actually working on digits .\nI bet it would do even slightly better .\nI could  and they are using a system that 's , um  you know , h is actually trained on digits , um , but h h otherwise uses the same , you know , decoder , the same , uh , training methods , and so forth ,\nMm - hmm .\nand I could ask them what they get  on TI - digits .\nYeah , bu although I 'd be  I think it 'd be interesting to just take this exact actual system so that these numbers were comparable\nMm - hmm .\nand try it out on TI - digits .\nWell , Adam knows how to run it ,\nYeah .\nYeah . No problem .\nso you just make a f\nYeah . Yeah . Cuz our sense from the other  from the Aurora , uh , task is that\nAnd try it with TI - digits ?\nMm - hmm .\nI mean , cuz we were getting sub one percent  numbers on TI - digits also with the tandem thing .\nMm - hmm .\nSo ,  one  so there were a number of things we noted from this .\nMmm .\nOne is , yeah , the SRI system is a lot better than the HTK\nHmm .\nthis , you know , very limited training HTK system .\nMm - hmm .\nUh , but the other is that , um , the digits  recorded here in this room with these close mikes , i uh , are actually a lot harder than the  studio - recording TI - digits . I think , you know , one reason for that , uh , might be that there 's still  even though it 's close - talking , there still is some noise and some room acoustics .\nMm - hmm . Mm - hmm .\nAnd another might be that , uh , I 'd  I would presume that in the studio , uh , uh , situation recording read speech that if somebody did something a little funny or n pronounced something a little funny or made a little  that they didn't include it ,\nThey didn't include it .\nthey made them do it again .\nWhereas , I took out  the ones that I noticed that were blatant  that were correctable .\nMmm . Yeah .\nSo that , if someone just read the wrong digit , I corrected it .\nYeah .\nAnd then there was another one where Jose couldn't tell whether  I couldn't tell whether he was saying zero or six . And I asked him and he couldn't tell either .\nHmm .\nSo I just cut it out .\nYeah .\nYou know , so I just e edited out the first , i uh , word of the utterance . Um , so there 's a little bit of correction but it 's definitely not as clean as TI - digits . So my expectations is TI - digits would , especially  I think TI - digits is all  American English .\nMm - hmm .\nRight ? So it would probably do even a little better still on the SRI system , but we could give it a try .\nWell . But  remember , we 're using a telephone bandwidth front - end here , uh , on this , uh  on this SRI system , so ,  um , I was  I thought that maybe that 's actually a good thing because it  it gets rid of some of the  uh , the noises , um , you know , in the  the  below and above the  um , the , you know , speech bandwidth\nMm - hmm . Mm - hmm .\nand , um , I suspect that to get sort of the last bit out of these higher - quality recordings you would have to in fact , uh , use models that , uh , were trained on wider - band data . And of course we can't do that or\nWha - what 's TI - digits ? I thought t\nIt 's wide - band , yeah . It 's  in  in fact , we looked it up\nIt is wide - band . OK .\nand it was actually twenty kilohertz sampling .\nOh , that 's right . I  I did look that up .\nMm - hmm .\nI couldn't remember whether that was TI - digits or one of the other digit tasks .\nYeah .\nRight . But  but , I would  Yeah . It 's  it 's easy enough to try , just run it on\nYeah .\nMm - hmm .\nSee w\nSo , Morgan , you 're getting a little breath noise .\nNow , eh , does\nYou might wanna move the mike down a little bit .\none  one issue  one issue with  with that is that  um , the system has this , uh , notion of a speaker to  which is used in adaptation , variance norm uh , you know , both in , uh , mean and variance normalization and also in the VTL  estimation .\nMm - hmm .\nSo\nYeah , I noticed the script that extracted it .\nDo y ? Is  ? So does  so th so does  does , um ,  the TI - digits database have speakers that are known ?\nYep . Yep .\nAnd is there  is there enough data or a comparable  comparable amount of data to  to what we have in our recordings here ?\nThat I don't know . I don't know . I don't know how many speakers there are ,\nYeah .\nand  and how many speakers per utterance .\nOK .\nWell , the other thing would be to do it without the adaptation and compare to these numbers without the adaptation . That would\nRight . Uh , but I 'm not so much worried about the adaptation , actually , than  than the , um ,  um  the , uh , VTL estimation .\nRight .\nIf you have only one utterance per speaker you might actually screw up on estimating the  the warping , uh , factor . So , um\nI strongly suspect that they have more speakers than we do . So , uh\nRight . But it 's not the amount of speakers , it 's the num it 's the amount of data per speaker .\nRight . So we  we could probably do an extraction that was roughly equivalent .\nRight . Right .\nUm .\nSo\nSo , although I  I sort of know how to run it , there are a little  a f few details here and there that I 'll have to  dig out .\nOK . The key  So th the system actually extracts the speaker ID from the waveform names .\nRight . I saw that .\nAnd there 's a  there 's a script  and that is actually all in one script . So there 's this one script that parses waveform names and extracts things like the , um , speaker , uh , ID or something that can stand in as a speaker ID . So , we might have to modify that script to recognize the , um , speakers ,  um , in the  in the , uh , um ,  TI - digits  database .\nRight . Right . And that , uh\nOr you can fake  you can fake  names for these waveforms that resemble the names that we use here for the  for the meetings .\nRight .\nThat would be the , sort of  probably the safest way to do\nI might have to do that anyway to  to do  because we may have to do an extract to get the  amount of data per speaker about right .\nUh - huh .\nThe other thing is , isn't TI - digits isolated digits ?\nRight .\nOr is that another one ? I 'm  I looked through a bunch of the digits t corp corpora , and now they 're all blurring .\nMm - hmm .\nCuz one of them was literally people reading a single digit . And then others were connected digits .\nYeah . Most of TI - digits is connected digits , I think .\nOK .\nThe  I mean , we had a Bellcore corpus that we were using . It was   that 's  that was isolated digits .\nMaybe it 's the Bell Gram . Bell Digits . Alright .\nUm .\nBy the way , I think we can improve these numbers if we care to compr improve them  by , um ,  not starting with the Switchboard models but by taking the Switchboard models and doing supervised adaptation on a small amount of digit data collected in this setting .\nYep .\nBecause that would adapt your models to the room acoustics and f for the far - field microphones , you know , to the noise . And that should really improve things , um , further . And then you use those adapted models , which are not speaker adapted but sort of acous you know , channel adapted\nChannel adapted .\nuse that as the starting models for your speaker adaptation .\nYeah .  But the thing is , uh  I mean , w when you  it depends whether you 're ju were just using this as a   a starter task for  you know , to get things going for conversational or if we 're really interested i in connected digits . And I  I think the answer is both . And for  for connected digits over the telephone you don't actually want to put a whole lot of effort into adaptation\nWell , I don't know .\nbecause  somebody  gets on the phone and says a number and then you just want it . You don't  don't , uh\nThis is  this  that one 's better .\nRight .\nMm - hmm .\nUm , but , you know , I  uh , my impression was that you were actually interested in the far - field microphone , uh , problem , I mean . So , you want to  you want to  That 's the obvious thing to try .\nOh . Oh .\nRight .\nRight ? Then , eh  because you  you don't have any\nYeah .\nThat 's where the most m acoustic mismatch is between the currently used models and the  the r the set up here .\nRight .\nSo .\nYeah . So that 'd be anoth another interesting data point .\nMm - hmm .\nI mean , I  I guess I 'm saying I don't know if we 'd want to do that as the  as\nOther way .\nOther way . Liz\nNow you 're all watching me .\nIt f it clips over your ears .\nAlright . This way .\nThere you go .\nIf you have a strong fe if you have a strong preference , you could use this .\nYou 're all watching . This is terrible .\nIt 's just we  we think it has some spikes . So , uh , we  we didn't use that one .\nI 'll get it .\nBut you could if you want .\nYeah . At any rate , I don't know if w\nI don't know . And Andre - Andreas , your  your microphone 's a little bit low .\nYeah .\nIt is ?\nI don't know if we wanna use that as the\nYeah .\nUh , it pivots .\nUh .\nSo if you see the picture\nIt  it  like this .\nI I\nand then you have to scr\nI  I already adjusted this a number of times .\nEh .\nI  I\nYeah , I think these mikes are not working as well as I would like .\ncan't quite seem to  Yeah , I think this contraption around your head is not  working so well .\nToo many adju too many adjustments . Yeah . Anyway , what I was saying is that I  I think I probably wouldn't want to see that as sort of like the norm , that we compared all things to .\nThat looks good . Yeah .\nTo , uh , the  to have  have all this ad all this , uh , adaptation . But I think it 's an important data point , if you 're  if  Yeah .\nRight .\nUm . The other thing that  that , uh  of course , what Barry was looking at was  was just that , the near versus far . And , yeah , the adaptation would get  th some of that .\nMm - hmm .\nBut , I think even  even if there was , uh , only a factor of two or something , like I was saying in the email , I think that 's   that 's a big factor . So\nMm - hmm .\nN\nLiz , you could also just use the other mike if you 're having problems with that one .\nWell .\nOK .\nYeah . This would be OK . We  we  we think that this has spikes on it ,\nIt 's this thing 's  This is too big for my head .\nso it 's not as good acoustically ,\nYeah , basically your ears are too big .\nbut\nI mean , mine are too . E th everybody 's ears are too big for these things .\nNo , my  my  But this is too big for my head . So , I mean ,   it doesn't  you know , it 's sit\nUh\nWell , if you 'd rather have this one then it 's\nOK .\nYeah .\nOh , well .\nIt 's  great .\nSo the  To get that , uh , pivoted this way , it pivots like this .\nNo this way . Yeah .\nYeah . There you go .\nAnd there 's a screw that you can tighten .\nAnd then it\nRight .\nRight .\nI already  tried to get it close .\nGood .\nSo if it doesn't bounce around too much , that 's actually good placement .\nOK .\nThat looks good .\nBut it looks like it 's gonna bounce a lot .\nSo , where were we ? Uh   Yeah .\nYeah .\nDigits . Adaptation .\nUh , adaptation , non - adaptation , um , factor of two , um  Oh , yeah . I know what I was go w\nWhat k u By the way , wh what factor of two did you  ?\nOh , no , no .\nI mean\nIt 's tha that  that we were saying , you know , well is  how much worse is far than near , you know .\nOh , th OK .\nAnd I mean it depends on which one you 're looking at ,\nThat factor of two .\nbut for the everybody , it 's  little under a factor or two .\nMm - hmm .\nYeah . I  I know what I was thinking was that maybe , uh , i i we could actually t t try at least looking at , uh , some of the  the large vocabulary speech from a far microphone , at least from the good one .\nMm - hmm .\nI mean , before I thought we 'd get , you know , a hundred and fifty percent error or something , but if   if , uh  if we 're getting thirty - five , forty percent or something ,  u um\nMm - hmm .\nActually if you run , though , on a close - talking mike over the whole meeting , during all those silences , you get , like , four hundred percent word error .\nMm - hmm . Right . I understand . But doing the same kind of limited thing\nOr  or some high number .\nYeah , sure . Get all these insertions . But I 'm saying if you do the same kind of limited thing  as people have done in Switchboard evaluations or as  a\nYeah . Where you know who the speaker is and there 's no overlap ? And you do just the far - field for those regions ?", "topic_id": 0, "keywords": "alignments, alignment, schedules, meetings, meeting", "dialogue_id": 2}, {"text": "Yeah . Yeah . The same sort of numbers that we got those graphs from . Right ?\nCould we do exactly the same thing that we 're doing now , but do it with a far - field mike ?\nYeah , do it with one of  on\nCuz we extract the times from the near - field mike , but you use the acoustics from the far - field mike .\nRight . I understand that . I just meant that  so you have  three choices . There 's , um  You can use times where that person is talking only from the transcripts but the segmentations were  were synchronized . Or you can do a forced alignment on the close - talking to determine that , the you know , within this segment , these really were the times that this person was talking and elsewhere in the segment other people are overlapping and just front - end those pieces . Or you can run it on the whole data , which is  which is , you know , a\nBut  but  but how did we get the  how did we determine the links , uh , that we 're testing on in the stuff we reported ?\nIn the H L T paper we took  segments that are channel  time - aligned , which is now h being changed in the transcription process , which is good , and we took cases where the transcribers said there was only one person talking here , because no one else had time  any words in that segment and called that \" non - overlap \" .\nAnd tha And that 's what we were getting those numbers from .\nYes . Tho - good  the good numbers .\nRight .\nThe bad numbers were from  the segments where there was overlap .\nWell , we could start with the good ones .\nYeah .\nBut anyway  so I think that we should try it once with  the same conditions that were used to create those , and in those same segments just use one of the P Z\nRight . So we  we can do that . Yeah .\nAnd then , you know , I mean , the thing is if we were getting , uh  what , thirty - five , forty percent , something like that on  on that particular set , uh , does it go to seventy or eighty ?\nRight .\nOr , does it use up so much memory we can't decode it ?\nIt might also depend on which speaker th it is and how close they are to the PZM ?\nUh\nI don't know how different they are from each other .\nYou want to probably choose the PZM channel that is closest to the speaker .\nTo be best\nYeah .\nFor this particular digit ones , I just picked that one .\nf\nWell\nOK . So we would then use that one , too ,\nSo\nOh , OK .\nThis is kind of central .\nor  ?\nYou know , it 's  so i but I would  I 'd pick that one . It 'll be less good for some people than for other , but I  I 'd like to see it on the same  exact same data set that  that we did the other thing on .\nActually  I sh actually should 've picked a different one ,\nRight ?\nbecause  that could be why the PDA is worse . Because it 's further away from most of the people reading digits .\nIt 's further away . Yeah . Yeah .\nThat 's probably one of the reasons .\nHmm . Mm - hmm .\nWell , yeah . You could look at , I guess , that PZM or something .\nYep .\nBut the other is , it 's very , uh  I mean , even though there 's  I 'm sure the f f the  the SRI , uh , front - end has some kind of pre - emphasis , it 's  it 's , uh   still , th it 's picking up lots of low - frequency energy .\nMm - hmm .\nSo , even discriminating against it , I 'm sure some of it 's getting through . Um . But , yeah , you 're right . Prob - a part of it is just the distance .\nAnd aren't these pretty bad microphones ?\nYep .\nI mean\nWell , they 're bad . But , I mean , if you listen to it , it sounds OK . You know ? u Yeah .\nYeah . When you listen to it , uh , the PZM and the PDA  Yeah , th the PDA has higher sound floor but not by a lot . It 's really pretty  uh , pretty much the same .\nI just remember you saying you got them to be cheap on purpose . Cheap in terms of their quality . So .\nWell , they 're  twenty - five cents or so .\nTh - we wanted them to be  to be typical of what would be in a PDA .\nYeah .\nMm - hmm .\nSo they are  they 're not the PZM three hundred dollar type . They 're the twenty - five cent ,\nYeah .\nbuy them in packs of thousand type .\nI see .\nBut , I mean , the thing is people use those little mikes for everything because they 're really not bad .\nEverything .\nMm - hmm .\nI mean , if you 're not  doing something ridiculous like feeding it to a speech recognizer , they  they   they  you know , you can hear the sou hear the sounds just fine .\nRight .\nYou know , it 's  They  I mean , i it 's more or less the same principles as these other mikes are built under , it 's just that  there 's less quality control . They just , you know , churn them out and don't check them . Um . So . So that was  Yeah . So that was i interesting result . So like I said , the front - end guys are very much interested in  in this is as  as well and\nSo  so , but where is this now ? I mean , what 's  where do we go from here ?\nYeah . That was gonna be my question .\nI mean , we  so we have a  we have a  a system that works pretty well but it 's not , you know , the system that people here are used to using  to working with .\nWell , I think what we wanna do is we want to  eh ,\nSo what  what do we do now ?\nand we 've talked about this in other  contexts  we want to  have the ability to feed it different features .\nMm - hmm .\nAnd then , um ,  from the point of view of the front - end research , it would be s uh , substituting for HTK .\nOK . OK .\nI think that 's the key thing . And then if we can feed it different features , then we can try all the different things that we 're trying there .\nOK . Alright .\nAnd then , um , uh , also Dave is  is thinking about using the data in different ways , uh , to  um , uh , explicitly work on reverberation\nMm - hmm .\nstarting with some techniques that some other people have  found somewhat useful , and  Yeah .\nOK . So  so the key  thing that 's missing here is basically the ability to feed , you know , other features  i into the recognizer\nRight .\nand also then to train the system .\nRight .\nOK . And , uh , es I don't know when Chuck will be back but that 's exactly what he  he 's gonna\nH h He 's  he 's sort of back , but he drove for fourteen hours an and wasn't gonna make it in today .\nOh , OK . So , I think that 's one of the things that he said he would be working on . Um .\nYeah .\nJust sort of t to make sure that  we can do that\nYeah .\nand  Um .\nRight .\nIt 's  uh , I mean , the  the front - end is f i tha that 's in the SRI recognizer is very nice in that it does a lot of things on the fly but it unfortunately  is not  designed and , um   like the , uh , ICSI system is , where you can feed it from a pipeline of  of the command . So , the  what that means probably for the foreseeable future is that you have to , uh , dump out , um  you know , if you want to use some new features , you have to dump them into individual files and  give those files to the recognizer .\nWe do  we tend to do that anyway .\nOK .\nOh . So , although you  you can pipe it as well , we tend to do it that way because that way you can concentrate on one block and not keep re - doing it over and over .\nOh , OK .\nYeah .\nAlright .\nYeah . So I 've  I\nSo tha that 's exactly what the P - file  is for .\nYeah .\nYeah , the  the  the cumbersome thing is  is , um  is that you actually have to dump out little  little files .\nUh\nSo for each segment that you want to recognize  you have to  dump out  a separate file .\nUh - huh .\nJust like i th like th as if there were these waveform segments , but instead you have sort of feature file segments . But , you know  So .\nCool . OK . So the s the  the next thing we had on the agenda was something about alignments ?\nOh . Yes , we have  I don't know , did you wanna talk about it , or  ? I can give a  I was just telling this to Jane and  and  W we  we were able to get some definite improvement on the forced alignments by looking at them first and then realizing the kinds of errors  that were occurring and um , some of the errors occurring very frequently are just things like the first word being moved to as early as possible in the recognition , which is a um , I think was both a  a pruning  problem and possibly a problem with needing constraints on word locations . And so we tried both of these st things . We tried saying  I don't know , I got this  whacky idea that  just from looking at the data , that when people talk  their words are usually chunked together . It 's not that they say one word and then there 's a bunch of words together . They 're  might say one word and then another word far away if they were doing just backchannels ? But in general , if there 's , like , five or six words and one word 's far away from it , that 's probably wrong on average . So , um  And then also , ca the pruning , of course , was too  too severe .\nSo that 's actually interesting . The pruning was the same value that we used for recognition . And we had lowered that  we had used tighter pruning after Liz ran some experiments showing that , you know , it runs slower and there 's no real difference in\nActually it was better with  slightly better or about th\nNo gain .\nit was the same with tighter pruning .\nRight . So for free recognition , this  the lower pruning value is better .\nIt 's probably cuz the recognition 's just bad en at a point where it 's bad enough that  that you don't lose anything .\nYou  Correct . Right . Um , but it turned out for  for  to get accurate alignments it was really important to open up the pruning significantly .\nRight .\nHmm .\nUm  because otherwise it would sort of do greedy alignment , um , in regions where there was no real speech yet from the foreground speaker .\nMm - hmm .\nUm ,  so that was one big factor that helped improve things and then the other thing was that , you know , as Liz said the  we f enforce the fact that , uh , the foreground speech has to be continuous . It cannot be  you cannot have a background speech hypothesis in the middle of the foreground speech . You can only have background speech at the beginning and the end .\nYeah . I mean , yeah , it isn't always true , and I think what we really want is some clever way to do this , where , um , you know , from the data or from maybe some hand - corrected alignments from transcribers that things like words that do occur just by themselves  a alone , like backchannels or something that we did allow to have background speech around it\nYeah .\nthose would be able to do that ,\nSorry .", "topic_id": 1, "keywords": "transcripts, transcription, backchannels, segments, talking", "dialogue_id": 2}, {"text": "but the rest would be constrained . So , I think we have a version that 's pretty good for the native speakers . I don't know yet about the non - native speakers . And , um , we basically also made noise models for the different  sort of grouped some of the  mouth noises together . Um , so , and then there 's a background speech model . And we also  There was some neat  or , interesting cases , like there 's one meeting where ,  um , Jose 's giving a presentation and he 's talking about , um , the word \" mixed  signal \" and someone didn't understand , uh , that you were saying \" mixed \"  I think , Morgan . And so your speech - ch was s saying something about mixed signal .\nYeah , yeah .\nAnd the next turn was a lot of people saying \" mixed \" , like \" he means mixed signal \" or \" I think it 's mixed \" . And the word \" mixed \" in this segment occurs , like , a bunch of times .\nSh\nAnd Chuck 's on the lapel here , and he also says \" mixed \" but it 's at the last one , and of course the aligner th aligns it everywhere else to everybody else 's \" mixed \" ,\nYeah .\ncuz there 's no adaptation yet . So there 's   I think there 's some issues about  u We probably want to adapt at least the foreground speaker . But , I guess Andreas tried adapting both the foreground and a background generic speaker , and that 's actually a little bit of a f funky model . Like , it gives you some weird alignments , just because often the background speakers match better to the foreground than the foreground speaker .\nOh\nYeah .\nSo there 's some things there ,\nOh .\nespecially when you get lots of the same words , uh , occurring in the\nWell , the  I  I think you can do better by  uh , cloning  so we have a reject phone . And you  and what we wanted to try with  you know , once we have this paper written and have a little more time ,  uh , t cloning that reject model and then one copy of it would be adapted to the foreground speaker to capture the rejects in the foreground , like fragments and stuff , and the other copy would be adapted to the background speaker .\nRight . I mean , in general we actually\nAnd\nRight now the words like  partial words are  reject models and you normally allow those to match to any word .\nMm - hmm .\nBut then the background speech was also a reject model , and so this constraint of not allowing rejects in between  you know , it needs to differentiate between the two . So just sort of working through a bunch of debugging kinds of issues .\nRight .\nAnd another one is turns , like people starting with  \" well I think \" and someone else is  \" well how about \" . So the word \" well \" is in this  in this  segment multiple times , and as soon as it occurs usually the aligner will try to align it to the first person who says it . But then that constraint of sort of  uh , proximity constraint will push it over to the person who really said it in general .\nIs the proximity constraint a hard constraint , or did you do some sort of probabilistic weighting distance , or  ?\nWe  we didn't\nRight now it 's a kluge .\nNo . We  w OK . We  it 's straightforward to actually just have a  a penalty that doesn't completely disallows it but discourages it . But , um , we just didn't have time to play with , you know , tuning yet another  yet another parameter .\nThe ve level . Yeah .\nYeah .\nAnd really the reason we can't do it is just that we don't have a  we don't have ground truth for these . So ,  we would need a hand - marked , um ,  word - level alignments or at least sort of the boundaries of the speech betw you know , between the speakers . Um , and then use that as a reference and tune the parameters of the  of the model , uh , to op to get the best  performance .\nYeah .\nG given  I  I mean , I wa I wa I was gonna ask you anyway , uh , how you assessed that things were better .\nMm - hmm .\nI looked at them . I spent two days  um , in Waves\nOK .\nOh , it was painful because  the thing is , you know the alignments share a lot in common , so  And you 're  yo you 're looking at these segments where there 's a lot of speech . I mean , a lot of them have a lot of words . Not by every speaker\nYeah .\nbut by some speaker there 's a lot of words . No , not\nYeah .\nI mean that if you look at the individual segments from just one person you don't see a lot of words ,\nJu\nYeah .\nbut altogether you 'll see a lot of words up there .\nYeah .\nMm - hmm .\nYeah .\nAnd so the reject is also mapping and pauses  So I looked at them all in Waves and just lined up all the alignments , and , at first it sort of looked like a mess and then the more I looked at it , I thought \" OK , well it 's moving these words leftward and  \" You know , it wasn't that bad . It was just doing certain things wrong . So  But , I don't , you know , have time to l  to look at all of them and it would be really useful to have , like , a  a transcriber who could use Waves , um , just mark , like , the beginning and end of the foreground speaker 's real words  like , the beginning of the first word , the end of the last word  and then we could , you know , do some adjustments .\nYeah . I  OK . I have to ask you something , is i does it have to be Waves ? Because if we could benefit from what you did , incorporate that into the present transcripts ,  that would help .\nNo .\nAnd then , um , the other thing is , I believe that I did hand So . One of these transcripts was gone over by a transcriber and then I hand - marked it myself so that we do have , uh , the beginning and ending of individual utterances . Um , I didn't do it word level ,\nMm - hmm .\nbut  but in terms\nMm - hmm .\nSo I  so for  for one of the N S A groups . And also I went back to the original one that I first transcribed and  and did it w uh , w uh , utterance by utterance for that particular one . So I think you do have  if that 's a sufficient unit , I think that you do have hand - marking for that . But it 'd be wonderful to be able to  benefit from your Waves stuff .\nMm - hmm .\nWe don't care what  what tool you use .\nYeah . I mean , if  if you can , um  if you wanna\nOK . I used it in Transcriber\nU uh\nand it 's  it 's in the\nwell , Jane and I were  just in terms of the tool , talking about this . I guess Sue had had some  reactions . You know , interface - wise if you 're looking at speech , you wanna be able to know really where the words are . And so ,  we can give you some examples of sort of what this output looks like ,\nYeah , that 's right . Middle of the word , or\num , and see if you can in maybe incorporate it into the Transcriber tool some way , or\nWell , I th I 'm thinking just ch e e incorporating it into the representation .\nUm .\nI mean , if it 's  if it 's\nYou mean like  Yeah , word start insights .\nif you have start points , if you have , like , time tags ,\nRight .\nwhich is what I assume . Isn't that what  what you  ? Well , see , Adam would be\nYeah , whatever you use .\nYeah .\nI mean , we convert it to this format that the , um , NIST scoring tool unders uh , CTM . Conversation Time - Marked file . And  and then that 's the  that 's what the\nI think Transcriber , uh , outputs CTM .\nIf it  ? OK .\nYeah .\nSo you would know this more than I would .\nI think so .\nSo , I mean\nIt seems like she  if she 's g if she 's moving time marks around ,\nRight .\nsince our representation in Transcriber uses time marks , it seems like there should be some way of  of using that  benefitting from that .\nRight .\nYeah , it wou the advantage would just be that when you brought up a bin you would be able  if you were zoomed in enough in Transcriber to see all the words ,\nMm - hmm .\nyou would be able to , like , have the words sort of located in time , if you wanted to do that .\nSo  so if we e e even just had a  a  It sounds like w we   we almost do .\nSo .\nUh , if we  We have two .\nWe have two .\nYeah . Just ha uh , trying out  the alignment  procedure that you have on that\nMm - hmm .\nyou could actually get something , um  uh , uh , get an objective measure . Uh\nMm - hmm .\nYou mean on  on the hand - marked , um  So we  we only r hav I only looked at actually alignments from one meeting that we chose ,\nYeah .\nI think MR four , just randomly , um  And\nActually , not randomly .\nNot randomly\nWe knew  we knew that it had these insertion errors from\nIt had sort of  average recognition performance in a bunch of speakers\nYeah . Yeah .\nand it was a Meeting Recorder meeting . Um . But , yeah , we should try to use what you have . I did re - run recognition on your new version of MR one .\nOh , good .\nI  I mean the  the one with Dan  Ellis in it  and Eric .\nGood ! Uh - huh . Yeah , exactly . Yeah . Yeah .\nI don't think that was the new version .\nUm  That  Yeah , actually it wasn't the new new , it was the medium new .\nOK .\nBut  but we would  we should do the  the latest version .\nOK .\nYeah .\nIt was the one from last week .\nYou  did you adjust the  the utterance times , um , for each channel ?\nYes . Yes , I did . And furthermore , I found that there were a certain number where   not  not a lot , but several times I actually  moved an utterance from  Adam 's channel to Dan 's or from Dan 's to Adam 's . So there was some speaker identif And the reason was because  I transcribed that at a point before   uh , before we had the multiple audio available f so I couldn't switch between the audio . I  I transcribed it off of the mixed channel entirely , which meant in overlaps , I was at a  at a terrific disadvantage .\nRight . Right .\nIn addition it was before the channelized , uh , possibility was there . And finally I did it using the speakers of my , um   of  you know , off the CPU on my  on my machine cuz I didn't have a headphone .\nRight .\nSo it @ @ , like , I mean  Yeah , I  I mean , i in retrospect  it would 've been good to ha  have got I should 've gotten a headphone . But in any case , um , thi this is  this was transcribed in a  in a ,  uh , less optimal way than  than the ones that came after it , and I was able to  you know , an and this meant that there were some speaker identif identifications which were changes .\nWell , I know there were some speaker labelling problems , um , after interruptions .\nYeah . Fixed that .\nIs that what you 're referring to ? I mean , cuz there 's this one instance when , for example , you 're running down the stairs .\nOh , well\nI remember this meeting really well .\nYeah .\nDon  Don has had   He knows  he can just read it like a play .\nRight . It 's a  Yeah , I 've  I 've  I 'm very well acquainted with this meeting .\nYeah .\nYeah , I can s\n\" And then she said , and then he said . \"\nYeah , I know it by heart . So , um ,  there 's one point when you 're running down the stairs .\nUh - oh .\nRight ? And , like , there 's an interruption . You interrupt somebody , but then there 's no line after that . For example , there 's no speaker identification after that line .\nUh - huh .\nIs that what you 're talking about ? Or were there mislabellings as far as , like , the a Adam was  ?\nThat was fixed , um , before  i i i I think I I think I understood that pretty\nYeah . Cuz I thought I let you know about that .\nThank you for mentioning . Yeah , no , tha that  That I think went away a couple of versions ago ,\nYeah . OK .\nbut it 's good to know .\nBut you 're actually saying that certain , uh , speakers were mis mis - identified .\nYeah . So , with  under  um , uh , listening to the mixed channel , there were times when , as surprising as that is , I got Adam 's voice confused with Dan 's and vice versa\nOK .\nnot for long utterances ,\nOK .\nYeah .\nbut jus just a couple of places ,\nMm - hmm .\nand embedde embedded in overlaps . The other thing that was w interesting to me was that I picked up a lot of , um , backchannels which were hidden in the mixed signal ,\nRight .\nwhich , you know , I mean , you c not  not too surprising . But the other thing that  I  I hadn't thought about this , but I thou I wanted to raise this when you were  uh , with respect to also a strategy which might help with the alignments potentially , but that 's  When I was looking at these backchannels , they were turning up usually   very often in  w well , I won't say \" usually \"  but anyway , very often , I picked them up in a channel  w which was the person who had asked a question . S so , like , someone says \" an and have you done the so - and - so ? \" And then there would be backchannels , but it would be the person who asked the question . Other people weren't really doing much backchannelling . And , you know , sometimes you have the  Yeah , uh - huh .\nWell , that 's interesting . Yeah .\nI mean , i it wouldn't be perfect , but  but it does seem more natural to give a backchannel when  when you 're somehow involved in the topic ,\nNo , that 's really interesting .\nMm - hmm .\nand the most natural way is for you to have initiated the topic by asking a question .\nWell ,\nThat 's interesting .\nI think  No . I think it 's  actually I think what 's going on is backchannelling is something that happens in two - party conversations .\nMm - hmm .\nAnd if you ask someone a question , you essentially initiating a little two - party conversation .\nYeah .\nWell , actu Yeah , when we looked at this\nExactly .\nSo then you 're  so and then you 're expected to backchannel because the person is addressing you directly and not everybody .\nExactly . Exactly my point . An - and so this is the expectation thing that  uh , uh ,\nYeah . Yeah .\nMm - hmm .\nRight .\njust the dyadic\nRight .\nBut in addition , you know , if someone has done this analysis himself and isn't involved in the dyad , but they might also give backchannels to verify what  what the answer is that this  that the  the answerer 's given\nH\nRight .\nI tell you , I say  I say \" uh - huh \" a lot ,\nIt 's\nThere you go .\nWell , but it 's interesting cuz , uh\nwhile people are talking to each other .\nBut there are fewer  I think there are fewer \" uh - huhs \" .\nThere you go . Yeah . Yeah .\nI mean , just from  We were looking at word frequency lists to try to find the cases that we would allow to have the reject words in between in doing the alignment . You know the ones we wouldn't constrain to be next to the other words .\nOh , yeah .\nAnd \" uh - huh \" is not as frequent as it sort of would be in Switchboard , if you looked at just a word frequency list of one - word short utterances . And \" yeah \" is way up there , but not \" uh - huh \" . And so I was thinking thi it 's not like  you 're being encouraged by everybody else to keep  talking in the meeting . And uh , that 's all , I I 'll stop there , cuz I I think what you say makes a lot of sense .\nWell , that 's right . And that would\nBut it was sort of\nWell , an And what you say is the  is the re uh , o other side of this , which is that , you know , so th there are lots of channels where you don't have these backchannels , w when a question has been asked and  and these\nRight . There 's just probably less backchannelling in general ,\nMm - hmm . So that 's good news , really .\neven if you consider every other person altogether one person in the meeting , but we 'll find out anyway . We were  I guess the other thing we 're  we 're  I should say is that we 're gonna , um try  compare this type of overlap analysis to Switchboard , where\nAnd\nand CallHome , where we have both sides , so that we can try to answer this question of , you know ,  is there really more overlap in meetings or is it just because we don't have the other channel in Switchboard\nMm - hmm .\nMm - hmm .\nand we don't know what people are doing . Try to create a paper out of that .\nYeah . I mean , y y you folks have probably  already told me , but were  were you intending to do a Eurospeech submission , or  ?\nUm , you mean the one due tomorrow ?\nYeah .\nYeah . Well , we 're still , like , writing the scripts for doing the research , and we will  Yes , we 're gonna try .\nMm - hmm .\nAnd I was telling Don , do not  take this as an example of how people should work .\nDo as I say ,\nThat 's r\nSo ,  we will try .\ndon't do as I do . Yeah .\nIt 'll probably be a little late ,\nWell\nbut I 'm gonna try it .\nIt is different . In previous years , Eurospeech only had the abstract due by now , not the full paper .\nRight .\nRight .\nAnd so all our timing was off . I 've given up on trying to do digits . I just don't think that what I have so far makes a Eurospeech paper .\nWell , I 'm no We may be in the same position , and I figured  we 'll try , because that 'll at least get us to the point where we have  We have this really nice database format that Andreas and I were working out that  It  it 's not very fancy . It 's just a ASCII line by line format , but it does give you information\nIt 's the  it 's the spurt format .\nIt  Yeah , we 're calling these \" spurts \" after Chafe . I was trying to find what 's a word for  a continuous region with  pauses around it ?\nHmm .\nYeah . I know that th the Telecom people use  use \" spurt \" for that .\nGood .\nThey do ? Oh !\nYes .\nOh .\nOh .\nAnd that 's  I mean , I  I was using that for a while when I was doing the rate of speech stuff ,\nI would jus\nbecause I  because I looked up in some books and I found  OK , I wanna find a spurt  in which\nAh , right ! It 's just , like , defined by the acoustics .\nand  an because  cuz it 's another question about how  many pauses they put in between them .\nHorrible .\nRight .\nBut how fast do they do  the words within the spurt ?\nRight .\nYeah .\nWell , that 's what we were calling spurt ,\nIt 's gonna\nyou know \" Burst \" also ?\nBurst .\nIsn't \" burst \" is used also ?\nso\nSpurt has the horrible name overloading with other  with hardware at ICSI .\nHere . Just very locally , yeah .\nWell , well , Chafe had this wor I think it was Chafe , or somebody had a  the word \" spurt \" originally ,\nBut  but that just\nHere @ @\nand so I  But tha that 's good to know .\nActually\nWas thi it 's Chafe ?\nWell , see , I know S Sue wrote about spurts of development .\nSo maybe we should talk\nMaybe it was Sue  ? Y\nBut , in any case , I think it 's a good term ,\nSo we have spurts and we have spurt - ify dot shell and spurt - ify\nYeah .\nand , uh\nHmm !\nYeah .\nAnd ma maybe  maybe Chafe did .\nUh .\nAnd then it 's got all  it 's a verb now .\nI know  I know Ch - Chafe dealt with\nSo s\nThat 's cool .\nW uh , w\nChafe speaks about intonation units .\nYes . Right .\nBut maybe he speaks about spurts as well\nWe\nand I just don't know . Yeah , go ahead .\nI 've heard \" burst \" also .\nSo what we 're doing  uh , this  this is just  maybe someone has s some  some ideas about how to do it better ,\nMmm .\nbut we  So we 're taking these , uh , alignments from the individual channels . We 're  from each alignment we 're producing , uh , one of these CTM files ,\nGreat .\nwhich essentially has  it 's just a linear sequence of words with the begin times for every word and the duration .\nIt looks like a Waves label file almost . Right ?\nAnd  and  and of course\nIt 's just\nRight . But it has  one  the first column has the meeting name , so it could actually contain several meetings . Um . And the second column is the channel . Third column is the , um , start times of the words and the fourth column is the duration of the words . And then we 're , um  OK . Then we have a messy alignment process where we actually insert into the sequence of words the , uh , tags for , like , where  where sentence  ends of sentence , question marks , um ,  various other things .\nYeah . These are things that we had Don\nUh .\nSo , Don sort of , um , propagated the punctuation from the original transcriber\nRight .\nso whether it was , like , question mark or period or ,  um , you know , comma and things like that , and we kept the  and disfluency dashes  uh , kept those in because we sort of wanna know where those are relative to the spurt overlaps\nMm - hmm . Right .\nsp overlaps ,\nSo  so those are actually sort of retro - fitted into the time alignment .\nor\nAnd then we merge all the alignments from the various channels and we sort them by time . And then there 's a  then there 's a process where you now determine the spurts . That is  Actually , no , you do that before you merge the various channels . So you  you id identify by some criterion , which is pause length  you identify the beginnings and ends of these spurts , and you put another set of tags in there to keep those straight .\nMm - hmm .\nAnd then you merge everything in terms of , you know , linearizing the sequence based on the time marks . And then  you extract the individual channels again , but this time you know where the other people start and end talking  you know , where their spurts start and end . And so you extract the individual channels , uh , one sp spurt by spurt as it were . Um , and inside the words or between the words you now have begin and end  tags for overlaps . So , you  you basically have everything sort of lined up and in a form where you can look at the individual speakers and how their speech relates to the other speakers ' speech .\nRight .\nUh , I mean , I think that 's actually really u useful also\nAnd\nbecause even if you weren't studying overlaps , if you wanna get a transcription for the far - field mikes , how are you gonna know which words from which speakers occurred at which times relative to each other ? You have to be able to  get a transcript like  like this anyway , just for doing far - field recognition . So , you know , it 's  it 's sort of\nYeah .\nI thi it 's just an issue we haven't dealt with before , how you time - align things that are overlapping anyway .\nThat 's wonderful .\nSo\nI mean , i I never thought about it before ,\nWell\nAnd  and we\nbut\nY yes .\nIn\nI mean , s when I came up with the original data  suggested data format based on the transcription graph , there 's capability of doing that sort of thing in there .\nRight . But you can't get it directly from the transcription .\nMm - hmm . Yeah , that 's right .\nRight . Well , this is  this is just\nYeah , this is like a poor man 's ver formatting version . But it 's , you know  It 's clean , it 's just not fancy .\nRight .\nUm .\nWell , there 's lots of little things . It 's like there 're twelve different scripts which you run and then at the end you have what you want . But , um , at the very last stage we throw away the actual time information . All we care about is whether  that there 's a certain word was overlapped by someone else 's word . So you sort of  at that point , you discretize things into just having overlap or no overlap . Because we figure that 's about the level of analysis that we want to do for this paper .\nMm - hmm .\nBut if you wanted to do a more fine - grained analysis and say , you know , how far into the word is the overlap , you could do that .\nYeah .\nIt 's just  it 'll just require more\nJust  sort of huge .\nyou know , slightly different\nWhat 's interesting is it 's exactly what , um , i in discussing with , um , Sue about this ,\nYeah .\num , she , um , i i i indicated that that  you know , that 's very important for overlap analysis .\nYeah . It 's  it 's nice to know ,\nRight .\nand also I think as a human , like , I don't always hear these in the actual order that they occur . So I can have two foreground speakers , you know , Morgan an and  um , Adam and Jane could all be talking , and I could align each of them to be starting their utterance at the correct time , and then look where they are relative to each other , and that 's not really what I heard .\nAnd that 's another thing she said .\nCuz it 's just hard to do .\nThis is  This is Bever 's  Bever 's effect ,\nY Yeah .\nwhen  where  In psy ps psycho - linguistics you have these experiments where people have perceptual biases a as to what they hear ,\nIt 's sort of  Yeah , you sort of move things around until you get to a  low information point\nthat  that  Not the best\nand yo then you can bring in the other person . So it 's  actually not even possible , I think , for any person to listen to a mixed signal , even equalize , and make sure that they have all the words in the right order . So , I guess , we 'll try to write this Eurospeech paper .\nMm - hmm . Superb .\nI mean , we will write it . Whether they accept it  late or not , I don't know . Um , and the good thing is that we have  It 's sort of a beginning of what Don can use to link the prosodic features from each file to each other .\nYeah .\nYeah . That 's the good thing about these pape\nSo . i You know , might as well .\nPlus , mayb\nHmm ?\nWe - I ju Otherwise we won't get the work done   on our deadline .\nI don't know , m\nYeah .\nI mean , u u Jane likes to look at data . Maybe , you know , you could  you could look at this format and see if you find anything interesting .\nYeah .\nI don't know .\nYeah .\nNo , it 's  that 's the good thing about these pape paper deadlines and , uh , you know , class projects , and   and things like that ,\nWell , what I 'm thinking is\nYeah .\nYeah .\nRight .\nMm - hmm .\nWell , my\nWell th th the other thing that  that  that yo that you usually don't tell your graduate students is that these deadlines are actually not that , um , you know , strictly enforced ,\nbecause you  you really get g\nForces you to do the work .\nYeah .\nYeah .\nExactly .\nStrict .\nbecause  the\nOh , now it 's out in the public , this  this  this secret information .\nbecause\nRight .\nYeah .\nI think we can ha\nbec b  Nah\nSo\nNo .\nNo .\nNah .\ni Because these  the conference organizers actually have an interest in getting lots of submissions .\nRight .\nRight .\nI mean , a  a monetary interest .\nYeah .\nSo   Um .\nTh - that 's  that 's true .\nAnd good ones , good ones , which sometimes means  a little extra time .\nAnd good submission\nThat 's\nRight .\nThat 's true .\nWell  That 's another issue ,\nBy th by the way , this is totally unfair , you may  you may feel ,\nbut\nbut the  the , uh  the morning meeting folks actually have an  an extra month or so .\nMm - hmm .\nYep .\nYep . The Aurora  there 's a special Aurora\nUh\nWhen\nThere 's a special Aurora session\nOh .\nand the Aurora pe people involved in Aurora have till Ma - uh , early May  or something to turn in their paper .\nMmm .\nOh .\nMmm .\nOh , well maybe we 'll submit to s   Actually\nWell , then you can just  Maybe you can submit the digits paper on e for the Aurora session .\nYeah .\nYeah .\nYeah .\nOh , I could !\nYeah .\nI if it w\nI could submit that to Aurora .\nWell\nThat would be pretty  pretty\nYeah .\ni it has\nYeah .\nS That wouldn't work .\nNo , it wouldn't work .\nIt 's not Aurora .\nIt 's  it 's not the Aurora  I mean , it  it 's  it 's actually the Aurora task .\nMaybe they 'll get s\nAurora 's very specific .\nIt\nWell , maybe it won't be after this  deadline  extension .\nBut  but the people  I mean , a  a paper that is not on Aurora would probably be more interesting at that point\nMaybe they 'll\nbecause everybody 's so sick and tired of the Aurora task .\nYeah .\nOh , I thought you meant this was just the digits section . I didn't know you meant it was Aurora digits .\nYeah .\nWell , no . If you  if you have  it 's to  if you discuss some relation to the Aurora task , like if you use the same\nThis is not the Aurora task . So they just do a little grep for\nDo  uh , d d Do not  do not  we are not setting a good example .\nUm . Well , a relation other than negation , maybe ,\nThis is not a\num . So .\nAnyway .\nI don't know .\nBut the good thing is this does\nWell , I I don't know . I mean , you could  you could do a paper on  what 's wrong with the Aurora task by comparing it to  other ways of doing it .\nHow well does an Aurora system do on  on  you know , on digits collected in a  in this environment ?\nDifferent way . Yeah .\nYeah .\nMaybe .\nMaybe .\nPretty hokey .\nI think it 's a littl little far - fetched . Nah , I mean , the thing is Aurora 's pretty closed community .\nYep .\nI mean , you know , the people who were involved in the   the only people who are allowed to test on that are people who  who made it above a certain threshold in the first round ,\nMm - hmm .\nIt 's very specific .\nuh  w in ninety - nine and it 's  it 's sort of a  it 's  not like a\nWell , that 's maybe why they don't f know that they have a crummy system . I mean , a crummy back - end . No , I mean  I mean , seriously , if you  if you have a very  No , I 'm sorry .\nUh ,  \" beep \"  \" bee \"\nI mean , th\nNo . I didn't mean anybody  any particular system . I meant this H T K back - end .\nOh , you don't like HTK ?\nIf they\nYeah .\nI don't h I don't have any stock in HTK or Entropic or anything .\nNo . I mean , this  it it 's the HTK  that is trained on a very limited amount of data .\nIt 's d it 's very specific .\nRight .\nYeah .\nBut so , if you  But maybe you should , you know , consider more  using more data , or  I mean\nOh , yeah . I  I really think that that 's true . And they i i\nIf yo if you sort of hermetically stay within one task and don't look left and right , then you 're gonna\nBut they  they had\ni But\nThey had something very specific in mind when they designed it . Right ?\nWell , u i\nRight .\nAnd so  so you can  you can argue about maybe that wasn't the right thing to do , but , you know , they  they  they had something specific .\nBut , one of the reasons I have Chuck 's messing around with  with the back - end that you 're not supposed to touch  I mean , for the evaluations , yes , we 'll run a version that hasn't been touched .\nMm - hmm . Mm - hmm .\nBut , uh , one of the reasons I have him messing around with that , because I think it 's sort of an open question that we don't know the answer to . People always say very glibly  that i if you s show improvement on a bad system , that doesn't mean anything , cuz it may not be   show  uh , because , you know , it doesn't tell you anything about the good system .\nMm - hmm .\nAnd I  I 've always sort of felt that that depends . You know , that if some peopl If you 're actually are getting at something that has some  conceptual substance to it , it will port .\nMm - hmm .\nAnd in fact , most methods that people now use were originally tried with something that was not their absolute  best system at some level . But of course , sometimes it doesn't , uh , port . So I think that 's  that 's an interesting question . If we 're getting  three percent error on , uh , u uh , English , uh , nati native speakers ,  um , using the Aurora system , and we do some improvements and bring it from three to two ,  do those same improvements bring , uh , th you know , the SRI system from one point three to  you know , to  point eight ?\nHmm . Mm - hmm .\nZero .\nWell . You know , so that 's  that 's something we can test .\nMmm . Right .\nSo . Anyway .\nOK .\nI think we 've   we 've covered that one up extremely well .\nMm - hmm .\nWhew !\nOK . So , um  Yeah . So tha so we 'll  you know , maybe you guys 'll have  have one . Uh , you  you and , uh  and Dan have  have a paper that  that 's going in .\nYeah .\nYou know , that 's  that 's pretty solid , on the segmentation  stuff .\nYeah . Yeah . I will send you the  the final version ,", "topic_id": 2, "keywords": "utterances, speech, conversations, utterance, mixed", "dialogue_id": 2}, {"text": "Yeah . And the Aurora folks here will  will definitely get something in on Aurora ,\nwhich is not\nActually this  this , um  So , there 's another paper .\nso .\nIt 's a Eurospeech paper but not related to meetings . But it 's on digits . So , um , uh , a colleague at SRI developed a improved version of MMIE training .\nUh - huh .\nAnd he tested it mostly on digits because it 's sort of a  you know , it doesn't take weeks to train it .\nRight .\nUm . And got some very impressive results , um , with , you know , discriminative , uh , Gaussian training . Um , you know , like , um , error rates  go from  I don't know , in very noisy environment , like from , uh , uh  I for now I  OK , now I have the order of magnit I 'm not sure about the order of magnitude . Was it like from ten percent to  eight percent or from e e you know , point  you know , from one percent to point eight percent ?\nH i it got  it got better .\nI mean , it 's a\nYeah , yeah .\nYeah .\nIt got better . That 's the important thing .\nHey , that 's the same percent relative ,\nYeah . But it 's\nso\nYeah . Right .\nYeah .\nIt 's , uh , something in\nYeah .\nTwenty percent relative gain .\nRight .\nYeah .\nYeah .\nYeah . Um ,  let 's see . I think the only thing we had left was  unless somebody else  Well , there 's a couple things . Uh , one is  anything that , um ,  anybody has to say about Saturday ? Anything we should do in prep for Saturday ? Um  I guess everybody knows about  I mean , u um , Mari was asking  was trying to come up with something like an agenda and we 're sort of fitting around people 's times a bit . But , um ,  clearly when we actually get here we 'll  move things around this , as we need to , but  so you can't absolutely count on it .\nOK .\nBut  but , uh\nYeah .\nAre we meeting in here probably or  ? OK .\nYeah . That was my thought .\nYeah .\nI think this is\nAre we recording it ?\nWe won't have enough microphones ,\nbut\nu No . I  I hadn't in intended to .\nThere 's no way .\nWe won we wanna  I mean , they 're  there 's gonna be , uh , Jeff , Katrin , Mari and two students .\nOK .\nSo there 's five  from there .\nAnd Brian .\nAnd Brian 's coming ,\nBut you know th\nso that 's six .\nAnd plus all of us .\nMm - hmm .\nUh\nCan use the Oprah mike .\nDepends how fast you can  throw it .\nIt seems like too many  too much coming and going .\nIt 's just  Yeah .\nMm - hmm .\nWe don't even have enough channel\nWell\nBecause it would be a different kind of meeting ,\nYeah .\nthat 's what I 'm\nWell\nBut\nYeah .\nI hadn't  really thought of it ,\nMaybe just  maybe not the whole day\nbut\nbut just , you know , maybe some  I mean ,\nMaybe part of it .\npart of it ?\nMaybe part of it .\nMake everyone read digits .\nAt the same time .\nAt the same time .\nAt the same time .\nPlease .\nYeah .\nWe c\nI don't know .\nThat 's their initiation into our\nAny\nw\nInto our  our  our cult .\nYeah , our  Yeah , our\nMaybe the sections that are not right afte you know , after lunch when everybody 's still munching and\nSo can you send out a schedule once you know it , jus ?\nOK . Well\nIs  is there a r ?\nOK . Yeah . I guess I sent it around a little bit .\nThere 's a res Is it changed now , or  ?\nBut  I hadn't heard back from Mari after I  I u u uh , brought up the point abou about Andreas 's schedule . So ,  um , maybe when I get back there 'll be  some  some mail from her .\nOK .\nSo , I 'll make a\nI 'm looking forward to seeing your representation . That 'd be , uh\nAnd w we should get  the two meetings from y\nI 'd like to see that . Yeah .\nI mean , I know about the first meeting , um , but the other one that you did , the NSA one , which we  hadn't done cuz we weren't running recognition on it , because the non - native speaker\nMm - hmm .\nthere were five non - native speakers .\nMm - hmm . I see . Mm - hmm .\nBut , it would be useful for the  to see what we get  with that one . So .\nGreat . OK . It 's , uh , two thousand eleven twenty - one one thousand .\nYeah , three . Right . So\nGreat . I sent email when I finished the  that one .\nN S A three , I think .\nThat was sort of son Yeah , that 's right . That 's right . That 's much simpler .\nI don't know what they said but I know the number .\nTh - that part 's definitely gonna confuse somebody who looks at these later .\nRight .\nI mean , this is  we we 're recording secret NSA meetings ?\nUm . Not the\nI mean , it 's\nYeah .\nYeah . Not that NSA .\nUh . The  th the\nThey are hard to understand .\nIt 's network services and applications .\nWait .\nThey 're very , uh , out there .\nThe\nI have no idea what they 're talking about .\nYeah .\nThe , um  th the other good thing about the alignments is that , um , it 's not always the machine 's fault if it doesn't work . So , you can actually find , um ,\nIt 's the person 's fault .\nproblem  uh , proble\nIt 's Morgan 's fault .\nYou can find\nIt 's always Morgan 's fault .\nYou can find , uh , problems with  with the transcripts , um , you know ,\nOh .\nYeah .\nand go back and fix them .\nTha - There are some cases like where the  the wrong speaker  uh , these ca Not a lot , but where the  the wrong person  the  the speech is addre attached to the wrong speaker\nBut\nand you can tell that when you run it . Or at least you can get  clues to it .\nInteresting .\nSo these are from the early transcriptions that people did on the mixed signals , like what you have .\nI guess it does w Mm - hmm . It also raises the possibility of , um , using that kind of representation  I mean , I don't know , this 'd be something we 'd wanna check ,  but maybe using that representation for data entry and then displaying it on the channelized , uh , representation , cuz it  I think that the  I mean , my  my preference in terms of , like , looking at the data is to see it  in this kind of musical score format .\nMm - hmm .\nAnd also , s you know , Sue 's preference as well .\nYeah , if you can get it to\nAnd  and  but , I mean , this  if this is a better interface for making these kinds of , uh , you know , lo clos local changes , then that 'd be fine , too . I don't  I have no idea . I think this is something that would need to be checked . Yeah .\nOK . Th - the other thing I had actually was , I  I didn't realize this till today , but , uh , this is , uh , Jose 's last day .\nYeah .\nIs my last  my last day .\nOh !\nOh .\nOh !\nYou 're not gonna be here tomorrow ?\nMy   my last meeting  about meetings .\nOh , that 's right . Tomorrow\nYeah .\nThe last meeting meeting ?\nBecause , eh , I leave , eh , the next Sunday .\nIt 's off .\nOh .\nMm - hmm .\nI will come back to home  to Spain .\nYeah .\nOh .\nI d so I  I jus\nMm - hmm .\nAnd I  I would like to  to  to say thank you very much , eh , to all people  in the group and at ICSI ,\nMm - hmm .\nYeah . It was good having you .\nMmm .\nYeah .\nbecause I  I enjoyed @ @ very much ,\nMmm .\nuh . And I 'm sorry by the result of overlapping , because , eh ,  I haven't good results , eh , yet but , eh ,  I   I pretend  to  to continuing out to Spain , eh , during the  the following months ,\nUh - huh .\neh , because I have , eh , another ideas but , eh , I haven't enough time to  to   with six months it 's not enough to   to  to research ,\nYep .\nYeah .\neh , and e i I mean , if , eh , the topic is , eh , so difficult , uh , in my opinion , there isn't\nYeah . Maybe somebody else will come along and will be , uh , interested in working on it and could start off from where you are also , you know . They 'd make use of  of what you 've done .\nYeah .\nYeah .\nYeah . But , eh , I  I will try to recommend , eh , at , eh ,  the Spanish government but , eh , the following @ @ scholarship , eh , eh ,  eh , will be here  more time , because eh , i in my opinion is  is better ,  eh , for us  to  to spend more time here and to work more time i i in a topic .\nYeah , it 's a very short time .\nNo ? But , uh\nYeah . Yeah .\nYeah , six months is hard .\nYeah . It is .\nI think a year is a lot better .\nYeah .\nYeah .\nIt 's difficult . You  e you have , eh  you are lucky , and you  you find a solution  in  in  in some few tim uh , months , eh ? OK . But , eh , I think it 's not , eh , common . But , eh , anyway , thank you . Thank you very much . Eh , I  I bring the chocolate , eh , to    to tear , uh , with  with you ,\nOh .\nAh .\nMmm .\nNice .\nuh . I  I hope if you need , eh , something , eh , from us in the future , I  I will be at Spain ,  to you help , uh .\nWell .\nGreat .\nGreat .\nRight .\nThank you , Jose .\nThank you .\nAnd , thank you very much .\nHave a good trip .\nYeah .\nYeah .\nKeep in touch .\nThank you .\nYeah . OK . I guess , uh , unless somebody has something else , we 'll read  read our digits\nDigits ?\nand we 'll get our\nUh .\nget our last bit of , uh , Jose 's  Jose  Jose 's digit\nOops .\nAre we gonna do them simultaneously or  ?\nYou  eh\nUh , I 'm sorry ?\nYe - ye you prefer , eh , to eat , eh , chocolate , eh , at the coffee break , eh , at the  ?  Or you prefer now , before after  ?\nWell , we have a time\nNo , we prefer to keep it for ourselves .\nDuring\nWell , we have a s a time  time constraint .\nYeah , yeah .\nduring digits .\nSo keep it away from that end of the table .\nYeah .\nYeah .\nYeah .\nWhy is it that I can read your mind ?\nYeah .\nWell , we 've gotta wait until after di after we take the mikes off .\nNo , no .\nSo are we gonna do digits simultaneously\nYou  This is our reward if we  do our digi\nWell ? Yeah .\nOK .\nYeah .\nor what ?\nSimultaneous digit chocolate task .\nI  I think , eh , it 's enough , eh , for more peopl for more people  after .\nWe 're gonna  we 're gonna do digits at the same\nOh .\nMmm !\nThat 's nice .\nBut , eh\nMm - hmm .\nOh , thanks , Jose .\nUm .\nWow .\nTo Andreas , the idea is  is good .  s To eat here .\nWell\nMmm .\nWow . Very nice .\nOh .\nOh , wow .\nTha - that 's  that looks great .\nOh , yeah . Th - it doesn't  it won't leave this room .\nAlright , so in the interest of getting to the\nWe could do digits while other people eat .\nYeah .\nSo it 's background crunching .\nYeah .\nYeah .\nMmm .\nWe don't have background chewing .\nNice .\nIs , eh , a  another acoustic event .\nBackground crunch . Yeah .\nNo , we don't have any data with background eating .\nMmm .\nYeah .\nI 'm serious . You\nShe 's  she 's serious .\nI am serious .\nIt 's just the rest of the digits  the rest of the digits are very clean ,\nShe is serious .\nMmm .\nWell  ?\nAre you  ? Oh , they 're clean .\nYeah !\num , without a lot of background noise ,\nAnd it  You have to write down , like , while y what you 're  what ch chocolate you 're eating\nso I 'm just not sure\ncuz they might make different sounds , like n nuts  chocolate with nuts , chocolate without nuts .\nOh .\nUm\nCrunchy frogs .\nChocolate adaptation .\nActually   actually kind of careful cuz I have a strong allergy to nuts , so I have to sort of figure out one without th\nThat w Oh , yeah , they  they might .\nIt 's hard to  hard to say .\nMaybe those ? They 're so  I don't know .\nI don't know . Um\nThis is  You know , this is a different kind of speech ,\nWell\nTake  take several .\nlooking at chocolates , deciding\nMmm .\nyou know , it 's another style .\nYeah . I may  I may hold off .\nMmm .\nBut if I was  eh , but maybe I 'll get some later . Thanks .\nMmm .\nWell  well , why don't we  ? He  he 's worried about a ticket . Why don't we do a simultaneous one ?\nOK .\nSimultaneous one ?\nOK .\nOK .\nMmm .\nAnd you laughed at me , too , f the first time I said that .\nOK .\nRemember to read the transcript number , please .\nRight .\nOK .\nI have to what ?\nOops .\nYeah .\nYou laughed at me , too , the first time I sa said\nI did ,\nYou really shouldn't , uh , te\nand now I love it so much .\nOK , everyone ready ?\nYou have to sort of , um  Jose , if you haven't done this , you have to plug your ears while you 're t talking\nW wait  wait a minute  wait a minute . W we want  we want\nso that you don't get confused , I guess .\nwe want it synchronized .\nYeah . Oh , you 've done this one before ?\nHey , you 've done this before . Haven't you ?\nYeah .\nThat 's\nTogether ?\nYou 've read  digits together with us , haven't you  I mean , at the same time ?\nI 'm not  we  we  Oh , and you haven't done this either .\nOK .\nOh , you haven't !\nNo .\nOh , OK .\nOh , yeah .\nI the first time is  traumatic ,\nWe\nbut\nY  Yeah , bu\nOh , and the groupings are important ,\nMmm .\nso yo you 're supposed to pause between the groupings .\nThe grouping .\nYeah .\nYeah .\nOK . So , uh\nYou mean that the  the grouping is supposed to be synchronized ?\nNo , no .\nNo .\nYeah , sure .\nNo ?\nThat 'd be good .\nSynchronized digits .\nNo .\nNo ?\nWe - we 'll give everybody the same sheet\nIt 's like a  like a Greek  like a Greek choir ?\nbut they say different\nYou know ?\nYes .\nHey , what a good idea .\nLike\nWe could do the same sheet for everyone .\nYeah .\nHave them all read them at once .\nWell , different digits\nEh\nbut same groupings .\nOr  or just same digits .\nSo they would all be  Yeah .\nYeah . That 'd be good .\nSee if anyone notices .\nThere 's so many possibilities .\nAnd then  then we can sing them next time .\nUh . OK , why don't we go ? Uh , one two three  Go !\nOK . Mmm !\nAnd Andreas has the last word .\nDid you read it twice or what ?\nHe 's try No , he 's trying to get good recognition performance .\nHe had the h\nYeah .\nHe had the  the long form .\nYeah .\nAnd we 're off .\nNo .", "topic_id": 3, "keywords": "aurora, mmie, training, performance, magnit", "dialogue_id": 2}, {"text": "Uh , is it the twenty - fourth ?\nnow we 're on .\nYeah .\nUh Chuck , is the mike type wireless\nYes .\nwireless headset ? OK .\nYes .\nYeah .\nFor you it is .\nYeah . We uh  we abandoned the lapel because they sort of were not too  not too hot , not too cold , they were  you know , they were  uh , far enough away that you got more background noise , uh , and uh  and so forth\nUh - huh .\nbut they weren't so close that they got quite the  you know , the really good  No , th\nOK .\nthey  I mean they didn't  Wait a minute . I 'm saying that wrong . They were not so far away that they were really good representative distant mikes ,\nUh - huh .\nbut on the other hand they were not so close that they got rid of all the interference . So it was no  didn't seem to be a good point to them . On the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle .\nYeah , yeah .\nThere 's uh , some kinds of junk that you get with these things that you don't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we  there seemed to be very strong opinions for uh , getting rid of lapels .\nThe mike number is\nSo ,\nUh , your mike number 's written on the back of that unit there .\nOh yeah . One .\nAnd then the channel number 's usually one less than that .\nOh , OK . OK .\nIt - it 's one less than what 's written on the back of your\nOK . OK .\nyeah . So you should be zero , actually .\nHello ? Yeah .\nFor your uh , channel number .\nYep , yep .\nAnd you should do a lot of talking so we get a lot more of your pronunciations . no , they don't  don't have a  have any Indian pronunciations .\nSo what we usually do is um , we typically will have our meetings\nYeah .\nand then at the end of the meetings we 'll read the digits . Everybody goes around and reads the digits on the  the bottom of their forms .\nSession R\nR - nineteen ?\nOK .\nR - nineteen .\nYeah . We 're  This is session R - nineteen .\nIf you say so . O K . Do we have anything like an agenda ? What 's going on ? Um . I guess um . So . One thing\nSunil 's here for the summer ?\nSunil 's here for the summer , right . Um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , I guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . Um .\nI could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know .\nMm - hmm . OK . Why don't you start with that ? That 's sort of\nOK .\nYeah ?\nWe um  So we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . And um , uh , we ordered uh , SUN - Blade - one - hundreds , and um , I 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running  So the plan for using these is , uh , we 're running P - make and Customs here and Andreas has sort of gotten that all uh , fixed up and up to speed . And he 's got a number of little utilities that make it very easy to um ,  run things using P - make and Customs . You don't actually have to write P - make scripts and things like that . The simplest thing  And I can send an email around or , maybe I should do an FAQ on the web site about it or something . Um ,\nHow about an email that points to the FAQ ,\nthere 's a c\nyou know what I 'm saying ?\nYeah , yeah .\nso that you can  Yeah .\nUh , there 's a command , uh , that you can use called \" run command \" . \" Run dash command \" , \" run hyphen command \" . And , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh  and run it there and it 'll duplicate your environment . So you can try this as a simple test with uh , the L S command . So you can say \" run dash command L S \" , and , um , it 'll actually export that  LS command to some machine in the institute , and um , do an LS on your current directory . So , substitute LS for whatever command you want to run , and um  And that 's a simple way to get started using  using this . And , so , soon , when we get all the new machines up ,  um , e then we 'll have lots more compute to use . Now th one of the nice things is that uh , each machine that 's part of the P - make and Customs network has attributes associated with it . Uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like \" run command \" , you can specify those attributes for your program . For example if you only want your thing to run under Linux , you can give it the Linux attribute , and then it will find the fastest available Linux machine and run it on that . So . You can control where your jobs go , to a certain extent , all the way down to an individual machine . Each machine has an attribute which is the name of itself . So you can give that as an attribute and it 'll only run on that . If there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . So , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now Andreas and I have been the main ones using it and we 're  Uh . The SRI recognizer has all this P - make customs stuff built into it .\nSo as I understand , you know , he 's using all the machines and you 're using all the machines ,\nSo .\nis the rough division of\nYeah . Exactly . Yeah , you know , I  I sort of got started  using the recognizer just recently and uh , uh I fired off a training job , and then I fired off a recognition job and I get this email about midnight from Andreas saying , \" uh , are you running two  trainings simultaneously s my m my jobs are not getting run . \" So I had to back off a little bit . But , soon as we get some more machines then uh  then we 'll have more compute available . So , um , that 's just a quick update about what we 've got . So .\nUm , I have  I have a question about the uh , parallelization ?\nMm - hmm .\nSo , um , let 's say I have like , a thousand little  little jobs to do ?\nMm - hmm .\nUm , how do I do it with \" run command \" ? I mean do\nYou could write a script uh , which called run command on each sub - job\nUh - huh . A thousand times ?\nright ? But you probably wanna be careful with that\nOK .\nbecause um , you don't wanna saturate the network . Uh , so , um , you know , you should  you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people\nOh , too much file transfer and stuff .\nWell it 's not that so much as that , you know , e with  if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . Um ,\nOK .\nso you should try to limit it to somet sometim some number around ten jobs at a time . Um . So if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gonna use \" run command \" , uh , to only have ten of those going at a time . And uh , then , when one of those finished you 'd fire off another one . Um ,\nI remember I  I forget whether it was when the Rutgers or  or Hopkins workshop , I remember one of the workshops I was at there were  everybody was real excited cuz they got twenty - five machines and there was some kind of P - make like thing that sit sent things out .\nMm - hmm . Mm - hmm .\nSo all twenty - five people were sending things to all twenty - five machines\nMm - hmm . Yeah .\nand  and things were a lot less efficient than if you 'd just use your own machine .\nYeah . Yep . Yeah , exactly . Yeah , you have to be a little bit careful .\nas I recall , but . Yeah .\nHmm .\nUm , but uh , you can also  If you have that level of parallelization um , and you don't wanna have to worry about writing the logic in  in a Perl script to take care of that , you can use um , P - make\nJust do P - make .\nand  and you basically write a Make file that uh , you know your final job depends on these one thousand things ,\ns Mm - hmm .\nand when you run P - make , uh , on your Make file , you can give it the dash capital J and  and then a number ,\nMm - hmm .\nand that number represents how many uh , machines to use at once . And then it 'll make sure that it never goes above that .\nRight .\nSo ,\nRight . OK .\nI can get some documentation .\nSo it  it 's  it 's not systematically queued . I mean all the jobs are running . If you launch twenty jobs , they are all running . Alright .\nIt depends . If you  \" Run command \" , that I mentioned before , is  doesn't know about other things that you might be running .\nUh - huh .\nSo , it would be possible to run a hundred run jobs at once ,\nRight .\nand they wouldn't know about each other . But if you use P - make , then , it knows about all the jobs that it has to run\nMm - hmm .\nand it can control , uh , how many it runs simultaneously .\nSo \" run command \" doesn't use P - make , or  ?\nIt uses \" export \" underlyingly . But , if you  i It 's meant to be run one job at a time ? So you could fire off a thousand of those , and it doesn't know  any one of those doesn't know about the other ones that are running .\nSo why would one use that rather than P - make ?\nWell , if you have , um  Like , for example , uh if you didn't wanna write a P - make script and you just had a , uh  an HTK training job that you know is gonna take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say \" run command \" and your HTK thing and it 'll find another machine , the fastest currently available machine and  and run your job there .\nNow , does it have the same sort of behavior as P - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it\nYes . Yeah , there are um  Right . So some of the machines at the institute , um , have this attribute called \" no evict \" . And if you specify that , in  in one of your attribute lines , then it 'll go to a machine which your job won't be evicted from .\nMm - hmm .\nBut , the machines that don't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and  and they were at lunch ,\nMm - hmm .\nthey come back from lunch and they start typing on the console , then your machine will get evicted  your job  will get evicted from their machine and be restarted on another machine . Automatically . So  which can cause you to lose time , right ? If you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . So . If you don't want your job to run on a machine where it could be evicted , then you give it the minus  the attribute , you know , \" no evict \" , and it 'll pick a machine that it can't be evicted from . So .\nUm , what  what about  I remember always used to be an issue , maybe it 's not anymore , that if you  if something required  if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ?\nMm - hmm .\nand you weren't hitting any keys ? cuz you were , home ?\nYeah , I  I 'm not sure how that works .\nYeah .\nUh , it seems like Andreas did something for that .\nHmm .\nUm .\nOK . We can ask him sometime .\nBut  Yeah . I don't know whether it monitors the keyboard or actually looks at the console TTY , so maybe if you echoed something to the you know , dev  dev console or something .\nYou probably wouldn't ordinarily , though . Yeah . Right ? You probably wouldn't ordinarily .\nHmm ?\nI mean you sort of  you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , \" screw this \" ,\nYeah , yeah .\nand   You know .\nYeah . Yeah , so , um ,\nYeah .\nyeah . I  I can  I 'm not sure about that one .\nyeah .\nBut uh .\nOK .\nUh , I need a little orientation about this environment and uh scr s how to run some jobs here because I never d did anything so far with this X emissions\nOK .\nSo , I think maybe I 'll ask you after the meeting .\nUm . Yeah . Yeah , and  and also uh , Stephane 's a  a really good resource for that if you can't find me .\nYeah , yeah , yeah . Yep . OK , sure\nMmm .\nEspecially with regard to the Aurora stuff .\nOK .\nHe  he knows that stuff better than I do .\nOK . Well , why don't we uh , uh , Sunil since you 're  haven't  haven't been at one of these yet , why don't yo you tell us what 's  what 's up with you ? Wh - what you 've been up to , hopefully .", "topic_id": 0, "keywords": "headset, interference, wireless, mikes, noise", "dialogue_id": 3}, {"text": "Um . Yeah . So , uh , shall I start from  Well I don't know how may I  how  OK . Uh , I think I 'll start from the post uh Aurora submission maybe .\nYeah .\nUh , yeah , after the submission the  what I 've been working on mainly was to take  take other s submissions and then over their system , what they submitted , because we didn't have any speech enhancement system in  in ours . So  So I tried uh , And u First I tried just LDA . And then I found that uh , I mean , if  if I combine it with LDA , it gives @ @ improvement over theirs . Uh\nAre y are you saying LDA ?\nYeah . Yeah .\nLDA . OK .\nSo , just  just the LDA filters . I just plug in  I just take the cepstral coefficients coming from their system and then plug in LDA on top of that . But the LDA filter that I used was different from what we submitted in the proposal .\nMm - hmm .\nWhat I did was  I took the LDA filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow  narrow band LDA filter that we submitted uh , I got new filters . So that seems to be giving  uh , improving over their uh , system . Slightly . But , not very significantly . And uh , that was uh , showing any improvement over  final  by plugging in an LDA . And uh , so then after  after that I  I added uh , on - line normalization also on top of that . And that  there  there also I n I found that I have to make some changes to their time constant that I used because th it has a  a mean and variance update time constant and  which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . But um , I didn't  I didn't play with that time constant a lot , I just t g I just found that I have to reduce the value  I mean , I have to increase the time constant , or reduce the value of the update value . That 's all I found So I have to . Uh , Yeah . And uh , uh , the other  other thing what I tried was , I just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the Aurora baseline , to see that how much the baseline itself improves by just supplying the information of the  I mean the w speech and nonspeech . And uh , I found that the baseline itself improves by twenty - two percent by just giving the wuh .\nUh , can you back up a second , I  I  I missed something , uh , I guess my mind wandered . Ad - ad When you added the on - line normalization and so forth , uh , uh things got better again ?\nYeah . No .\nor is it ?\nNo . No , things didn't get better with the same time constant that we used .\nDid it not ? No , no . With a different time constant .\nWith the different time constant I found that  I mean , I didn't get an improvement over not using on - line normalization ,\nOh .\nbecause I  I found that I would have change the value of the update factor .\nNo you didn't , OK .\nBut I didn't play it with play  play quite a bit to make it better than .\nYeah .\nSo , it 's still not\nOK .\nI mean , the on - line normalization didn't give me any improvement .\nOK .\nAnd uh , so ,\nOK .\noh yeah So I just stopped there with the uh , speech enhancement . The  the other thing what I tried was the  adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the  the second  the new phase is going to be with the endpointed speech . And just to get a feel of how much the baseline itself is going to change by adding this endpoint information , I just , uh , use\nHmm .\nSo people won't even have to worry about , uh , doing speech - nonspeech then .\nYeah that 's , that 's what the feeling is like . They 're going to give the endpoint information .\nMmm .\nG I guess the issue is that people do that anyway ,\nI see .\neverybody does that ,\nYeah .\nand they wanted to see , given that you 're doing that , what  what are the best features that you should use .\nYeah , I see .\nSo ,\nI mean clearly they 're interact . So I don't know that I entirely agree with it .\nYeah .\nBut  but it might be uh  In some ways it might be better t to  rather than giving the endpoints , to have a standard that everybody uses and then interacts with .\nMm - hmm .\nBut , you know . It 's  it 's still someth reasonable .\nSo , are people supposed to assume that there is uh  Are  are people not supposed to use any speech outside of those endpoints ?\nUh\nOr can you then use speech outside of it for estimating background noise and things ?\nNo . No . That i I  Yeah . Yeah , yeah , exactly . I guess that is  that is where the consensus is . Like y you will  you will  You 'll be given the information about the beginning and the end of speech but the whole speech is available to you .\nOK .\nSo .\nSo it should make the spectral subtraction style things work even better ,\nYeah .\nbecause you don't have the mistakes in it . Yeah ?\nYeah . So\nOK .\nSo that  that  The baseline itself  I mean , it improves by twenty - two percent . I found that in s one of the SpeechDat - Car cases , that like , the Spanish one improves by just fifty percent by just putting the endpoint . w\nWow .\nI mean you don't need any further speech enhancement with fifty . So , uh ,\nSo the baseline itself improves by fifty percent .\nYeah , by fifty percent .\nYeah .\nWow .\nSo it 's g it 's gonna be harder to  beat that actually .\nYeah .\nYeah , so\nBut  but\nso that is when uh , the  the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . And I think they have  they have actually changed their qualification c criteria now . And uh , Yeah , I guess after that , I just went home f I just had a vacation fo for four weeks . Uh .\nOK . No , that 's  that 's  that 's a good  good update .\nYe Yeah , and I  I came back and I started working on uh , some other speech enhancement algorithm . I mean , so  I  from the submission what I found that people have tried spectral subtraction and Wiener filtering . These are the main uh , approaches where people have tried ,\nYeah .\nso just to  just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , I  I 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . And\nMm - hmm .\nSo , I 've been actually running some s So far I 've been trying it only on Matlab . I have to  to  to test whether it works first or not\nYeah .\nand then I 'll p port it to C and I 'll update it with the repository once I find it it giving any some positive result . So , yeah .\nS So you s you So you said one thing I want to jump on for a second . So  so now you 're  you 're getting tuned into the repository thing that he has here\nYeah .\nand  so we we 'll have a  single place where the stuff is .\nYep . Yeah .\nCool . Um , so maybe uh , just briefly , you could remind us about the related experiments . Cuz you did some stuff that you talked about last week , I guess ?\nMm - hmm .\nUm , where you were also combining something  both of you I guess were both combining something from the uh , French Telecom system with  the u uh\nRight .\nI  I don't know whether it was system one or system two , or  ?\nMm - hmm . It was system one . So\nOK .\nwe  The main thing that we did is just to take the spectral subtraction from the France Telecom , which provide us some speech samples that are uh , with noise removed .\nSo I let me  let me just stop you there . So then , one distinction is that uh , you were taking the actual France Telecom features and then applying something to\nUh , no there is a slight different . Uh I mean , which are extracted at the handset because they had another back - end blind equalization\nYeah .\nYeah .\nYeah . But that 's what I mean .\nYeah .\nBut u u Sorry ,\nYeah .\nyeah , I 'm not being  I 'm not being clear .\nYeah .\nWhat I meant was you had something like cepstra or something , right ?\nYeah , yeah , yeah , yeah .\nAnd so one difference is that , I guess you were taking spectra .\nThe speech .\nYeah .\nYeah . But I guess it 's the s exactly the same thing because on the heads uh , handset they just applied this Wiener filter and then compute cepstral features ,\nYeah , the cepstral f The difference is like  There may be a slight difference in the way\nright ? or  ?\nbecause they use exactly the baseline system for converting the cepstrum once you have the speech . I mean , if we are using our own code for th I mean that  that could be the only difference .\nRight .\nI mean , there is no other difference .\nMm - hmm .\nYeah .\nBut you got some sort of different result . So I 'm trying to understand it . But uh , I th\nYeah , well I think we should uh , have a table with all the result because I don't know I uh , I don't exactly know what are your results ? But ,\nOK . OK .\nMmm . Yeah , but so we did this , and another difference I guess is that we just applied uh , proposal - one system after this without  well , with our modification to reduce the delay of the  the LDA filters ,\nUh - huh .\nand\nAnd the filter\nWell there are slight modifications , but it was the full proposal - one . In your case , if you tried just putting LDA , then maybe on - line normalization  ?\nOnly LDA . Yeah . Af - I  after that I added on - line normalization , yeah .\nMm - hmm . So we just tried directly to  to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . Um , but , what seems clear also is that we have to retune the time constants of the on - line normalization .\nYeah , yeah . Yeah .\nBecause if we keep the value that was submitted uh , it doesn't help at all . You can remove on - line normalization , or put it , it doesn't change anything . Uh , uh , as long as you have the spectral subtraction . But , you can still find some kind of optimum somewhere , and we don't know where exactly\nYeah .\nbut , uh .\nYeah , I assume .\nSo it sounds like you should look at some tables of results or something\nRight .\nYeah .\nYeah .\nand see where i where the   where they were different and what we can learn from it .\nMm - hmm . Mm - hmm .\nwithout any change . OK .\nBut it 's\nYeah . Well ,\nIt 's the new .\nwith  with  with changes ,\nwith\nThe new .\nbecause we change it the system to have\nOh yeah , I mean the  the new LDA filters .\nThe new .\nI mean  OK .\nYeah . LDA filters . There are other things that we finally were shown to improve also like , the sixty - four hertz cut - off .\nMm - hmm .\nMm - hmm .\nw Uh , it doesn't seem to hurt on TI - digits , finally .\nOK .\nMaybe because of other changes .\nOK .\nUm , well there are some  minor changes , yeah .\nMm - hmm .\nAnd , right now if we look at the results , it 's , um , always better than  it seems always better than France Telecom for mismatch and high - mismatch . And it 's still slightly worse for well - matched .\nBut\nUm , but this is not significant . But , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . Even with very minor  uh , even if it 's only slightly worse for well - matched .\nMm - hmm .\nAnd significantly better for HM . Uh , but , well . I don't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot HM , and MM ,\nYeah .\nso , um , I guess what will happen  I don't know what will happen . But , the different contribution , I think , for the different test set will be more even .\nBecause the  your improvement on HM and MM will also go down significantly in the spreadsheet so . But the  the well - matched may still\nMm - hmm .\nI mean the well - matched may be the one which is least affected by adding the endpoint information .\nRight .\nYeah . So the  the MM\nMm - hmm .\nMM and HM are going to be v hugely affected by it . Yeah .\nYeah , so um , yeah .\nYeah . But they d the  everything I mean is like , but there that 's how they reduce  why they reduce the qualification to twenty - five percent or some  something on .\nMm - hmm .\nBut are they changing the weighting ?\nUh , no , I guess they are going ahead with the same weighting .\nYeah .\nYeah . So there 's nothing on\nI don't understand that .\nYeah .\nI guess I  I haven't been part of the discussion , so , um , it seems to me that the well - matched condition is gonna be unusual ,\nUsual .\nin this case . Unusual .\nUh - huh .\nBecause , um , you don't actually have good matches ordinarily for what any @ @  particular person 's car is like , or\nMmm .\nuh ,\nMmm .\nIt seems like something like the middle one is  is more natural .\nHmm . Right .\nSo I don't know why the  well - matched is uh\nMm - hmm .\nYeah , but actually the well  well the well - matched um , uh , I mean the  the well - matched condition is not like , uh , the one in TI - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . It 's like , this is not calibrated by SNR or something . The well - matched has also some  some mismatch in that which is other than the\nThe well wa matched has mismatch ?\nhas  has also some slight mismatches , unlike the TI - digits where it 's like prefectly matched\nPerfect to match .\nbecause it 's artificially added noise .\nYeah .\nBut this is natural recording .\nYeah . So remind me of what well - matched meant ?\nThe  the well - matched is like\nYou 've told me many times .\nthe  the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing .\nYeah . Well , so it means that if the database is large enough , it 's matched .\nIt 's  it 's\nBecause it\nOK , it 's\nYeah .\nin each set you have a range of conditions  Well\nRight . So , I mean , yeah , unless they deliberately chose it to be different , which they didn't because they want it to be well - matched , it is pretty much  You know , so it 's  so it 's sort of saying if you\nIt 's  it 's not guaranteed though .\nYeah .\nUh , it 's not guaranteed .\nYeah .\nRight .\nMm - hmm .\nYeah because the m the main  major reason for the m\nRight .\nthe main mismatch is coming from the amount of noise and the silence frames and all those present in the database actually .\nAgain , if you have enough  if you have enough\nNo yeah , yeah . Yeah .\nSo it 's sort of i i it 's sort of saying OK , so you  much as you train your dictation machine for talking into your computer , um , you  you have a car , and so you drive it around a bunch and  and record noise conditions , or something , and then  I don't think that 's very realistic , I mean I th\nMm - hmm .\nI  I you know , so I  I  I  you know , I guess they 're saying that if you were a company that was selling the stuff commercially , that you would have a bunch of people driving around in a bunch of cars , and  and you would have something that was roughly similar and maybe that 's the argument , but I 'm not sure I buy it , so .\nYeah , yeah , yeah .", "topic_id": 1, "keywords": "lda, speech, speechdat, filters, filtering", "dialogue_id": 3}, {"text": "Uh , So What else is going on ?\nMmm . You Yeah . We are playing  we are also playing , trying to put other spectral subtraction mmm , in the code . Um , it would be a very simple spectral subtraction , on the um , mel energies which I already tested but without the um frame dropping actually , and I think it 's important to have frame dropping if you use spectral subtraction .\nIs it  is spectral subtraction typically done on the  after the mel , uh , scaling or is it done on the FFT bins ?\nUm ,\nDoes it matter , or  ?\nI d I don't know . Well , it 's both  both uh , cases can i\nOh .\nYeah . So - some of the proposal , uh , we 're doing this on the bin  on the FFT bins ,\nHmm .\nothers on the um , mel energies . You can do both , but I cannot tell you what 's  which one might be better or  I\nHmm .\nI guess if you want to reconstruct the speech , it may be a good idea to do it on FFT bins .\nI don't know . Yeah , but\nMmm .\nBut for speech recognition , it may not . I mean it may not be very different if you do it on mel warped or whether you do it on FFT . So you 're going to do a linear weighting anyway after that .\nI see .\nWell  Yeah ?\nHmm .\nSo , it may not be really a big different .\nWell , it gives something different , but I don't know what are the , pros and cons of both .\nIt I Uh - huh .\nHmm .\nSo\nOK .\nThe other thing is like when you 're putting in a speech enhancement technique , uh , is it like one stage speech enhancement ? Because everybody seems to have a mod two stages of speech enhancement in all the proposals , which is really giving them some improvement .\nYeah .\nMm - hmm .\nMm - hmm .\nI mean they just do the same thing again once more .\nMm - hmm .\nAnd  So , there 's something that is good about doing it  I mean , to cleaning it up once more .\nYeah , it might be .\nYeah ,\nYeah .\nso we can\nSo maybe in my implementation I should also try to inspire me from this kind of thing\nYeah . That 's what\nWell , the other thing would be to combine what you 're doing .\nand  Yeah .\nI mean maybe one or  one or the other of the things that you 're doing would benefit from the other happening first .\nThat 's wh Yeah . So ,\nRight , so he 's doing a signal subspace thing , maybe it would work better if you 'd already done some simple spectral subtraction , or maybe vi maybe the other way around ,\nYeah , mm - hmm .\nYeah .\nyou know ?\nSo I 've been thinking about combining the Wiener filtering with signal subspace ,\nMm - hmm .\nI mean just to see all  some  some such permutation combination to see whether it really helps or not .\nMm - hmm . Mm - hmm . Mm - hmm . Yeah . Yeah .\nHow is it  I  I guess I 'm ignorant about this , how does  I mean , since Wiener filter also assumes that you 're  that you 're adding together the two signals , how is  how is that differ from signal subspace ?\nThe signal subspace ? The\nYeah .\nThe signal subspace approach has actually an in - built Wiener filtering in it .\nOh , OK .\nYeah . It is like a KL transform followed by a Wiener filter . Is the signal is  is a signal substrate .\nOh , oh , OK so the difference is the KL .\nSo , the  the different  the c the  the advantage of combining two things is mainly coming from the signal subspace approach doesn't work very well if the SNR is very bad . It 's  it works very poorly with the poor SNR conditions , and in colored noise .\nI see . So essentially you could do simple spectral subtraction , followed by a KL transform , followed by a\nWiener filtering . It 's a  it 's a cascade of two s\nWiener filter . Yeah , in general , you don't  that 's right you don't wanna othorg orthogonalize if the things are noisy . Actually . Um , that was something that uh , Herve and I were talking about with um , the multi - band stuff , that if you 're converting things to from uh , bands , groups of bands into cepstral coef you know , local sort of local cepstral coefficients that it 's not that great to do it if it 's noisy .\nMm - hmm . OK . Yeah . So .\nUh , so .\nSo that  that 's one reason maybe we could combine s some  something to improve SNR a little bit , first stage ,\nYeah .\nand then do a something in the second stage which could take it further .\nWhat was your point about  about colored noise there ?\nOh , the colored noise uh\nYeah .\nthe colored noise  the  the v the signal subspace approach has  I mean , it  it actually depends on inverting the matrices . So it  it  ac the covariance matrix of the noise . So if  if it is not positive definite ,\nMm - hmm .\nI mean it has a  it 's  It doesn't behave very well if it is not positive definite ak It works very well with white noise because we know for sure that it has a positive definite .\nSo you should do spectral subtraction and then add noise .\nSo the way they get around is like they do an inverse filtering , first of the colo colored noise\nYeah .\nand then make the noise white ,\nYeah .\nand then finally when you reconstruct the speech back , you do this filtering again .\nYeah , right .\nI was only half kidding . I mean if you  sort of  you do the s spectral subtraction , that also gets rid\nYeah .\nYeah .\nYeah .\nand then you  then  then add a little bit l noise  noise addition  I mean , that sort of what J  JRASTA does , in a way .\nYeah .\nIf you look at what JRASTA doing essentially i i it 's equivalent to sort of adding a little  adding a little noise ,\nHuh ? Uh - huh .\nUh - huh .\nin order to get rid of the effects of noise .\nSo .\nOK .\nYeah . Uh , yeah . So there is this . And maybe we  well we find some people so that  uh , agree to maybe work with us , and they have implementation of VTS techniques so it 's um , Vector Taylor Series that are used to mmm ,  uh f to model the transformation between clean cepstra and noisy cepstra . So . Well , if you take the standard model of channel plus noise , uh , it 's  it 's a nonlinear eh uh , transformation in the cepstral domain .\nMm - hmm . Yes .\nAnd uh , there is a way to approximate this using uh , first - order or second - order Taylor Series and it can be used for  uh , getting rid of the noise and the channel effect .\nWho is doing this ?\nUh w working in the cepstral domain ? So there is one guy in Grenada ,\nYeah , in Grenada one of my friend .\nand another in  uh , Lucent that I met at ICASSP .\nWho 's the guy in Grenada ?\nuh ,\nUh , Jose Carlos Segura .\nI don't know him .\nThis VTS has been proposed by CMU ?\nMm - hmm .\nIs it  is it the CMU ? Yeah , yeah , OK .\nYeah , yeah , yeah . Originally the idea was from CMU .\nFrom C .\nMm - hmm . Yeah .\nUh - huh .\nWell , it 's again a different thing   that could be tried . Um ,\nUh - huh .\nMmm , yeah .\nYeah , so at any rate , you 're looking general , uh , standing back from it , looking at ways to combine one form or another of uh , noise removal , uh , with  with these other things we have ,\nMm - hmm .\nuh , looks like a worthy thing to  to do here .\nUh , yeah . But , yeah . But for sure there 's required to  that requires to re - check everything else , and re - optimize the other things\nOh yeah .\nand , for sure the on - line normalization may be the LDA filter . Um ,\nWell one of the  seems like one of the things to go through next week when Hari 's here ,\nI\ncuz Hari 'll have his own ideas too  or  I guess not next week ,\nUh - huh .\nweek and a half , uh , will be sort of go through these alternatives , what we 've seen so far , and come up with some game plans . Um . You know . So , I mean one way would  he Here are some alternate visions . I mean one would be , you look at a few things very quickly , you pick on something that looks like it 's promising and then everybody works really hard on the same  different aspects of the same thing . Another thing would be to have t to  to pick two pol two plausible things , and  and you know , have t sort of two working things for a while until we figure out what 's better ,\nMm - hmm .\nand then , you know , uh , but , w um , uh , he 'll have some ideas on that too .\nThe other thing is to , uh  Most of the speech enhancement techniques have reported results on small vocabulary tasks . But we  we going to address this Wall Street Journal in our next stage , which is also going to be a noisy task so s very few people have reported something on using some continuous speech at all . So , there are some  I mean , I was looking at some literature on speech enhancement applied to large vocabulary tasks and spectral subtraction doesn't seems to be the thing to do for large vocabulary tasks . And it 's  Always people have shown improvement with Wiener filtering and maybe subspace approach over spectral subtraction everywhere . But if we  if we have to use simple spectral subtraction , we may have to do some optimization  to make it work @ @ .\nSo they 're making  there  Somebody 's generating Wall Street Journal with additive  artificially added noise or something ?\nYeah , yeah .\nSort of a  sort of like what they did with TI - digits , and ?\nYeah . Yeah .\nYeah , OK .\nI m I guess Guenter Hirsch is in charge of that . Guenter Hirsch and TI .\nOK .\nMaybe Roger  r Roger , maybe in charge of .\nAnd then they 're  they 're uh , uh , generating HTK scripts to\nYeah . Yeah , I don't know . There are  they have  there is no  I don't know if they are converging on HTK or are using some Mississippi State ,\nMis - Mississippi State maybe ,\nyeah . I 'm not sure about that .\nyeah . Yeah , so that 'll be a little  little task in itself .\nYeah .\nUm , well we 've  Yeah , it 's true for the additive noise , y artificially added noise we 've always used small vocabulary too . But for n there 's been noisy speech this larv large vocabulary that we 've worked with in Broadcast News . So we we did the Broadcast News evaluation\nMm - hmm .\nand some of the focus conditions were noisy and  and\nIt had additive n\nBut we  but we didn't do spectral subtraction . We were doing our funny stuff , right ? We were doing multi multi uh , multi - stream and  and so forth .\nYeah .\nBut it , you know , we di stuff we did helped . I mean it , did something .\nOK .\nSo . Um , now we have this um , meeting data . You know , like the stuff we 're  recording right now ,\nYeah . Yeah .\nand  and uh , that we have uh , for the  uh , the quote - unquote noisy data there is just  noisy and reverberant actually . It 's the far field mike . And uh , we have uh , the digits that we do at the end of these things . And that 's what most o again , most of our work has been done with that , with  with uh , connected digits .\nUh - huh .\nUm , but uh , we have recognition now with some of the continuous speech , large vocabulary continuous speech , using Switchboard  uh , Switchboard recognizer ,\nYeah . OK .\nuh , no training ,  from this , just  just plain using the Switchboard .\nOh . You just take the Switchboard trained  ? Yeah ,\nThat 's  that 's what we 're doing ,\nyeah .\nyeah . Now there are some adaptation though ,\nOK . Yeah . That 's cool .\nthat  that uh , Andreas has been playing with ,\nOK .\nbut we 're hop uh , actually uh , Dave and I were just talking earlier today about maybe at some point not that distant future , trying some of the techniques that we 've talked about on , uh , some of the large vocabulary data . Um , I mean , I guess no one had done  yet done test one on the distant mike using uh , the SRI recognizer and , uh ,\nI don't  not that I know of .\nYeah , cuz everybody 's scared .\nYeah .\nYou 'll see a little smoke coming up from the  the CPU or something  trying to  trying to do it ,\nThat 's right\nbut uh , yeah . But , you 're right that  that  that 's a real good point , that uh , we  we don't know yeah , uh , I mean , what if any of these ta I guess that 's why they 're pushing that in the uh  in the evaluation .\nYeah .", "topic_id": 2, "keywords": "spectral, fft, speech, mel, talking", "dialogue_id": 3}, {"text": "Uh , But um , Good . OK . Anything else going on ? at you guys ' end ,\nI don't have good result , with the  inc including the new parameters ,\nor  ?\nI don't have good result . Are  similar or a little bit worse .\nWith what  what other new p new parameter ?\nYou 're talking about your voicing ?\nYeah .\nYeah .\nSo maybe  You probably need to back up a bit\nYeah .\nMm - hmm .\nseeing as how Sunil ,\nI tried to include another new parameter to the traditional parameter ,\nyeah .\nthe coe the cepstrum coefficient ,\nUh - huh .\nthat , like , the auto - correlation , the R - zero and R - one over R - zero\nMm - hmm . Mm - hmm .\nand another estimation of the var the variance of the difference for  of the spec si uh , spectrum of the signal and  and the spectrum of time after filt mel filter bank .\nI 'm so sorry . I didn't get it .\nNuh . Well . Anyway . The  First you have the sp the spectrum of the signal ,\nMm - hmm .\nand you have the  on the other side you have the output of the mel filter bank .\nMm - hmm .\nYou can extend the coefficient of the mel filter bank and obtain an approximation of the spectrum of the signal .\nMmm . OK .\nI do the difference\nOK .\nI found a difference at the variance of this different\nUh - huh .\nbecause , suppose we  we think that if the variance is high , maybe you have n uh , noise .\nYeah .\nAnd if the variance is small , maybe you have uh , speech .\nUh - huh .\nTo  to To  The idea is to found another feature for discriminate between voice sound and unvoice sound .\nOK .\nAnd we try to use this new feature  feature . And I did experiment  I need to change  to obtain this new feature I need to change the size  the window size  size . of the a of the  analysis window size , to have more information .\nYeah . Make it longer .\nUh , sixty - two point five milliseconds I think .\nOK .\nAnd I do  I did two type of experiment to include this feature directly with the  with the other feature and to train a neural network to select it voice - unvoice - silence  silence\nUnvoiced . Well .\nand to  to concat this new feature . But the result are n with the neural network I have more or less the same result .\nAs using just the cepstrum ,\nResult .\nor  ?\nYeah .\nOK .\nYeah . It 's neve e e sometime it 's worse , sometime it 's a little bit better , but not significantly .\nUh , is it with TI - digits , or with  ?\nAnd  No , I work with eh , Italian and Spanish basically .\nOK . OK .\nAnd if I don't y use the neural network , and use directly the feature the results are worse .\nUh - huh .\nBut Doesn't help .\nI  I  I really wonder though .\nMm - hmm .\nI mean we 've had these discussions before , and  and one of the things that struck me was that  uh , about this line of thought that was particularly interesting to me was that we um  whenever you condense things , uh , in an irreversible way , um , you throw away some information . And , that 's mostly viewed on as a good thing , in the way we use it , because we wanna suppress things that will cause variability for uh particular , uh , phonetic units . Um , but , you 'll do throw something away . And so the question is , uh , can we figure out if there 's something we 've thrown away that we shouldn't have . And um . So , when they were looking at the difference between the filter bank and the FFT that was going into the filter bank , I was thinking \" oh , OK , so they 're picking on something they 're looking on it to figure out noise , or voice  voiced property whatever . \" So that  that 's interesting . Maybe that helps to drive the  the thought process of coming up with the features . But for me sort of the interesting thing was , \" well , but is there just something in that difference which is useful ? \" So another way of doing it , maybe , would be just to take the FFT uh , power spectrum , and feed it into a neural network ,\nTo know\nand then use it , you know , in combination , or alone , or  or whatever\nWi - with what targets ?\nVoiced , unvoiced is like\nUh , no .\nOh . Or anything .\nNo the  just the same  same way we 're using  I mean , the same way that we 're using the filter bank .\nPhones .\nOh , OK .\nExact way  the same way we 're using the filter bank .\nMm - hmm .\nI mean , the filter bank is good for all the reasons that we say it 's good . But it 's different . And , you know , maybe if it 's used in combination , it will get at something that we 're missing . And maybe , you know , using , orth you know , KLT , or uh , um , adding probabilities , I mean , all th all the different ways that we 've been playing with , that we would let the  essentially let the neural network determine what is it that 's useful , that we 're missing here .\nMm - hmm . Mm - hmm .\nMm - hmm .\nYeah , but there is so much variability in the power spectrum .\nWell , that 's probably why y i it would be unlikely to work as well by itself , but it might help in combination .\nMm - hmm . Mmm .\nBut I  I  I have to tell you , I can't remember the conference , but , uh , I think it 's about ten years ago , I remember going to one of the speech conferences and  and uh , I saw within very short distance of one another a couple different posters that showed about the wonders of some auditory inspired front - end or something , and a couple posters away it was somebody who compared one to uh , just putting in the FFT and the FFT did slightly better . So I mean the  i i It 's true there 's lots of variability ,\nMm - hmm .\nbut again we have these wonderful statistical mechanisms for quantifying that a that variability , and you know , doing something reasonable with it .\nMm - hmm .\nSo , um , uh , It - it 's same , you know , argument that 's gone both ways about uh , you know , we have these data driven filters , in LDA , and on the other hand , if it 's data driven it means it 's driven by things that have lots of variability , and that are necessarily  not necessarily gonna be the same in training and test , so , in some ways it 's good to have data driven things , and in some ways it 's bad to have data driven things . So ,\nYeah , d\npart of what we 're discovering , is ways to combine things that are data driven than are not .\nYeah .\nUh , so anyway , it 's just a thought , that  that if we  if we had that  maybe it 's just a baseline uh , which would show us \" well , what are we really getting out of the filters \" , or maybe i i probably not by itself , but in combination , uh ,\nMm - hmm .\nyou know , maybe there 's something to be gained from it , and let the  But , you know , y you 've only worked with us for a short time , maybe in a year or two you w you will actually come up with the right set of things to extract from this information . But , maybe the neural net and the H M Ms could figure it out quicker than you .\nMaybe .\nSo .\nYeah ,\nIt 's just a thought .\nI can  I will try to do that .\nYeah .\nWhat  one  one um p one thing is like what  before we started using this VAD in this Aurora , the  th what we did was like , I  I guess most of you know about this , adding this additional speech - silence bit to the cepstrum and training the HMM on that .\nMm - hmm .\nThat is just a binary feature and that seems to be  improving a lot on the SpeechDat - Car where there is a lot of noise but not much on the TI - digits . So , a adding an additional feature to distin to discriminate between speech and nonspeech was helping . That 's it .\nWait  I  I 'm sorry ?\nYeah , we actually added an additional binary feature to the cepstrum , just the baseline .\nYeah ?\nYou did some experiment .\nYeah , yeah . Well , in  in the case of TI - digits it didn't actually give us anything , because there wasn't any f anything to discriminate between speech ,\nYeah .\nand it was very short . But Italian was like very  it was a huge improvement on Italian .\nHmm . Well  Mm - hmm . But anyway the question is even more , is within speech , can we get some features ? Are we drop dropping information that can might be useful within speech ,\nOK .\nI mean . To  maybe to distinguish between voice sound and unvoiced sounds ?\nMm - hmm . Yeah , yeah . Yeah .\nAnd it 's particularly more relevant now since we 're gonna be given the endpoints .\nYeah .\nSo .\nMm - hmm .\nYeah , yeah .\nUh . So .\nMmm .\nMmm .\nUm .\nThere was a paper in ICASSP  this ICASSP  over the uh extracting some higher - order uh , information from the cepstral coefficients and I forgot the name . Some is some harmonics I don't know , I can  I can pull that paper out from ICASSP . It\nTalking cumulants or something ?\nYeah .\nHuh ? Uh , I don't know .\nCumulants or something .\nI don't remember .\nBut  No .\nIt wa it was taking the , um  It was about finding the higher - order moments of  Yeah .\nYeah ,\nAnd I 'm not sure about whether it is the higher - order moments , or\ncumulants , yeah .\nmaybe higher - order cumulants\nOh .\nand  Yeah . It was  it was\nOr m e\nYeah . I mean , he was showing up uh some  something on noisy speech ,\nYeah .\nsome improvement on the noisy speech .\nMm - hmm .\nSome small vocabulary tasks .\nUh .\nSo it was on PLP derived cepstral coefficients .\nYeah , but again  You could argue that th that 's exactly what the neural network does .\nMmm .\nSo n neural network uh , is in some sense equivalent to computing , you know , higher - order moments of what you\ntrying to f to Moments , yeah . Yeah .\nyeah . So . I mean , it doesn't do it very specifically ,\nMm - hmm .\nand pretty  you know . But .\nYep .\nUh , anything on your end you want to talk about ? Uh .\nUm , nothing I wanna really talk about . I can  I can just uh , um , share a little bit  Sunil hasn't  hasn't heard about uh , what I 've been doing .\nYeah .\nUm , so , um , I told you I was  I was  I was getting prepared to take this qualifier exam . So basically that 's just , um , trying to propose um , uh , your next your  your following years of  of your PHD work , trying  trying to find a project to  to define and  and to work on . So , I 've been , uh , looking into , um , doing something about r uh , speech recognition using acoustic events . So , um , the idea is you have all these  these different events , for example voicing , nasality , R - coloring , you know burst or noise , uh , frication , that kinda stuff , um , building robust um , primary detectors for these acoustic events , and using the outputs of these robust detectors to do speech recognition . Um , and , um , these  these primary detectors , um , will be , uh , inspired by , you know , multi - band techniques , um , doing things , um , similar to Larry Saul 's work on , uh , graphical models to  to detect these  these , uh , acoustic events . And , um , so I  I been  I been thinking about that and some of the issues that I 've been running into are , um , exactly what  what kind of acoustic events I need , what  um , what acoustic events will provide a  a good enough coverage to  in order to do the later recognition steps . And , also , um , once I decide a set of acoustic events , um , h how do I  how do I get labels ? Training data for  for these acoustic events . And , then later on down the line , I can start playing with the  the models themselves , the  the primary detectors . Um , so , um , I kinda see  like , after  after building the primary detectors I see um , myself taking the outputs and feeding them in , sorta tandem style into  into a um , Gaussian mixtures HMM back - end , um , and doing recognition . Um . So , that 's  that 's just generally what I 've been looking at .\nYeah .\nUm ,\nBy  by the way , uh , the voiced - unvoiced version of that for instance could tie right in to what Carmen was looking at .\nYeah .\nSo ,\nMm - hmm .\nyou know , um , if you  if a multi - band approach was helpful as  as I think it is , it seems to be helpful for determining voiced - unvoiced ,\nMm - hmm .\nthat one might be another thing .\nMm - hmm .\nYeah . Yeah . Um , were  were you gonna say something ?", "topic_id": 3, "keywords": "parameters, parameter, spectrum, filt, cepstrum", "dialogue_id": 3}, {"text": "Mmm .\nOh . It looked  OK , never mind . Um , yeah . And so , this  this past week um , I 've been uh , looking a little bit into uh , TRAPS um , and doing  doing TRAPS on  on these e events too , just , um , seeing  seeing if that 's possible . Uh , and um , other than that , uh , I was kicked out of I - house for living there for four years .\nOh no . So you live in a cardboard box in the street now\nYeah .\nor , no ?\nUh , well , s s som something like that .\nYeah .\nIn Albany , yeah . Yeah . And uh . Yep . That 's it .\nSuni - i d ' you v did uh  did you find a place ?\nUh , no\nIs that out of the way ?\nnot yet . Uh , yesterday I called up a lady who ha who will have a vacant room from May thirtieth and she said she 's interviewing two more people . So . And she would get back to me on Monday . So that 's  that 's only thing I have and Diane has a few more houses . She 's going to take some pictures and send me after I go back . So it 's  that 's\nOK .\nOh . So you 're not down here permanently yet ?\nNo . I 'm going back to OGI today .\nAh ! Oh , OK .\nOh .\nOK . And then , you 're coming back uh\nUh , i I mean , I  I p I plan to be here on thirty - first .\nThirty - first ,\nYeah , well if there 's a house available or place to\nOK .\nThirty - first .\nWell , I mean i i if  if\nYeah , I hope .\nThey 're available , and they 'll be able to get you something , so worst comes to worst we 'll put you up in a hotel for  for  for a while\nYeah . So , in that case , I 'm going to be here on thirty - first definitely .\nuntil you  OK .\nYou know , if you 're in a desperate situation and you need a place to stay , you could stay with me for a while . I 've got a spare bedroom right now .\nOh . OK . Thanks . That sure is nice of you . So , it may be he needs more than me .\nOh r oh . Oh no , no . My  my cardboard box is actually a nice spacious two bedroom apartment .\nSo a two bedroom cardboard box . Th - that 's great .\nYeah . Yeah .  Yeah .\nThanks Dave .\nyeah\nYeah .\nUm ,\nYeah .\nDo y wanna say anything about  You  you actually been  Uh , last week you were doing this stuff with Pierre , you were  you were mentioning . Is that  that something worth talking about , or  ?\nUm , it 's  Well , um , it  I don't think it directly relates . Um , well , so , I was helping a speech researcher named Pierre Divenyi and he 's int He wanted to um , look at um , how people respond to formant changes , I think . Um . So he  he created a lot of synthetic audio files of vowel - to - vowel transitions , and then he wanted a psycho - acoustic um , spectrum . And he wanted to look at um , how the energy is moving  over time in that spectrum and compare that to the  to the listener tests . And , um . So , I gave him a PLP spectrum . And  to um  he  he t wanted to track the peaks so he could look at how they 're moving . So I took the um , PLP LPC coefficients and um , I found the roots . This was something that Stephane suggested . I found the roots of the um , LPC polynomial to , um , track the peaks in the , um , PLP LPC spectra .\nwell there is aligned spectral pairs , is like the  the  Is that the aligned s\nIt 's a r root LPC , uh , of some sort .\nOh , no .\nMm - hmm .\nSo you just\nYeah .\ninstead of the log you took the root square , I mean cubic root or something . What di w I didn't get that .\nNo , no . It 's  it 's  it 's taking the  finding the roots of the LPC polynomial .\nPolynomial . Yeah . Is that the line spectral\nSo it 's like line spectral pairs .\nOh , it 's like line sp\nExcept I think what they call line spectral pairs they push it towards the unit circle , don't they ,\nYeah , yeah , yeah , yeah .\nto sort of ? But it  But uh , you know . But what we 'd used to do w when I did synthesis at National Semiconductor twenty years ago , the technique we were playing with initially was  was taking the LPC polynomial and  and uh , finding the roots . It wasn't PLP cuz Hynek hadn't invented it yet , but it was just LPC , and uh , we found the roots of the polynomial , And th When you do that , sometimes they 're f they 're what most people call formants , sometimes they 're not .\nMmm .\nSo it 's  it 's  it 's a little ,\nHmm .\nuh  Formant tracking with it can be a little tricky cuz you get these funny  values in  in real speech ,\nSo you just  You typically just get a few roots ?\nbut .\nYou know , two or three ,\nWell you get these complex pairs .\nsomething like that ?\nAnd it depends on the order that you 're doing , but .\nMm - hmm .\nRight . So , um , if  @ @  Every root that 's  Since it 's a real signal , the LPC polynomial 's gonna have real coefficients . So I think that means that every root that is not a real root  is gonna be a c complex pair ,\nMm - hmm .\num , of a complex value and its conjugate . Um . So for each  And if you look at that on the unit circle , um , one of these  one of the members of the pair will be a positive frequency , one will be a negative frequency , I think . So I just  So , um , f for the  I 'm using an eighth - order polynomial and I 'll get three or four of these pairs\nYeah .\nHmm .\nwhich give me s which gives me three or four peak positions .\nThis is from synthetic speech , or  ?\nIt 's  Right . Yeah .\nYeah . So if it 's from synthetic speech then maybe it 'll be cleaner . I mean for real speech in real  then what you end up having is , like I say , funny little things that are  don't exactly fit your notion of formants all that well .\nHow did\nBut  but mostly they are .\nBut\nMostly they do .\nYeah .\nMmm ,\nAnd  and what  I mean in  in what we were doing , which was not so much looking at things , it was OK\nI\nbecause it was just a question of quantization . Uh , we were just you know , storing  It was  We were doing , uh , stored speech , uh , quantization .\nMm - hmm .\nBut  but uh , in your case um , you know\nActually you have peaks that are not at the formant 's positions , but they are lower in energy\nBut  there 's some of that , yes .\nand  Well they are much lower .\nIf this is synthetic speech can't you just get the formants directly ? I mean h how is the speech created ?\nIt was created from a synthesizer , and um\nWasn't a formant synthesizer was it ?\nI bet it  it might have  may have been\nI  d d this\nbut maybe he didn't have control over it or something ?\nIn  in fact w we  we could get , um , formant frequencies out of the synthesizer , as well . And , um , w one thing that the , um , LPC approach will hopefully give me in addition , um , is that I  I might be able to find the b the bandwidths of these humps as well . Um , Stephane suggested looking at each complex pair as a  like a se second - order IIR filter .\nYeah .\nUm , but I don't think there 's a g a really good reason not to um , get the formant frequencies from the synthesizer instead . Except that you don't have the psycho - acoustic modeling in that .\nYeah , so the actual  So you 're not getting the actual formants per se . You 're getting the  Again , you 're getting sort of the , uh\nMm - hmm .\nYou 're getting something that is  is uh , af strongly affected by the PLP model . And so it 's more psycho - acoustic . So it 's a little  It 's  It 's  It 's sort of  sort of a different thing .\nOh , I see . That 's sort of the point .\nBut  Yeah . i Ordinarily , in a formant synthesizer , the bandwidths as well as the ban uh , formant centers are\nYeah .\nI mean , that 's  Somewhere in the synthesizer that was put in , as  as what you\nMm - hmm .\nBut  but yeah , you view each complex pair as essentially a second - order section , which has , uh , band center and band width , and um , um  But . Yeah . O K . So , uh , yeah , you 're going back today and then back in a week I guess ,\nYeah .", "topic_id": 4, "keywords": "albany, place, diane, bedroom, room", "dialogue_id": 3}, {"text": "and . Yeah . Great ! Well , welcome .\nThanks .\nI guess we should do digits quickly .\nOh yeah , digits .\nMmm .\nI almost forgot that .\nDigits .\nI almost forgot our daily digits .\nYou wanna go ahead ?\nSure .\nOK .", "topic_id": 5, "keywords": "digits, great, welcome, quickly, forgot", "dialogue_id": 3}, {"text": "Ah , so comfortable .\nSmooth .\nMm - hmm . Good . I know that he 's going to like , Taiwan and other places to eat . So .\nOn ? Am I on ?\nYep . Yep .\nI think I 'm on ?\nYeah .\nGood . Good .\nBye .\nActually\nI just had one of the most frustrating meetings of my career .\nIt 's definitely not the most frustrating meeting I 've ever had .\nYou a You 're  you remember you 're being recorded at this point .\nOh , yeah , so , w we didn't yet specify with whom .\nYeah .\nYeah .\nRight .\nBut um .\nUh , right .\nSo that 's why Keith and I are going to be a little dazed for the first half m the meeting .\nUh .\nHuh . Yeah , I 'm just gonna sit here and\nRight . Yeah , I  I  I avoided that as long as I could for you guys ,\ngrowl .\nbut , uh\nYeah .\nMm - hmm .\nFor which we thank you , by the way .\nAre very appreciative , yeah .\nRight .\nI know you were  you were doing that , but , anyway .\nOh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ?\nOh , I could tell you had a rough day , man !\nNah .\nWhat ?\nI love that story .\nYeah , it 's a great story .\nOK .\nOh my goodness .\nOh yeah , um , Liz suggested we could start off by uh , doing the digits all at the same time .\nWhat ?\nAll at the same time . I don't know if  I would get distracted and confused , probably .\ne\nReally ? Do we have to like , synchronize ?\nWell , I think you 're supposed to  OK . We can do this .\nAre you being silly ?\nOh wait do we have t\nEverybody 's got different digits ,\nYep .\nright ?\nYeah , do we have to time them at the same time or just overlapping\nUh .\nYou 're kidding .\nNo , no , just  just start whenever you want .\nNo .\nAnd any rate ?\ne yeah , the\nAlright .\nWell , they  they have s they have the close talking microphones for each of us ,\nYeah , that 's true .\nso", "topic_id": 0, "keywords": "meeting, meetings, talking, distracted, sit", "dialogue_id": 4}, {"text": "Yeah .\nyeah , there 's separate channels .\nAlright .\nOK .\nYeah .\nSo when I say\nJust plug one ear .\nYou lose .\nOK .\nOK , bye ! That was a great meeting !\nRight .\nAlright .\nSo -  Now , uh , why ?\nJust to save time .\nOK .\nDoes matter for them .\nAre we gonna start all our meetings out that way from now on ?\nNo .\nOh . Too bad . I kinda like it .\nWell , could we ?\nIt 's strangely satisfying .\nYeah . It 's a ritual .\nAre we to r Just to make sure I know what 's going on , we 're talking about Robert 's thesis proposal today ? Is that\nWe could .\ntrue ?\nWe are ?\nWe might .\nOK .\nIs\nWell , you  you had s you said there were two things that you might wanna do . One was rehearse your i i talk\nOh yes , and that too .\nNot  not rehearse , I mean , I have just not spent any time on it , so I can show you what I 've got , get your input on it , and maybe some suggestions , that would be great . And the same is true for the proposal . I will have time to do some revision and some additional stuff on various airplanes and trains . So , um . I don't know how much of a chance you had to actually read it\nI haven't looked at it\nbecause\nyet ,\nbut you could always send me comments per electronic mail\nbut I will .\nand they will be incorporated .\nOK .\nUm ,  the  It basically says , well \" this is construal \" , and then it continues to say that one could potentially build a probabilistic relational model that has some general , domain - general rules how things are construed , and then the idea is to use ontology , situation , user , and discourse model to instantiate elements in the classes of the probabilistic relational model  to do some inferences in terms of what is being construed as what\nHmm .\nin our beloved tourism domain . But , with a focus on\nCan I s Sorry .\nI think I need a copy of this , yes .\nHmm ?\nOK , we can  we can  we can pass  pass my , uh  we can pass my extra copy around .\nI is there an extra copy around ?\nUh . He sent it . OK . You can keep it .\nEr , actually , my only copy , now that I think about it ,\nAlrigh\nOK .\nUm , I don't  I , uh  I don't need it .\nbut . I already read half of it , so it 's OK .\nUm , actually this is the  the newest version after your comments ,\nOK .\nand\nYeah , no I s I s I see this has got the castle in it , and stuff like that .\nYeah .\nYep .\nOh , maybe the version I didn't have that I  mine  the w did the one you sent on the email have the\nYeah .\nThat was the most recent one ?\nUh , yeah , I think so .\nYep .\nOK . Cuz I read halfway but I didn't see a castle thing .\nI 'm changing this . Just so you know .\nYeah ,\nBut , anyway .\num , if you would have checked your email you may have received a note from Yees asking you to send me the , uh , up - to - d\nOh . Oh , sorry . OK . Sorry .\ncurrent formalism thing that you presented .\nOK . I will . OK . OK . OK .\nBut for this it doesn't matter . But , uh\nWe can talk about it later . That 's not even ready , so . Um , OK ! Go on t to , uh , whatever .\nAnd\nI 'm making changes . \" Don't worry about that . \" OK . Mmm - mmm . Oh ! OK , sorry , go on .\nAnd any type of comment whether it 's a spelling or a syntax or\nMm - hmm .\nreadability\nThere 's only one \" S \" in \" interesting \" .\nHmm ?\nThere 's only one \" S \" in \" interesting \" . On page five .\nInteresting .\nAnyway . And y uh , email any time , but most usefully before\nThe twenty - first I 'm assuming .\nThe twenty - first ?\nTwenty - ninth .\nNo , this is the twenty - first .\nThat 's\nWhat , today 's the twenty - first ?\nWell , better hurry up then !\nOh , man !\nBefore the twenty - ninth ,", "topic_id": 1, "keywords": "meeting, rehearse, meetings, proposal, talking", "dialogue_id": 4}, {"text": "The twenty - ninth .\nOK .\nOK .\nThat 's when I 'm meeting with Wolfgang Wahlster to sell him this idea .\nMm - hmm . OK .\nOK ? Then I 'm also going to present a little talk at EML , about what we have done here and so of course , I 'm  I 'm gonna start out with this slide , so the most relevant aspects of our stay here , and um , then I 'm asking them to imagine that they 're standing somewhere in Heidelberg and someone asks them in the morning  The Cave Forty - Five is a  is a well - known discotheque which is certainly not open at that  that time . And so\nOK .\nthey 're supposed to imagine that , you know , do they think the person wants to go there , or just know where it is ? Uh , which is probably not , uh , the case in that discotheque example , or in the Bavaria example , you just want to know where it is . And so forth . So basically we can make a point that here is ontological knowledge but if it 's nine  nine PM in the evening then the discotheque question would be , for example , one that might ask for directions instead of just location . Um ,  and so forth and so forth . That 's sort of motivating it . Then what have we done so far ? We had our little bit of , um , um , SmartKom stuff , that we did , um , everth\nOh , you 've got the parser done . Sorry .\nThat 's the  not the construction parser . That 's the , uh , tablet - based parser ,\nOK .\nEasy parser .\nOK .\nand the generation outputter .\nHalfway done ? Yeah .\nThat 's done .\nMmm .\nYou have to change those strategies ,\nOK .\nright ? That 's , ten words ?\nYeah . Well , i it , you know . Maybe twelve .\nTwelve ? OK . And , um , and Fey is doing the synthesis stuff as we speak . That 's all about that . Then I 'm going to talk about the data , you know these things about  uh , actually I have an example , probably . Two s Can you hear that ? Or should I turn the l volume on .\nMm - hmm .\nI could hear it .\nI I can hear it .\nI heard it .\nThey might not hear it in the  well maybe they will . I don't know .\nThis was an actual , um , subject ? Ah .\nMm - hmm .\nSounds like Fey .\nYeah .\nBut they 're  they 're mimicking the synthesis when they speak to the computer ,\nOh , OK .\nthe  you can observe that all the time , they 're trying to match their prosody onto the machine .\nOh really . Interesting . Oh , it 's pretty slow .\nYeah , you have to\nWh\nThe system breaking .\nWhat is the s ? Oh !\nOK . And so forth and so forth . Um , I will talk about our problems with the rephrasing , and how we solved it , and some preliminary observations , also , um , I 'm not gonna put in the figures from Liz , but I thought it would interesting to , uh , um , point out that it 's basically the same . Um , as in every human - human telephone conversation , and the human - computer telephone conversation is of course quite d quite different from , uh , some first , uh , observations . Then sort of feed you back to our original problem cuz , uh  how to get there , what actually is happening there today , and then maybe talk about the big picture here , e tell a little bit  as much as I  can about the NTL story . I  I wa I do wanna , um  I 'm not quite sure about this , whether I should put this in , um , that , you know , you have these two sort of different ideas that are  or two different camps of people envisioning how language understanding works , and then ,  talk a bit about the embodied and simulation approach favored here and as a prelude , I 'll talk about monkeys in Italy . And , um , Srini was gonna send me some slides but he didn't do it , so from  but I have the paper , I can make a resume of that , and then I stole an X - schema from one of your talks I think .\nOh . I was like , \" where 'd you get that ? \" OK .\nYeah , that looks familiar .\n\" Looks familiar . \"\nI think that 's Bergen , Chang , something , or the other .\nUh .\nWhatever .\nOK .\nUm , and that 's  now I 'm not going to bring that . So that 's basically what I have , so far , and the rest is for airplanes . So X - schemas , then , I would like to do  talk about the construction aspect and then at the end about our Bayes - net .\nMm - hmm .\nEnd of story . Anything I forgot that we should mention ? Oh , maybe the FMRI stuff . Should I mention the fact that , um , we 're also actually started  going to start to look at people 's brains in a more direct way ?\nYou certainly can . I mean I y I you know , I don't know\nYou might just wanna like , tack that on , as a comment , to something .\nRight , um .\n\" Future activities \" something .\nWell , the time to mention it , if you mention it , is when you talk about mirror neurons , then you should talk about the more recent stuff , about the kicking\nYeah .\nand , you know , the  yeah , yeah  and  that the plan is to see to what extent the  you 'll get the same phenomena with stories about this , so that\nMm - hmm .\nand that we 're planning to do this , um , which , we are . So that 's one thing . Um . Depends . I mean , there is a , um , whole language learning story , OK ?\nYeah .\nwhich , uh , actually , i i even on your five - layer slide , you  you 've got an old one that  that leaves that off .\nYeah , I  I  I do have it here .\nHmm .\nYeah .\nUm . And , of course , you know , the  the big picture is this bit .\nRight .\nBut , you know , it would  But I don't think I  I am capable of  of do pulling this off and doing justice to the matter . I mean , there is interesting stuff in her terms of how language works , so the emergentism story would be nice to be  you know , it would be nice to tell people how  what 's happening there , plus how the , uh , language learning stuff works ,\nOK , so , so anyway , I  I agree that 's not central .\nbut\nMm - hmm .\nWhat you might wanna do is , um , and may not , but you might wanna  this is  rip off a bunch of the slides on the anal there  the  there  we 've got various i generations of slides that show language analysis , and matching to the underlying image schemas , and , um , how the construction and simulation  that ho that whole th\nYeah , th that  that 's c that comes up to the X - schema slide ,\nOK , right .\nso basically I 'm gonna steal that from Nancy ,\nOK , I can give you a more recent  if you want\none of Nancy 's st\nwell , that might have enough .\nUh , I  yeah , but I also have stuff you  trash you left over ,\nOK .\nyour quals and your triple - AI .\nThe quals w the  the  the quals slides would be fine .\nYeah .\nYou could get it out of there , or some\nWhich I can even email you then , you know , like there probably was a little  few changes , not a big deal . Yeah , you could steal anything you want , I don't care . Which you 've already done , obviously . So . Sorry\nWell , I  I don't feel bad about it at all\nNo , you shouldn't .\nbecause  because you are on the , uh , title .\nOh , that 's great , that 's great .\nI mean on the  the , you 're  that 's  see , that 's you .\nI 'm glad to see propagation .\nYeah . Yeah .\nMmm .\nHmm ? Propagated ?\nYes .\nI mean I might even mention that this work you 're doing is sort of also with the MPI in Leipzig , so .\nIt 's  it 's certainly related , um ,\nBecause , um , EML is building up a huge thing in Leipzig .\nmight wanna say . Is it ?\nSo it  It 's on biocomputation . Would\nYeah , it 's different , this is the , uh , DNA building , or someth the double helix building .\nYeah .\nYeah .\nKind of a different level of analysis .\nThe  yeah it was  it turns out that if  if you have multiple billions of dollars , y you can do all sorts of weird things , and\nWait , they 're building a building in the shape of DNA ,\nWhat ?\nis that what you said ?\nRoughly , yeah .\nOh ! Oh boy !\nO\nIncluding cr cross - bridges ,\nWhat ?\nand\nOh my god !\nThat 's brilliant ! Hhh .\nYou d you really  now I I spent  the last time I was there I spent maybe two hours hearing this story which is , um\nOf what\nY You definitely wanna w don't wanna waste that money on research ,\nthe building ?\nyou know ?\nRight .\nThat 's horrible .\nRight . Well , no , no , y i there 's infinite money . See you th you th you then fill it with researchers .\nAnd give them more money . They just want a fun place for them to  to work .\nRight . Right .\nAnd everybody gets a trampoline in their office .\nWell , the  the offices are actually a little  the , think of um , ramps , coming out of the double helix and then you have these half - domes , glass half - domes , and the offices are in  in the glass half - dome .\nReally ?\nYeah .\nAlright , let 's stop talking about this .\nDoes it exist yet ?\nYeah .\nThey are w now building it ?\nUh , as a model .\nHmm .\nBut I th", "topic_id": 2, "keywords": "heidelberg, bavaria, discotheque, cave, place", "dialogue_id": 4}, {"text": "So , yeah , I think that 's  that 's a good point , th th that the date , the , uh , a lot of the  this is interacting with , uh , people in Italy but also definitely the people in Leipzig and the  the b the combination of the biology and the Leipzig connection might be interesting to these guys , yeah . OK . OK . Anyway ! Enough of that , let 's talk about your thesis proposal .\nYeah , if somebody has something to say .\nYep .\nYou might want to , uh , double - check the spellings of the authors ' names on your references , you had a few , uh , misspells in your slides , there . Like I believe you had \" Jackendorf \" .\nUm .\nUh , unless there 's a person called \" Jackendorf \" ,\nOn that one ?\nNo , no , no .\nyeah . But that 's the only thing I noticed in there .\nIn the presentation ?\nIn the presentation .\nI 'll probably  I c might have  I 'll probably have comments for you separately , not important . Anyway .\nOh , in the presentation here .\nYeah , that 's what he was talking about .\nYeah .\nI was ac actually worried about bibtex . Uh . No , that 's quite possible . That 's copy and paste from something .\nSo I did note i i it looks like the , uh , metaphor didn't get in yet .\nUh , it did , there is a reference to Srini\nWell , s reference is one thing , the question is is there any place  Oh , did you put in something about ,\nMetonymy and metaphor here , right ?\nuh , the individual , we 'd talked about putting in something about people had , uh  Oh yeah , OK . Good . I see where you have it . So the top of the second  of pa page two you have a sentence .\nMm - hmm .\nBut , what I meant is , I think even before you give this , to Wahlster , uh , you should , unless you put it in the text , and I don't think it 's there yet , about  we talked about is the , um , scalability that you get by , um , combining the constructions with the general construal mechanism . Is that in there ?\nYeah , mmm . Um .\nUh , OK , so where  where is it , cuz I 'll have to take a look .\nUm , but I  I did not focus on that aspect but , um  Ehhh , um , it 's just underneath , uh , um , that reference to metaphor . So it 's the last paragraph before two . So on page two , um , the main focus\nUh , OK . Yeah .\nBut that 's really\nThat 's not about that , is it ?\nYeah .\nNo , it  it  it s says it but it doesn't say  it doesn't  it d it d\nWhy .\nyeah , it doesn't give the punch line .\nMm - hmm .\nCuz let me tell the gang what I think the punch line is , because it 's actually important , which is , that , the constructions , that , uh , Nancy and Keith and friends are doing , uh , are , in a way , quite general but cover only base cases . And to make them apply to metaphorical cases and metonymic cases and all those things , requires this additional mechanism , of construal . And the punch line is , he claimed , that if you do this right , you can get essentially orthogonality , that if you introduce a new construction at  at the base level , it should com uh , interact with all the metonymies and metaphors so that all of the projections of it also should work .\nMm - hmm .\nAnd , similarly , if you introduce a new metaphor , it should then uh , compose with all of the constructions .\nMm - hmm . Yeah .\nAnd it  to the extent that that 's true then  then it 's a big win over anything that exists .\nSo does that mean instead of having tons and tons of rules in your context - free grammar you just have these base constructs and then a general mechanism for coercing them .\nYeah .\nMm - hmm . So that , you know , for example , uh , in the metaphor case , that you have a kind of direct idea of a source , path , and goal and any metaphorical one  and abstract goals and all that sort of stuff   you can do the same grammar .\nMmm .\nAnd it is the same grammar . But , um , the trick is that the  the way the construction 's written it requires that the object of the preposition for example be a container . Well , \" trouble \" isn't a container , but it gets constr construed as a c container .\nRight .\nEt cetera . So that 's  that 's where this , um ,\nSo with construal you don't have to have a construction for every possible thing that can fill the rule .\nRight . So 's it 's  it  it 's a very big deal , i i in this framework , and the thesis proposal as it stands doesn't , um , I don't think , say that as clearly as it could .\nNo , it doesn't say it at all . No . Even though   One could argue what  if there are basic cases , even . I mean , it seems like nothing is context - free .\nOh , nothing is context - free , but there are basic cases . That is , um , there are physical containers , there are physical paths , there  you know , et cetera .\nBut \" walked into the cafe and ordered a drink , \" and \" walked into the cafe and broke his nose , \" that 's sort of\nOh , it doesn't mean that they 're unambiguous .\nMmm . Yeah .\nI mean , a cafe can be construed as a container , or it can be construed you know as  as a obstacle ,\nUh - huh .\nor as some physical object . So there are multiple construals . And in fact that 's part of what has to be done . This is why there 's this interaction between the analysis and the construal .\nMm - hmm . Yep .\nThe b the  the double arrow .\nYep .\nSo , uh , yeah , I mean , it doesn't magically make ambiguity go away .\nNo .\nBut it does say that , uh , if you walked into the cafe and broke your nose , then you are construing the cafe as an obstacle .\nMm - hmm .\nAnd if that 's not consistent with other things , then you 've gotta reject that reading .\nYep .\nYou con  you conditioned me with your first sentence , and so I thought , \" Why would he walk into the cafe and then somehow break his nose ? \" uh , oh , uh\nHe slipped on the wet floor .\nRight .\nYou don't find that usage , uh  uh , I checked for it in the Brown national corpus .\nYeah .\nThe \" walk into it \" never really means , w as in walked smack\nBut \" run into \" does .\nYeah , but , y y if you find \" walked smacked into the cafe \" or \" slammed into the wall \"\nYeah , no , but \" run into \" does .\nMm - hmm .\nBecause you will find \" run into , \" uh ,\nCars run into telephone poles all the time .\nwell , or \" into the cafe \" for that m\nRight .\nyou know  \" His car ran into the cafe . \"\nYeah . Or you can run into an old friend , or run .\nWell , you can \" run into \" in that sense too .\nYeah , \" run into \" might even be more impact sense than , you know , container sense .\nBut , uh , Right .\nDepends .\nBut  Like , \" run into an old friend \" , it probably needs its own construction . I mean , uh , you know , George would have I 'm sure some exa complicated ex reason why it really was an instance of something else\nMm - hmm . Mm - hmm .\nand maybe it is , but , um , there are idioms and my guess is that 's one of them , but , um  I don't know .\nAll contact . I mean , there there 's contact that doesn't  social contact , whatever . I mean .\nUh .\nSudden surprising contact ,\nYeah , but it 's  it 's  it 's  it 's  Right . i Yeah , it 's more\nright ?\nForceful .\nBut of course , no , i i I mean it has a life of its own . It 's sort of partially inspired by the spatial\nWell , this is this motivated  but yeah\nYeah .\noh yeah , mo for sure , motivated , but then you can't parse on motivated .\nYeah . Yeah . Right .\nUh ,\nToo bad .\nYou should get a T - shirt that says that .\nOK .\nThere 's  there 's lots of things you could make T - shirts out of , but , uh , this has gotten  I mean wh We don't need the words to that .\nPro - probably not your marks in the kitchen , today .\nWhat ? Oh , no no no no no no no no no , we 're not going there .\nNot  not your marks .\nOK .\nOK , so , um ,\nIn other news .\nanything else you want to ask us about the thesis proposal , you got\nWell ,\nWe could look at a particular thing and give you feedback on it .\nWell there  actually  the  i what would have been really nice is to find an example for all of this , uh , from our domain . So maybe if we w if we can make one up  now , that would be c incredibly helpful .\nSo , w where it should illustrate\nOK .\nuh  wh when you say all this , do you mean , like , I don't know , the related work stuff ,\nHow\nas well as , mappings ?\nw Well we have , for example , a canonical use of something\nRight  right  r\nand y it 's , you know , we have some constructions and then it 's construed as something , and then we  we may get the same constructions with a metaphorical use that 's also relevant to the  to the domain .\nOK , f let 's  let 's suppose you use \" in \" and \" on \" . I mean , that 's what you started with .\nMm - hmm .\nSo \" in the bus \" and \" on the bus , \" um , that 's actually a little tricky in English because to some extent they 're synonyms . OK .\nI had two hours w with George on this , so it ,\nOK , what did he say .\nDid you ?\num  Um .\nJoin the club .\nRight . Oh , h that 's\n\" On the bus \" is a m is a metaphorical metonymy that relates some meta path metaphorically and you 're on  on that path and th w I mean it 's  he  there 's a platform notion ,\nYeah , I  I believe all that , it 's just\nright ? \" he 's on the  standing on the bus waving to me . \"\nYeah .\nBut th the regular as we speak \" J Johno was on the bus to New York , \"\nYeah . Yeah .\num , uh , he 's  that 's , uh , what did I call it here , the transportation schema , something ,\nYeah .\nwhere you can be on the first flight , on the second flight ,\nYeah .\nand you can be , you know , on the wagon .\nRight . So  so that  that may or may not be what you  what you want to do . I mean you could do something much simpler\nYeah .\nlike \" under the bus , \" or something , where\nBut it 's  it 's  unfortunately , this is not really something a tourist would ever say . So .\nWell , unless he was repairing it or something ,\nYeah .\nbut yeah .\nBut um .\nUh , but OK .\nSo in terms of the  this\nI see .\nWe had  we had  initially we 'd  started discussing the \" out of film . \"\nRight .\nAnd there 's a lot of \" out of \" analysis , so , um ,\nRight .\ncould we capture that with a different construal of\nYeah , it 's a little  it 's , uh  we 've thought about it before , uh t uh  to use the examples in other papers , and it 's  it 's a little complicated . Cuz you 're like , it 's a state of  there 's resource ,\nOut of  out of film , in particular .\nright , and like , what is film ,\nYeah .\nthe state  you know . You 're out of the state of having film , right ? and somehow film is standing for the re the resour the state of having some resource is just labeled as that resource .\nIt 's\nI mean .\nyeah , I mean ,\nIt 's a little bit\nbut  and plus the fact that there 's also s I mean , can you say , like , \" The film ran out \" you know , or , maybe you could say something like \" The film is out \"\nYeah , is film the trajector ?\nso like the  the film went away from where it should be , namely with you , or something , right ? You know . The  the film  the film is gone , right ? Um , I never really knew what was going on , I mean I  I find it sort of a little bit farfetched to say that  that \" I 'm out of film \" means that I have left the state of having film or something like that ,\nIt 's weird . That\nbut .\nOr , \" having \" is also , um , associated with location ,\nUh .\nright ?\nYeah . Yeah .\nso if the film left , you know  state is being near film .\nSo running  running out of something is different from being out of somewhere .\nOr being out of something as , uh  as well . So \" running out of it \" definitely has a process aspect to it .\nMm - hmm . But that 's from run , yeah .\nSo ,\nMm - hmm .\nb that 's OK ,\nYeah .\nI mean  b but the difference\nIs the d the final state of running out of something is being out of it .\nis\nYeah . So th\nRight .\nYeah . You got there .\nThat part is fine .\nYou got to out of it .\nYeah .\nYeah .\nBut , uh\nHmm !\nYeah , so  so nob so no one has in  in  of the , uh , professional linguists ,\nUh .\nthey haven't  there was this whole thesis on \" out of \" .\nThere was ? Who ?\nWell , there  I thought  or there was a paper on it .\nOut .\nHuh ?\nThere was one on  on \" out \" or \" out of \" ?\nThere was a Well , it may be just \" out \" . Yeah .\nOK .\nI think there was \" over \" but there was also a paper on \" out \" .\nYeah , Lind - Susan Lindner ,\nOh , yeah , you 're right . Yeah .\nOr something .\nright ? The  the  \" the syrup spread out \" ?\nYeah , and all that sort of stuff .\nThat kind of thing ?\nYeah . And undoubtably there 's been reams of work about it in cognitive linguistics ,\nOK . But anyway . We 're not gonna do that between now and next week .\nbut . Yeah .\nYeah .\nOK . So , um\nIt 's not one of the y it 's more straightforward ones  forward ones to defend , so you probably don't want to use it for the purposes\nMm - hmm .\nRight .\nth these are  you 're addressing like , computational linguists ,\nOK .\nright . Or  are you ?\nThere 's gonna be four computational linguists ,\nOK . But more emphasis on the computational ? Or emphasis on the linguist ?\ncomputer it 's  More  there 's going to be the  just four computational linguists , by coincidence , but the rest is , whatever , biocomputing people and physicists .\nOh , OK .\nNo no no , but not for your talk . I 'm - we 're worrying about the th the thes\nOh , the thesis !\nOh , I meant this ,\nit 's just for one guy .\nThat 's  that 's computa should be very computational ,\nyou know , like  OK . So I would try to  I would stay away from one that involves weird construal stuff .\nand , uh , someth\nYeah .\nYeah .\nRight .\nYou know , it 's an obvious one\nTotally weird stuff .\nI mean the  the old bakery example might be nice ,\nbut , uh\n\" Is there a bakery around here \" . So if you c we really just construe it as a\nYeah .\nAround ?\nNo , it 's the bakery itself\nOh .\nis it a building ? uh , that you want to go to ? or is it something to eat that you want to buy ?\nOh , oh yeah . Yeah , we 've thought about that . Right . Right .\nAnd then\nNnn . No . What ? \" Bakery \" can't be something you 're gonna eat .\nNo , no . The question is d do you wanna  do you wanna construe  do you wanna constr - strue\nSh\nIt 's a speech - act .\nr Exactly . It 's because do you wanna c do you want to view the bakery as a p a place that  that  i for example , if  y\nYeah . Where you can get baked goods .\nWell th well , that 's one . You want to buy something . But the other is , uh , yo you might have smelled a smell and are just curious about whether there 'd be a bakery in the neighborhood , or ,\nMm - hmm .\num , pfff you know , you wonder how people here make their living , and  there 're all sorts of reasons why you might be asking about the existence of a bakery\nYeah .\nthat doesn't mean , \" I want to buy some baked goods . \"\nOK .\nBut  um , those are interesting examples but it 's not clear that they 're mainly construal examples .\nSo it 's a lot of pragmatics , there , that\nYeah .\nMmm .\nThere 's all sorts of stuff going on .\nmight be beyond what you want to do .\nSo let 's  so let 's think about this from the point of view of construal . So let 's first do a  So the metonymy thing is probably the easiest and a and actually the  Though , the one you have isn't quite\nYou mean the s You mean \" the steak wants to pay \" ?\nN no not that one , that 's  that 's a  the sort of background . This is the t uh , page five .\nAbout Plato and the book ?\nOh .\nNo .\nUm .\nNo .\nHow much does it cost ?\nJust beyond that .\nOnward .\nWhere is the castle ?\nYeah .\nA castle .\nHow old is it ? How much does it cost ?\nOh .\nMm - hmm .\nTo go in , that 's like\nTwo hundred million dollars .\nRight . It 's not for sale . Uh . So\nYeah , I think that 's a good example , actually .\nS\nYeah , that 's good . u\nBut as Nancy just su suggested it 's probably ellipticus .\nEllipsis .\nHuh .\nLike , \" it \" doesn't refer to \" thing , \" it refers to acti you know , j thing standing for activ most relevant activity for a tourist  you could think of it that way , but .\nYeah .\nWell , shoot , isn't that  I mean , that 's what\nWell , I mean , my argument here is  it 's  it 's  it 's the same thing as \" Plato 's on the top shelf , \"\nfiguring that out is what this is about .\nYeah , yeah , no , I I agree .\nI 'm con you know , th that you can refer to a book of Plato by using \" Plato , \"\nYeah . No no , I  I 'm agreeing that this is a good , um\nand you can refer back to it , and so you can  Castles have  as tourist sites , have admission fees , so you can say \" Where is the castle , how much does it cost ? \" Um . \" How far is it from here ? \"\nMm - hmm .\nSo , You 're also not referring to the width of the object , or so ,\nHmm . Mm - hmm .\nwww .\nMmm .\nOK . Can we think of a nice metaphorical use of \" where \" in the tourist 's domain ? Um .\nHmm .\nSo you know it 's  you  you can sometimes use \" where \" f for \" when \"\nO\nin the sense of , you know , um , where  wh where  where was , um , \" where was Heidelberg , um , in the Thirty Years ' War ? \" Or something .\nMm - hmm .\nUh , yeah .\nYou know , or some such thing . Um .\nLike what side were they on ,\nWhat ?\nYeah . Essentially , yeah .\nor  ?\nOK . I was like , \" Huh ? It was here . \" Like   Um .\nBut anyway th so there are  there are cases like that . Um ,\nAh ! Or like its developmental state or something like that , you could  I guess you could get that .\nYeah .\nUm .\nUm .\nI mean , there 's also things like  I mean , s um , I guess I could ask something like \" Where can I find out about blah - blah - blah \" in a sort of  doesn't nece I don't necessarily have to care about the spatial location , just give me a phone number\nYeah . There certainly is that , yeah .\nand I 'll call them or something like that ?\nYou know , \" Where could I learn its opening hours , \" or something .\nYeah .\nBut that 's not metaphorical .\nHmm .\nIt 's another\nYeah .\nSo we 're thinking about , um , or we could also think about , uh\nWell , I  I  I\nHow about \" I 'm in a hurry \" ?\nState .\nIt i But it 's a state  and the  the issue is , is that  it may be just a usage ,\nHmm ?\nyou know , that it 's not particularly metaphorical , I don't know .\nMmm .\nRight . So you want a more exotic one  version of that .\nOh .\nYeah . Yeah , right .\nI 'm really into\nAh ! How about I  I  I  you know , \" I 'm in  I 'm in a state of exhaustion \" ?\nDo you really say that ?\nor something like that , which a tourist w Huh ?\nWould you really say that ?\nA st uh , well , you can certainly say , um , you know , \" I 'm in overload . \" Tu - stur tourists will often say that .\nYeah .\nI I 'm really into art .\nYeah , I was gonna say , like\nUh\nOh , you can do that ? Really ? Of course that 's  that  that 's definitely a , uh\nFixed .\nA fixed expression , yeah .\nthat 's a , uh  Right . But .\nThere 're too  there 're all sorts of fixed expressions I don't  like uh \" I 'm out of sorts now ! \"\nRight .\nLike  \" I 'm in trouble ! \"\nWell I  when , uh  just f u the data that I 've looked at so far that rec\nYeah .\nI mean , there 's tons of cases for polysemy .\nRight .\nUh - huh .\nSo , you know , mak re making reference to buildings as institutions , as containers , as build\nRight .\nyou know , whatever . Um , so ib in mus for example , in museums , you know , as a building or as something where pictures hang versus , you know , ev something that puts on exhibits , so forth .\nRight . As an institution ,\nBut\nyeah .\nUm .\nWhy don't you want to use any of those ?\nHmm ?\nSo y you don't wanna use one that 's\nYeah , well  No , but this  that 's what I have , you know , started doing .\nThe castle  the  that old castle one is sort of\nMetonymy , polysemy .\nI love Van Gogh .\nYeah .\n\" I wanna go see the Van Gogh . \"\nAh !\nOh geez .\nAnyway , I 'm sorry .\nBut I think the argument should be  uh , can be made that , you know , despite the fact that this is not the most met metaphorical domain , because people interacting with HTI systems try to be straightforward and less lyrical ,\nYeah .\nconstrual still is , uh , you know , completely , um , key in terms of finding out any of these things , so , um .\nRight . So that 's  that 's  that 's a  that 's a reasonable point , that it  in this domain you 're gonna get less metaphor and more metonymy .\nWe , uh  I  with a  I looked  with a student I looked at the entire database that we have on Heidelberg for cases of metonymy .\nAnd polysemy , and stuff like that . Yeah .\nHardly anything . So not even in descriptions w did we find anything , um , relevant .\nI have to go .\nAlright . Yeah .\nBut OK this is just something we 'll  we 'll see , um ,\nRight . s See you .\nand deal with .\nOK , well . I guess if anybody has additional suggestions ,\nI mean maybe the \" where is something \" question as a whole , you know , can be construed as , u i locational versus instructional request .\nw Yeah .\nSo , if we 're not talk about the lexic\nLocation versus what ?\ninstruction .\nInstruction . Oh , directions ? Yeah .\nSure .\nOh , I thought that was  definitely treated as an example of construal .\nYeah .\nRight ?\nYeah but then you 're not on the lexical level , that 's sort of one level higher .\nOh , you want a lexical example .\nBut I don't need it .\nWell , you might want both .\nMm - hmm .\nYeah .\nAlso it would be nice to get  ultimately to get a nice mental space example ,\nWe\nso , even temporal references are  just in the spatial domain are rare .\nBut it 's  it 's easy to make up plausible ones .\nWhen  when you 're getting information on objects .\nYou know .\nSo , I mean\nRight , you know  you know , where r Yeah . What color was this in  in in the nain nineteenth century .\nYeah .\nWhat was this p instead of  wh what  you know  how was this painted , what color was this painted , um , was this alleyway open .\nYeah , maybe we can include that also in our second , uh , data run .\nUh .\nWe c we can show people pictures of objects and then have then ask the system about the objects and engage in conversation on the history and the art and the architecture and so forth .\nMm - hmm . OK . So why don't we plan to give you feedback electronically . Wish you a good trip . All success .\nFor some reason when you said \" feedback electronically \" I thought of that  you ever see the Simpsons where they 're  like the family 's got the buzzers and they buzz each other when they don't like what the other one is saying ?\nYeah . That 's the  first one , I think . The very very first one .\nIt was a very early one . I don't know if it 's the first one .\nMmm . Mmm .", "topic_id": 3, "keywords": "leipzig, linguistics, thesis, corpus, heidelberg", "dialogue_id": 4}, {"text": "OK , this is one channel . Can you uh , say your name and talk into your mike one at a time ?\nThis is Eric on channel three , I believe .\nOK . Uh , I don't think it 's on there , Jane .\nTasting one two three , tasting .\nOK , this is Jane on channel five .\nUh , I still don't see you Jane .\nOh , darn , what am I doing wrong ?\nCan you see me on channel four ? Really ?\nYeah , I s\nMy lucky day .\nUh , screen no ,  it is , oh , maybe it just warmed up ?\nNo .\nOh , darn , can you can't see channel five yet ?\nUh , well , the mike isn't close enough to your mouth , so .\nOh , this would be k OK , is that better ?\nS uh , try speaking loudly ,\nI like the high quality labelling .\nso ,\nHello ,\nOK , good .\nDavid , can we borrow your labelling machine to improve the quality of the labelling a little bit here ?\nhello . Alright .\nThank you .\nOne t\nHow  how many are there , one to five ?\nOne five , yeah .\nYeah , please .\nWould you like to join the meeting ?\nWell , we don't wanna renumber them ,\nI bet\ncuz we 've already have like , forms filled out with the numbers on them . So , let 's keep the same numbers on them .\nYeah , OK , that 's a good idea .\nOK , Dan , are you on ?\nI 'm on  I 'm on two and I should be on .\nGood .\nYeah .\nWant to join the meeting , Dave ? Do we  do  do we have a spare , uh\nAnd I 'm getting lots of responses on different ones , so I assume  the various and assorted P Z Ms are on .\nWe ' r we 're  we ' r This is  this  this is a meeting meeting .\nThis is abou we 're  we 're mainly being taped but we 're gonna talk about , uh , transcription for the m future meeting meetings .\nStuff . Yeah , this is not something you need to attend . So .\nYeah . e OK .\nYou 're always having one of those days , Dave .\nY you 'd be welcome .\nBesides , I don't want anyone who has a weird accent .\nYou 'd be welcome .\nRight , Dan ?\nSo , I don't understand if it 's neck mounted you don't get very good performance .\nIt 's not neck mounted . It 's supposed to be h head mounted .\nYeah . It  it should be head mounted . Right ?\nWell , then put it on your head .\nI don't know .\nRight .\nWhat are you doing ?\nCuz when you do this , you can  Rouww - Rouww .\nWhy didn't I  you were saying that but I could hear you really well on the  on the transcription  on the , uh , tape .\nWell , I m I would prefer that people wore it on their head\nI  I don't know .\ni\nbut they were complaining about it . Because it 's not  it doesn't go over the ears .\nWhy ?\nIt 's badly designed .\nIt 's very badly designed so it 's\nIt 's very badly designed ?\nWhat do you mean it doesn't go over the ears ?\nWhy ? It 's not s It 's not supposed to cover up your ears .\nYeah but , there 's nowhere to put the pad so it 's comfortable .\nI mean , it 's only badly\nSo that 's what you 're d He 's got it on his temples so it cuts off his circulation .\nOh , that 's strange .\nYeah , that 's  that 's what I have .\nAnd it feels so good that way .\nIt feels so good when I stop .\nSo I  I again would like to do some digits .\nSomebody wanna\nTry it .\nUm .\nSomebody wanna close the door ?\nSure .\nOK .\nWe could do it with noise .\nSo let me\nYou 're always doing digits .\nWell , you know , I 'm just that sort of  digit - y g sorta guy . OK . So this is Adam .\nUh , this is the same one I had before .\nI doubt it .\nIt 's still the same words .\nI think we 're session four by the way . Or m it might be five .\nPsss ! Oh , that 's good .\nNo\nI didn't bring my previous thing .\nWe didn't\nNow , just to be sure , the numbers on the back , this is the channel ?\nThat 's the microphone number .\nThat 's the microphone number .\nYeah , d leave the channel blank .\nUh - oh . OK , good .\nBut number has to be  ? So we have to look up the number .\nFive\nRight .\nOK , good .\nGood . OK . Well , this is Jane , on mike number five . Um . I just start ? Do I need to say anything more ?\nUh , transcript number .\nTranscript number\nOK , this is Eric on microphone number three ,\nThis is Beck on mike four .\nThanks . Should I turn off the VU meter Dan ? Do you think that makes any difference ?\nOh , God . No , let me do it .\nWhy ? Are you gonna do something other than hit \" quit \" ?\nNo , but I 'm gonna look at the uh , logs as well .\nOh . Should have done it before .\nUh , you said turn off the what ?\nThe VU meter which tells you what the levels on the various mikes are and there was one hypothesis that perhaps that   the act of recording the VU meter was one of the things that contributed to the errors .\nOh . Oh , I see .\nYeah , but Eric , uh , you didn't think that was a reasonable hypothesis , right ?\nI See .\nThat was me ,\nOh , I 'm sorry y\nI thought that was\nThat was malarkey .\nWell , the only reason that could be is if the driver has a bug . Right ? Because the machine just isn't very heavily loaded .\nNo chance of that .\nNo chance of that . Just because it 's beta . Look OK ?\nYeah , there  there  there was  there was a  there was a bug . There was a glitch last time we ran .\nAre - are yo are you recording where the table mikes are by the way ?\nNo .\nDo you know which channels\nYeah , we usually do that .\nNo , we don't .\nYeah .\nBut we  we ought to st we ought to standardize .\nWhy not ?\nI think ,  uh , I s I spoke to somebody , Morgan ,  about that . I think  I think we should put mar Well , no , w we can do that .\nWhy don't you just do this ?\nI mean , that 's what we 've done before .\nI know what they  they 're  they 're four , three , two , one . In order now .\nFour .\nThree , two ,  and one .\nThree .\nBut I think  I think we should put them in standard positions . I think we should make little marks on the table top .\nWhich means we need to move this thing , and sorta decide how we 're actually going to do things .\nSo that we can put them\nOh , OK .\nI guess that 's the point .\nSo .\nIt 'll be a lot easier if we have a  if we have them permanently in place or something like that .\nRight .\nI do wish there were big booms coming down from the ceiling .\nYou do ?\nYeah .\nWould it make you feel more important ?\nMmm .\nYeah , yeah , yeah .\nI see .\nWait till the projector gets installed .\nYou know .\nThat 'll work .\nOh , that 'll be good .\nThat 'll work .\nOh , gosh .\nCuz it 's gonna hang down , make noise .\nOK .\nWhen 's it gonna be installed ?\nOK .\nWell ,  it depends on\nI see .\nIs this b is this being recorded ?\nThat 's right .\nUh , I think Lila actually is almost getting r pretty close to even getting ready to put out the purchase order .\nOK . Cool .\nI handed it off to her about a month ago .\nI see .", "topic_id": 0, "keywords": "channel, channels, mike, labelling, mikes", "dialogue_id": 5}, {"text": "OK , so , topic of this meeting is I wanna talk a little bit about transcription . Um , I 've looked a little bit into commercial transcription services and Jane has been working on doing transcription . Uh , and so we wan wanna decide what we 're gonna do with that and then get an update on the electronics , and then , uh , maybe also talk a little bit about some infrastructure and tools , and so on . Um , you know , eventually we 're probably gonna wanna distribute this thing and we should decide how we 're gonna  how we 're gonna handle some of these factors . So .\nDistribute what ?\nHmm ?\nThe data ?\nRight . Right . I mean , so we 're  we 're collecting a corpus and I think it 's gonna be generally useful . I mean , it seems like it 's not a corpus which is  uh , has been done before . And so I think people will be interested in having  having it ,\nOh .\nand so we will\nu Using , like , audio D V Ds or something like that ?\nExcuse me ?\nYes .\nAudio D V\nWell , or something . Yeah , audio D V C Ds ,\nOr t\nyou know .\nYeah . tapes .\nAnd  and so how we do we distribute the transcripts , how do we distribute the audio files , how do we  how do we just do all that infrastructure ?\nWell , I think  I mean , for that particular issue ther there are known sources where people go to  to find these kind of things like the LDC for instance .\nYeah ,\nRight , but  but so should we do it in the same format as LDC\nthat 's right .\nand what does that mean to what we 've done already ?\nRight . The  It 's not so much the actu The logistics of distribution are secondary to  preparing the data in a suitable form for distribution .\nRight .\nRight . So , uh , as it is , it 's sort of a  ad - hoc combination of stuff Dan set and stuff I set up , which we may wanna make a little more formal . So .\nAnd the other thing is that , um , University of Washington may want to start recording meetings as well ,\nRight .\nin which case w w we 'll have to decide what we 've actually got so that we can give them a copy .\nThat 's right .\nA field trip .\nYeah . I was actually thinking I wouldn't mind spending the summer up there . That would be kind of fun .\nOh , really ?\nYeah . Visit my friends and spend some time\nDifferent for you . Yes .\nWell , and then also I have a bunch of stuff for doing this digits . So I have a bunch of scripts with X Waves , and some Perl scripts , and other things that make it really easy to extract out  and align where the digits are . And if U d UW 's going to do the same thing I think it 's worth while for them to do these digits tasks as well .\nMm - hmm .\nAnd what I 've done is pretty ad - hoc , um , so we might wanna change it over to something a little more standard .\nHmm .\nYou know , STM files , or XML , or something .\nAn - and there 's interest up there ?\nWhat 's that ?\nThere 's interest up there ?\nWell they  they certainly wanna collect more data . And so they 're applying , I think I B Is that right ? Something like that .\nI don't know .\nUm , for some more money to do more data . So we were planning to do like thirty or forty hours worth of meetings . They wanna do an additional hundred or so hours . So , they want a very large data set . Um , but of course we 're not gonna do that if we don't get money . So .\nI see .\nAnd I would like that just to get a disjoint speaker set and a disjoint room . I mean , one of the things Morgan and I were talking about is we 're gonna get to know this room really well ,\nMm - hmm .\nthe  the acoustics of this room .\nAll about that .\nIncluding the fan .\nIncluding the fan .\nDid you notice the fan difference ?\nOh , now you 've touched the fan control , now all our data 's gonna be\nHear the difference ?\nOh , it 's enormous .\nYeah , it 's great .\nOh , that 's better .\nDo you wanna leave it off or not ?\nThat 's better .\nAll the others have been on .\nThat 's\nYeah , the  You sure ?\nOh , yeah .\ny Absolut\nAbsolutely .\nYou   You think that\nYeah .\nthings after the f then This fan 's wired backwards by the way . Uh , I think this is high speed here .\nYeah , it 's noticeable .\nWell , not clear .\nWell it 's  well like  \" low \" is mid  mid - scale .\nMaybe it  Maybe it isn't .\nSo it could be  that it 's not actually wired backwards\nThat 's right .\nit 's just that ambiguous .\nI was wondering also , Get ready .  whether the lights made any noise .\nUh - huh .\nThere 's definitely  Yep .\nOh , they do .\nYeah , a little bit .\nYeah .\nHigh pitch hum . Wow .\nSo ,  do our meetings in the dark with no air conditioning in the future .\nYeah , just get a variety .\nI think candles would be nice if they don't make noise .\nThey 're very good .\nOh , yeah .\nIt would  you know , it would real really mean that we should do short meetings when you  turn off the   turn off the air conditioning ,\nCarbon monoxide poisoning ?\nShort meetings , that 's right . Or  Yeah , sort of  r r\ngot to finish this meeting .\nTear t  Tear your clothing off to stay cool .\nThat 's right .\nActually , the a th air  the air conditioning 's still working , that 's just an auxiliary fan .\nRight , I see .\nSo\nSo , um , in addition to this issue about the UW stuff there was announced today , uh , via the LDC , um , a corpus from I believe Santa Barbara .\nYeah , I saw it . I 've been watching for that corpus .\nUm , of general spoken English .\nYeah . Yep .\nAnd I don't know exactly how they recorded it but apparently there 's a lot of different  styles of speech and what not .\nMm - hmm .\nAnd\nThey had people come in to a certain degree and they  and they have DAT recorders .\nI see . So it is sort of far field stuff . Right ?\nI  I assume so , actually , I hadn't thought about that . Unless they added close field later on but , um , I 've listened to some of those data and I , um , I 've been  I  I was actually on the advisory board for when they set the project up .\nMm - hmm .\nOh , OK .\nWhat 's it sound like ?\nI 'm glad to see that it got released .\nYeah , I  I wish\nSo it it 's a very nice thing .\nI wish we had someone here working on adaptation\nS\nbecause it would nice to be able to take that stuff and adapt it to a meeting setting . You know\nBut it may be  it may be useful in\nHow do you mean  do you mean mechanical adaptation or\nNo , software , to adapt the speech recognition .\nOK .\nWell , what I was thinking is it may be useful in transcribing , if it 's far field stuff ,\nMm - hmm .\nright ? In doing , um , some of our first automatic speech recognition models , it may be useful to have that kind of data\nGreat idea .\nbecause that 's very different than any kind of data that we have so far .\nThat 's true .\nAnd  and their recording conditions are really clean . I mean , I 've  I 've heard  I 've listened to the data .\nWell that 's not good , right ?\nThat 's  that 's not great .\nIt sounds\nTr\nwell but what I mean is that , um\nBut far field means great distance ? I mean\nJust these .\nNot head mounted ?\nYeah .\nAnd so that 's why they 're getting away with just two channels or something , or are they using multiple DATs ?\nUm , oh , good question and I can't ans answer it .\nWell we can look into it .\nI don't know .\nNo , and their web  their web page didn't answer it either . So I 'm , I uh , was thinking that we should contact them .\nOK .\nSo it 's  that 's sort of a beside - the - point point . But .\nSo we can get that just with , uh , media costs ,\nStill a point .\nRight .\nis that right ?\nUh , in fact we get it for free\nOh .\ncuz they 're distributing it through the LDC .\nGreat .\nYep .\nSo that would be  yeah , that would be something to look into . So .\nSo , I can  I can actually arrange for it to arrive in short order if we 're\nThe other thing too is from  from a\nWell , it 's silly to do unless we 're gonna have someone to work on it , so maybe we need to think about it a little bit .\nHuh .\nThe other thing too is that their their jus their transcription format is really nice and simple in  in the discourse domain . But they also mentioned that they have it time aligned . I mean , I s I  I saw that write - up .\nYeah . Maybe we should  maybe we should get a copy of it just to see what they did\nYeah , absolutely .\nYeah .\nso  so that we can  we can compare .\nIt 's very nice .\nOK , why don't you go ahead and do that then Eric ?\nAbsolutely .\nAlright , I 'll do that . I can't remember the name of the corpus . It 's Corps - S\nCSAE .\nS\nCorpus of Spoken American English .\nRight , OK .\nYeah , sp I 've been  I was really pleased to see that . I knew that they   they had had some funding problems in completing it\nUh - huh .\nYeah .\nbut , um ,\nWell they 're\nthis is clever .\nApparently this was like phase one\nGot it through the LDC .\nand the there 's still more that they 're gonna do apparently or something like that unless of course they have funding issues\nGreat . Great .\nand then then it ma they may not do phase two but  from all the web documentation it looked like , \" oh , this is phase one \" , whatever that means .\nSuper . Super . Great . Yeah , that  I mean , they 're really well respected in the linguistics d side too and the discourse area ,\nOK .\nand  So this is a very good corpus .\nBut , it uh it would also maybe help be helpful for Liz , if she wanted to start working on some discourse issues , you know , looking at some of this data and then ,\nRight .\nyou know  So when she gets here maybe that might be a good thing for her .\nActually , that 's another thing I was thinking about is that maybe Jane should talk to Liz , to see if there are any transcription issues related to discourse that she needs to get marked .\nOK .\nMaybe we should have a big meeting meeting .\nSure , of course .\nThat would be a meeting meeting meeting ?\nA meeting meeting meeting .\nYeah .\nWell this is the meeting about the meeting meeting meeting . So .\nOh .\nUm .\nRight . But maybe we should , uh find some day that Liz  uh , Liz and Andreas seem to be around more often .\nMm - hmm .\nSo maybe we should find a day when they 're gonna be here and  and Morgan 's gonna be here , and we can meet , at least this subgroup . I mean , not necessarily have the U - dub people down .\nWell , I was even thinking that maybe we need to at least ping the U - dub  to see\nWe need  we need to talk to them some more .", "topic_id": 1, "keywords": "corpus, transcription, transcripts, audio, recording", "dialogue_id": 5}, {"text": "you know , say \" this is what we 're thinking about for our transcription \" , if nothing else . So , well w shall we move on and talk a little bit about transcription then ?\nMm - hmm . Let 's .\nYeah .\nOK , so   since that 's what we 're talking about . What we 're using right now is a tool , um , from this French group , called \" Transcriber \" that seems to work very well . Um , so it has a , uh , nice useful Tcl - TK user interface and , uh ,\nThi - this is the process of converting audio to text ?\nRight .\nAnd this requires humans just like the  the STP stuff .\nYes , yeah . Right , right . So we 're  we 're at this point only looking for word level . So all  all  so what you have to do is just identify a segment of speech in time , and then write down what was said within it , and identify the speaker . And so the things we  that we know  that I know I want are  the text , the start and end , and the speaker . But other people are interested in for example stress marking . And so Jane is doing primary stress ,  um , stress marks as well . Um , and then things like repairs , and false starts , and ,  filled pauses , and all that other sort of stuff ,  we have to decide how much of that we wanna do .\nI did include a glo  uh , a certain first pass . My  my view on it was when you have a repair  then , uh  it seems  I mean , we saw , there was this presentation in the  one of the speech group meetings about how\nMm - hmm .\nand I think Liz has done some stuff too on that , that it , uh   that you get it bracketed in terms of like  well , if it 's parenthetical , which I know that Liz has worked on , then  uh  y y you 'll have different prosodic aspects .\nMm - hmm .\nHmm .\nAnd then also  if it 's a r if it 's a repair where they 're  like what I just did ,  then it 's nice to have sort of a sense of the continuity of the utterance , the start to be to the finish . And , uh , it 's a little bit deceptive if you include the repai the pre - repair part  and sometimes or of it 's in the middle . Anyway ,  so what I was doing was bracketing them to indicate that they were repairs which isn't uh , very time - consuming .\nMm - hmm .\nI is there already some sort of plan in place for how this gonna be staffed or done ? Or is it real  is that what we 're talking about here ?\nWell , that 's part of the thing we 're talking about . So what we wanted to do was have Jane do basically one meeting 's worth , you know , forty minutes to an hour ,\nMm - hmm .\nand\nAs a pilot study .\nYourself ?\nYeah .\nIt  this is  this is like five times real time or ten times real time\nYeah , as a pilot study .\nTen times about , is  and so one of the things was to get an estimate of how long it would take , and then also what tools we would use . And so the next decision which has to be made actually pretty soon is how are we gonna do it ? So .\nAnd so you make Jane do the first one so then she can decide , oh , we don't need all this stuff , just the words are fine .\nThat 's right , that 's right .\nThat 's right .\nI wanna hear about these  uh , we have a g you were s continuing with the transcription conventions for s\nR right , so  so one  one option is to get linguistics grad students and undergrads to do it . And apparently that 's happened in the past . And I think that 's probably the right way to do it . Um , it will require a post pass , I mean people will have to look at it more than once to make sure that it 's been done correctly , but I just can't imagine that we 're gonna get anything that much better from a commercial one . And the commercial ones I 'm sure will be much more expensive .\nCan't we get Joy to do it all ?\nYeah right .\nNo ,  that 's\nWe will just get Joy and Jane to do everything .\nIs tha wasn't that what she was doing before ? Yeah , that 's right .\nBut , you know , that 's what we 're talking about is getting some slaves who  who need money\nRight .\nand , uh , duh , again o\nI object to that characterization !\nOh , really .\nI meant Joy . And so again , I have to say \" are we recording \"\nOh , thank you . OK .\nand then say , uh , Morgan has  has consistently resisted telling me how much money we have .\nRight . Well , the answer is zero .\nSo .\nThere 's a reason why he 's resisted .\nWell , if it 's zero then we can't do any transcription .\nBut .\nI mean , cuz we 're  we\nRight .\nI have such a hard name .\nI mean , I  I can't imagine us doing it ourselves . Right ?\nWell , we already  we already   We already have a plan in place for the first meeting .\nN right .\nRight ? That 's\nWell th there is als Yeah , really . There is also the o other possibility which is if you can provide not money but instructional experience or some other perks ,  you can  you could get people to  to um , to do it in exchange .\nRight .\nWell , i b but seriously , I  I mean , Morgan 's obviously in a bind over this and thing to do is just the field of dreams theory , which is we we go ahead as though there will be money at the time that we need the money .\nMm - hmm .\nYeah .\nAnd that 's  that 's the best we can do .\nRight .\nRight .\ni b To not do anything until we get money is  is ridiculous .\nRight .\nWe 're not gonna do any  get anything done if we do that .\nMm - hmm .\nYeah .\nSo at any rate , Jane was looking into the possibility of getting students , at  is that right ? Talking to people about that ?\nI 'm afraid I haven't made any progress in that front yet .\nOK .\nI should 've sent email and I haven't yet .\nYeah , right . So , uh\nI d do  So until you actually  have a little experience with what this  this French thing does we don't even have\nAnd I do have\nShe 's already done quite a bit .\nOh , we have .\nI have  a bunch of hours ,\nYeah .\nI 'm sorry . So that 's where you came up with the f the ten X number ?\nyeah .\nOr is that really just a guess ?\nActually that 's the  the one people usually use , ten X .\nHow fast are you ?\nAnd I haven't really calculated  How fast am I ?\nYeah i\nI haven't done a s see , I 've been at the same time doing kind of a boot strapping in deciding on the transcription conventions that  that are   you know , and  and stuff like , you know , how much\nMmm .\nRight .\nThere 's some interesting human factors problems like ,  yeah , what span of  of time is it useful to segment the thing into in order to uh , transcribe it the most quickly .\nYeah .\nCuz then , you know , you get like   if you get a span of five words , that 's easy .\nYeah .\nBut then you have to take the time to mark it . And then there 's the issue of  it 's easier to   hear it th right the first time if you 've marked it at a boundary instead of  somewhere in the middle ,\nMm - hmm .\ncuz then the word 's bisected or whatever and  And so I mean , I 've been sort of playing with , uh , different ways of mar cuz I 'm thinking , you know , I mean , if you could get optimal instructions you could cut back on the number of hours it would take .\nYeah .\nD does uh  this tool you 're using is strictly  it doesn't do any speech recognition does it ?\nNo .\nNo , it doesn't but what a super tool . It 's a great environment .\nBut  but is there anyway to  to wire a speech recognizer up to it and actually run it through\nThat 's an interesting idea .\nWe 've  we 've thought about doing that\nHey !\nbut the recognition quality is gonna be horrendous .\nWell , a couple things .\nWow .\nFirst of all the time marking you 'd get  you could get by a tool .\nThat 's true .\nAnd so if the  if  if the issue really\nThat 's interesting .\nuh , I 'm think about the close caption that you see running by on  on live news casts .\nMost of those are done by a person .\nYou know , yo I know  I know that .\nYeah , I\nNo , I understand . And  in a lot of them you see typos and things like that ,\nMm - hmm .\nbut it  but it occurs to me that  it may be a lot easier to correct things than it is to do things from scratch , no matter how wonderful the tool is .\nYeah . Yeah , we\nBut if  if there was a way to merge the two\nWell , I mean , but sometimes it 's easier to type out something instead of going through and figuring out which is the right\nI mean , we 've talked about it\nThat 'd be fun .\nbut\nI mean , it depends on the error rate , right ?\nWell s but  but again the timing is for fr should be for free . The timing should be\nBut we don't care about the timing of the words .\nWell I thought you just  that 's  said that was a critical issue .\nWe don't care about the timing of the words , just of the utterances .\nNo , uh the  the boundary\nWe cut it s s\nWe don't  we don't know , actually .\nboundary .\nWe haven't decided which  which time we care about , and that 's kind of one of the things that you 're saying , is like   you have the option to put in more or less timing data  and , uh , be in the absence of more specific instructions ,  we 're trying to figure out what the most convenient thing to do is .\nYeah , so  so what  what she 's done so far , is sort of  more or less breath g not breath groups ,  sort of phrases , continuous phrases .\nYeah .\nAnd so , um , that 's nice because you  you separate when you do an extract , you get a little silence on either end . So that seems to work really well .\nThat 's ideal .\nUm .\nYeah .\nAlthough I was  I  you know , the alternative , which I was sort of experimenting with before I ran out of time ,  recently was ,  um   that , you know , ev if it were like an arbitrary segment of time  i t pre - marked cuz it does take time to put those markings in .\nYeah .\nIt 's really the i the interface is wonderful because , you know , the time it takes is you listen to it ,  and then you press the return key . But then , you know , it 's like ,  uh , you press the tab key to stop the flow and   and , uh , the return key to p to put in a marking of the boundary . But , you know , obviously there 's a lag between when you hear it and when you can press the return key\nYeah .\nso it 's slightly delayed , so then you  you listen to it a second time and move it over to here .\na\nSo that takes time .\ni a\nNow if it could all be pre - marked at some ,  l you know , good\nar but\nHmm .\nAre  are those d delays adjustable ? Those delays adjustable ? See a lot of people who actually build stuff with human computer interfaces  understand that delay ,\nYeah .\nand  and so when you  by the time you click it it 'll be right on because it 'll go back in time to put the\nYeah .\nIt could do that\nYeah , uh , not in this case .\nWe could program that pretty easily ,\ncouldn't it .\nIt has other\ncouldn't we Dan ? Yeah , mis Mister TCL ?\nYeah .\nOh , interesting point .\nI would have thought so , yeah .\nAh !  Interesting point .\nMmm .\nOK , that would make a difference .\nBut , um\nI mean , it 's not bad\nBut , if we tried to do automatic speaker ID .\nbut it does  take twice .\nI mean , cuz primarily the markings are at speaker change .\nYeah , yeah , but\nBut that would be\nBut we 've got  we 've got the most channel data . We 'd have to do it from your signal . Right . I mean , we 've  we 've got  we 've got a lot of data .\nOh , good point ! Ah !\nYeah , I guess the question is how much time will it really save us versus the time to write all the tools to do it .\nWe 've got volume .\nRight . but the chances are if we if we 're talking about collecting  ten or a hundred hours , which is going to take a hundred or a thousand hours to transcribe\nIf\nBut\nif we can go from ten X to five X we 're doing a big\nWe 're gonna need  we 're gonna need ten to a hundred hours to train the tools , and validate the tools the do the d to  to do all this anyway .\nRight . So maybe\nWow .\nIf we 're just doing silence detection\nBut  but it op\nI knew you were gonna do that . Just saw it coming .\nI 'm sorry . I wish you had told me  wish you 'd told me .\nPut  put it on your sweater .\nAt what part ? OK , I 'm alright .\nUm , i it seems like  Well , uh , I don't know . Yeah . I mean , it  it 's  it 's maybe like   a week 's work to get to do something like this . So forty or fifty hours .\nRight .\nCould you get it so that with  so it would  it would detect volume on a channel and insert a marker ? And the  the format 's really transparent .\nSure .\nYeah .\nIt 's just a matter of  a very c clear  it 's XML , isn't it ?\nMm - hmm .\nIt 's very  I mean , I looked at the  the file format and it 's just  it has a t a time   a time indication and then something or other , and then an end time or something or other .\nSo maybe  maybe we could try the following experiment . Take the data that you 've already transcribed\nMm - hmm .\nand\nIs this already in the past or already in the future ?\nAlready in the past .\nYou 've already  you 've already done some ?\nShe 's  she 's done about half a meeting .\nShe  she 's done one  she 's one\nYes I have .\nOh - Oh , I see .\nRight .\nOK ,\nRight ?\nRight .\ngood .\nAbout half ?\nI 'm go\nS I 'm not sure if it 's that 's much but anyway , enough to work with .\nRight .\nSeveral minutes .\nUm , and  and throw out the words , but keep the time markings . And then go through  I mean , and go through and  and try and re - transcribe it , given that we had perfect boundary detection .\nOK . Good idea .\nAnd see if it  see if it  see if it feels easier to you .\nOK .\nAnd forgetting all the words because you 've been thr\nYeah , that 's what I was thinking . I 'd  I 'd be cheating a little bit g with familiarity effect .\nYeah , I mean uh , that 's part of the problem is , is that what we really need is somebody else to come along .\nWell , no , you should do it  you should do it   Do it again from scratch and then do it again at the boundaries . So you do the whole thing three times and then we get\nYeah .\nNo . Now , there 's a plan .\nAnd then  then w since we need some statistics do it three more .\nOK .\nAnd so you 'll get  you 'll get down to one point two X by the time you get done .\nOh , yeah . I 'll do that tomorrow . I should have it finished by the end of the day .\nNo , but the thing is the fact that she 's  she 's did it before just might give a lower bound . That 's all .\nYeah .\nRight .\nUh , which is fine .\nExactly .\nIt 's  And if the lower bound is nine X then w it 's a waste of time .\nYeah .\nRight .\nWell , uh but there 's an extra problem which is that I didn't really keep accurate\nOh !\nuh , it wasn't a pure task the first time ,\nYeah .\nso   uh , it 's gonna be an upper bound in  in that case . And it 's not really strictly comparable . So I think though it 's a good proposal to be used on a new  a new batch of text that I haven't yet done yet in the same meeting . Could use it on the next segment of the text .\nThe point we  where do we get the  the  the oracle boundaries from ?\nRight .\nOr the boundaries .\nYeah , one person would have to assign the boundaries and the  and the other person would have to\nWell , but couldn't I do it for the next\nWe  we  we could get fake\nI mean that 's easy enough .\nOh , I see what you mean .\nI could do that .\nWell , but the oracle boundaries would come from volume on a partic specific channel wouldn't they ?\nNo , no .\nThat would be the automatic boundaries .\nNo , no , no , no . You wanna know  given  Given a perfect human segmentation , I mean , you wanna know how well\nYeah .\nI mean , the  the question is , is it worth giving you the segmentation ?\nOh , I see what you mean .\nI mean , that  that 's easy enough .\nRight .\nYeah .\nI could generate the segmentation and  and you could do the words , and time yourself on it . So .\nA little double - blind - ear kind of thing .\nYep .\nI see . OK .\nSo it  that might be worth doing .\nThat 's good . I like that .\nThat would at least tell us whether it 's worth spending a week or two trying to get a tool , that will compute the segmentations .\nRight .\nAnd the thing to keep in mind too about this tool , guys is that  sure , you can do the computation for what we 're gonna do in the future but if  if UW 's talking about doing two , or three , or five times as much stuff and they can use the same tool , then obviously there 's a real multiplier there .\nRight .\nAnd the other thing too is with  with speaker identification , if  if that could handle speaker identification that 's a big deal .\nWell it w\nRight .\nWell , use it . Yeah , that 's why we s bought the expensive microphones .\nOK . Yeah , I mean , that 's a nice feature .\nYep .\nYeah , yeah .\nThat 's a major  that 's like , one of the two things that\nI mean , there 's gonna  there 's gonna be  in the meeting , like the reading group meeting that we had the other day , that 's  it 's gonna be a bit of a problem\nOK .\nbecause , like , I wasn't wearing a microphone\nYes .\nf and there were other people that weren't wearing microphones .\nThat\nBut you didn't say anything worth while anyway , right ?\nThat 'll s\nRight .\nThat 's pretty much true\nYeah .\nit might save ninety percent of the work though .\nbut  but , yes .\nSo .\nSo I  I need to  we need to look at what  what the final output is but it seems like  we  it doesn't  it seems like it 's not really not that hard to have an automatic tool to generate  the phrase marks , and the speaker , and speaker identity without putting in the words .\nYeah . I 've already become pretty familiar with the format ,\nThat 'd be so great .\nso it would be easy .\nMm - hmm .\nYeah . Yeah .\nIf you 'd tell me where it is , huh ?\nWe didn't finish the  the part of work already completed on this , did we ? I mean , you   you talked a little bit about the transcription conventions ,\nMm - hmm .\nand , I guess you 've mentioned in your progress report , or status report , that you had written a script to convert it into  So ,  I  when I  i the  it 's quickest for me in terms of  the transcription part  to say  something like , you know , if   if Adam spoke to , um  to just say , \" A colon \" , Like who could be , you know , I mean at the beginning of the line .\nMmm .\nand E colon  instead of entering the interface for speaker identification and clicking on the thing , uh , indicating the speaker ID . So , and then he has a script that will convert it into the  the thing that , uh , would indicate speaker ID .\nIt 's pretty cute .\nIf that 's clear .\nOK .\nBut at any rate . So , um ,\nIt 's Perl script .\nRight . So  so I think the guess at ten X seems to be pretty standard . Everyone  more or less everyone you talk to says about ten times for hard technical transcription .\nMm - hmm .\nUsing wh using stone age\nYeah .\nusing stone age tools .\nThat 's right .\nUsing  using stone age tools . I mean , I looked at Cyber Transcriber\nYeah , well that 's true , but\nwhich is a service that you send an audio file , they do a first - pass speech recognition . And then they  they do a clean up . But it 's gonna be horrible . They 're never gonna be able to do a meeting like this .\nNo .\nRight .\nWhat  i just approximately , what did you find out in terms of price or  or whatever ?\nWell , for Cyber Transcriber they don't quote a price . They want you to call and  and talk . So for other services , um , they were about thirty dollars an hour .\nOf  of tape ?\nThirty  So , yeah .\nOr of action ?\nFor thirty dollars an hour for  of their work .\nOK . OK . Oh , of their\nSo  so if it 's ten times it 's three hundred dollars an hour .\nOh !\nSo that 's three  that 's three hours .\nOK .\nD did you talk to anybody that does closed captioning for  for uh , TV ?\nRight .\nNo .\nCuz they a usually at the end of the show they 'll tell what the name of the company is , the captioning company that 's doing it .\nMm - hmm . Yeah , so  so my  my search was pretty cursory .\nInteresting .\nIt was just a net search . And , uh , so it was only people who have web pages and are doing stuff through that .\nWell , you know , the  the thing  the thing about this is thinking kind of , maybe a little more globally than I should here but   that really this could be a big contribution we could make . Uh , I mean , we 've been through the STP thing , we know what it  what it 's like to  to manage the  manage the process , and admittedly they might have been looking for more detail than what we 're looking for here but  it was a  it was a big hassle , right ?\nYeah .\nI mean , uh , you know , they  they constantly could 've reminding people and going over it . And clearly some new stuff needs to be done here . And it 's  it 's only  our time , where \" our \" of course includes Dan ,  Dan and you guys . It doesn't include me at all . Uh . j Just seems like\nYeah , I mean I don't know if we 'd be able to do any thing f to help STP type problems . But certainly for this problem we can do a lot better than\nBec Why ? Because they wanted a lot more detail ?\nRight .\nNo . Because they had  because they only had two speakers , right ? I mean , the  the segmentation problem is\nTrivial .\nOnly had two .\nThey had two speakers over the telephone .\nOh , I see . So what took them so long ?\nUm , mostly because they were doing much lower level time .\nYeah .\nSo they were doing phone and syllable transcription , as well as , uh , word transcription .\nRight . Right .\nRight .\nMm - hmm .\nAnd so we 're  w we decided early on that we were not gonna do that .\nI see . But there 's still the same issue of managing the process , of   of reviewing and keeping the files straight , and all this stuff , that  which is clearly a hassle .\nYep .\nYeah .\nRight . And so  so what I 'm saying is that if we hire an external service I think we can expect three hundred dollars an hour .\nYeah .\nI think that 's the ball park . There were several different companies that   and the  the range was very tight for technical documents . Twenty - eight to thirty - two dollars an hour .\nAnd who who knows if they 're gonna be able to m manage multal multiple channel data ?\nYeah , they won't .\nThey won't .\nThey w they 'll refuse to do it .\nWe 'll have to mix them .\nMm - hmm .\nYeah .\nRight .\nNo , but I mean , they  they  they won't  they won't  they will refuse to transcribe this kind of material .\nAnd then there 's the problem also that\nThat 's not what they 're d quoting for , right ?\nYes , it is .\nWell , they might   they might quote it\nFor quoting meetings ?\nSev - several of them say that they 'll do meetings , and conferences , and s and so on . None of them specifically said that they would do speaker ID , or speaker change mark .\nWow . Yeah .\nThey all just said transcription .\nTh - th the th there may be just multiplier for five people costs twice as much and for ten people co  Something like that .\nYeah , yeah , yeah .\nWell , the  the way it worked is it  it was scaled . So what they had is ,  if it 's an easy task it costs twenty - four dollars an hour and it will take maybe five or six times real time . And what they said is for the hardest tasks , bad acoustics , meeting settings , it 's thirty - two dollars an hour and it takes about ten times real time . So I think that we can count on that being about what they would do .\nI see . Yeah .\nIt would probably be a little more\nRight .\nYeah .\nbecause we 're gonna want them to do speaker marking .\nA lot of companies I 've worked for y the , uh  the person leading the meeting , the executive or whatever , would sort of go around the room and  and mentally calculate h how many dollars per hour this meeting was costing ,\nSo .\nright ? In university  atmosphere you get a little different thing . But you know , it 's a lot like , \" he 's worth fifty an hour , he 's worth  \" And so he so here we 're thinking , \" well let 's see , if the meeting goes another hour it 's going to be another thousand dollars . \" You know ? It 's\nYep , we have to have a short meeting .\nSo ch  So every everybody ta Talk really fast .\nThat 's very interesting .\nStop talking !\nYeah .\nLet 's get it over with .\nTalk  slowly but with few words .\nAnd clearly .\nThat 's right .\nAnd only talk when you 're pointed to .\nThere you go .\nContent words only .\nWe could have some telegraphic meetings . That might be interesting .\nYeah , it 'd be cheap .\nCheap to transcribe .\nSo . But at any rate , so we  we have a ballpark on how much it would cost if we send it out .\nAnd we 're talking about do doing how many hours worth of meetings ?\nThirty or forty .\nSo thirty or forty thousand dollars .\nWell , for ten thousand dollars .\nYeah .\nSo , meanwhile\nOh . What  Well , it was thirty times\nThree hundred .\nThree hundred dollars an hour .\nOh , I 'm sorry , three hundred .\nRight .\nRight , I w got an extra factor of three there .\nSo it 's thirty dollars an hour , essentially , right ?\nYeah .\nBut we can pay a graduate student seven dollars an hour . And the question is what 's the difference\nHow  how much lower are they ?\nor ei eight dollars . What  do you know what the going rate is ? It 's  it 's  on the order of eight to ten .\nI think uh that would give us a  a good  good estimate .\nI think . But I 'm not sure .\nI 'd  I 'd say\nTen .\nyeah , I was gonna say eight  you 'd say ten ?\nLet 's say ten .\nYeah , give them a break .\nCuz it 's easier .\nThe - these are not for engineering graduate students , right ?\nRight , these are linguistics grad students . Six .\nYeah , I  I  I don't  I don't know what the  I don't know what the standard\nThat 's right .\nbut there is a standard pay scale\nMm - hmm .\nI just don't know what it is .\nYeah , that 's right . That 's right .\nUm , so that means that even if it takes them thirty times real time it 's cheaper to  to do graduate students .\nAnd there 's another aspect too .\nI mean , that 's why I said originally , that I couldn't imagine sending it out 's gonna be cheaper .\nNo , it isn't . So .\nThe other thing too is that , uh , if they were linguistics they 'd be  you know , in terms of like the post editing , i uh  tu uh content wise they might be easier to handle cuz they might get it more right the first time .\nAnd also we would have control of  I mean , we could give them feedback . Whereas if we do a service it 's gonna be limited amount .\nYep , yep .\nMmm .\nI mean , we can't tell them , you know , \" for this meeting we really wanna mark stress\nGood point .\nYep .\nand for this meeting we want  \"\nNo .\nGood point .\nAnd  and they 're not gonna provide  they 're not gonna provide stress , they 're not gonna re provide repairs , they 're not gonna  provide  they  they may or may not provide speaker ID . So that we would have to do our own tools to do that . So\nMm - hmm .\nI just\nYeah .\nJust hypoth hypothetically assuming that  that we go ahead and ended up using graduate students . I who  who 's the person in charge ? Who 's gonna be the Steve here ?\nI hope it 's Jane .\nYou ?\nIs that alright ?\nOh , interesting . Um , now would this involve some manner of uh , monetary compensation or would I be the voluntary , uh , coordinator of multiple transcribers for checking ?\nUm , I would imagine there would be some monetary involved but we 'd have to talk to Morgan about it .\nYeah , out of  out of Adam 's pocket .\nYeah .\nOK .\nYou know , it just means you have to stop working for Dave . See ?\nOh ,\nThat 's why Dave should have been here .\nI don't wanna stop working for Dave .\nTo pr protect his people .\nWell , I would like you to do it because you have a lot more experience than I do ,\nOh , cool . Yeah .\nbut if  if that 's not feasible , I will do it with you as an advisor .\nUh - huh .\nW we 'd like you to do it and we 'd like to pay you .\nWe 'll see .\nYeah .\nNot being Morgan though , it 's\nOK .\nRight .\nOh , I see .\nWe 'd like to . Unfortunately\nWell\nYeah .\nYeah .\nYeah , six dollars an hour .\nYeah , I see .\nThat 's a\nAnd  and then\nOK . Boy , if I wanted to increase my income I could start doing the transcribing again .\nYeah , that 's right . Yeah .\nan an an and be and be sure and say , would you like fries with that when you 're thinking about your pay scale .\nI see . Good . Yeah , no , that  I  I would be interested in that  in becoming involved in the project in some aspect like that\nOK . More .\nmore . Yeah . Uh - huh . Yeah .\nUm , any more on transcript we wanna talk about ?\nWhat s so what are you  so you 've done some portion of the first meeting . And what 's your plan ?\nYes . Mm - hmm .", "topic_id": 2, "keywords": "transcription, transcribers, transcribe, utterances, transcriber", "dialogue_id": 5}, {"text": "To carry on doing it ?\nWhat  Well , you know what I thought was right now we have p So I gave him the proposal for the transcription conventions . He made his , uh , suggestion of improvement .\nOK .\nThe  the  It 's a good suggestion . So as far as I 'm concerned those transcription conventions are fixed right now . And so my next plan would be\nWhat  what do they  what do they cover ?\nThey 're very minimal . So ,  it would be good to  just to summarize that . So , um ,  one of them is the idea of how to indicate speaker change ,\nYeah .\nand this is a way which meshes well with  with , uh , making it  so that , uh , you know , on the  At the\nYeah .\nBoy , it 's such a nice interface . When you  when you get the , um  you  you get the speech signal you also get  down beneath it ,  an indication of ,  uh , if you have two speakers overlapping in a s in a single segment , you see them  one  displayed one above each other . And then at the same time  the top s part of the screen is the actual verbatim thing . You can clip  click on individual utterances and it 'll take you immediately to that part of the speech signal , and play it for you . And you can , eh you can work pretty well between those two  these two things .\nIs there a limit to the number of speakers ?\nUm , the user interface only allows two . And so if  if you 're using their interface to specify overlapping speakers you can only do two .\nHmm .\nBut my script can handle any . And their save format can handle any . And so , um , using this  the convention that Jane and I have discussed , you can have as many overlapping speakers as you want .\nDo y is this a , uh , university project ?\nYeah .\nTh - this is the French software , right ?\nYeah , French .\nYeah , yeah ,\nYeah . And they 're  they 've been quite responsive .\ntheir academic .\neh\nI 've been exchanging emails on various issues .\nOh , really ?\nUh , did you ask them to change the interface for more speakers ?\nOh .\nYes , and they said that 's on  in  in the works for the next version .\nGood .\nOh , so multi multichannels .\nGood .\nMultichannels was also  Well , they said they wanted to do it but that the code is really very organized around single channels . So I think that 's n unlikely to ha happen .\nI see . OK .\nDo - do you know what they 're using it for ? Why 'd they develop it ?\nFor this exact task ?\nFor transcription .\nAre they linguists ?\nIt 's\nBut I mean , are they  are they linguists or are they speech recognition people ?\nI think they 're linguists .\nHo\nLinguists .\nHmm .\nYeah .\nThey 're  they have some connection to the LDC cuz the LDC has been advising them on this process , the Linguistic Data Consortium . Um ,\nMm - hmm .\nso  but a apart from that .\nIt 's also  All the source is available .\nYeah .\nSo .\nRight .\nIf you  if you speak TCLTK .\nGreat . Mm - hmm .\nAnd they have  they 've actually asked if we are willing to do any development and I said , well , maybe .\nRight .\nGood .\nSo if we want  if we did  if we did something like programmed in a delay , which actually I think is a great idea , um , I 'm sure they would want that incorporated back in .\nMm - hmm . Yeah , I do too .\nMm - hmm .\nTheir pre pre - lay .\nPre - lay .\nWay .\nPre - lay . Well , and they 've thought about things . You know , I mean , they  they do have  So you have  when you  when you play it back , um , it 's  it is useful to have , uh , a  a break mark to  se segment it . But it wouldn't be strictly necessary cuz you can use the  uh , the tabbed key to toggle  the sound on and off . I mean , it 'll stop the s speech you know if you if you press a tab . And , um . And so , uh , that 's a nice feature . And then also once you 've put a break in then you have the option of  cycling through the unit . You could do it like multiply until you get  crazy and decide to stop cycling through that unit .\nLoop it ? Yo - you n you know , there 's al also the  the user interface that 's missing .\nOr  or  or\nIt 's missing from all of our offices , and that is some sort of analog input for something like this . It 's what audio people actually use of course . It 's something that wh  when you move your hand further , the sound goes faster past it , like fast forward . You know , like a joy stick or a  uh , you could wire a mouse or trackball to do something like that .\nWhy , that 's  That 's not something I wanted to have happen .\nNo , but I 'm saying if this is what professionals who actually do this kind of thing for  for  for  m for video or for audio   where you  you need to do this ,\nI see . Uh - huh .\nand so you get very good at sort of jostling back and forth , rather than hitting tab , and backspace , and carriage return , and enter , and things like that .\nMmm . Mmm .\nUh - huh .\nYeah , we talked about things like foot pedals and other analog\nYeah .\nMm - hmm .\nSo  I mean , tho those are things we could do but I  I just don't know how much it 's worth doing . I mean we 're just gonna have\nYe - Yeah .\nYeah .\nRight .\nYeah , I  I agree . They  they have several options . So , uh , you know , I mentioned the looping option . Another option is it 'll pause when it reaches the end of the boundary . And then to get to the next boundary you just press tab\nHmm .\nand it goes on to the next unit .\nCool .\nI mean , it 's very nicely thought out .\nHmm .\nThey thought about  and also it 'll  go around the c the , uh , I wanna say cursor but I 'm not sure if that 's the right thing .\nPoint , whatever .\nAnyway , you can  so they thought about different ways of having windows that you c uh work within ,\nMm - hmm .\nand  But so in terms of the con the conventions , then ,  uh , basically ,  uh , it 's strictly orthographic which means with some w provisions for , uh , w uh ,  colloquial forms . So if a person said , \" cuz \" instead of \" because \" then I put a   an apostrophe at the beginning of the word and then in  in double ang angle brackets what the full lexical item would be .\nMm - hmm .\nAnd this could be  something that was handled by a table or something but I think  to have a convention marking it as a non - standard or wha I don't mean standard  but a  a  a non  uh , ortho orthographic , uh , whatever .\nMm - hmm .\nNon - canonical .\nMm - hmm .\n\" Gonna \" or \" wanna \" , you know , the same thing . And  and there would be limits to how much refinement you want in indicating something as non - standard pres pronunciation .\nHow are you handling backchannels ?\nBackchannels ?\nComments .\nUm , you know  oh , yes , there was some  in my view , when i when you 've got it densely overlapping , um , I didn't worry about  I didn't worry about s specific start times .\nWhat do you mean by du\nI sort of thought that this is not gonna be  easily processed anyway and  maybe I shouldn't spend too much time getting exactly when the person said  \" no \" , or , you know , uh , i \" immediate \" .\nYeah .\nAnd instead just sort of rendered \" within this time slot ,  there were two people speaking during part of it\nYeah .\nand  if you want more detail , figure it out for yourself \" ,\nMm - hmm .\nWell , I think what  w what Eric was talking about was channels other than the direct speech ,\nI see .\nwas sort of the way I felt @ @\nright ?\nWell , yeah , what I mean is wh I mean , when somebody says \" uh - huh \" in the middle of , uh , a @ @\nYep .\nUh - huh . That happened very seldom .\nOh , cuz I was  I was listening to  Dan was agreeing a lot to things that you were saying as you were talking .\nUh - huh . Uh - huh .\nOh , well , thank you Dan .\nSo .\nAppreciate it . Well , if it  if there was a word like \" right \" , you know , then I wou I would indicate  that it happened within the same tem time frame\nYeah , there 's an overlapping mark .\nAnd\nYeah .\nbut wouldn't say exactly when it happened .\nI 'll be right back .\nI transcribed a minute of this stuff\nI see .\nand there was a lot of overlapping . It was\nA lot of overlapping , yeah .\nWell there there 's a lot of overlapping at the beginning and end .\nYeah . Yeah .\nHuge amounts .\nIt was at the beginning .\nUm , when  when no one i when we 're not actually in the meeting ,  and we 're all sort of separated , and  and doing things . But even during the meeting there 's a lot of overlap but it  it 's marked pretty clearly . Um , some of the backchannel stuff Jane had some comments  and  but I think a lot of them were because you were at the meeting . And so I think that  that often   often you can't tell .\nYeah , well that 's true . That 's another issue .\nI mean , Jane had  had comments like uh , to  who  who the person was speaking to .\nYeah .\nYeah .\nMm - hmm .\nOnly when it was otherwise gonna be puzzling\nYeah .\nbecause he was in the other room talking .\nYeah , but someone who , uh ,  was just the transcriber wouldn't have known that .\nYeah .\nOr when Dan said , \" I wa I wasn't talking to you \" .\nRight .\nThat 's true . I know .\nSo you take a bathroom break in the middle and  and keep your head mount\nYou have to turn off your mike .\nYeah .\nOh , you do ?\nYou don't have to .\nWell he was so  so he was checking the meter levels and  and we were handling things while he was labeling the  the whatever it was , the PDA ?\nMm - hmm .\nUh - huh .\nAnd  and so he was  in  sort of  you were sort of talking  you know , so I was saying , like   \" and I could label this one left . Right ? \" And he  and he said , \" I don't see anything \" . And he said   he said ,  \" I wasn't talking to you \" . Or  it wasn't  it didn't sound quite that rude .\nBut\nBut really , no , uh  w you know in the context if you know he can't hear what he 's saying\nbut when you w when you listen to it\nhe he It was a lot funnier if you were there though .\nUh , yeah ,\nWell what  what it  what happens is if you 're a transcriber listening to it it sounds like Dan is just being a total   totally impolite .\nI know . Well , you 'll see . You can listen to it . Oh , I thought it was you who was . No , well , but you were  you were asking off the wall questions .\nUm  But  but if you knew that  that I wasn't actually in the room , and that Dan wasn't talking to me , it  it became OK . So .\nI see .\nSo th\nAnd that 's w that 's where I added comments .\nHmm .\nThe rest of the time I didn't bother with who was talking to who but  but this was unusual circum circumstance .\nSo this is  this is gonna go on the meeting meeting transcriber bloopers tape , right ?\nYes . Right .\nWell and part of it was funny , uh  reason was because it was a mixed signal so you couldn't get any clues from volume  that , you know , he was really far away from this conversation .\nStereo . Yeah .\nYou couldn't do that symmetrically in any case .\nNo .\nOh . I should rewrite the mix tool to put half the people in one channel and half in the other . I have a  auto - gain - mixer tool that mixes all the head mounted microphones into one signal\nThat 's a good idea .\nMm - hmm .\nand that seems to work really well for the uh  transcribers .\nGreat .\nBut I thought it would be  you know , I  I didn't wanna add more contextual comments than were needed but that , it seemed to me , clarified that the con what was going on . And , uh  OK ,\nSo , s\nso normalization\nI was just gonna ask , uh , so I just wanted to c sort of finish off the question I had about backchannels ,\nMmm .\nif that 's OK ,\nYeah . OK .\nwhich  which was , so say somebody 's talking for a while\nYeah .\nand somebody goes \" mm - hmm \" in the middle of it , and  and  and what not , does the conversation come out from the  or the person who 's speaking for the long time as one segment and then there 's this little tiny segment  of this other speaker or does it  does the fact that there 's a backchannel split the  the  the  it in two .\nOK , my  my focus was to try and maintain conten con content continuity and , uh , to keep it within what he was saying . Like  I wouldn't say breath groups but prosodic or intonational groups as much as possible . So  if someone said \" mm - hmm \" in the middle of a  of someone 's ,  uh , uh , intonational contour ,  I  I indicated it as , like what you just did .\nOK .\nthen I indicated it as a segment which contained  @ @  this utterance plus an overlap .\nBut that 's  but there 's only one  there 's only one time boundary for both speakers ,\nOK .\nright ?\nYeah , that 's right . And you know , it could be made more precise than that\nI see ,\nbut I just thought\nI see , OK .\nYeah .\nRight .\nI think whenever we use these speech words we should always  do the thing like you 're talking about , accent ,\nOh , I see what you mean . And then  \" hesitation \" . Yeah . OK , and so then , uh , in terms of like words like \" uh \" and \" um \" I just wrote them because I figured there 's a limited number , and I keep them to a  uh , limited set because it didn't matter if it was \" mmm \" or \" um \" ,   you know , versus \" um \" . So I just always wrote it as U M .\nOK .\nAnd \" uh - huh \" , you know , \" UHUH . \" I mean , like a s set of like five . But in any case   I didn't mark those .\nNo .\nMm - hmm .\n\" Uh - huh \" is \" U H H U H . \" H U H . \"\nI 'd be happy with that . That 'd be fine . It 'd be good to have that in the  in the conventions , what 's to be used .\nHuh - uh .\nI  I did notice that there were some segments that had pauses on the beginning and end . We should probably mark areas that have no speakers as no speaker . Then , so question mark colon is fine for that .\nYeah , that 's a fine idea . That 's a fine idea .\nJust say silence .\nWell , what 's that mean ?\nYeah , OK . Yeah .\nYou mean re\nNo one 's talking .\nye s Oh . Silence all around .\nYep .\nYep .\nWe have to mark those ?\nSo I had\nDon't they  d can't we just leave them unmarked ?\nI d Well , you see , that 's possible too .\nWell , I wanna leave the marked  I don't want them to be part of another utterance . So you just  you need to have the boundary at the start and the end .\nOK . Sure .\nMm - hmm . Now that 's refinement that , uh , maybe it could be handled by part of the  part of the script or something more\nUh , yeah , it seems like  it seems like the , uh , tran the transcription problem would be very different if we had these  automatic speaker detection turn placing things . Because suddenly  I mean , I don't know , actually it sounds like there might be a problem  putting it into the software if the software only handles two parallel channels . But assuming we can get around that somehow .\nMm - hmm . Well you were saying , I think it can read\nIt can read and write as many as you want , it 's just that it\nUh - huh .\nBut what if you wanna edit it ? Right ? I mean , the point is we 're gonna generate  this transcript with five  five tracks in it , but with no words . Someone 's gonna have to go in and type in the words . Um , and if there are five  five people speaking at once ,\nRight , i it 's  I didn't explain it well . If we use the  the little  the conventions that Jane has established , I have a script that will convert from that convention to their saved convention .\nOh , yeah . Yes .\nWhich allows five .\nRight .\nAnd it can be m edited after the fact ,\nYes .\ncan't it also ? But their  but their format , if you wanted to in indicate the speakers right there instead of doing it through this indirect route ,  then i they  a c window comes up and it only allows you to enter two speakers .\nYeah . Right .\nBut you 're saying that by the time you call it back in to  from their saved format it opens up a window with window with five speakers ?\nSo . But .\nRight .\nOh ! That is sort of  f\nIt 's just user interface .\nThey didn't quite go the whole\nSo i it 's\nYeah , they didn't go the whole route ,\nthe  the  the whole saved form the saved format and the internal format , all that stuff , handles multiple speakers .\ndid they ? They just\nIt 's just there 's no user interface for specifying multiple  any more than two .\nRight . So your  your script solves  Doesn't it solve all our problems ,\nAnd that\nYep .\ncuz we 're always gonna wanna go through this preprocessing\nYep .\nuh , assuming it works .\nYep .\nAnd that works nicely cuz this so quick to enter . So I wouldn't wanna do it through the interface anyway adding which  worry who the speaker was .\nYep .\nI see . Right . Good .\nAnd then , uh , let 's see what else . Oh , yes , I  I wanted to have  So sometimes a pers I  uh in terms of like the continuity of thought  for transcriptions , it 's  i it isn't just words coming out , it 's like there 's some purpose for an utterance . And  sometimes someone will  do a backchannel in the middle of it but you wanna show that it 's continued at a later point . So I have  I have a convention of putting like a dash  arrow just to indicate that this person 's utterance continues . And then when it uh , catches back up again then there 's an arrow dash , and then you have the opposite direction  to indicate continuation of ones own utterance versus , um , sometimes  we had the situation which is  you know , which you  which you get in conversations ,  of someone continuing someone else 's utterance ,\nMmm .\nand in that case I did a tilde arrow versus a arrow tilde ,  to indicate that it was continuation but it wasn't  Oh , I guess I did  equal arrow for the  for the own  for yourself things\nMm - hmm .\ncuz it 's  the speakers the same . And then tilde arrow if it was a different  if a different speaker , uh , con continuation .\nMmm .\nOh .\nBut just , you know , the arrows showing continuation of a thought .\nMm - hmm .\nAnd then you could track whether it was the same speaker or not by knowing  you know , at the end of this unit you 'd know what happened later . And that was like this person continued\nMm - hmm .\nand you 'd be able to  look for the continuation .\nSo\nBut the only time that becomes ambiguous is if you have two speakers . Like , if you   If you only have one person , if you only have one thought that 's continuing across a particular time boundary , you just need  one arrow at each end , and if it 's picked up by a different speaker , it 's picked up by a different speaker . The time it becomes ambiguous if you have more than one speaker and that  and they sort of swap . I guess if you have more than one thread going , then you   then you need to know whether they were swapped or not .\nMm - hmm . Mm - hmm .\nHow often does that happen do you think ?\nMm - hmm .\nHopefully not very much .\nYeah , I didn't use it very often .", "topic_id": 3, "keywords": "utterances, transcription, transcriptions, speech, utterance", "dialogue_id": 5}, {"text": "Especially for meetings . I mean , if i if you were just recording someone 's day , it would be impossible . You know ,\nIt l ou\nif you were trying to do a remembrance agent . But I think for meetings it 's probably alright .\nHmm .\nBut , a lot of these issues , I think that for  uh , from my point of view , where I just wanna do speech recognition and information retrieval , it doesn't really matter .\nSure .\nBut other people have other interests .\nI know .\nSo .\nBut it  it does feel  it does feel like it 's really in there . I  you know I did this  I did this transcription and I marked that , I marked it with ellipsis because it seemed like there was a difference . It 's something you wanted to indicate that it  that I  this was the end of the phrase , this was the end of  that particular transcript , but it was continued later .\nRight .\nAnd I picked up with an ellipsis .\nExcellent . Yeah .\nI didn't have the equal , not equal thing .\nYeah . Well that 's  you know , I mean  I  that 's why I didn't  I didn't do it n  I mean , that 's why I thought about it , and  and re - ev\nYeah , yeah .\nand it didn't do  I didn't do it in ten times the   the time .\nWell , so anyway , are we interested then in writing tools to try to generate any of this stuff automatically ?\nYeah .\nIs that something you want to do , Dan ?\nNo .\nNo .\nBut it 's something @ @ that I feel we definitely ought to do .\nI also wanted to ask you if you have a time estimate on the part that you transcribed . Do you have a sense of how long\nYeah , it took me half an hour to transcribe a minute , but I didn't have any  I didn't even have a\nOK .\nI was trying to get Transcriber to run but I couldn't . So I was doing it by typ typing into a text file and trying to fit  It was horrible .\nOK . OK .\nSo thirty to one 's what you got ?\nMm - hmm .\nSo that 's a new upper limit ?\nYeah .\nWell , I mean , that 's  that 's because you didn't have the segmentation help and all the other\nBut I think for a first try that 's about right .\nIs it\nSo  so if we hired a who if we hired a whole bunch of Dan 's\nThat 's right .\nYeah .\nIt was actually  it was quite  it was a t\na\nIf we  hire an infinite number of Dan 's\nit w\nIt 'd b a a\nAnd there 's always a warm up thing of\nAre we gonna run out of disk space by the way ?\nYeah .\nOK ,\nNo .\ngood .\nOK .\nd Doesn't it beep in the other room when you 're out of disk space ?\nSo  Is there\nNo .\nMaybe we should s consider also , um , starting to build up a web site around all of these things .\nWeb site ! That 's great !\nI know .\nDan 's sort of already started .\nWe could have like business - to - business E - commerce as well !\nThat 's right . No , but I 'm it would be interesting  it would be interesting to see\nCan we sell banner ads ?\nGet  get paid for click - throughs ?\nWhat a good idea ,\nYeah .\nthat 's how we could pay for the transcription .\nI want to introduce  I  I want to introduce the word \" snot - head \" into the conversation at this point .\nWe can have\nYou wanna word that won't be recognized ?\nYou see , cuz  uh , cuz  Exactly . Um .\nOh , I don't think so .\nNo .\nHey , what about me ?\nThe r w What  OK .\nYou 're the one who raised the issue .\nNo . Alright , see here 's  here 's  here 's my thought behind it which is that , uh , the  the stuff that you 've been describing , Jane , I gu one has to ,  of course  indicate ,   um , i is very interesting ,\nAlright .\nand I I 'd like to be able to  to pore through , you know , the  the types of tr conventions that you 've come up with and stuff like that .\nYeah , yeah , yeah .\nSo I would like to see that kind of stuff on the web .\nOK , now , w the alternative to a web site would be to put it in Doctor speech .\nYes . Yes .\nCuz  cuz what I have is a soft link to my transcription  that I have on my account\nEither 's fine .\nWe c\nbut it doesn't matter .\nWe can do it all .\nwe can do it all ! We can write\nOK .\nOh .\nWeb site 's nice .\nYeah .\nThen you have to t you have to do an HT access .\nWeb site 's what ?\nWe could actually  maybe we could use the TCL plug - in . Oh , man .\nOoo ! He 's committed himself to something .\nOw . See he said the word TCL and  and that 's\nBut he does such a good job of it . He should be allowed to  to , you know , w do it .\nI know , I know .\nI know , but that  but , I  Right . But I should be allowed to but\nIf you just did a crappy job ,  no nobody would want you to do it .\nI sh I shouldn't be allowed to by m by my own   by my  according to my own priorities . Alright . Let 's look at it anyway . So definitely we should  we should have some kind of access to the data .\nAnd we have  we have quite a disparate number of web and other sorts of documents on this project sort of spread around .\nYeah .\nI have several and Dan has a few ,\nYes .\nand\nRight , so we can add in links and stuff like that to other things .\nAh !\nYep .\nNice .\nWell , yeah .\nThe\nWell so then th\nTry  try to s consolidate . I mean , who wants to do that though ?\nthe other side is , yeah .\nUh , right .\nNo one wants to do that . So .\nYeah .\nRight , that 's the problem .\nWell , we could put  we could put sort of a disorganized sort of group gestalt\nWhy ? What  what 's  what 's the issue ?\nNo one owns the project .\nNo one what ?\nNo one owns the project .\nYeah , I own the project but I don't wanna do it .\nNo one wants to own the project .\nRight .\nW well  Do  But\nIt 's mine ! All mine !\nWell then you have to do the web site .\nBut\n\" Wah - hah - hah - hah - hah - hah . \"\nYou know , it 's like , it 's that simple .\nb but  but  but what are you  what are you talking about for web site hacking ?\nNo\nYou 're talking about writing HTML , right ?\nYeah , I  I 'm talking about putting together all the data in a form that  that is legible , and pleasant to read , and up to date , and et cetera , et cetera , et cetera .\nYeah .\nBut , is it against the law to actually use a tool to help your job go easier ?\nAbsolutely . It 's  it 's absolutely against the law to use a tool . I haven't found any tools that I like .\nYou y\nIt 's just as easy to use  to edit the raw HTML as anything else .\nNo kidding ?\nThat 's obviously not true ,\nIt 's obviously not true .\nbut you have\nNo , it it it 's obviously true that he hasn't found any he likes .\nRight . That 's true .\nThe question is what is  what 's he looked at .\nWhich one do you use Jim ?\nI use something called Trellix .\nOh , that 's right . I remember . Yeah .\nAnd it\nWhich produces also site maps .\nNow , I guess if I were  if I were doing more powerful  excuse me  more complex web sites I might want to .\nit 's - it it 's very powerful .\nBut most of the web sites I do aren't that complex .\nWell , would this be to document it also for outside people or mainly for in house use ?\nBut . I think both .\nNo , I think in\nMostly in house .\nThat 's right .\nI think mostly internal .\nWell , yeah ,\nOK .\nbut what does internal mean ?\nNo , both .\nI mean , you 're leaving . People at UW wanna look at it . I mean , it 's  it 's internal  until\nRight . Internal to the project .\nI see .\nWe could do an HT access which would accommodate those things .\nI  I  I  I\nOK , well , send me links and I wi send me pointers , rather , and I 'll put it together .\nI 'm not  o\nWonderful .\nOK . I 'm not sure how  how  important that distinction is . I don't think  we should say ,  \" oh , it 's internal therefore we don't have to make it very good \" . I mean , you can say  \" oh  oh , it 's internal\nNo . No .\ntherefore we can put data in it that we don't  we don't have to worry about releasing \" . But I think the point is to try and  be coherent and make it a nice presentation .\nRight . I agree .\nYeah , it is true , that is  it benefits to\nCuz you 're gonna have to wor do the work sooner or later .\nYeah .\nThat 's right . I mean , it 's the early on .\nEven if it 's just writing things up .\nYep .\nYou know ?", "topic_id": 4, "keywords": "speech, transcript, transcription, conversation, transcribed", "dialogue_id": 5}, {"text": "It 's a great idea .\nOK , um , let 's move on to electronics .\nAh . Great .\nd we  we out of tape  out of disk ?\nNo , we 're doing  we 're doing great .\nI  I was looking for the actual box I plan to use , uh , but I  c all I could  I couldn't find it at the local store . But this is  the  the technology . It 's actually a little bit thinner than this . And it 's two by two , by one , and it would fit right under the  right under th the the  the  the lip ,\nYeah , does everyone know about the lip on the table ? It 's great .\nyeah . There 's a lip in these tables .\nNice .\nAnd , it oc I p especially brought the bottom along to try and generate some frequencies that you may not already have recorded .\nClink ! Clink !\nLet 's see   see what it does to the  But this was the uh  just  just to review , and I also brought this  along rather than the projector so we can put these on the table , and sort of w push them around .\nAnd  and crinkle them and\nWhat ?\nAnd th \" that \" being a diagram .\nWhat ?\nThat  that 's the six tables that we 're looking at . These six tables here ,  with  with little boxes sort of , uh , in the middle here .\nI see .\nOK .\nWhich es would  I mean , the  the boxes are pretty much out of the way anyway . I 'll - I 'll show you the   the cro this is the table cross section . I don't know if people realize what they 're looking at .\nYou trying to  screw up the m the microphones ?\nYes . He is . Absolutely .\nI mean th\nWell why not ? I mean , cuz this is what 's gonna happen . You got plenty of data . I won't come to your next meeting . And  and  and you So this is the box 's\nGet your paper off my PDA !\nYeah .\nYeah , let  let the record show that this is exhibit two B .\nThat 's right . \" Or not to be \" . Yeah , yeah .\nYeah .\nUh , the box , uh  there 's a half inch lip here . The box is an inch thick so it hangs down a half an inch . And so the  the two  head set jacks would be in the front and then the little LED to indicate that that box is live . The  the important issue about the LED is the fact that we 're talking about eight of these total , which would be sixteen channels . And , uh , even though we have sixteen channels back at the capture , they 're not all gonna be used for this .\nHmm .\nSo there 'd be a subset of them used for  obviously j just use the ones at this end for   for this many . So  Excuse me . you 'd like a  a way to tell whether your box is live , so the LED wouldn't be on .\nRight . All the lights .\nSo if you 're plugged in it doesn't work and the LED is off that 's  that 's a tip off . And then the , uh  would wire the  all of the cables in a  in a bundle come through here and o obviously collect these cables at the same time .\nThat 's good .\nUh , so this  this notion of putting down the P Z Ms  and taking them away would somehow have to be turned into leaving them on the table\nRight . Well , we wanna do that definitely .\nor  or  Right .\nSo .\nRight . And so the  you  we just epoxy them down or something . Big screw into the table .\nVelcro .\nUh , and even though there 's eight cables they 're not really very big around so my model is to get a  a  a p piece of\nSleeve .\nyeah , that  that stuff that people put with the little  you slip the wires into that 's  sort of shaped like that cross section .\nOh . OK , not just sleeve them all ?\nYeah . I 'm  I 'm r a I 'm going up and then I 'm going down .\nAnd leave them loose ?\nNo .\nThat looks like a semi - circle .\nYeah . It 's like a  it 's a sleeping policeman .\nWhoo !\nSpeed bump !\nSleeping pol\nSpeed bump .\nSpeed A \" sleeping policeman \" !\nYeah , it 's like a speed bum  An\nSpeed bump . That 's good . There we go s\nCool .\nAnd they 're ac they 're actually ext extruded from plastic .\nWhat is\nThey sorta look like this .\nOh .\nWhat does that mean ?\nThat 's the s that 's British for speed bump ,\nIs it a speed bump ?\nSo that the wires go through here .\nyeah .\nWow .\nOh , is that right ?\nYeah .\nI never heard that .\nThat 's really cruel .\nSo .\nAh !\nOK , so that\ns So it would c basically go on the diagonal here .\nIt could go either way .\nSo why do we have sixteen channels instead of like some fewer number ?\nYeah .\nI guess .\nUh , because the\nHow else are you gonna distribute them around the tables ?\nBecause they 're there .\nWell , OK , let me rephrase that . Why two each ?\nOh , because then you don't have to just have one each . So that if t if you have two people sitting next to each other they can actually go into the same box .\nYeah .\nOK .\nAnd to  See , thi this is really the way people sit on this table . Th\nOK .\nMm - hmm .\nUh . Dot , dot , dot .\nWhich means two at each station .\nWell that  that 's the way people sit . That 's how many chairs are in the room .\nYeah .\nAlright .\nYeah , I 'm just saying that for the recording .\nYeah .\nRight .\nRight .\nOK .\nAnd certainly you could do a thing where all sixteen were plugged in .\nBut then none of these .\nUh if  if you ha if you had nothing else .\nRight . N none of these and no P Z Ms then .\nYeah . Right . Right . I agree .\nOnly if you had  Well it depends on this box , right ?\nOh , true enough . And actually , at the m my plan is to only bring eight wires out of this box .\nExactly .\nOh , I didn't understand\nThis  this box  Thi - thi thi this box is a one off deal .\nThat being the wiring box .\nOh , I see , I see .\nUh . And , uh , it 's function is to s to , uh , essentially a wire converter to go from these little blue wires to these black wires , plus supply power to the microphones cuz the  the  he the , uh , cheap head mounteds all require low voltage .\nSo  so you 'd imagine some sort of  in some sort of patch panel on top to figure out what the mapping was between each d of these two and each of those one or what ?\nHmm !\nWell I w I I the simplest thing I could imagine , i which is really , really simple is to  quite literally that these things plug in . And there 's a  there 's a plug on the end of each of these  these , uh , ei eight cables .\nWhat\nYeah .\nOK . Each of the blue wires ?\nBut there are only four .\nAn - and there 's only  there 's only four slots that are  you know , in  in the first version or the version we 're planning to  to build .\nMm - hmm .\nYeah .\nMm - hmm .\nYeah .\nSo  that  that was the whole issue with the LED , that you plug it in , the LED comes on , and  and  and you 're live .\nOh , then it comes on . I see , I see . OK , good .\nNow the  the   the subtle issue here is that  tha I  I haven't really figured out a solution for this . So , we it 'll have to be convention . What happens if somebody unplugs this because they plug in more of something else ?\nMm - hmm .\nWell the  there 's no clever way to let the up stream guys know that you 're really not being powered . So  th there will be a certain amount of looking at cables has to be done if people , uh , rewire things .\nRight .\nYeah , I mean , we  I had that last time .\nBut .\nBut uh there are actually  that you know , there 's an extra  there 's a mix out on the radio receiver ?\nMm - hmm .\nSo there are actually six  XLR outs on the back of the radio receiver and only five cables going in , I had the wrong five , so I ended up  not recording one of the channels and recording the mix .\nHow interesting . D did you do any recognition on the mix  mix out ?\nHmm .\nNo .\nWonder whether it works any\nBut I subtracted the four that I did have from the mix and got a pretty good approximation of the @ @ .\nGot the fifth ?\nYou g\nCool .\nOh , how great .\nAnd did it work ?\nYeah .\nDid it sound good ?\nIt 's not bad .\nIs it  is\nIt 's not bad ,\nWow .\nyeah .\nAin't science wonderful ?\nThat 's amazing .\nYeah .\nSo what 's the schedule on these things ?\nSo\nBut , you always\nWow .\nUh , well I was wrestling with th with literally the w number of connectors in the cable and the   the , uh ,  powering system . And I  I was gonna do this very clever phantom power and I decided a couple days ago not to do it .\nHmm !\nSo I 'm ready to build it . Which is to say , uh , the neighborhood of a week to get the circuit board done .\nMm - hmm . So I think the other thing I 'd like to do is , do something about the set up\nSee\nso that it 's a little more presentable and organized .\nI agree .\nAnd I 'm  I 'm just not sure what that is . I mean , some sort of cabinet .\nWell I can build a cabinet . The  the difficulty for this kind of project is the intellectual capital to design the cabinet .\nMm - hmm .\nIn other words , to figure out ex exactly what the right thing is . That cabinet can  can go away . We can use that for  for uh kindling or something . But if you can imagine what the right form factor is . Dan - Dan and I have sort of gone around on this , and we were thinking about something that opened up in the top  to allow access to the mixer for example .\nMm - hmm .\nBut there 's these things sticking out of the mixer which are kind of a pain , so you end up with this thing that  if if you stuck the mixer up here and the top opened , it 'd be  it 'd be fine . You wouldn't necessarily  Well , you s understand what I 'm\nYeah , I understand .\nYeah .\nthe  the  you can  you can start  start s sketching it out ,\nSo .\nand I can certainly build it out of oak no problem , would it  you know , arb you know , arbitrarily amount of\nI need a desk at home too , alright ? Is that gonna be a better solution than just going out and buy one ?\nWell , the  as we found out with the  the thing that , uh , Jeff bought a long time ago to hold our stereo system  the stuff you buy is total crap . And I mean this is something you buy .\nMm - hmm .\nAnd  and\nAnd it 's total crap .\nIt 's total crap . Well , it 's useless for this function . Works fine for holding a Kleenex ,\nRight , Kleenex and telephones .\nbut it  Right .\nUm , so yeah , I g I guess it 's just a question , is that something you wanna spend your time on ?\nOh , I  I 'm paid for .\nOK , great .\nI have no problem . No , but w certainly one of the issues is  is the , uh  is security .\nHmm ? Mm - hmm .\nI mean , we 've been  been  been lax and lucky .\nLax .\nYeah . Yep .\nReally lucky with these things . But they 're not ours , so\nYeah .\nthe , uh  the flat panels .\nOh , yeah !\nI 'm telling you , I 'm just gonna cart one of them away if they stay there much longer .\nWell w yeah , exactly .\nUh , let the record show at  uh  at f four thirty - five  Adam Janin says\nWow . Tempting .\nWe 'll know  we 'll know to come after .\nTempting . Yeah .\nSo , um , j uh , then the other question is do we wanna try to do a user interface that 's available out here ?\nSorry ?\nSlipped  almost slipped it by Dan .\nUse - user interface\nA user interface . I mean , do we wanna try to get a monitor ? Or just something .\nOh ! Sure .\nOh .\nWell of course we do .\nAnd how do we want to do that ?\nYou mean like see  see meter readings , from  while sitting here .\nJ just so we see something .\nWow .\nHow about use the thing that um ACIRI 's doing .\nYeah .\nWhich is to say just laptop with a wireless .\nYeah , yeah , yeah . Sure .\nOh .\nWhich we 'll borrow from them ,  when we need it .\nWhat 's wrong with yours ? If we bought you a  a\nOh , a Applecard . Sure . Right . Yeah , you could use my machine .\nWell\nWhat ?\nI have an IRAM machine I 've borrowed and we can use it .\nI  or the\nN no , I 'm  I 'm  I 'm serious . Does  does the wireless thing work on your\nWait , isn't that an ethernet connection or is that a phone ?\nUh , that 's an ethernet connection .\nWell\nIt 's going next door .\nYeah  no  no I 'm a I  I  I ain't joking here .\nWe jus\nI 'm serious , that  that   it  it\nYeah . No , no , absolutely , that 's the right way to do it . T to have it uh , just\nIt 's very convenient especially if Dan happens to be sitting at that end of the table to not have to run down here and  and look in the thing every so often ,\nYeah . And given  given that we 've got a wireless  that we 've got a  we got the field .\nbut just have the  It 's right there .\nRight .\nRight ? The antenna 's right there ,\nRight .\nYeah . Yeah .\nright outside the\nI don't know .\nY I mean , we need  obviously need to clear this with ACIRI but , uh , how tough can that be ? There  it you 'd  all you need 's web access , isn't it ?\nW we don't need X access\nIn  in theory .\nbut I mean that 's fine . That 's  that 's what it does ,\nOK ,\nyeah .\ngreat , great .\nUm ,\nSo\nright , so it 's just a question of getting a laptop and a wireless modem .\nWith a  with a  with a  w\nNo , and he  he had , reque @ @  my  my proposal is you have a laptop .\nNo . Yeah . I do !\nYou don't ?\nYeah . Yeah , yeah .\nIf  if we bought you the thing would you mind using it with i the  the\nNo , I would love to but I 'm not sure if my laptop is compatible with the wave LAN thing they 're using .\nReally ?\nTo  Mac .\nWell Apple has their own thing , right ?\nHe 's\nYour new one ?\nAirport .\nI 'm sorry ?\nApple has their own thing . And\nI thought it just came through a serial p or an Ethernet port .\nYeah , I think what  I think you  I think it just plug plugs in a PC card , so you could probably make it run with that , but .\nThe question is , is there an Apple driver ?\nI  e\nYeah , I 'm sure . I imagine there is . But  uh anyway there are  there are abs there are a bunch of machines at ICSI that have those cards\nBut the two t\nand so I think if w if it doesn't  we should be able to find a machine that does that . I  I mean I know that doesn't  don't  don't the important people have those little blue VAIOs that\nWell , uh , b that  to me that 's a whole nother . That 's a whole nother issue .\nHmm . Hmm .\nYeah .\nThe  the idea of con convincing them that we should use their network i is fairly straight forward .\nYeah . Yeah .\nThe idea of being able to walk into their office and say , \" oh , can I borrow your machine for a while \" , is  is  is a non - starter .\nYeah . I see .\nThat  I  I don't think that 's gonna work . So , I mean , either  either we figure out how to use a machine somebody already  in the group already owns ,  a a and the idea is that if it 's it perk , you know , it 's an advantage not  not a disadvan   or else we  we literally buy a machine e exactly for that purpose .\nYeah . Yeah , yeah . Absolutely . Yeah .\nCertainly it solves a lot of the problems with leaving a monitor out here all the time .\nYeah .\nI  I  I  I 'm  I 'm not a big fan of doing things to the room that make the room less attractive for other people ,\nRight .\nright ? Which is part of the reason for getting all this stuff out of the way\nYeah .\nand   and , so a monitor sitting here all the time you know people are gonna walk up to it and go , \" how come I can't get , you know , Pong on this \" or , whatev\nMm - hmm . Right . I 've  I 've borrowed the IRAM VAIO Sony thingy ,\nWell\nand I don't think they 're ever gonna want it back .\nYeah .\nRight .\nYou 're kidding !\nWell , the next conference they will .\nSo . Sure .\nYeah .\nBut that does mean  so we can use that as well .\nWell , uh , the  certainly , u you should give it a shot first See whether you you can get compatible stuff .\nMm - hmm .\nUh , ask them what it costs . Ask them if they have an extra one . Who knows , they might have an extra  hardware s\nI 'd trade them a flat panel display for it . Yeah .\nWhat is the , um , projector supposed to be hooked up to ?\nGood . Uh , the , uh  Tsk . It 's gonna be hooked up to all sorts of junk . There 's gonna be actually a  a plug at the front that 'll connect to people 's laptops so you can walk in and plug it in . And it 's gonna be con connected to the machine at the back . So we certainly could use that as  as a constant reminder of what the VU meters are doing .\nHuge VU meters .\nSo people sitting here  are going  \" testing , one , two , three \" !\nBut I mean , that 's another  that 's another possibility that , you know , solves\nIt  a\nYeah .\nYeah .\nThat 's an end\nBut  but  but I think the idea of having a control panel it 's  that 's there in front of you is really cool .\nYeah . Yeah , yeah .\nMm - hmm .\nI think and uh , having  having it on wireless is  is the neatest way  neatest way to do it .\nR\nI had\nAs long as you d as l as long as you 're not tempted to sit there and f keep fiddling with the volume controls going , \" can you talk a bit louder ? \"\nYeah .\nI had actually earlier asked if I could borrow one of the cards to do wireless stuff\nYeah .\nand they said , \" sure , whenever you want \" . So I think it won't be a problem .\nOh , cool . OK .\nAnd  and it 's a  a PCMCIA card , right ?\nYep .\nPC card ,\nPC card .\nso you can have a slot ,\nYeah , yeah .\nright ? In your new machine ?\nIt 's  it really come down to the driver .\nIs it with s\nYeah .\nI mean\nRight , I mean , and if  and if his doesn't work , as I said , we can use the PC .\nRight , i it 'll  it 'll work  It 'll work the first time . I  I trust Steve Jobs .\nGood .\nUm ,\nSo\nwell , that sounds like a d good solution one way or the other .\nSo Jim is gonna be doing wiring and you 're gonna give some thought to cabinets ?\nUh , y yeah .\nGreat .\nWe  we need to  figure out what we want . Uh\nWe 'd  I think\nHey , what are those green lights doing ?\nThey 're flashing !\nUh - oh ! Uh - oh ! Does that  it means  it means it 's gonna explode . No .\nCut the red wire , the red wire !\nUm\nWhen people talk , it  they go on and off .\nThis  So again , Washington wants to equip a system . Our system , we spent ten thousand dollars on equipment not including the PC . However , seven and a half thousand of that was the wireless mikes . Uh ,\nMm - hmm .\nusing  using these\nAnd it  and the f the five thousand for the wires , so if I 'm gonna do  No .\nYeah ,\nIt 's a joke .\nthat 's true\nI have to do\nbut we haven't spent that , right ? But once we  once we 've done the intellectual part of these , uh , we can just knock them out , right ?\nCheap .\nWe can start   we  you can make a hundred of them or something .\nOh , of the  of the boards ? Yeah , yeah , sure , right .\nAnd then we could  Washington could have a system that didn't have any wireless but would had  what 's based on these\nMm - hmm .\nand it would cost\nA PC and a peanuts .\nPeanuts .\nPC and two thousand dollars for the A - to - D stuff .\nYeah .\nAnd that 's about  cuz you wouldn't even need the mixer if you didn't have the  Oh th  the P Z\nRight .\nP Z Ms cost a lot . But anyway you 'd save , on the seven  seven or eight thousand for the  for the wireless system . So actually that might be attractive .\nRight .\nGood .\nOK , I can move my thumb now .\nThat 's a great idea .\nWhat ?\nIt 's nice  it 's nice to be thinking toward that .\nOh , I thought like if we talked softer the disk lasts longer .\nWell , actually shorten\nYeah .\nThere 's a speech compression program that works great on things like this , cuz if the dynamic range is low it encodes it with fewer bits . And so most of the time no one 's talking so it shortens it dramatically . But  if you talk quieter , the dynamic range is lower and it will compress better . So .\nYeah .\nOh . Hmm .\nIt also helps if you talk in a monotone .\nProbably .\nConstant volume all the time .\nOh , interesting . And shorter words .\nShorter words .\nNow , shorter words wouldn't  would induce more dynamics , right ? You want to have\nYeah , but if the words are more predictable .\nHow about if you just go \" uh \" ?\nHuh .\nUh .\nThat 's a long word !\nHow do you spell that ?", "topic_id": 5, "keywords": "tables, projector, tape, diagram, electronics", "dialogue_id": 5}, {"text": "I don't know .\nOK , can you do one more round of digits ? Are we done talking ?\nWell it 's a choice  if we get a choice , let 's keep talking .\nDo we have more to talk about ?\nSure . No , I 'm done .\nI 'm done .\nAre you done ?\nI 'm done ,\nI 'm done .\nyeah .\nDan isn't but he 's not gonna say anything .\nBut  you  you  you  there 's a problem  a structural problem with this though . You really need an incentive at the end if you 're gonna do digits again . Like , you know , candy bars or something ,\nI 'll  I 'll remember to bring M and M 's next time .\nor  or  or  or or a little , uh  you know , toothbrushes like they give you at the d dentist .\nMmm !\nOr both .\nOr both .\nSorry .\nEric , you and I win . We didn't make any mistakes .\nIt 's harder at the end than at the beginning .\nWe don't know that for sure , do we ?\nI should have mentioned that s uh , to pause between lines but\nNo , I know . I 'm just giving you a hard time .\nIt 's  it 's only a hard time for the transcriber not for the speech recognizer .\nTha - tha\nBut  I also think you said channel four\nMe .\nand I think you meant microphone four . And I think that 's a mistake .\nVery good . So Eric , you win . But the other thing is that there 's a  there 's a colon for transcripts . And there shouldn't be a colon . Because see , everything else is stuff you fill in .\nYeah , that 's been filled in for you .\nRight ? Automatically .\nBut they 're in order !\nBut real\nThey start , six , seven , eight , nine , zero , one , two , three , four , five , six , eight , nine .\nWhere 'd they come from ?\nAnd they 're in order because they 're sorted lexically by the file names , which are  have the numbers in digits .\nOh .\nAnd so they 're actually  this is like all the  all utterances that were generated by speaker MPJ or something .\nOh .\nAnd then within MPJ they 're sorted by what he actually said .\nUgh ! I didn't know that . I should have randomized it .\nWow .\nIt doesn't matter ! It 's like  Cuz you said \" six , seven , eight \" .\nWell , we think it doesn't matter .\nWe think it doesn't matter . If I  if not I\nBut the real question I have is that , why bother with these ?\nOh , interesting .\nWhy don't you just ask people to repeat numbers they already know ? Like phone numbers , you know , social security numbers .\nCuz we have these writt written down , right ?\nBecause  Right .\nThat 's why\nIf we have it , uh\nI know .\nSocial security numbers .\nI kn\nwe don't have to transcribe .\nYou can  you can generate\nBank account numbers .\nCredit card numbers ,\nWe don't have to tran\nyeah .\nYeah , please .\nYeah . That 's a great idea .\nPassport numbers .\nYeah , so you just say   say your credit card numbers , say your phone numbers , say your mother 's maiden name .\nBet we could do it .\nYou know pe\nPassword to your account .\npeople off the street .\nGo on .\nThis\nActually , this  I got this directly from another training set , from Aurora .\nAlright .\nSo . We can compare directly .\nLooks good . Looks like there were no errors .\nI was  I  the reason I made my mistake was\nWhat ?\nWa - was this  ?\nThere were no  there were no direct driver errors , by the look of it , which is good .\nGreat .\nGood news .\nOK , the mike 's off .\nSo I 'm gonna stop it . Yeah , OK .\nOK .\nThank you all .\nMony on the mike .\nUh - oh .", "topic_id": 6, "keywords": "talk, pause, talking, say, end", "dialogue_id": 5}, {"text": "OK , we 're going .\nDamn .\nAnd uh Hans - uh , Hans - Guenter will be here , um , I think by next  next Tuesday or so .\nOh , OK .\nMm - hmm .\nSo he 's  he 's going to be here for about three weeks ,\nOh ! That 's nice .\nJust for a visit ?\nand , uh  Uh , we 'll see .\nHuh .\nWe might  might end up with some longer collaboration or something .\nCool .\nSo he 's gonna look in on everything we 're doing\nMm - hmm .\nand give us his  his thoughts . And so it 'll be another  another good person looking at things .\nOh . Hmm .\nTh - that 's his spectral subtraction group ?\nYeah ,\nIs that right ?\nyeah .\nOh , OK . So I guess I should probably talk to him a bit too ?\nOh , yeah . Yeah . Yeah . No , he 'll be around for three weeks . He 's , uh , um , very , very , easygoing , easy to talk to , and , uh , very interested in everything .\nReally nice guy .\nYeah , yeah .\nYeah , we met him in Amsterdam .\nYeah , yeah , he 's been here before .\nOh , OK .\nI mean , he 's  he 's  he 's  he 's\nWh - Back when I was a grad student he was here for a , uh , uh  a year or  n six months .\nI haven't noticed him .\nN nine months .\nSomething like that .\nSomething like that .\nYeah .\nYeah . Yeah . He 's  he 's done a couple stays here .\nHmm .\nYeah .", "topic_id": 0, "keywords": "hans, met, amsterdam, spectral, talk", "dialogue_id": 6}, {"text": "So , um ,   I guess we got lots to catch up on . And we haven't met for a couple of weeks . We didn't meet last week , Morgan . Um , I went around and talked to everybody , and it seemed like they  they had some new results but rather than them coming up and telling me I figured we should just wait a week and they can tell both  you know , all of us . So , um , why don't we  why don't we start with you , Dave , and then , um , we can go on .\nOh , OK .\nSo .\nSo , um , since we 're looking at putting this , um  mean log m magnitude spectral subtraction , um , into the SmartKom system , I I did a test seeing if , um , it would work using past only  and plus the present to calculate the mean . So , I did a test , um ,  where I used twelve seconds from the past and the present frame to , um , calculate the mean . And\nTwelve seconds  Twelve  twelve seconds back from the current  frame , is that what you mean ?\nUh  Twelve seconds , um , counting back from the end of the current frame ,\nOK , OK .\nyeah . So it was , um , twen I think it was twenty - one frames and that worked out to about twelve seconds .\nMm - hmm .\nAnd compared to , um , do using a twelve second centered window , I think there was a drop in performance but it was just a slight drop .\nHmm !\nMm - hmm .\nIs  is that right ?\nUm , yeah , I mean , it was pretty  it was pretty tiny . Yeah .\nUh - huh . So that was encouraging . And , um , that  that  um , that 's encouraging for  for the idea of using it in an interactive system like And , um , another issue I 'm  I 'm thinking about is in the SmartKom system . So say twe twelve seconds in the earlier test seemed like a good length of time , but what happens if you have less than twelve seconds ? And , um  So I w bef before , um  Back in May , I did some experiments using , say , two seconds , or four seconds , or six seconds . In those I trained the models using mean subtraction with the means calculated over two seconds , or four seconds , or six seconds . And , um , here , I was curious , what if I trained the models using twelve seconds but I f I gave it a situation where the test set I was  subtracted using two seconds , or four seconds , or six seconds . And , um  So I did that for about three different conditions . And , um  I mean , I th I think it was , um , four se I think  I think it was , um , something like four seconds and , um , six seconds , and eight seconds . Something like that . And it seems like it  it  it hurts compared to if you actually train the models  using th that same length of time but it  it doesn't hurt that much . Um , u usually less than point five percent , although I think I did see one where it was a point eight percent or so rise in word error rate . But this is , um , w where , um , even if I train on the , uh , model , and mean subtracted it with the same length of time as in the test , it  the word error rate is around , um , ten percent or nine percent . So it doesn't seem like that big a d a difference .\nBut it  but looking at it the other way , isn't it  what you 're saying that it didn't help you to have the longer time for training , if you were going to have a short time for\nThat  that 's true . Um ,\nI mean , why would you do it , if you knew that you were going to have short windows in testing .\nWa\nYeah , it seems like for your  I mean , in normal situations you would never get twelve seconds of speech , right ? I 'm not  e u\nYou need twelve seconds in the past to estimate , right ? Or l or you 're looking at six sec  seconds in future and six in\nYeah .\nUm , t twelve s\nNo , total .\nN n uh  For the test it 's just twelve seconds in the past .\nNo , it 's all  Oh , OK .\nIs this twelve seconds of  uh , regardless of speech or silence ? Or twelve seconds of speech ?\nOf  of speech .\nOK .\nMm - hmm .\nThe other thing , um , which maybe relates a little bit to something else we 've talked about in terms of windowing and so on is , that , um , I wonder if you trained with twelve seconds , and then when you were two seconds in you used two seconds , and when you were four seconds in , you used four seconds , and when you were six  and you basically build up to the twelve seconds . So that if you have very long utterances you have the best ,\nYeah .\nbut if you have shorter utterances you use what you can .\nRight . And that 's actually what we 're planning to do in\nOK . Yeah .\nBut  s so I g So I guess the que the question I was trying to get at with those experiments is , \" does it matter what models you use ? Does it matter how much time y you use to calculate the mean when you were , um , tra doing the training data ? \"\nRight . But I mean the other thing is that that 's  I mean , the other way of looking at this , going back to , uh , mean cepstral subtraction versus RASTA kind of things , is that you could look at mean cepstral subtraction , especially the way you 're doing it , uh , as being a kind of filter . And so , the other thing is just to design a filter . You know , basically you 're  you 're  you 're doing a high - pass filter or a band - pass filter of some sort and  and just design a filter . And then , you know , a filter will have a certain behavior and you loo can look at the start up behavior when you start up with nothing .\nMm - hmm .\nAnd  and , you know , it will , uh , if you have an IIR filter for instance , it will , um , uh , not behave in the steady - state way that you would like it to behave until you get a long enough period , but , um , uh , by just constraining yourself to have your filter be only a subtraction of the mean , you 're kind of , you know , tying your hands behind your back because there 's  filters have all sorts of be temporal and spectral behaviors .\nMm - hmm .\nAnd the only thing , you know , consistent that we know about is that you want to get rid of the very low frequency component .\nHmm .\nBut do you really want to calculate the mean ? And you neglect all the silence regions  or you just use everything that 's twelve seconds , and\nUm , you  do you mean in my tests so far ?\nYe - yeah .\nMost of the silence has been cut out .\nOK .\nJust  There 's just inter - word silences .\nMm - hmm . And they are , like , pretty short . Shor\nPretty short .\nYeah , OK .\nYeah .\nYeah . Mm - hmm . So you really need a lot of speech to estimate the mean of it .\nWell , if I only use six seconds , it still works pretty well .\nYeah . Yeah . Uh - huh .\nI saw in my test before . I was trying twelve seconds cuz that was the best  in my test before\nOK .\nand that increasing past twelve seconds didn't seem to help .\nHmm . Huh .\nth um , yeah , I guess it 's something I need to play with more to decide how to set that up for the SmartKom system . Like , may maybe if I trained on six seconds it would work better when I only had two seconds or four seconds , and\nYeah . Yeah . And , um\nOK .\nYeah , and again , if you take this filtering perspective and if you essentially have it build up over time . I mean , if you computed means over two and then over four , and over six , essentially what you 're getting at is a kind of , uh , ramp up of a filter anyway . And so you may  may just want to think of it as a filter . But , uh , if you do that , then , um , in practice somebody using the SmartKom system , one would think   if they 're using it for a while , it means that their first utterance , instead of , you know , getting , uh , a forty percent error rate reduction , they 'll get a  uh , over what , uh , you 'd get without this , uh , um , policy , uh , you get thirty percent . And then the second utterance that you give , they get the full  you know , uh , full benefit of it if it 's this ongoing thing .\nOh , so you  you cache the utterances ? That 's how you get your , uh\nWell , I 'm saying in practice , yeah ,\nM\nAh . OK .\nthat 's  If somebody 's using a system to ask for directions or something ,\nOK .\nyou know , they 'll say something first . And  and to begin with if it doesn't get them quite right , ma m maybe they 'll come back and say , \" excuse me ? \"\nMm - hmm .\nuh , or some  I mean it should have some policy like that anyway .\nMm - hmm .\nAnd  and , uh , uh , in any event they might ask a second question . And it 's not like what he 's doing doesn't , uh , improve things . It does improve things , just not as much as he would like . And so , uh , there 's a higher probability of it making an error , uh , in the first utterance .\nWhat would be really cool is if you could have  uh , this probably  users would never like this  but if you had  could have a system where ,  before they began to use it they had to introduce themselves , verbally .\nMm - hmm .\nYou know . \" Hi , my name is so - and - so ,\nYeah .\nI 'm from blah - blah - blah . \" And you could use that initial speech to do all these adaptations and\nRight .\nMm - hmm .\nOh , the other thing I guess which  which , uh , I don't know much about  as much as I should about the rest of the system but  but , um , couldn't you , uh , if you  if you sort of did a first pass I don't know what kind of , uh , uh , capability we have at the moment for  for doing second passes on  on , uh , uh , some kind of little  small lattice , or a graph , or confusion network , or something . But if you did first pass with , um , the  with  either without the mean sub subtraction or with a  a very short time one , and then , um , once you , uh , actually had the whole utterance in , if you did , um , the , uh , uh , longer time version then , based on everything that you had , um , and then at that point only used it to distinguish between , you know , top N , um , possible utterances or something , you  you might  it might not take very much time . I mean , I know in the large vocabulary stu uh , uh , systems , people were evaluating on in the past , some people really pushed everything in to make it in one pass but other people didn't and had multiple passes . And , um , the argument , um , against multiple passes was u u has often been \" but we want to this to be r you know  have a nice interactive response \" . And the counterargument to that which , say , uh , BBN I think had ,  was \" yeah , but our second responses are  second , uh , passes and third passes are really , really fast \" .\nMm - hmm .\nSo , um , if  if your second pass takes a millisecond who cares ? Um .\nS so , um , the  the idea of the second pass would be waiting till you have more recorded speech ? Or  ?\nYeah , so if it turned out to be a problem , that you didn't have enough speech because you need a longer  longer window to do this processing , then , uh , one tactic is  you know , looking at the larger system and not just at the front - end stuff   is to take in , um , the speech with some simpler mechanism or shorter time mechanism ,\nMm - hmm .\num , do the best you can , and come up with some al possible alternates of what might have been said . And , uh , either in the form of an N - best list or in the form of a lattice , or  or confusion network , or whatever .\nMm - hmm .\nAnd then the decoding of that is much , much faster or can be much , much faster if it isn't a big bushy network . And you can decode that now with speech that you 've actually processed using this longer time , uh , subtraction .\nMmm .\nSo I mean , it 's  it 's common that people do this sort of thing where they do more things that are more complex or require looking over more time , whatever , in some kind of second pass .\nMm - hmm . OK .\num , and again , if the second pass is really , really fast  Uh , another one I 've heard of is  is in  in connected digit stuff , um , going back and l and through backtrace and finding regions that are considered to be a d a digit , but , uh , which have very low energy .\nMm - hmm . OK .\nSo , uh  I mean , there 's lots of things you can do in second passes , at all sorts of levels . Anyway , I 'm throwing too many things out . But .\nSo is that , uh  that it ?\nI guess that 's it .", "topic_id": 1, "keywords": "smartkom, spectral, log, seconds, decoding", "dialogue_id": 6}, {"text": "OK , uh , do you wanna go , Sunil ?\nYep . Um , so , the last two weeks was , like  So I 've been working on that Wiener filtering . And , uh , found that , uh , s single  like , I just do a s normal Wiener filtering , like the standard method of Wiener filtering . And that doesn't actually give me any improvement over like  I mean , uh , b it actually improves over the baseline but it 's not like  it doesn't meet something like fifty percent or something . So , I 've been playing with the v\nImproves over the base line MFCC system ? Yeah .\nYeah . Yeah . Yeah . So , um  So that 's  The improvement is somewhere around , like , thirty percent over the baseline .\nIs that using  in combination with something else ?\nNo , just  just one stage Wiener filter\nWith  with a\nwhich is a standard Wiener filter .\nNo , no , but I mean in combination with our on - line normalization or with the LDA ?\nYeah , yeah , yeah , yeah . So I just plug in the Wiener filtering .\nOh , OK .\nI mean , in the s in our system , where\nOh , OK .\nSo , I di i di\nSo , does it g does that mean it gets worse ? Or  ?\nNo . It actually improves over the baseline of not having a Wiener filter in the whole system . Like I have an LDA f LDA plus on - line normalization , and then I plug in the Wiener filter in that ,\nYeah ?\nso it improves over not having the Wiener filter . So it improves but it  it doesn't take it like be beyond like thirty percent over the baseline . So\nBut that 's what I 'm confused about , cuz I think  I thought that our system was more like forty percent without the Wiener filtering .\nNo , it 's like , uh ,\nMmm .\nIs this with the v new VAD ?\nwell , these are not  No , it 's the old VAD . So my baseline was ,  uh ,  nine  This is like  w the baseline is ninety - five point six eight , and eighty - nine , and\nSo I mean , if you can do all these in word errors it 's a lot  a lot easier actually .\nWhat was that ? Sorry ?\nIf you do all these in word error rates it 's a lot easier , right ?\nOh , OK , OK , OK . Errors , right , I don't have .\nOK , cuz then you can figure out the percentages .\nIt 's all accuracies .\nYeah .\nThe baseline is something similar to a w I mean , the t the  the baseline that you are talking about is the MFCC baseline , right ?\nThe t yeah , there are two baselines .\nOr  ?\nOK . So the baseline  One baseline is MFCC baseline that  When I said thirty percent improvement it 's like MFCC baseline .\nMm - hmm .\nSo  so  so what 's it start on ? The MFCC baseline is  is what ? Is at what level ?\nIt 's the  it 's just the mel frequency and that 's it .\nNo , what 's  what 's the number ?\nUh , so I I don't have that number here . OK , OK , OK , I have it here . Uh , it 's the VAD plus the baseline actually . I 'm talking about the  the MFCC plus I do a frame dropping on it . So that 's like  the word error rate is like four point three . Like  Ten point seven .\nFour point three . What 's ten point seven ?\nIt 's a medium misma OK , sorry . There 's a well ma well matched , medium mismatched , and a high matched .\nAh .\nSo I don't have the  like the\nYeah .\nSo\nOK , four point three , ten point seven ,\nAnd forty forty .\nand\nForty percent is the high mismatch .\nOK .\nAnd that becomes like four point three\nNot changed .\nYeah , it 's like ten point one . Still the same . And the high mismatch is like eighteen point five .\nEighteen point five .\nFive .\nAnd what were you just describing ?\nOh , the one is  this one is just the baseline plus the , uh , Wiener filter plugged into it .\nBut where 's the , uh , on - line normalization and so on ?\nOh , OK . So  Sorry . So , with the  with the on - line normalization , the performance was , um , ten  OK , so it 's like four point three . Uh , and again , that 's the ba the ten point , uh , four and twenty point one . That was with on - line normalization and LDA . So the h well matched has like literally not changed by adding on - line or LDA on it . But the  I mean , even the medium mismatch is pretty much the same . And the high mismatch was improved by twenty percent absolute .\nOK , and what kind of number  an and what are we talking about here ?\nIt 's the It - it 's Italian .\nIs this TI - digits\nI 'm talking about Italian ,\nor  Italian ?\nyeah .\nAnd what did  So , what was the , um , uh , corresponding number , say , for , um , uh , the Alcatel system for instance ?\nMmm .\nDo you know ?\nYeah , so it looks to be , um\nYou have it ?\nYep , it 's three point four , uh , eight point , uh , seven , and , uh , thirteen point seven .\nYep .\nOK .\nSo  Thanks .\nOK .\nMm - hmm .\nOK .\nSo , uh , this is the single stage Wiener filter , with  The noise estimation was based on first ten frames .\nMm - hmm .\nActually I started with  using the VAD to estimate the noise and then I found that it works  it doesn't work for Finnish and Spanish because the VAD endpoints are not good to estimate the noise because it cuts into the speech sometimes , so I end up overestimating the noise and getting a worse result . So it works only for Italian by u for  using a VAD to estimate noise .\nMm - hmm .\nIt works for Italian because the VAD was trained on Italian .\nMm - hmm .\nSo , uh  so this was , uh  And so this was giving  um , this  this was like not improving a lot on this baseline of not having the Wiener filter on it . And , so , uh , I ran this stuff with one more stage of Wiener filtering on it but the second time , what I did was I  estimated the new Wiener filter based on the cleaned up speech , and did , uh , smoothing in the frequency to  to reduce the variance\nMm - hmm .\nI mean , I have  I 've  I 've observed there are , like , a lot of bumps in the frequency when I do this Wiener filtering which is more like a musical noise or something . And so by adding another stage of Wiener filtering , the results on the SpeechDat - Car was like , um  So , I still don't have the word error rate . I 'm sorry about it . But the overall improvement was like fifty - six point four six . This was again using ten frames of noise estimate and two stage of Wiener filtering . And the rest is like the LDA plu and the on - line normalization all remaining the same . Uh , so this was , like , compared to , uh , uh  Fifty - seven is what you got by using the French Telecom system , right ?\nNo , I don't think so .\nY i\nIs it on Italian ?\nNo , this is over the whole SpeechDat - Car . So\nOh , yeah , fifty - seven\npoint\nRight .\nYeah , so the new  the new Wiener filtering schema is like  some fifty - six point four six which is like one percent still less than what you got using the French Telecom system .\nUh - huh . Mm - hmm .\nBut it 's a pretty similar number in any event .\nIt 's very similar .\nYeah . But again , you 're  you 're more or less doing what they were doing , right ?\nIt 's  it 's different in a sense like I 'm actually cleaning up the cleaned up spectrum which they 're not doing . They 're d what they 're doing is , they have two stage  stages of estimating the Wiener filter , but  the final filter , what they do is they  they take it to their time domain by doing an inverse Fourier transform .\nYeah .\nAnd they filter the original signal using that fil filter ,\nUh - huh .\nwhich is like final filter is acting on the input noisy speech rather than on the cleaned up . So this is more like I 'm doing Wiener filter twice , but the only thing is that the second time I 'm actually smoothing the filter and then cleaning up the cleaned up spectrum first level . And so that  that 's  that 's what the difference is .\nOK .\nAnd actually I tried it on s the original clean  I mean , the original spectrum where , like , I  the second time I estimate the filter but actually clean up the noisy speech rather the c s first  output of the first stage and that doesn't  seems to be a  giving , I mean , that much improvement . I  I didn didn't run it for the whole case . And  and what I t what I tried was , by using the same thing but  Uh , so we actually found that the VAD is very , like , crucial . I mean , just by changing the VAD itself gives you the  a lot of improvement\nMm - hmm .\nby instead of using the current VAD , if you just take up the VAD output from the channel zero ,  when  instead of using channel zero and channel one , because that was the p that was the reason why I was not getting a lot of improvement for estimating  the noise . So I just used the channel zero VAD to estimate the noise so that it gives me some reliable mar markers for this noise estimation .\nWhat 's a channel zero VAD ?\nUm ,\nI 'm  I 'm confused about that .\nso , it 's like\nSo it 's the close - talking microphone .\nYeah , the close - talking without\nOh , oh , oh , oh .\nSo because the channel zero and channel one are like the same speech , but only w I mean , the same endpoints .\nBut the only thing is that the speech is very noisy for channel one , so you can actually use the output of the channel zero for channel one for the VAD . I mean , that 's like a cheating method .\nRight . I mean , so a are they going to pro What are they doing to do , do we know yet ? about  as far as what they 're  what the rules are going to be and what we can use ?\nYeah , so actually I received a  a new document , describing this .\nYeah , that 's\nAnd what they did finally is to , mmm , uh , not to align the utterances but to perform recognition , um , only on the close - talking microphone ,\nWhich is the channel zero .\nand to take the result of the recognition to get the boundaries uh , of speech .\nSo it 's not like that 's being done in one place or one time .\nAnd\nThat 's  that 's just a rule and we 'd  you  you were permitted to do that . Is  is that it ?\nUh , I think they will send , um , files but we  we don't  Well , apparently\nOh , so they will send files so everybody will have the same boundaries to work with ?\nYeah . Yeah .\nBut actually their alignment actually is not seems to be improving in like on all cases .\nOK .\nOh , i Yeah , so what happened here is that , um , the overall improvement that they have with this method  So  Well , to be more precise , what they have is , they have these alignments and then they drop the beginning silence and  and the end silence but they keep , uh , two hundred milliseconds before speech and two hundred after speech . And they keep the speech pauses also . Um , and the overall improvement over the MFCC baseline So , when they just , uh , add this frame dropping in addition it 's r uh , forty percent , right ?\nMm - hmm .\nFourteen percent , I mean .\nMm - hmm .\nYeah , which is\nUm , which is , um , t which is the overall improvement . But in some cases it doesn't improve at all . Like , uh , y do you remember which case ?\nMm - hmm .\nIt gives like negative  Well , in  in like some Italian and TI - digits ,\nYeah , some @ @ .\nright ?\nRight .\nYeah . So by using the endpointed speech , actually it 's worse than the baseline in some instances , which could be due to the word pattern .\nMmm . Yeah .\nYeah ,\nAnd  Yeah , the other thing also is that fourteen percent is less than what you obtain using a real VAD .\nYeah , our neural net\nSo with without cheating like this .\nYeah , yeah .\nSo  Uh  So I think this shows that there is still work  Uh , well , working on the VAD is still  still important I think .\nYeah , c\nUh\nCan I ask just a  a high level question ? Can you just say like one or two sentences about Wiener filtering and why  why are people doing that ?\nHmm .\nWhat 's  what 's the deal with that ?\nOK , so the Wiener filter , it 's  it 's like  it 's like you try to minimize  I mean , so the basic principle of Wiener filter is like you try to minimize the , uh , d uh , difference between the noisy signal and the clean signal if you have two channels . Like let 's say you have a clean t signal and you have an additional channel where you know what is the noisy signal .\nMm - hmm .\nAnd then you try to minimize the error between these two .\nMm - hmm .\nSo that 's the basic principle . And you get  you can do that  I mean , if  if you have only a c noisy signal , at a level which you , you w try to estimate the noise from the w assuming that the first few frames are noise or if you have a w voice activity detector , uh , you estimate the noise spectrum .\nMm - hmm .\nAnd then you\nDo you assume the noise is the same ?\nYeah . in  yeah , after the speech starts .\nUh - huh .\nSo  but that 's not the case in , uh , many  many of our cases but it works reasonably well .\nI see .\nAnd  and then you What you do is you , uh b fff . So again , I can write down some of these eq Oh , OK . Yeah . And then you do this  uh , this is the transfer function of the Wiener filter , so \" SF \" is a clean speech spectrum , power spectrum\nMm - hmm .\nAnd \" N \" is the noisy power spectrum . And so this is the transfer function .\nRight\nAnd ,\nactually , I guess\nYeah .\nYeah .\nAnd then you multiply your noisy power spectrum with this . You get an estimate of the clean power spectrum .\nI see . OK .\nSo  but the thing is that you have to estimate the SF from the noisy spectrum , what you have . So you estimate the NF from the initial noise portions and then you subtract that from the current noisy spectrum to get an estimate of the SF . So sometimes that becomes zero because you do you don't have a true estimate of the noise . So the f filter will have like sometimes zeros in it\nMm - hmm .\nbecause some frequency values will be zeroed out because of that . And that creates a lot of discontinuities across the spectrum because @ @ the filter . So , uh , so  that 's what  that was just the first stage of Wiener filtering that I tried .\nSo is this , um , basically s uh , similar to just regular spectral subtraction ?\nIt\nIt 's all pretty related ,\nYeah .\nyeah . It 's  it 's  there 's a di there 's a whole class of techniques where you try in some sense to minimize the noise .\nUh - huh .\nAnd it 's typically a mean square sense , uh  uh  uh , i in  in  in some way . And , uh  uh , spectral subtraction is  is , uh  uh , one approach to it .\nDo people use the Wiener filtering in combination with the spectral subtraction typically , or is i are they sort of competing techniques ?\nNot seen . They are very s similar techniques .\nYeah . O oh , OK .\nSo it 's like I haven't seen anybody using s Wiener filter with spectral subtraction .\nMm - hmm .\nI see , I see .\nI mean , in the long run you 're doing the same thing\nMm - hmm .\nYeah .\nbut y but there you make different approximations , and  in spectral subtraction , for instance , there 's a  a  an estimation factor .\nMmm .\nYou sometimes will figure out what the noise is and you 'll multiply that noise spectrum times some constant and subtract that rather than  and sometimes people  even though this really should be in the power domain , sometimes people s work in the magnitude domain because it  it  it works better .\nMm - hmm .\nAnd , uh , uh , you know .\nSo why did you choose , uh , Wiener filtering over some other  one of these other techniques ?\nUh , the reason was , like , we had this choice of using spectral subtraction , Wiener filtering , and there was one more thing which I which I 'm trying , is this sub space approach . So , Stephane is working on spectral subtraction .\nOh , OK .\nSo I picked up\nSo you 're sort of trying @ @ them all .\nY Yeah ,\nAh ,\nwe just wanted to have a few noise production  compensation techniques\nI see . Oh , OK .\nand then pick some from that\nMm - hmm .\npick one .\nI m I mean  yeah , I mean , there 's Car - Carmen 's working on another , on the vector Taylor series .\nVA Yeah , VAD . w Yeah .\nSo they were just kind of trying to cover a bunch of different things with this task and see , you know , what are  what are the issues for each of them .\nAh , OK . That makes sense .\nYeah .\nYeah . Mm - hmm . Mm - hmm .\nUm .\nCool , thanks .\nSo  so one of  one of the things that I tried , like I said , was to remove those zeros in the fri filter by doing some smoothing of the filter .\nYeah .\nMm - hmm .\nLike , you estimate the edge of square and then you do a f smoothing across the frequency so that those zeros get , like , flattened out .\nMm - hmm .\nAnd that doesn't seems to be improving by trying it on the first time . So what I did was like I p did this and then you  I plugged in the  one more  the same thing but with the smoothed filter the second time .\nMm - hmm .\nAnd that seems to be working .\nMm - hmm .\nSo that 's where I got like fifty - six point five percent improvement on SpeechDat - Car with that . And  So the other thing what I tried was I used still the ten frames of noise estimate but I used this channel zero VAD to drop the frames . So I 'm not  still not estimating . And that has taken the performance to like sixty - seven percent in SpeechDat - Car , which is  which  which like sort of shows that by using a proper VAD you can just take it to further , better levels . And  So .\nSo that 's sort of like , you know , best - case performance ?\nYeah , so far I 've seen sixty - seven  I mean , no , I haven't seen s like sixty - seven percent . And , uh , using the channel zero VAD to estimate the noise also seems to be improving but I don't have the results for all the cases with that . So I used channel zero VAD to estimate noise as a lesser 2 x frame , which is like ,  everywhere I use the channel zero VAD . And that seems to be the best combination , uh , rather than using a few frames to estimate and then drop a channel .\nSo I 'm  I 'm still a little confused . Is that channel zero information going to be accessible during this test .\nNnn , no . This is just to test whether we can really improve by using a better VAD .\nMm - hmm .\nSo ,\nMm - hmm .\nI mean  So this is like the noise compensation f is fixed\nMm - hmm .\nbut you make a better decision on the endpoints . That 's , like  seems to be\nMm - hmm .\nso we c so I mean , which  which means , like , by using this technique what we improve just the VAD\nYes .\nwe can just take the performance by another ten percent or better .\nOK .\nSo , that  that was just the , uh , reason for doing that experiment . And , w um  Yeah , but this  all these things , I have to still try it on the TI - digits , which is like I 'm just running . And there seems to be not improving a  a lot on the TI - digits , so I 'm like investigating that , why it 's not . And , um , um  Well after that . So , uh  so the other  the other thing is  like I 've been  I 'm doing all this stuff on the power spectrum . So  Tried this stuff on the mel as well  mel and the magnitude , and mel magnitude , and all those things . But it seems to be the power spectrum seems to be getting the best result . So , one of  one of reasons I thought like doing the averaging , after the filtering using the mel filter bank , that seems to be maybe helping rather than trying it on the mel filter ba filtered outputs .\nMm - hmm . Mm - hmm .\nSo just th\nMa Makes sense .\nYeah , th that 's  that 's the only thing that I could think of why  why it 's giving improvement on the mel . And , yep . So that 's it .\nUh , how about the subspace stuff ?\nSubspace ,  I 'm  I 'm like  that 's still in  a little bit in the back burner because I 've been p putting a lot effort on this to make it work , on tuning things and other stuff .\nOK .\nSo I was like going parallely but not much of improvement . I 'm just  have some skeletons ready , need some more time for it .\nOK .\nMmm .\nTha - that it ?\nYep . Yep .", "topic_id": 2, "keywords": "wiener, improvement, improving, improves, filtering", "dialogue_id": 6}, {"text": "Cool . Do you wanna go , Stephane ?\nUh , yeah . So ,  I 've been , uh , working still on the spectral subtraction . Um , So to r to remind you   a little bit of  of what I did before , is just  to apply some spectral subtraction with an overestimation factor also to get , um , an estimate of the noise , uh , spectrum , and subtract this estimation of the noise spectrum from the , uh , signal spectrum ,  but subtracting more when the SNR is  is , uh , low , which is a technique that it 's often used .\n\" Subtracting more \" , meaning  ?\nSo you overestimate the noise spectrum . You multiply the noise spectrum by a factor , uh , which depends on the SNR .\nOh , OK . I see .\nSo , above twenty DB , it 's one , so you just subtract the noise .\nMm - hmm .\nAnd then it 's b Generally  Well , I use , actually , a linear , uh , function of the SNR ,\nMm - hmm .\nwhich is bounded to , like , two or three ,  when the SNR is below zero DB .\nMm - hmm . Mm - hmm .\nUm , doing just this , uh , either on the FFT bins or on the mel bands , um , t doesn't yield any improvement\nOh ! Um , uh , what are you doing with negative , uh , powers ?\no Yeah . So there is also a threshold , of course , because after subtraction you can have negative energies ,\nMm - hmm .\nand  So what I  I just do is to put , uh  to  to add  to put the threshold first and then to add a small amount of noise , which right now is speech - shaped . Um\nSpeech - shaped ?\nYeah , so it 's  a it has the overall  overall energy , uh  pow it has the overall power spectrum of speech . So with a bump around one kilohertz .\nSo when y when you talk about there being something less than zero after subtracting the noise , is that at a particular frequency bin ?\ni Uh - huh . Yeah .\nOK .\nThere can be frequency bins with negative values .\nAnd so when you say you 're adding something that has the overall shape of speech , is that in a  in a particular frequency bin ? Or you 're adding something across all the frequencies when you get these negatives ?\nFor each frequencies I a I 'm adding some , uh , noise , but the a the amount of  the amount of noise I add is not the same for all the frequency bins .\nAh ! OK . I gotcha . Right .\nUh . Right now I don't think if it makes sense to add something that 's speech - shaped , because then you have silence portion that have some spectra similar to the sp the overall speech spectra .\nMm - hmm .\nBut  Yeah . So this is something I can still work on ,\nSo what does that mean ?\nbut  Hmm .\nI 'm trying to understand what it means when you do the spectral subtraction and you get a negative . It means that at that particular frequency range you subtracted more energy than there was actually\nThat means that  Mm - hmm . Yeah . So  so yeah , you have an  an estimation of the noise spectrum , but sometimes , of course , it 's  as the noise is not perfectly stationary , sometimes this estimation can be , uh , too small , so you don't subtract enough . But sometimes it can be too large also . If  if the noise , uh , energy in this particular frequency band drops for some reason .\nMm - hmm . Mm - hmm .\nMmm .\nSo in  in an ideal word i world  if the noise were always the same , then , when you subtracted it the worst that i you would get would be a zero . I mean , the lowest you would get would be a zero , cuz i if there was no other energy there you 're just subtracting exactly the noise .\nRight .\nMm - hmm ,\nYep , there 's all  there 's all sorts of , uh , deviations from the ideal here .\nyeah .\nI mean , for instance , you 're  you 're talking about the signal and noise , um , at a particular point . And even if something is sort of stationary in ster terms of statistics , there 's no guarantee that any particular instantiation or piece of it is exactly a particular number or bounded by a particular range .\nMm - hmm .\nSo , you 're figuring out from some chunk of  of  of the signal what you think the noise is . Then you 're subtracting that from another chunk ,\nMm - hmm .\nand there 's absolutely no reason to think that you 'd know that it wouldn't , uh , be negative in some places .\nMm - hmm . Hmm .\nUh , on the other hand that just means that in some sense you 've made a mistake because you certainly have stra subtracted a bigger number than is due to the noise .\nMm - hmm .\nUm  Also , we speak  the whole  where all this stuff comes from is from an assumption that signal and noise are uncorrelated . And that certainly makes sense in s in  in a statistical interpretation , that , you know , over , um , all possible realizations that they 're uncorrelated\nMm - hmm .\nor assuming , uh , ergodicity that i that i um , across time , uh , it 's uncorrelated . But if you just look at  a quarter second , uh , and you cross - multiply the two things , uh , you could very well , uh , end up with something that sums to something that 's not zero . So in fact , the two signals could have some relation to one another . And so there 's all sorts of deviations from ideal in this . And  and given all that , you could definitely end up with something that 's negative . But if down the road you 're making use of something as if it is a power spectrum , um , then it can be bad to have something negative . Now , the other thing I wonder about actually is , what if you left it negative ? What happens ?\nIs that the log ?\nI mean , because  Um , are you taking the log before you add them up to the mel ?\nAfter that . No , after .\nRight . So the thing is , I wonder how  if you put your thresholds after that , I wonder how often you would end up with , uh  with negative values .\nBut you will  But you end up reducing some neighboring frequency bins  @ @ in the average , right ? When you add the negative to the positive value which is the true estimate .\nYeah . But nonetheless , uh , you know , these are  it 's another f kind of smoothing , right ? that you 're doing .\nYeah .\nRight . So , you 've done your best shot at figuring out what the noise should be , and now i then you 've subtracted it off . And then after that , instead of  instead of , uh , uh , leaving it as is and adding things  adding up some neighbors , you artificially push it up .\nHmm .\nWhich is , you know , it 's  there 's no particular reason that that 's the right thing to do either , right ?\nYeah , yeah .\nSo , um , uh , i in fact , what you 'd be doing is saying , \" well , we 're d we 're  we 're going to definitely diminish the effect of this frequency in this little frequency bin in the  in the overall mel summation \" . It 's just a thought . I d I don't know if it would be\nSort of the opposite of that would be if  if you find out you 're going to get a negative number , you don't do the subtraction for that bin .\nYeah . Uh - huh . That is true .\nNnn , yeah ,\nMm - hmm .\nalthough\nThat would be almost the opposite , right ? Instead of leaving it negative , you don't do it . If your  if your subtraction 's going to result in a negative number , you  you don't do subtraction in that .\nYeah , but that means that in a situation where you thought that  that the bin was almost entirely noise , you left it .\nYeah . Yeah , I 'm just saying that 's like the opposite .\nWe just\nUh .\nYeah .\nYeah .\nYeah .\nWell , yeah that 's  that 's the opposite ,\nMm - hmm .\nyeah .\nAnd , yeah , some people also  if it 's a negative value they , uh , re - compute it using inter interpolation from the edges and bins .\nFor frames , frequency bins .\nYeah .\nWell , there are different things that you can do .\nOh .\nPeople can also , uh , reflect it back up and essentially do a full wave rectification instead of a  instead of half wave .\nOh .\nBut it was just a thought that  that it might be something to try .\nMm - hmm . Mm - hmm . Yep . Well , actually I tried ,  something else based on this , um , is to  to put some smoothing , um , because it seems to  to help or it seems to help the Wiener filtering\nMm - hmm .\nand , mmm  So what I did is , uh , some kind of nonlinear smoothing . Actually I have a recursion that computes  Yeah , let me go back a little bit . Actually , when you do spectral subtraction you can , uh , find this  this equivalent in the s in the spectral domain . You can uh compute , y you can say that d your spectral subtraction is a filter , um , and the gain of this filter is the , um ,  signal energy minus what you subtract , divided by the signal energy . And this is a gain that varies over time , and , you know , of course , uh , depending on the s on the noise spectrum and on the speech spectrum . And  what happen actually is that during low SNR values , the gain is close to zero but it varies a lot . Mmm , and this  this is the cause of musical noise and all these  the   the fact you  we go below zero one frame and then you can have an energy that 's above zero .\nMm - hmm .\nAnd  Mmm . So the smoothing is  I did a smoothing actually on this gain , uh , trajectory . But it 's  the smoothing is nonlinear in the sense that I tried to not smooth if the gain is high , because in this case we know that , uh , the estimate of the gain is correct because we  we are not close to  to  to zero , um , and to do more smoothing if the gain is low . Mmm . Um . Yeah . So , well , basically that 's this idea , and it seems to give pretty good results , uh , although I 've just  just tested on Italian and Finnish . And on Italian it seems  my result seems to be a little bit better than the Wiener filtering ,\nMm - hmm . Yeah , the one you showed yesterday .\nright ?\nRight ?\nYeah .\nUh , I don't know if you have these improvement the detailed improvements for Italian , Finnish , and Spanish there\nFff . No , I don't have , for each ,\nor you have  just have your own .\nI  I just  just have the final number here .\nMm - hmm .\nSo these numbers he was giving before with the four point three , and the ten point one , and so forth , those were Italian , right ?\nYeah , yeah , yeah . So  so , no ,\nYeah .\nUh\nI actually didn't give you the number which is the final one ,\nuh , no , we 've\nwhich is , after two stages of Wiener filtering . I mean , that was I just  well , like the overall improvement is like fifty - six point five . So ,\nRight .\nMm - hmm .\nI mean , his number is still better than what I got in the two stages of Wiener filtering .\nYeah .\nRight .\nOn Italian . But on Finnish it 's a little bit worse , apparently .\nMm - hmm .\nUm\nBut do you have numbers in terms of word error rates on  on Italian ? So just so you have some sense of reference ?\nYeah . Uh , so , it 's , uh , three point , uh , eight .\nUh - huh .\nAm I right ?\nOh , OK . Yeah , right , OK .\nAnd then , uh , d uh , nine point , uh , one .\nMm - hmm .\nAnd finally , uh , sixteen point five .\nAnd this is , um , spectral subtraction plus what ?\nPlus  plus nonlinear smoothing . Well , it 's  the system  it 's exactly the sys the same system as Sunil tried ,\nOn - line normalization and LDA ?\nbut\nYeah . Yeah .\nYeah . But instead of double stage Wiener filtering , it 's  it 's this smoothed spectral subtraction . Um , yeah .\nWhat is it the , um , France Telecom system uses\nRight .\nfor  Do they use spectral subtraction , or Wiener filtering , or  ?\nThey use spectral subtraction , right .\nFor what ?\nFrench Telecom .\nIt  it 's Wiener filtering ,\nOh , it 's  it 's Wiener filtering .\nam I right ?\nOh .\nSorry .\nWell , it 's some kind of Wiener filtering\nYeah , filtering . Yeah , it 's not exactly Wiener filtering but some variant of Wiener filtering .\nYeah .\nI see .\nYeah .\nYeah , plus , uh , I guess they have some sort of cepstral normalization , as well .\ns They have like  yeah , th the  just noise compensation technique is a variant of Wiener filtering ,\nMm - hmm .\nplus they do some  some smoothing techniques on the final filter . The  th they actually do the filtering in the time domain .\nMmm .\nYeah .\nHmm .\nSo they would take this HF squared back , taking inverse Fourier transform . And they convolve the time domain signal with that .\nOh , I see .\nAnd they do some smoothing on that final filter , impulse response .\nHmm .\nBut they also have two  two different smoothing @ @ .\nI mean , I 'm  I 'm @ @ .\nOne in the time domain and one in the frequency domain by just taking the first , um , coefficients of the impulse response .\nBut .\nSo , basically it 's similar . I mean , what you did , it 's similar\nIt 's similar in the smoothing and\nbecause you have also two  two kind of smoothing .\nYeah .\nOne in the time domain , and one in the frequency domain ,\nYeah . The frequency domain .\nyeah .\nDoes the smoothing in the time domain help\nUm\nWell , do you get this musical noise stuff with Wiener filtering or is that only with , uh , spectral subtraction ?\nNo , you get it with Wiener filtering also .\nYeah .\nDoes the smoothing in the time domain help with that ? Or some other smoothing ?\nOh , no , you still end up with zeros in the s spectrum . Sometimes .\nYeah .\nHmm .\nI mean , it 's not clear that these musical noises hurt us in recognition .\nHmm .\nWe don't know if they do .\nYeah .\nI mean , they  they sound bad .\nMm - hmm .\nYeah , I know .\nBut we 're not listening to it , usually .\nMm - hmm .\nHmm .\nUh , actually the  the smoothing that I did  do here reduced the musical noise . Well , it\nMm - hmm . Yeah , yeah ,\nMmm .\nthe\nWell , I cannot  you cannot hear beca well , actually what I d did not say is that this is not in the FFT bins . This is in the mel frequency bands . Um  So , it could be seen as a f a  a smoothing in the frequency domain because I used , in ad mel bands in addition and then the other phase of smoothing in the time domain . Mmm . But , when you look at the spectrogram , if you don't have an any smoothing , you clearly see , like  in silence portions , and at the beginning and end of speech , you see spots of high energy randomly distributed over the  the spectrogram .\nMm - hmm . Mm - hmm .\nUm\nThat 's the musical noise ?\nWhich is musical noise ,\nMm - hmm .\nyeah , if  if it  If you listen to it  uh , if you do this in the FFT bins , then you have spots of energy randomly distributing . And if you f if you re - synthesize these spot sounds as , like , sounds ,\nMm - hmm .\nuh\nWell , none of these systems , by the way , have  I mean , y you both are  are working with , um , our system that does not have the neural net ,\nAnd\nYep .\nright ?\nYeah .\nMm - hmm .\nOK . So one would hope , presumably , that the neural net part of it would  would improve things further as  as they did before .\nYeah . Yeah . Um  Yeah , although if  if we , um , look at the result from the proposals ,  one of the reason , uh , the n system with the neural net was , um , more than  well , around five percent better , is that it was much better on highly mismatched condition . I 'm thinking , for instance , on the TI - digits trained on clean speech and tested on noisy speech .\nMm - hmm .\nUh , for this case , the system with the neural net was much better .\nMm - hmm .\nBut not much on the  in the other cases .\nYeah .\nAnd if we have no , uh , spectral subtraction or Wiener filtering , um , i the system is  Uh , we thought the neural  neural network is much better than before , even in these cases of high mismatch . So , maybe the neural net will help less but , um\nMaybe .\nCould you train a neural net to do spectral subtraction ?\nYeah , it could do a nonlinear spectral subtraction\nMm - hmm .\nbut I don't know if it  I mean , you have to figure out what your targets are .\nYeah , I was thinking if you had a clean version of the signal and  and a noisy version , and your targets were the M F - uh , you know , whatever , frequency bins\nMm - hmm .\nRight .\nMm - hmm .\nYeah , well , that 's not so much spectral subtraction then ,\nMm - hmm .\nbut  but  but it 's  but at any rate , yeah , people , uh\nPeople do that ?\ny yeah , in fact , we had visitors here who did that I think when you were here ba way back when .\nMm - hmm .\nHmm .\nUh , people  d done lots of experimentation over the years with training neural nets . And it 's not a bad thing to do . It 's another approach .\nHmm .\nM I mean , it 's  it , um\nMm - hmm .\nThe objection everyone always raises , which has some truth to it is that , um , it 's good for mapping from a particular noise to clean but then you get a different noise .\nMm - hmm .\nAnd the experiments we saw that visitors did here showed that it  there was at least some , um ,   gentleness to the degradation when you switched to different noises . It did seem to help . So that  you 're right , that 's another  another way to go .\nHow did it compare on  I mean , for  for good cases where it  it  uh , stuff that it was trained on ? Did it do pretty well ?\nOh , yeah , it did very well .\nMmm .\nYeah .\nMmm .\nUm ,\nMm - hmm .\nbut to some extent that 's kind of what we 're doing . I mean , we 're not doing exactly that , we 're not trying to generate good examples but by trying to do the best classifier you possibly can , for these little phonetic categories ,\nMm - hmm . You could say it 's sort of built in .\nIt 's  Yeah , it 's kind of built into that .\nHmm .\nAnd  and that 's why we have found that it  it does help .\nMm - hmm .\nUm  so , um , yeah , I mean , we 'll just have to try it . But I  I would  I would  I would imagine that it will help some . I mean , it  we 'll just have to see whether it helps more or less the same , but I would imagine it would help some .\nMm - hmm .\nSo in any event , all of this  I was just confirming that all of this was with a simpler system .\nYeah ,\nOK ?\nyeah . Um , Yeah , so this is th the , um  Well , actually , this was kind of the first try with this spectral subtraction plus smoothing ,\nMm - hmm .\nand I was kind of excited by the result .\nMm - hmm .\nUm , then I started to optimize the different parameters . And , uh , the first thing I tried to optimize is the , um , time constant of the smoothing . And it seems that the one that I chose for the first experiment was the optimal one , so  uh ,\nIt 's amazing how often that happens .", "topic_id": 3, "keywords": "subtract, subtraction, subtracting, spectrum, subtracted", "dialogue_id": 6}, {"text": "Um , so this is the first thing . Um  Yeah , another thing that I  it 's important to mention is , um , that this has a this has some additional latency . Um . Because when I do the smoothing , uh , it 's a recursion that estimated the means , so  of the g of the gain curve . And this is a filter that has some latency . And I noticed that it 's better if we take into account this latency . So , instead o of using the current estimated mean to , uh , subtract the current frame , it 's better to use an estimate that 's some somewhere in the future . Um\nAnd that 's what causes the latency ? OK .\nYou mean , the m the mean is computed o based on some frames in the future also ?\nMm - hmm .\nYeah .\nOr  or no ?\nIt 's the recursion , so it 's  it 's the center recursion , right ?\nMm - hmm .\nUm  and the latency of this recursion is around fifty milliseconds .\nOne five ?\nOne five ? Five zero ?\nFive zero ,\nFive zero .\nyeah .\nYeah .\nUm ,\nI 'm sorry ,\nmmm .\nwhy  why is that delay coming ? Like , you estimate the mean ?\nYeah , the mean estimation has some delay , right ?\nOh , yeah .\nI mean , the  the filter that  that estimates the mean has a time constant .\nIt isn't  OK , so it 's like it looks into the future also . OK .\nYeah .\nWhat if you just look into the past ?\nIt 's , uh , not as good . It 's not bad .\nHow m by how much ?\nUm , it helps a lot over the ba the baseline but , mmm\nBy how much ?\nit  It 's around three percent , um , relative .\nWorse .\nYeah . Yeah . Um ,\nHmm .\nmmm  So , uh\nIt 's depending on how all this stuff comes out we may or may not be able to add any latency .\nYeah , but  Yeah . So , yeah , it depends . Uh , y actually , it 's  it 's l it 's three percent . Right . Mmm . Yeah , b but I don't think we have to worry too much on that right now while  you kno . Mm - hmm .\nUm , s Yeah , I mean , I think the only thing is that\nSo\nI would worry about it a little .\nMm - hmm .\nBecause if we completely ignore latency , and then we discover that we really have to do something about it , we 're going to be  find ourselves in a bind .\nMm - hmm .\nSo , um , you know , maybe you could make it twenty - five . You know what I mean ?\nYeah .\nYeah , just , you know , just be  be a little conservative\nOh yes .\nbecause we may end up with this crunch where all of a sudden we have to cut the latency in half or something .\ns Mm - hmm . Yeah .\nOK .\nUm . So , yeah , there are other things in the , um , algorithm that I didn't , uh , @ @ a lot yet ,\nOh !\nwhich\nSorry . A quick question just about the latency thing . If  if there 's another part of the system that causes a latency of a hundred milliseconds , is this an additive thing ? Or c or is yours hidden in that ?\nMm - hmm .\nUh\nNo , it 's  it 's added .\nIt 's additive . OK .\nMm - hmm .\nWe can  OK . We can do something in parallel also , in some like  some cases like , if you wanted to do voice activity detection .\nUh - huh .\nAnd we can do that in parallel with some other filtering you can do .\nMmm .\nSo you can make a decision on that voice activity detection and then you decide whether you want to filter or not .\nYeah .\nBut by then you already have the sufficient samples to do the filtering .\nMm - hmm .\nSo  So , sometimes you can do it anyway .\nI mean , couldn't , uh  I  Couldn't you just also  I mean , i if you know that the l the largest latency in the system is two hundred milliseconds , don't you  couldn't you just buffer up that number of frames and then everything uses that buffer ?\nYeah .\nAnd that way it 's not additive ?\nWell , in fact , everything is sent over in buffers cuz of  isn't it the TCP buffer some  ?\nYou mean , the  the data , the super frame or something ?\nMm - hmm .\nYeah , yeah .\nYeah .\nYeah , but that has a variable latency because the last frame doesn't have any latency\nMm - hmm .\nand first frame has a twenty framed latency . So you can't r rely on that latency all the time .\nYeah .\nBecause  I mean the transmission over  over the air interface is like a buffer .\nYeah .\nTwenty frame\nYeah .\ntwenty four frames .\nYeah .\nSo  But the only thing is that the first frame in that twenty - four frame buffer has a twenty - four frame latency . And the last frame doesn't have any latency .\nMm - hmm .\nBecause it just goes as\nYeah , I wasn't thinking of that one in particular\nYeah .\nbut more of , you know , if  if there is some part of your system that has to buffer twenty frames , uh , can't the other parts of the system draw out of that buffer and therefore not add to the latency ?\nYeah . Yeah . And  and that 's sort of one of the  all of that sort of stuff is things that they 're debating in their standards committee .\nOh ! Hmm .\nMm - hmm . Yeah . So , um , there is uh ,  these parameters that I still have to  to look at . Like , I played a little bit with this overestimation factor , uh , but I still have to  to look more at this , um , at the level of noise I add after . Uh , I know that adding noise helped , um , the system just using spectral subtraction without smoothing , but I don't know right now if it 's still important or not , and if the level I choose before is still the right one . Same thing for the shape of the  the noise . Maybe it would be better to add just white noise instead of speech shaped noise .\nThat 'd be more like the JRASTA thing in a sense . Yeah .\nMm - hmm . Um , yep . Uh , and another thing is to  Yeah , for this I just use as noise estimate the mean , uh , spectrum of the first twenty frames of each utterance . I don't remember for this experiment what did you use for these two stage\nI used ten  just ten frames . Yeah , because\nThe ten frames ?\nI mean , the reason was like in TI - digits I don't have a lot . I had twenty frames most of the time .\nMm - hmm . Um . But , so what 's this result you told me about , the fact that if you use more than ten frames you can  improve by t\nWell , that 's  that 's using the channel zero . If I use a channel zero VAD to estimate the noise .\nOh , OK .\nWhich\nBut this is ten frames plus  plus\nChannel zero dropping .\nchannel\nHmm .\nUh , no , these results with two stage Wiener filtering is ten frames\nt Oh , this\nbut possibly more . I mean , if channel one VAD gives you\nf Yeah . Mm - hmm . Yeah .\nYeah . OK . Yeah , but in this experiment I did  I didn't use any VAD . I just used the twenty first frame to estimate the noise . And  So I expected it to be a little bit better ,  if , uh , I use more  more frames . Um . OK , that 's it for spectral subtraction . The second thing I was working on is to , um , try to look at noise estimation ,  mmm , and using some technique that doesn't need voice activity detection . Um , and for this I u simply used some code that , uh ,  I had from  from Belgium , which is technique that , um , takes a bunch of frame , um , and for each frequency bands of this frame , takes a look at the minima of the energy . And then average these minima and take this as an  an energy estimate of the noise for this particular frequency band . And there is something more to this actually . What is done is that ,  uh , these minima are computed , um , based on , um , high resolution spectra . So , I compute an FFT based on the long , uh , signal frame which is sixty - four millisecond\nSo you have one minimum for each frequency ?\nWhat  what I  what I d uh , I do actually , is to take a bunch of  to take a tile on the spectrogram and this tile is five hundred milliseconds long and two hundred hertz wide .\nMmm .\nAnd this tile  Uh , in this tile appears , like , the harmonics if you have a voiced sound , because it 's  it 's the FTT bins . And when you take the m the minima of  of these  this tile , when you don't have speech , these minima will give you some noise level estimate , If you have voiced speech , these minima will still give you some noise estimate because the minima are between the harmonics . And  If you have other  other kind of speech sounds then it 's not the case , but if the time frame is long enough , uh , like s five hundred milliseconds seems to be long enough ,  you still have portions which , uh , are very close  whi which minima are very close to the noise energy .\nI 'm confused . You said five hundred milliseconds\nMmm ?\nbut you said sixty - four milliseconds . Which is which ? What ?\nSixty - four milliseconds is to compute the FFT , uh , bins .\nYeah ,\nThe  the FFT .\nyeah .\nUm , actually it 's better to use sixty - four milliseconds because , um , if you use thirty milliseconds , then , uh , because of the  this short windowing and at low pitch , uh , sounds ,  the harmonics are not , wha uh , correctly separated .\nMm - hmm .\nSo if you take these minima , it  b  they will overestimate the noise a lot .\nSo you take sixty - four millisecond F F Ts and then you average them  over five hundred ? Or  ? Uh , what do you do over five hundred ?\nSo I take  to  I take a bunch of these sixty - four millisecond frame to cover five hundred milliseconds ,\nAh . OK .\nand then I look for the minima ,\nMmm .\nI see .\non the  on  on the bunch of uh fifty frames , right ?\nI see .\nMmm . So the interest of this is that , as y with this technique you can estimate u some reasonable noise spectra with only five hundred milliseconds of  of signal , so if the  the n the noise varies a lot , uh , you can track  better track the noise ,\nMm - hmm .\nwhich is not the case if you rely on the voice activity detector . So even if there are no no speech pauses , you can track the noise level . The only requirement is that you must have , in these five hundred milliseconds segment ,  you must have voiced sound at least . Cuz this  these will help you to  to track the  the noise level . Um . So what I did is just to simply replace the VAD - based , uh , noise estimate by this estimate , first on SpeechDat - Car  Well , only on SpeechDat - Car actually . And it 's , uh , slightly worse , like one percent relative compared to the VAD - based  estimates . Um , I think the reason why it 's not better , is that the SpeechDat - Car noises are all stationary . Um . So , u y y there really is no need to have something that 's adaptive\nMm - hmm .\nand  Uh , well , they are mainly stationary . Um . But , I expect s maybe some improvement on TI - digits because , nnn , in this case the noises are all sometimes very variable . Uh , so I have to test it . Mmm .\nBut are you comparing with something  e I 'm  I 'm  p s a little confused again , i it  Uh , when you compare it with the V A D - based ,\nMm - hmm .\nVAD - Is this  is this the  ?\nIt 's  It 's the France - Telecom - based spectra , s uh , Wiener filtering and VAD . So it 's their system but just I replace their noise estimate by this one .\nOh , you 're not doing this with our system ?\nIn i I 'm not  No , no . Yeah , it 's our system but with just the Wiener filtering from their system . Right ? Mmm .\nOK .\nYeah . Actually , th the best system that we still have is , uh , our system but with their noise compensation scheme , right ?\nRight . But\nSo I 'm trying to improve on this , and  by  by replacing their noise estimate by , uh , something that might be better .\nOK . But the spectral subtraction scheme that you reported on also re requires a  a noise estimate .\nYeah . Yeah .\nCouldn't you try this for that ?\nBut I di\nDo you think it might help ?\nNot yet , because I did this in parallel ,\nI see ,\nand I was working on one and the other .\nI see . Yeah .\nUm ,\nYeah .\nYeah , for  for sure I will . I can try also , mmm , the spectral subtraction .\nSo I 'm also using that n new noise estimate technique on this Wiener filtering what I 'm trying .\nOK .\nSo I  I have , like , some experiments running , I don't have the results .\nMm - hmm .\nYeah .\nSo .\nYeah .\nI don't estimate the f noise on the ten frames but use his estimate .\nYeah .\nMm - hmm . Um . Yeah . I , um , also implemented a sp um  spectral whitening idea which is in the , um , Ericsson proposal . Uh , the idea is just to  um , flatten the log , uh , spectrum , um , and to flatten it more if the  the probability of silence is higher . So in this way , you can also reduce  somewhat reduce the musical noise and you reduce the variability if you have different noise shapes , because the  the spectrum becomes more flat in the silence portions . Um . Yeah . With this , no improvement , uh , but there are a lot of parameters that we can play with and , um  Actually , this  this could be seen as a soft version of the frame dropping because , um , you could just put the threshold and say that \" below the threshold , I will flatten  comp completely flatten the  the spectrum \" . And above this threshold , uh , keep the same spectrum . So it would be like frame dropping , because during the silence portions which are below the threshold of voice activity probability ,  uh , w you would have some kind of dummy frame which is a perfectly flat spectrum . And this , uh , whitening is something that 's more soft because , um , you whiten  you just , uh , have a function  the whitening is a function of the speech probability , so it 's not a hard decision .\nMm - hmm .\nUm , so I think maybe it can be used together with frame dropping and when we are not sure about if it 's speech or silence , well , maybe it has something do with this .\nIt 's interesting . I mean , um , you know , in  in JRASTA we were essentially adding in , uh , white  uh , white noise dependent on our estimate of the noise .\nMm - hmm .\nOn the overall estimate of the noise . Uh , I think it never occurred to us to use a probability in there .\nMm - hmm .\nYou could imagine one that  that  that made use of where  where the amount that you added in was , uh , a function of the probability of it being s speech or noise .\nMm - hmm . Mm - hmm . Yeah , w Yeah , right now it 's a constant that just depending on the  the noise spectrum .\nThere 's\nYeah .\nMm - hmm . Mm - hmm .\nCuz that  that brings in sort of powers of classifiers that we don't really have in , uh , this other estimate . So it could be  it could be interesting .\nMm - hmm . Mm - hmm .\nWhat  what  what point does the , uh , system stop recording ? How much\nIt 'll keep going till  I guess when they run out of disk space ,\nIt went a little long ? I mean , disk\nbut  I think we 're OK .\nSo .\nOK .\nYeah . Uh  Yeah , so there are  with this technique there are some  I just did something exactly the same as  as the Ericsson proposal but , um ,  the probability of speech is not computed the same way . And I think , i for  yeah , for a lot of things , actually a g a good speech probability is important . Like for frame dropping you improve , like  you can improve from ten percent as Sunil showed , if you use the channel zero speech probabilities .\nMm - hmm . Mm - hmm .\nFor this it might help , um\nMm - hmm .\nS so , yeah . Uh , so yeah , the next thing I started to do is to ,  uh , try to develop a better voice activity detector . And , um  I d um  yeah , for this I think we can maybe try to train the neural network for voice activity detection on all the data that we have , including all the SpeechDat - Car data . Um  And so I 'm starting to obtain alignments on these databases . Um , and the way I mi I do that is that I just use the HTK system but I train it only on the close - talking microphone . And then I aligned  I obtained the Viterbi alignment of the training utterances . Um  It seems to be , uh i Actually what I observed is that for Italian it doesn't seem  Th - there seems to be a problem .\nNo . So , it doesn't seems to help by their use of channel zero or channel one .\nWell . Because  What ?\nUh , you mean their d the frame dropping , right ? Yeah , it doesn't\nYeah . Yeah . So , u but actually the VAD was trained on Italian also ,\nItalian .\nso  Um , the c the current VAD that we have was trained on , uh , t SPINE , right ?\nTI - digits .\nItalian , and TI - digits with noise and\nUh , yeah . And it seems to work on Italian but not on the Finnish and Spanish data . So , maybe one reason is that s s Finnish and Spanish noise are different . And actually we observed  we listened to some of the utterances and sometimes for Finnish there is music in the recordings and strange things , right ?\nYeah .\nUm  Yeah , so the idea was to train all the databases and obtain an alignment to train on these databases , and , um , also to , um , try different kind of features ,  uh , as input to the VAD network . And we came up with a bunch of features that we want to try like , um , the spectral slope , the , um , the degree o degree of voicing with the features that , uh , we started to develop with Carmen , um , e with , uh , the correlation between bands and different kind of features ,\nYeah . Mm - hmm .\nand  Yeah .", "topic_id": 4, "keywords": "smoothing, latency, delay, estimation, mean", "dialogue_id": 6}, {"text": "The energy also .\nThe energy .\nYeah .\nYeah , right .\nYeah . Of course . Yeah .\nOK . Well , Hans - Guenter will be here next week so I think he 'll be interested in all  all of these things . And , so .\nMm - hmm .\nMmm .\nOK , shall we , uh , do digits ?\nYeah .\nWant to go ahead , Morgan ?\nSure .\nOK .", "topic_id": 5, "keywords": "energy, digits, morgan, hans, things", "dialogue_id": 6}, {"text": "OK .\nOK we 're on and we seem to be working .\nYes .\nOK .\nWe didn't crash  we 're not crashing anymore\nOne , two , three , four , f\nand it really bothers me .\nYeah ?\nNo crashing .\nI do . I crashed when I started this morning .\nYou crashed  crashed this morning ? I did not crash this morning .\nYeah ?\nOh ! Well maybe it 's just , you know , how many t u u u u how many times you crash in a day .\nReally ? Yeah . Maybe , yeah .\nFirst time  first time in the day , you know .\nOr maybe it 's once you 've  done enough meetings  it won't crash on you anymore .\nYeah .\nNo ?\nYeah .\nIt 's a matter of experience .\nYeah .\nYeah .\nSelf - learning , yeah .\nThat 's  that 's great .\nYeah .\nUh .\nYeah .\nDo we have an agenda ? Liz  Liz and Andreas can't sh can't  uh , can't come .\nI do .\nSo , they won't be here .\nI have agenda and it 's all me .\nDid\nCuz no one sent me anything else .\nDid they send , uh , the messages to you about the meeting today ?\nI have no idea but I just got it a few minutes ago .\nOh .\nRight when you were in my office it arrived .\nOh . OK , cuz I checked my mail . I didn't have anything .\nSo , does anyone have any a agenda items other than me ? I actually have one more also which is to talk about the digits .\nUh , right , so  so I  I was just gonna talk briefly about the NSF ITR .\nMm - hmm . Yeah .\nOh , great .\nUh , and then , you have\nCan w\nI mean , I won't say much , but   uh , but then , uh , you said  wanna talk about digits ?\nI have a short thing about digits and then uh I wanna talk a little bit about naming conventions , although it 's unclear whether this is the right place to talk about it . So maybe just talk about it very briefly and take the details to the people who  for whom it 's relevant .\nRight .\nYeah .\nI could always say something about transcription . I 've been   but  but  uh , well\nWell if we  Yeah , we shouldn't add things in just to add things in . I 'm actually pretty busy today ,\nYeah .\nso if we can    we\nYeah , yeah , yeah .\na short meeting would be fine .\nThis does sound like we 're doing fine , yeah . That won't do .\nSo the only thing I wanna say about digits is , we are pretty much done with the first test set . There are probably forms here and there that are marked as having been read that weren't really read . So I won't really know until I go through all the transcriber forms and extract out pieces that are in error . So I wa Uh . Two things . The first is what should we do about digits that were misread ? My opinion is , um , we should just throw them out completely , and have them read again by someone else . You know , the grouping is completely random ,\nUh - huh .\nso it  it 's perfectly fine to put a  a group together again of errors and have them re - read , just to finish out the test set .\nOh ! By  throw them out completely ?\nUm , the other thing you could do is change the transcript to match what they really said . So those are  those are the two options .\nYeah .\nMm - hmm .\nBut there 's often things where people do false starts . I know I 've done it , where I say  say a\nWhat the transcribers did with that is if they did a correction , and they eventually did read the right string ,  you extract the right string .\nOh , you 're talking about where they completely read the wrong string and didn't correct it ?\nYeah .\nYeah . And didn't notice . Which happens in a few places .\nYeah .\nAh .\nYeah .\nSo  so\nWell , and s and you 're talking string - wise , you 're not talking about the entire page ?\nCorrect .\nYeah .\nI get it .\nAnd so the  the two options are change the transcript to match what they really said , but then  but then the transcript isn't the Aurora test set anymore . I don't think that really matters because the conditions are so different . And that would be a little easier .\nWell how many are  how  how often does that happen ?\nMmm , five or six times .\nOh , so it 's not very much .\nNo , it 's not much at all .\nSeems like we should just change the transcripts\nYeah .\nOK .\nto match .\nYeah , it 's five or six times out of  thousands ?\nYeah .\nFour thousand .\nFour thousand ?\nFour thous Ah ! Four thousand .\nYeah , it 's\nYeah , I would , uh ,  tak do the easy way ,\nYeah .\nyeah .\nOK .\nYeah .\nIt  it 's kinda nice  I mean , wh who knows what studies people will be doing on  on speaker - dependent things\nMmm .\nand so I think having  having it all\nYeah .\nthe speakers who we had is  is at least interesting .\nSo you  um , how many digits have been transcribed now ?\nFour thousand lines . And each line is between one and about ten digits .\nFour thousand lines ?\nI didn't  I didn't compute the average . I think the average was around four or five .\nSo that 's a couple hours of  of , uh , speech , probably .\nWow .\nYep . Yep .\nWhich is a yeah reasonable  reasonable test set .\nMm - hmm .\nMm - hmm .\nAnd , Jane , I do have a set of forms which I think you have copies of somewhere .\nMm - hmm . Yeah , true .\nOh you do ? Oh OK , good , good .\nMm - hmm . Mm - hmm .\nYeah , I was just wond I thought I had  had all of them back from you . And then the other thing is that , uh , the forms in front of us here that we 're gonna read later , were suggested by Liz\nNo , not yet .\nbecause she wanted to elicit some different prosodics from digits . And so , uh , I just wanted people to , take a quick look at the instructions\nMm - hmm .\nEight eight two two two nine .\nand the way it wa worked and see if it makes sense and if anyone has any comments on it .\nI see . And the decision here , uh , was to continue with uh the words rather than the  the numerics .\nUh , yes , although we could switch it back . The problem was O and zero . Although we could switch it back and tell them always to say \" zero \" or always to say \" O \" .\nOh\nOr neither .\nYeah .\nBut it 's just two thing  ways that you can say it .\nMm - hmm .\nRight ?\nSure .\nOh .\nUm  um ,\nYeah .\nthat 's the only thought I have because if you t start talking about these , you know u tr She 's trying to get at natural groupings , but it  there 's  there 's nothing natural about reading numbers this way .\nRight .\nI mean if you saw a telephone number you would never see it this way .\nThe  the problem also is she did want to stick with digits . I mean I 'm speaking for her since she 's not here .\nYeah .\nBut , um , the other problem we were thinking about is if you just put the numerals ,  they might say forty - three instead of four three .\nYeah .\nMmm .\nYeah .\nYeah .\nYeah .\nWell , if there 's space , though , between them . I mean , you can  With  when you space them out they don't look like , uh , forty - three anymore .\nYeah .\nWell , she and I were talking about it ,\nYeah .\nand she felt that it 's very , very natural to do that sort of chunking .\nShe 's right . It 's  it  it 's a different problem . I mean it 's a  it 's a  it 's an interesting problem  I mean , we 've done stuff with numbers before , and yeah sometimes people  If you say s \" three nine eight one \" sometimes people will say \" thirty - nine eighty - one \" or \" three hundred  three hundred eighty - nine one \" , or  I don't think they 'd say that ,\nYeah .\nbut  but th\nNot very frequently\nno\nbut ,  they certainly could .\nBut  Yeah . Uh , th thirty - eight ninety - one is probably how they 'd do it .\nSo . I mean , this is something that Liz and I spoke about\nBut  I see .\nand , since this was something that Liz asked for specifically , I think we need to defer to her .\nMm - hmm .\nYeah .\nOK . Well , we 're probably gonna be collecting meetings for a while and if we decide we still wanna do some digits later we might be able to do some different ver different versions ,\nDo something different ,\nbut this is the next suggestion ,\nyeah .\nso . OK . OK , so uh e l I guess , let me , uh , get my  my short thing out about the NSF . I sent this  actually this is maybe a little side thing . Um , I  I sent to what I thought we had , uh , in some previous mail , as the right joint thing to send to , which was \" M  MTG RCDR hyphen joint \" .\nIt was . Joint . Yep .\nBut then I got some sort of funny mail saying that the moderator was going to\nIt 's  That 's because they set the one up at UW\nthat 's not on our side , that 's on the U - dub  side .\nOh .\nAnd so U - UW set it up as a moderated list .\nYeah .", "topic_id": 0, "keywords": "crash, crashing, meeting, crashed, meetings", "dialogue_id": 7}, {"text": "Oh , OK .\nAnd , I have no idea whether it actually ever goes to anyone so you might just wanna mail to Mari\nNo  no , th I got  I got , uh , little excited notes from Mari and Jeff and so on ,\nand\nso it 's\nOK , good .\nYeah .\nSo the moderator actually did repost it .\nYeah .\nCuz I had sent one earlier  Actually the same thing happened to me  I had sent one earlier . The message says , \" You 'll be informed \" and then I was never informed but I got replies from people indicating that they had gotten it , so .\nRight .\nIt 's just to prevent spam .\nI see . Yeah so O  OK . Well , anyway , I guess  everybody here  Are y are  you are on that list , right ? So you got the note ?\nMm - hmm .\nYeah ? OK .\nYeah .\nUm , so this was , uh , a , uh , proposal that we put in before on  on more  more higher level , uh , issues in meetings , from  I guess higher level from my point of view . Uh ,  and , uh , meeting mappings , and , uh  so is i for  it was a  proposal for the ITR program , uh , Information Technology Research program 's part of National Science Foundation . It 's the  second year of their doing , uh , these grants . They 're  they 're  a lot of them are  some of them anyway , are larger  larger grants than the usual , small NSF grants , and . So , they 're very competitive , and they have a first phase where you put in pre - proposals , and we  we , uh , got through that . And so th the  the next phase will be  we 'll actually be doing a larger proposal . And I 'm  I  I hope to be doing very little of it . And  uh ,  which was also true for the pre - proposal , so . Uh , there 'll be bunch of people working on it . So .\nWhen 's  when 's the full proposal due ?\nUh , I think April ninth , or something . So it 's about a month .\np s\nUm\nYep . And they said end of business day you could check on the reviewer forms ,\nu\nis that\nTomorrow .\nTomorrow . March second , I said .\nTomorrow ?\nI 've been a day off all week .\nTomorrow .\nYeah .\nI guess that 's a good thing cuz that way I got my papers done early .\nIt would be interesting\nSo that 's amazing you showed up at this meeting !\nIt is . It is actually quite amazing .\nYeah .\nIt 'll be interesting to see the reviewer 's comments .\nYeah . Yeah . My favorite is was when  when  when one reviewer says , uh , \" you know , this should be far more detailed \" , and the nex the next reviewer says , \" you know , there 's way too much detail \" .\nYep . Or \" this is way too general \" , and the other reviewer says , \" this is way too specific \" .\nYeah .\nYeah .\nYeah .\nYeah .\n\" This is way too hard \" , \" way too easy \" .\nWe 'll see . Maybe there 'll be something useful . And  and , uh\nWell it sounded like they  they  the first gate was pretty easy . Is that right ? That they didn't reject a lot of the pre - proposals ?\nDo you know anything about the numbers ?\nNo . Just  just th\nIt 's just from his message it sounded like that .\nYeah . Yeah . I said something , yeah .\nGary Strong 's\nI\nthere was a sentence at the end of one of his paragraphs\nYeah .\nI\nI should go back and look . I didn't  I don't think that 's true .\nYeah , OK .\nMmm . He said the next phase 'll be very , competitive\nVery  very ,\nbecause we didn't want to weed out much in the first phase .\nyeah . Yeah .\nWell we 'll have to see what the numbers are .\nOr something like that ,\nMm - hmm .\nso .\nHmm .\nYeah . But they  they have to weed out enough so that they have enough reviewers .\nRight .\nYeah .\nSo , uh , you know , maybe they didn't r weed out as much as usual , but it 's  it 's usually a pretty  But it  Yeah . It 's  it 's certainly not  I 'm sure that it 's not down to one in two or something of what 's left .\nRight .\nI 'm sure it 's , you know\nHow  how many awards are there , do you know ?\nWell there 's different numbers of w awards for different size  They have three size grants . This one there 's , um  See the small ones are less than five hundred thousand total over three years and that they have a fair number of them . Um , and the large ones are , uh , boy , I forget , I think , more than , uh , more than a million and a half , more than two million or something like that . And  and we 're in the middle  middle category .\nMm - hmm .\nI think we 're , uh , uh , I forget what it was . But , um  Uh , I don't remember , but it 's  pr probably along the li I  I could be wrong on this yeah , but probably along the lines of fifteen or  that they 'll fund , or twenty . I mean when they  Do you  do you know how many they funded when they f in  in Chuck 's , that he got last year ?\nI don't  I don't know .\nYeah .\nI thought it was smaller , that it was like four or five , wasn't it ?\nWell they fund\nI  I 'm\nthey\nI don't remember .\nyeah . I mean\nUh it doesn't matter , we 'll find out one way or another .\nYeah . I mean last time I think they just had two categories , small and big ,\nMm - hmm .\nand this time they came up with a middle one , so it 'll  there 'll be more of them that they fund than  of the big .\nIf we end up getting this , um , what will it mean to ICSI in terms of , w wh where will the money go to , what would we be doing with it ?\nUh .\nExactly what we say in the proposal .\nI  I mean uh which part is ICSI though .\nYou know , it  i None of it will go for those yachts that we 've talking about .\nI mean  Dang !\nUm , well , no , I mean it 's  u It\nIt 's just for the research  to continue the research on the Meeting Recorder stuff ?\nIt 's extending the research , right ? Because the other\nYeah .\nYeah it 's go higher level stuff than we 've been talking about for Meeting Recorder .\nYeah . Yeah the other things that we have , uh , been working on with , uh , the c with Communicator  uh , especially with the newer things  with the more acoustically - oriented things are  are  are  are lower level . And , this is dealing with , uh , mapping on the level of  of , um , the conversation  of mapping the conversations\nMm - hmm . Right , right .\nto different kind of planes . So . Um . But , um . So it 's all it 's all stuff that none none of us are doing right now , or none of us are funded for , so it 's  so it 's  it would be new .\nSo assuming everybody 's completely busy now , it means we 're gonna hafta , hire more students , or , something ?\nWell there 's evenings , and there 's weekends , and  Uh . Yeah , there  there would be  there would be new hires , and  and there  there would be expansion , but , also , there 's always   for everybody there 's  there 's always things that are dropping off , grants that are ending , or other things that are ending , so ,\nRight .\nthere 's  there 's a  continual need to  to bring in new things .\nMm - hmm .\nYep .\nRight .\nBut  but there definitely would be new  new  new , uh , students ,\nI see .\nand so forth , both at  at UW and here .\nAre there any students in your class who are  expressing interest ?\nUm , not  clear yet . Not clear yet .\nOther than the one who 's already here .\nI mean we got   we have  yeah , two of them are  two in the c There 're  two in the class already here , and then  and  and , uh  uh , then there 's a third who 's doing a project here , who , uh  But he  he  he won't be in the country that long ,\nMm - hmm .\nand , maybe another will end up .\nYep .\nActually there is one other guy who 's looking  that  that 's that guy , uh , Jeremy ?  I think .\nMm - hmm .\nAnyway , yeah that 's  that 's all I was gonna say is that  that that 's  you know , that 's nice and we 're sorta preceding to the next step , and ,  it 'll mean some more work , uh , you know , in  in March in getting the proposal out , and then , it 's , uh , you know  We 'll see what happens . Uh , the last one was  that you had there ,  was about naming ?\nYep . It just , uh  we 've been cutting up sound files , in  for ba both digits and for , uh , doing recognition . And Liz had some suggestions on naming and it just brought up the whole issue that hasn't really been resolved about naming . So , uh , one thing she would like to have is for all the names to be the same length so that sorting is easier . Um ,\nYeah .\nsame number of characters so that when you 're sorting filenames you can easily extract out bits and pieces that you want . And that 's easy enough to do . And I don't think we have so many meetings that that 's a big deal just to change the names . So that means , uh , instead of calling it \" MR one \" , \" MR two \" , you 'd call it \" MRM zero zero one \" , \" MRM zero zero two \" , things like that . Just so that they 're  they 're all the same length .\nBut , you know , when you , do things like that you can always  as long as you have  uh , you can always search from the beginning or the end of the string .\nThe problem is that they 're a lot of fields .\nYou know , so \" zero zero two \"\nAlright ,\nYeah .\nso we  we have th we 're gonna have the speaker ID , the session , uh  uh , information on the microphones ,\nYeah , well , your example was really\ninformation on the speak on the channels and all that .\nUh - huh .\ni\nAnd so if each one of those is a fixed length , the sorting becomes a lot easier .\nOK .\nShe wanted to keep them  the same lengths across different meetings also . So like , the NSA meeting lengths ,  all filenames are gonna be the same length as the Meeting Recorder meeting names ?\nYep . And as I said , the it 's  we just don't have that many that that 's a big deal .\nCuz of digits .\nAnd so , uh , um , at some point we have to sort of take a few days off , let the transcribers have a few days off , make sure no one 's touching the data and reorganize the file structures . And when we do that we can also rationalize some of the naming .\nI  I would think though that the transcribe  the transcripts themselves wouldn't need to have such lengthy names .\nRight .\nSo , I mean , you 're dealing with a different domain there , and with start and end times and all that , and channels and stuff ,\nRight . So the only thing that would change with that is just the directory names ,\nso , it 's a different  set .\nI would change them to match . So instead of being MR one it would be MRM zero zero one . But I don't think that 's a big deal .\nFine . Fine .\nSo for  for m the meetings we were thinking about three letters and three numbers for meeting I Ds . Uh , for speakers , M or F and then three numbers , For , uh  and , uh , that also brings up the point that we have to start assembling a speaker database so that we get those links back and forth and keep it consistent . Um , and then , uh , the microphone issues . We want some way of specifying , more than looking in the \" key \" file , what channel and what mike . What channel , what mike , and what broadcaster . Or  I don't know how to s say it . So I mean with this one it 's this particular headset with this particular transmitter w  as a wireless .\nYeah .\nYep .\nAnd you know that one is a different headset and different channel . And so we just need some naming conventions on that .\nYeah .\nAnd , uh ,\nUh - huh .\nthat 's gonna become especially important once we start changing the microphone set - up . We have some new microphones that I 'd like to start trying out , um , once I test them . And then we 'll  we 'll need to specify that somewhere . So I was just gonna do a fixed list of , uh , microphones and types .\nYeah .\nSo , as I said\nOK .\nThat sounds good .\nYeah .\nUm ,   since we have such a short agenda list I guess I wi I will ask how  how are the transcriptions going ? Yeah .\nThe  the news is that I 've  I uh  s So  in s um  So I 've switched to  Start my new sentence . I  I switched to doing the channel - by - channel transcriptions to provide , uh , the  uh , tighter time bins for  partly for use in Thilo 's work and also it 's of relevance to other people in the project . And , um , I discovered in the process a couple of  of interesting things , which , um , one of them is that , um , it seems that there are time lags involved in doing this , uh , uh , using an interface that has so much more complexity to it . And I  and I wanted to maybe ask , uh , Chuck to help me with some of the questions of efficiency . Maybe  I was thinking maybe the best way to do this in the long run may be to give them single channel parts and then piece them together later . And I  I have a script , I can piece them together . I mean , so it 's like , I  I know that I can take them apart and put them together and I 'll end up with the representation which is where the real power of that interface is .\nMm - hmm .\nAnd it may be that it 's faster to transcribe a channel at a time with only one , uh , sound file and one , uh , set of  of , uh , utterances to check through .\nYeah .", "topic_id": 1, "keywords": "proposal, proposals, mail, notes, conversation", "dialogue_id": 7}, {"text": "I 'm a little confused . I thought that  that one of the reason we thought we were so much faster than  than , uh , the  the other transcription , uh , thing was that  that we were using the mixed  file .\nOh , yes . OK . But , um , with the mixed , when you have an overlap , you only have a  a choice of one start and end time for that entire overlap , which means that you 're not tightly , uh , tuning the individual parts th of that overlap by different speakers .\nMm - hmm . Yeah .\nSo someone may have only said two words in that entire big chunk of overlap .\nYeah .\nAnd for purposes of  of , uh , things like  well , so things like training the speech - nonspeech segmentation thing .\nYeah .\nTh - it 's necessary to have it more tightly tuned than that .\nOK .\nAnd w and w and , you know , is a It would be wonderful if , uh , it 's possible then to use that algorithm to more tightly tie in all the channels after that but , um , you know , I 've  th the  So , I I don't know exactly where that 's going at this point . But m I was experimenting with doing this by hand and I really do think that it 's wise that we 've had them start the way we have with , uh , m y working off the mixed signal , um , having the interface that doesn't require them to do the ti uh , the time bins for every single channel at a t uh , through the entire interaction .\nMm - hmm .\nUm , I did discover a couple other things by doing this though , and one of them is that , um , um , once in a while a backchannel will be overlooked by the transcriber .\nMm - hmm .\nAs you might expect ,\nSure .\nbecause when it 's a b backchannel could well happen in a very densely populated overlap . And if we 're gonna study types of overlaps , which is what I wanna do , an analysis of that , then that really does require listening  to every single channel all the way through the entire  length for all the different speakers . Now , for only four speakers , that 's not gonna be too much time , but if it 's nine speakers , then that i that is more time . So it 's li you know , kind of wondering  And I think again it 's like this  it 's really valuable that Thilo 's working on the speech - nonspeech segmentation because maybe , um , we can close in on that wi without having to actually go to the time that it would take to listen to every single channel from start to finish through every single meeting .\nYeah , but those backchannels will always be a problem I think . Uh especially if they 're really short and they 're not very loud and so it  it can  it  it will always happen that also the automatic s detection system will miss some of them , so .\nOK . Well so then  then , maybe the answer is to , uh , listen especially densely in places of overlap ,\nYeah .\njust so that they 're  they 're not being overlooked because of that , and count on accuracy during the sparser phases .\nYeah .\nCuz there are large s spaces of the  That 's a good point . There are large spaces where there 's no overlap at all . Someone 's giving a presentation ,\nYeah .\nor whatever . That 's  that 's a good  that 's a good thought . And , um , let 's see , there was one other thing I was gonna say . I  I think it 's really interesting data to work with , I have to say , it 's very enjoyable . I really , not  not a problem spending time with these data . Really interesting . And not just because I 'm in there . No , it 's real interesting .\nUh , well I think it 's a short meeting . Uh , you 're  you 're  you 're still in the midst of what you 're doing from what you described last time , I assume ,\nIs true .\nand\nI haven't results , eh , yet\nYeah .\nbut , eh , I  I 'm continue working with the mixed signal now ,  after the  the last experience .\nYeah . Yeah .\nAnd  and I 'm tried to  to , uh , adjust the  to  to improve , eh , an harmonicity , eh , detector that , eh , I  I implement .\nYeah .\nBut I have problem because , eh , I get , eh , eh , very much harmonics now .\nYeah .\nUm , harmonic  possi possible harmonics , uh , eh , and now I 'm  I 'm  I 'm trying to  to find , eh , some kind of a , um   of h of help , eh , using the energy to  to distinguish between possible harmonics , and  and other fre frequency peaks , that , eh , corres not harmonics . And , eh , I have to  to talk with y with you , with the group , eh , about the instantaneous frequency , because I have , eh , an algorithm , and , I get , mmm , eh , t t results  similar results , like , eh , the paper , eh , that I  I am following . But , eh , the  the rules , eh , that , eh , people used in the paper to  to distinguish the harmonics , is  doesn't work well .\nMm - hmm .\nAnd I  I  I  I not sure that i  eh , the  the way  o to  ob the way to obtain the  the instantaneous frequency is  right , or it 's  it 's not right . Eh ,\nYeah .\nI haven't enough file feeling to  to  to distinguish what happened .\nYeah , I 'd like to talk with you about it . If  if  if , uh  If I don't have enough time and y you wanna discuss with someone else  some someone else besides us that you might want to talk to , uh , might be Stephane .\nYeah . I talked with Stephane and  and Thilo\nYeah and  and Thilo , yeah .\nand ,\nYeah , but\nthey  nnn they   they    they  didn't\nI 'm not too experienced with  harmonics\nI see .\nthey think that  the experience is not enough to\nand\nIs  is this the algorithm where you hypothesize a fundamental , and then get the energy for all the harmonics of that fundamental ?\nNo , no it 's  No  No . No .\nAnd then hypothesize a new fundamental and get the energy\nYeah , that 's wh\nNo . I  I  I  I don't proth process the  the fundamental . I   I , ehm  I calculate the  the phase derivate using the FFT .\nYeah .\nAnd  The algorithm said that , eh ,  if you  if you change the  the   the , eh , nnn  the X - the frequency \" X \" , eh , using the in the instantaneous frequency , you can find , eh , how , eh , in several frequencies that proba probably the  the harmonics , eh ,\nUh - huh .\nthe errors of peaks  the frequency peaks , eh , eh , move around  these , eh  eh frequency harmonic  the frequency of the harmonic . And ,  eh , if you  if you compare the  the instantaneous frequency ,  eh ,  of the  of the , eh , continuous , eh ,  eh , filters , that , eh  that , eh , they used eh , to   to  to get , eh , the  the instantaneous frequency ,\nMm - hmm .\nit probably too , you can find ,  eh , that the instantaneous frequency  for the continuous , eh ,  eh  the output of the continuous filters are very near . And in  my case  i in  equal with our signal ,  it doesn't happened .\nYeah . I 'd hafta look at that and think about it .\nAnd\nIt 's  it 's  it 's  I haven't worked with that either so I 'm not sure  The way   the simple - minded way I suggested was what Chuck was just saying , is that you could make a  a sieve . You know , y you actually say that here is\nYeah .\nLet 's  let 's hypothesize that it 's this frequency or that frequency , and  and , uh , maybe you  maybe you could use some other cute methods to , uh , short cut it by  by uh , making some guesses ,\nYeah .\nbut  but uh  uh  uh , I would , uh  I mean you could make some guesses from , uh  from the auto - correlation or something but  but then , given those guesses , try , um , uh , only looking at the energy at multiples of the  of that frequency , and  and see how much of the  take the one that 's maximum . Call that the\nYeah .\nBut\nUsing the energy of the  of the multiple of the frequency .\nOf all the harmonics of that . Yeah .\nYeah .\nDo you hafta do some kind of , uh , low - pass filter before you do that ?\nI don't use .\nOr\nBut , I  I know many people use , eh , low - pass filter to  to  to get , eh , the pitch .\nNo . To get the pitch , yes .\nI don't use . To get the pitch , yes .\nTo get the pitch , yeah .\nBut the harmonic , no .\nBut i But the harmonics are gonna be , uh , uh , I don't know what the right word is . Um , they 're gonna be dampened by the uh , vocal tract , right ? The response of the vocal tract .\nYeah ?\nYeah ?\nAnd so  just looking at the energy on those  at the harmonics , is that gonna  ?\nWell so the thing is that the  This is for , uh , a , um\nI m what you 'd like to do is get rid of the effect of the vocal tract . Right ?\nYeah .\nAnd just look at the  at  at the signal coming out of the glottis .\nYeah . Uh , well , yeah that 'd be good .\nYeah .\nBut , uh  but I  but   but I don't know that you need to\nOpen wide !\nbut I don't need you  know if you need to get rid of it . I mean that 'd  that 'd be nice but I don't know if it 's ess if it 's essential . Um , I mean  cuz I think the main thing is that , uh , you 're trying\nUh - huh .\nwha what are you doing this for ? You 're trying distinguish between the case where there is , uh  where  where there are more than  uh , where there 's more than one speaker and the case where there 's only one speaker .\nSorry .\nSo if there 's more than one speaker , um  yeah I guess you could  I guess  yeah you 're  so you 're not distinguished between voiced and unvoiced , so  so , i if you don't  if you don't care about that\nYeah .\nSee , if you also wanna  just determine  if you also wanna determine whether it 's unvoiced ,  then I think you want to  look  look at high frequencies also , because the f the fact that there 's more energy in the high frequencies is gonna be an ob sort of obvious cue that it 's unvoiced .\nYeah .\nBut , i i uh   I mean i i but , um , other than that I guess as far as the one person versus two persons , it would be  primarily a low frequency phenomenon . And if you looked at the low frequencies , yes the higher frequencies are gonna  there 's gonna be a spectral slope . The higher frequencies will be lower energy . But so what . I mean   that 's  that 's w\nI will prepare for the next week eh , all my results about the harmonicity and  will  will try to come in and to discuss here , because , eh , I haven't enough feeling to   to u  many time to   to understand what happened with the  with , eh , so many peaks , eh , eh , and  I  I see the harmonics there many time but , eh ,  there are a lot of peaks , eh , that , eh , they are not harmonics .\nYeah .\nUm , I have to discover what  what is the  the w the best way to  to   to  c to use them\nWell , but  yeah I don't think you can  I mean you 're not gonna be able to look at every frame , so I mean  I  I mean I  I really  I I really thought that the best way to do it , and I 'm speaking with no experience on this particular point , but ,  my impression was that the best way to do it was however you  You 've used instantaneous frequency , whatever .  However you 've come up  you  with your candidates , you wanna see how much of the energy is in that\nYeah . Yeah .\nas coppo as opposed to all of the  all  the total energy . And , um , if it 's voiced , I guess  so  so y I think maybe you do need a voiced - unvoiced determination too . But if it 's voiced ,\nYeah .\num , and the , uh  e the fraction of the energy that 's in the harmonic sequence that you 're looking at is relatively low , then it should be  then it 's more likely to be an overlap .\nIs height . Yeah . This  this is the idea  the idea I  I  I had to  to compare the  the ratio of the   the energy of the harmonics with the  eh , with the , eh , total energy in the spectrum and try to get a ratio to  to distinguish between overlapping and speech . Mmm .\nBut you 're looking a y you 're looking at  Let 's take a second with this . Uh , uh , you 're looking at f at the phase derivative , um , in  in , uh , what domain ? I mean this is  this is in  in  in  in bands ? Or  or\nNo , no , no .\nJust  just overall\nIt 's a  it 's a  o i w the band  the band is , eh , from zero to  to four kilohertz . And I  I ot I\nAnd you just take the instantaneous frequency ?\nYeah . I u m t I  I used two m two method  two methods . Eh , one , eh , based on the F  eh , FTT . to FFT to  to obtain the  or to study the harmonics from  from the spectrum directly ,\nYeah .\nand to study the energy and the multiples of\nYeah .\nfrequency . And another  another algorithm I have is the  in the  instantaneous frequency , based on  on  on the FFT to  to  to calculate the  the phase derivate in the time . Eh , uh n the d I mean I  I have two  two algorithms .\nRight .\nBut , eh , in m  i in my opinion the  the  the instantaneous frequency , the  the  the behavior , eh , was  th it was very interesting . Because I  I saw  eh , how the spectrum  concentrate , eh ,\nOh !\naround the  the harmonic . But then when I apply the  the rule , eh , of the  in the   the instantaneous frequency of the ne of the continuous filter in the  the near filter , the  the rule that , eh , people propose in the paper doesn't work . And I don't know why .\nBut the instantaneous frequency , wouldn't that give you something more like the central frequency of the  you know , of the  where most of the energy is ? I mean , I think if you  Does i does it  Why would it correspond to pitch ?\nYeah . I  I  I not sure . I  I  I try to  to\nYeah .\nWhen  first I    I calculate , eh , using the FFT ,\nDi - digital camera .\nthe  the\nKeep forgetting .\nI get the   the spectrum ,\nYeah .\nand I represent all the frequency .\nYeah .\nAnd  when ou I obtained the instantaneous frequency . And I change  the  the  the @ @ , using the instantaneous frequency , here .\nOh , so you scale  you s you do a  a scaling along that axis according to instantaneous\nI use  Yeah .\nIt 's a kinda normalization .\nYeah . Yeah . Because when  when\nOK .\neh , when i I  I use these  these frequency , eh , the range is different , and the resolution is different .\nYeah .\nAnd I observe more  more or less , thing like this . And the paper said that , eh , these frequencies are probably , eh , harmonics .\nI see . Huh .\nBut , eh , they used , eh , a rule , eh , based in the  in the  because to  to calculate the instantaneous frequency , they use a Hanning window .\nYeah .", "topic_id": 2, "keywords": "transcription, overlap, overlaps, overlapping, speech", "dialogue_id": 7}, {"text": "And , they said that , eh , if  these  peak are , eh , harmonics , the f instantaneous frequency , of the contiguous , eh  w eh eh , filters are very near , or have to be very near . But , eh , phh ! I don't  I  I  I  I don I I  and I don't know what is the  what is the distance . And I tried to  to put different distance , eh , to put difference , eh  eh , length of the window , eh , different front sieve , Pfff ! and I  I not sure what happened .\nOK , yeah well I  I guess I 'm not following it enough . I 'll  probably gonna hafta look at the paper , but  which I 'm not gonna have time to do in the next few days , but   but I 'm  I 'm curious about it .\nYeah .\nUm , uh , OK .\nI I did i it did occur to me that this is  uh , the return to the transcription , that there 's one third thing I wanted to  to ex raise as a to as an issue which is , um , how to handle breaths . So , I wanted to raise the question of whether people in speech recognition want to know where the breaths are . And the reason I ask the question is , um , aside from the fact that they 're obviously very time - consuming to encode , uh , the fact that there was some  I had the indication from Dan Ellis in the email that I sent to you ,\nYeah .\nand you know about , that in principle we might be able to , um , handle breaths by accessi by using cross - talk from the other things , be able that  in principle , maybe we could get rid of them , so maybe  And I was  I  I don't know , I mean we had this an and I didn't  couldn't get back to you ,\nYeah .\nbut the question of whether it 'd be possible to eliminate them from the audio signal , which would be the ideal situation ,\nI don't know  think it 'd be ideal .\ncuz\nUh - uh .\nWe - See , we 're  we 're dealing with real speech and we 're trying to have it be as real as possible\nYeah .\nand breaths are part of real speech .\nWell , except that these are really truly  I mean , ther there 's a segment in o the one I did  n the first one that I did for  i for this ,\nYeah .\nwhere truly w we 're hearing you breathing like  as if we 're  you 're in our ear , you know , and it 's like  it 's like\nYeah .\nI y i I mean , breath is natural , but not\nIt is  but it is if you record it .\nYeah .\nExcept that we 're  we 're trying to mimic  Oh , I see what you 're saying . You 're saying that the PDA application would have  uh , have to cope with breath .\nYeah .\nWell\nNo .\nBut\nAn - any application may have to .\nThe P D A might not have to ,\nNo  i\nbut more people than just PDA users are interested in this corpus .\nYeah .\nSo  so mean you 're right\nOK , then the  then  I have two questions .\nwe could remove it ,\nYeah ?\nbut I  I think  we don't wanna w remove it from the corpus ,  in terms of delivering it because the  people will want it in there .\nYeah . If it gets\nOK , so maybe the question is notating it . Yeah ?\nYeah  i Right . If  if it gets in the way of what somebody is doing with it then you might wanna have some method which will allow you to block it , but you  it 's real data . You don't wanna b but you don't\nOK , well\nIf s you know , if there 's a little bit of noise out there , and somebody is  is talking about something they 're doing , that 's part of what we accept as part of a real meeting , even  And we have the f uh  the uh  the  the fan and the  in the projector up there , and , uh , this is  it 's  this is actual stuff that we  we wanna work with .\nWell this is in very interesting\nSo .\nbecause i it basically has a i it shows very clearly the contrast between , uh , speech recognition research and discourse research because in  in discourse and linguistic research , what counts is what 's communit communicative .\nMm - hmm .\nAnd  breath , you know , everyone breathes , they breathe all the time . And once in a while breath is communicative , but r very rarely . OK , so now , I had a discussion with Chuck about the data structure\nMm - hmm .\nand the idea is that the transcripts will  that  get stored as a master there 'll be a master transcript which has in it everything that 's needed for both of these uses .\nMm - hmm .\nAnd the one that 's used for speech recognition will be processed via scripts . You know , like , Don 's been writing scripts\nMm - hmm .\nand  and , uh , to process it for the speech recognition side . Discourse side will  have this  this side over he the  we we 'll have a s ch Sorry , not being very fluent here . But , um , this  the discourse side will have a script which will stri strip away the things which are non - communicative . OK . So then the  then  let 's  let 's think about the practicalities of how we get to that master copy with reference to breaths . So what I would  r r what I would wonder is would it be possible to encode those automatically ? Could we get a breath detector ?\nOh , just to save the transcribers time .\nWell , I mean , you just have no idea . I mean , if you 're getting a breath several times every minute ,\nMm - hmm .\nand just simply the keystrokes it takes to negotiate , to put the boundaries in , to  to type it in , i it 's just a huge amount of time .\nMm - hmm .\nOops .\nWh - what\nYeah .\nAnd you wanna be sure it 's used , and you wanna be sure it 's done as efficiently as possible , and if it can be done automatically , that would be ideal .\nwhat if you put it in but didn't put the boundaries ?\nWell , but\nSo you just know it 's between these other things ,\nWell , OK . So now there 's  there 's another  another possibility\nright ?\nwhich is , um , the time boundaries could mark off words  from nonwords . And that would be extremely time - effective , if that 's sufficient .\nYeah I mean I 'm think if it 's too  if it 's too hard for us to annotate the breaths per se ,  we are gonna be building up models for these things and these things are somewhat self - aligning , so if  so ,  we  i i if we say there is some kind of a thing which we call a \" breath \" or a \" breath - in \" or \" breath - out \" ,  the models will learn that sort of thing . Uh , so  but you  but you do want them to point them at some region where  where the breaths really are . So\nOK . But that would maybe include a pause as well ,\nWell , there 's a there 's\nand that wouldn't be a problem to have it , uh , pause plus breath plus laugh plus sneeze ?\nYeah , i You know there is  there 's this dynamic tension between  between marking absolutely everything , as you know , and  and  and marking just a little bit and counting on the statistical methods . Basically the more we can mark the better . But if there seems to be a lot of effort for a small amount of reward in some area , and this might be one like this  Although I  I  I 'd be interested to h get  get input from Liz and Andreas on this to see if they  Cuz they 've - they 've got lots of experience with the breaths in  in , uh , uh , their transcripts .\nThey have lots of experience with breathing ?\nI\nActually  Well ,  yes they do , but we   we can handle that without them here . But  but  but , uh , you were gonna say something about\nYeah , I  I think , um , one possible way that we could handle it is that , um , you know , as the transcribers are going through , and if they get a hunk of speech that they 're gonna transcribe , u th they 're gonna transcribe it because there 's words in there or whatnot . If there 's a breath in there , they could transcribe that .\nYeah . Yeah .\nThat 's what they 've been doing . So , within an overlap segment , they  they do this .\nRight . But  Right . But if there 's a big hunk of speech , let 's say on Morgan 's mike where he 's not talking at all , um , don't  don't worry about that .\nYeah .\nSo what we 're saying is , there 's no guarantee that , um  So for the chunks that are transcribed , everything 's transcribed . But outside of those boundaries , there could have been stuff that wasn't transcribed . So you just  somebody can't rely on that data and say \" that 's perfectly clean data \" . Uh  do you see what I 'm saying ?\nYeah , you 're saying it 's  uncharted territory .\nSo I would say don't tell them to transcribe anything that 's outside of a grouping of words .\nThat sounds like a reasonable  reasonable compromise .\nYeah , and that 's  that  that quite co corresponds to the way I  I try to train the speech - nonspeech detector , as I really try to  not to detect those breaths which are not within a speech chunk but with  which are just in  in a silence region .\nYeah .\nAnd they  so they hopefully won't be marked in  in those channel - specific files .\nu I  I wanted to comment a little more just for clarification about this business about the different purposes .\nBut\nYeah , so\nMm - hmm .\nSee , in a  in a way this is a really key point , that for speech recognition , uh , research , uh , um , e a  it 's not just a minor part . In fact , the  I think I would say the core thing that we 're trying to do is to recognize the actual , meaningful components in the midst of other things that are not meaningful . So it 's critical  it 's not just incidental it 's critical for us to get these other components that are not meaningful . Because that 's what we 're trying to pull the other out of . That 's our problem . If we had nothing\nYeah .\nif we had only linguistically - relevant things  if  if we only had changes in the spectrum that were associated with words , with different spectral components , and , uh , we  we didn't have noise , we didn't have convolutional errors , we didn't have extraneous , uh , behaviors , and so forth , and  moving your head and all these sorts of things , then , actually speech recognition i i isn't that bad right now . I mean you can you know it 's   it 's  the technology 's come along pretty well .\nYeah .\nThe  the  the reason we still complain about it is because is  when  when you have more realistic conditions then  then things fall apart .\nOK , fair enough . I guess , um , I  uh , what I was wondering is what  what  at what level does the breathing aspect enter into the problem ? Because if it were likely that a PDA would be able to be built which would get rid of the breathing , so it wouldn't even have to be processed at thi at this computational le well , let me see , it 'd have to be computationally processed to get rid of it , but if there were , uh , like likely on the frontier , a good breath extractor then , um , and then you 'd have to\nBut that 's a research question , you know ? And so\nYeah , well , see and that 's what I wouldn't know .\nthat  And we don't either . I mean so  so the thing is it 's  it  right now it 's just raw d it 's just data that we 're collecting , and so  we don't wanna presuppose that people will be able to get rid of particular degradations because that 's actually the research that we 're trying to feed . So , you know , an and maybe  maybe in five years it 'll work really well ,\nOK .\nand  and it 'll only mess - up ten percent of the time , but then we would still want to account for that ten percent , so .\nI guess there 's another aspect which is that as we 've improved our microphone technique , we have a lot less breath in the  in the more recent , uh , recordings , so it 's  in a way it 's an artifact that there 's so much on the  on the earlier ones .\nUh - huh . I see .\nOne of the  um , just to add to this  one of the ways that we will be able to get rid of breath is by having models for them . I mean , that 's what a lot of people do nowadays .\nRight .\nRight .\nYeah .\nAnd so in order to build the model you need to have some amount of it marked , so that you know where the boundaries are .\nHmm .\nYeah .\nSo  I mean , I don't think we need to worry a lot about breaths that are happening outside of a , you know , conversation . We don't have to go and search for them to  to mark them at all , but , I mean , if they 're there while they 're transcribing some hunk of words , I 'd say put them in if possible .\nOK , and it 's also the fact that they differ a lot from one channel to the other because of the way the microphone 's adjusted .\nYeah .\nMm - hmm .\nOK .\nShould we do the digits ?\nYep . OK .\nOK .\nMmm . Alright .", "topic_id": 3, "keywords": "harmonics, frequency, filters, hearing, peak", "dialogue_id": 7}, {"text": "Alright .\nSo are you\nSo .\nAre we going ?\nIt is uh , must be February fifteenth .\nYeah .\nYu I think the date 's written in there , yep . And actually if everyone could cross out the R - nine next to \" Session \" , and write MR eleven .\nYeah . Yeah . We didn't have a front - end meeting today .\nAnd let 's remember also to make sure that one 's  gets marked as unread , unused .\nOK .\nMR eleven .\nMR eleven .\nThat sounds like a spy code .\nMmm . OK . So .\nThere 's lots of clicking I 'm sure as I 'm trying to get this to work  correctly .\nAgenda . Any agenda items today ?\nI wanna talk a little bit about getting  how we 're gonna to get people to edit bleeps , parts of the meeting that they don't want to include . What I 've done so far , and I wanna get some opinions on , how to  how to finish it up .\nOK .\nI wanna ask about um , some aud audio monitoring on some of the  um  well some of the equipment . In particular , the  well uh , that 's just what I wanna ask .\nOK audio monitoring , Jane .\nBa - based on some of the tran uh  i In listening to  some of these meetings that have already been recorded there are sometimes big spikes on particular things , and in pact  in fact this one I 'm talking on is one of  of the ones that showed up in one of the meetings ,\nOh really .\nso I\n\" Spikes \" , you mean like uh , instantaneous click type spikes , or  ?\nMm - hmm . Yeah .\nSpikes ?\nClicks .\nYeah .\nHmm .\nYeah .\nHuh .\nAnd I don't know what the e electronics is but .\nYeah .\nYeah .\nWell , I think it 's\nTouching .\nuh , it  it could be a number of things .\nYeah .\nIt could be touching and fiddling , and the other thing is that it could  the fact that it 's on a wired mike is suspicious . It might be a connector .\nOh , OK . Well maybe  Then we don't really have to talk about that as an\nYou could try an experiment and say \" OK , I 'm about to test for spikes \" ,\nI  I take that off the agenda .\nand then wiggle the thing there , and then go and when they go to transcribe it , it could , ask them to come and get you .\nYeah . Right .\n\" Come get me when you transcribe this and see if there 's spikes . \"\nOh that\nUm .\nWell , OK .\nNo I 'm just\nI mean , were this a professional audio recording ,  what we would do   what you would do is  in testing it is , you would actually do all this wiggling and make sure that  that  that things are not giving that kind of performance . And if they are , then they can't be used .\nRight .\nSo . Um . Let 's see . I guess  I would like to have a discussion about you know where we are on uh , recording , transcription you know , basically you know where we are on the corpus .\nGood .\nAnd then um , the other thing which I would like to talk about which is a real meta - quest , I think , deal is , uh , agendas . So maybe I 'll  I 'll start with that actually . Uh , um .  Andreas brought up the fact that he would kinda like to know , if possible , what we were gonna be talking about because he 's sort of peripherally involved to this point , and if there 's gonna be a topic about  discussion about something that he uh strongly cares about then he would come and  And I think part of  part of his motivation with this is that he 's trying to help us out , in the  because of uh the fact that the meetings are  are tending to become reasonably large now on days when everybody shows up and so , he figures he could help that out by not showing\nMmm .\nand  and I 'm sure help out his own time . by not showing up if it 's a meeting that he 's  he 's  So , uh in order  I 'd  I think that this is a wish on his part . Uh . It 's actually gonna be hard because it seems like a lot of times uh things come up that are unanticipated and  and\nRight .\nBut um , we could try anyway , uh , do another try at coming up with the agenda uh , at some point before the meeting , uh , say the day before .\nWell maybe it would be a good idea for one of us to  like on Wednesday , or Tuesday send out a reminder for people to send in agenda items .\nYeah .\nOK . You  you wanna volunteer to do that ?\nSure .\nOK . Alright so we 'll send out agenda request .\nLet me\nUh .\nThat 'll be  I think that 'll help\nI 'll put that on my spare brain or it will not  get done .\nThat 'll help a lot , actually .\nYeah , I have to tell you for the uh  for the admin meeting that we have , Lila does that um every time before an admin meeting . And uh , she ends up getting the agenda requests uh , uh ten minutes before the meeting . But  but   But . Uh .  But we can try . Maybe it 'll work .\nMmm .\nYeah . Maybe . Weirder things have happened .\nYeah .\nI 'm wondering if he were to just , uh , specify particular topics , I mean . Maybe we 'd be able to meet that request of his a little more .\nI would  I would also guess that as we get more into processing the data and things like that there 'll be more things of interest to him .\nWell then\nYeah . Actually it  This  this maybe brings up another topic which is um  So we 're done with that topic . The other topic I was thinking of was the sta status on microphones and channels , and all that .\nYeah , actually I  I was going to say we need to  talk about that too .\nYeah . Why  why don't we do that .\nOK . Um , the new microphones , the two new ones are in . Um .  And they are being assembled as we speak , I hope . And I didn't bring my car today so I 'm gonna pick them up tomorrow . Um , and then the other question I was thinking about is  well , a couple things . First of all , if the other headsets are a lot more comfortable , we should probably just go ahead and get them . So we 'll have to evaluate that when they come in ,\nand get people 's opinions on  on what they think of them . Um , then the other question I had is maybe we should get another wireless . Another wireless setup . I mean it 's expensive , but it does seem to be  better than the wired .\nSo how many channels do you get to have in a wireless setup ?\nUm , well , I 'm pretty sure that you can daisy - chain them together so what we would do is replace the wired mikes with wireless . So we currently have one base station with six wireless mike , possibility of six wireless receivers , and apparently you can chain those together . And so we could replace our wired mikes with wireless if we bought another base station and more wireless mikes .\nSo , um .\nAnd  So , you know it 's still , it 's fifteen minus six .\nSo let 's see we\nRight ? So we could have up to nine .\nAnd right now we can have up to six .\nRight . And we have five , we 're getting one more .\nYeah .\nAnd it 's um , about nine hundred dollars for the base station , and then eight hundred per channel .\nOh . So yeah so the only  Beyond the mike  the cost of the mikes the only thing is the base station that 's nine hundred dollars .\nRight .\nOh , we should do it .\nOK . OK , so I 'll look into how you daisy - chain them and  and then just go ahead and order them .\nYeah . Yeah .\nI don't quite understand how that  how that works , . If  So we 're not increasing the number of channels . OK .\nNo , we 're just replacing the wired  the two wired that are still working ,\nOK . I see .\nalong with a couple of the wired that aren't working , one of the wired that 's not working , with a wireless .\nYeah .\nThree wireds work ,\nBasically we found\nright ?\nI  I guess three wireds work , yeah .\nYeah . Yeah .\nYeah . But we 've had more problems with that .\nYep .\nAnd that sort of bypasses the whole  the whole Jimbox thing and all that .\nRight .\nAnd so um , we  we seem to have uh , a reliable way of getting the data in , which is through the ra Sony radio mikes , as long as we 're conscious about the batteries .\nRight .\nThat seems to be the key issue .\nEveryone 's battery OK ?\nI checked them this morning , they should be .\nOK .\nYeah . Um ,  That 's the only thing with them . But the quality seems really good and  Um I heard from UW that they 're  they 're uh very close to getting their , uh setup purchased . They 're  they 're  they 're buying something that you can just sort of buy off the shelf .\nWell we should talk to them about it because I know that SRI is also in the process of looking at stuff , and so , you know , what we should try to keep everyone  on the same page with that .\nYeah .\nSRI , really ?\nYeah .\nOh .\nThey got sa apparent Well , Maybe  this needs to be bleeped out ? I have no clue .\nUh , I don't know .\nI don't know how much of it 's public .\nProbably we shouldn't  probably we shouldn't talk about funding stuff .\nRight .\nYeah . But anyway there 's  there 's  there 's uh , uh other activities that are going on there and  and uh  and NIST and UW . So . Um . But  but yeah I thin I think that at least the message we can tell other people is that our experience is  is quite positive with the Sony ,\nRight .\nuh , radio - mikes . Now the one thing that you have said that actually concerns me a little is you 're talking about changing the headsets meaning changing the connector , which means some hand - soldering or something , right ?\nUh , no , we 're having the  them do it .\nNo ?\nSo it 's so hand - soldering it , but I 'm not doing it .\nOh .\nSo , they  they charge\nOK . Nothing against you and your hand - soldering\nright .\nbut\nYou 've never seen my hand - soldering . But uh , a as I said they 're coming in .\nUh , OK , so that 's being done professionally and\nI  I mean\nYeah .\nYeah . I mean .\nYeah .\nAs professionally as I guess you can get it done .\nWell , it could  if they do a lot of it , it 's\nI mean i it 's just their repair shop . Right ? Their maintenance people .\nWell , we 'll see what it  it 's like .\nYep .\nThat  tha that can be quite good . Th - this  Yeah , OK . Good . Yeah . So let 's go with that .\nAnd , I mean we 'll see , tomorrow , you know , what it looks like .\nUh , Yeah . So , um , uh , Dave isn't here but he was going to start working on some things with the digits . Uh , so he 'll be interested in what 's going on with that . I guess  Was  the decision last time was that the  the uh transcribers were going to be doing stuff with the digits as well ? Has that started , or is that  ?\nMm - hmm . Yeah . Uh , it would be to use his interface and I was going to meet with him today about that .\nRight , so , the decision was that Jane did not want the transcribers to be doing any of the paperwork . So I did the  all that last week . So all the  all the forms are now  on the computer . And uh , then I have a bunch of scripts that we 'll read those and let the uh  transcribers use different tools . And I just want to talk to Jane about how we transition to using those .\nMm - hmm . So he has a nice set up that they  it w it will be efficient for them to do that .\nOK .\nI  I don't think it 'll take too long .\nSo anyway\nSo , you know , just uh , a matter of a few days I suspect .\nSo anyway I think we  we have at least one uh , user for the digits once they get done , which will be Dave .\nRight . I 've already done five or six  sets .\nOK .\nSo if he wanted to , you know , just have a few to start with , he could . You know , and I also have a bunch of scripts that will , like , generate P - files and run recognition on them also .\nYeah , he might  he might be asking  Right . OK . Uh , is Dave  I don't know if Dave is on the list , if he 's invited to these meetings , uh if he knows .\nI don't tend to get an invitation myself for them even .\nNo , no .\nUh , we don't have a active one but I 'll make sure he 's on the list .\nYeah . Should we call him ? I mean is he  d is he definitely not available today ?\nI don't know .\nShould I call his office and see ?\nHe was in .\nI mean , he 's still taking classes , so uh , he may well have conflicts .\nUh , well i it 's uh\nYeah .\nYeah .\nYeah , he was in  s\nHe wasn't there at cof\nYeah , so this might be a conflict for him .\nYeah .\nYeah .\nOK .\nOK . Uh , so .\nYeah didn't he say his signal - processing class was like  Tuesdays and Thursdays ?\nI think he has a class . Yeah .\nYeah . He might have .\nOh well , whatever .\nYou talking about David Gelbart ?\nOh , OK .\nYeah .\nYeah .\nYeah .\nYeah .\nYes .\nYeah , I think he 's taking two twenty - five A which is now .\nYeah .", "topic_id": 0, "keywords": "agenda, meeting, meetings, agendas, monitoring", "dialogue_id": 8}, {"text": "So .\nYeah .\nOK .\nOK . So , that 's why we 're not seeing him . OK . Uh , transcriptions , uh , beyond the digits , where we are , and so on .\nOK .\nAnd the  and the recordings also ,\nUm\njust where we are . Yeah .\nWell , so um , should we  we don't wan wanna do the recording status first , or  ?\nWell , we have about thirty - two hours uh as of , I guess a week and a half ago , so we probably now have about thirty - five hours .\nAnd  and that 's  that 's uh  How much of that is digits ? It 's uh  that 's including digits ,\nThat 's including digits .\nright ?\nI haven't separated it out so I have no clue how much of that is digits .\nSo  Yeah . So anyway there 's at least probably thirty hours , or something of  There 's got to be more than thirty hour\nMmm .\nOf  of non - digits ?\ni it couldn't  of  Of non - digits .\nYeah , absolutely . I mean , the digits don't take up that much time .\nYeah , yeah . OK .\nOK , and the transcribers h I , uh , don't have the exact numbers , but I  think it would come to about eleven hours that are finished uh , transcribing from them right now . The next step is to  that I 'm working on is to insure that the data are clean first , and then channelized . What I mean by clean is that they 're spell - checked , that the mark - up is consistent all the way throughout , and also that we now incorporate these additional conventions that uh , Liz requested in terms of um , um  in terms of having a s a systematic handling of numbers , and acronyms which I hadn't been specific about . Um , for example , i they 'll say uh \" ninety - two \" . And you know , so how  you could\nNine two ,\ne Exactly .\nright .\nSo if you just say \" nine two \" , the  there are many s ways that could have been expressed . An - and I just had them  I  I mean , a certain number of them did put the words down , but now we have a convention which also involves having it followed by , um , a gloss th and things .\nYou know , Jane ?\nMm - hmm .\nUm , one suggestion and you may already be doing this , but I 've noticed in the past that when I 've gone through transcriptions and you know in  in order to build lexicons and things , if you um , just take all the transcriptions and separate them into words and then alphabetize them ,  a lot of times just scanning down that list you 'll find a lot of  inconsistencies and mis\nMisspelled .\nYeah .\nYou 're talking about the type token frequency listings , and I use those too . Y you mean just uh  on each  on each line there 's a one word right ? It 's one token from the  from the corpus .\nMm - hmm . Mm - hmm .\nYeah , those are e extremely efficient and I and I  I agree that 's a very good use of it .\nOh so you already have that , OK .\nWell that 's  that 's a way  that 's  You know , the spell - check basically does that but  but in addition  yes , that 's  that 's exactly the strategy I wanna do in terms of locating these things which are you know colloquial spoken forms which aren't in the lexicon .\nMm - hmm . Cuz a lot of times they 'll appear next to each other , and uh ,\nExactly . And then you ca then you can do a s\nYeah .\ni in alphabetized lists , they 'll appear next to each other and  and so it makes it easier .\nAbsolutely . I agree . That 's a very good  that 's a very good uh , suggestion . And that was  that 's my strategy for handling a lot of these things , in terms of things that need to be glossed . I didn't get to that point but  So there are numbers , then there are acronyms , and then um , there 's a  he she wants the uh , actually a  an explicit marker of what type of comment this is , so i curly b inside the curly brackets I 'm gonna put either \" VOC \" for vocalized , like cough or like laugh or whatever , \" NONVOC \" for door - slam , and \" GLOSS \" for things that have to do with  if they said a s a spoken form with this  m this pronunciation error .\nRight .\nI already had that convention\nOh that 's great .\nbut I  I haven't been asking these people to do it systematically cuz I think it most  ha most efficiently handled by uh  by a  a filter . That was what I was always planing on . So that , you know you get a whole long list  exactly what you 're saying , you get a whole list of things that say \" curly bracket laugh curly bracket \" ,\nMm - hmm .\nthen y you know it 's  it 's  You  you risk less error if you handle it by a filter , than if you have this transcriber ch laboriously typing in sort of a VOC space ,\nYeah .\nso man So many ways that error prone .\nRight . Right .\nSo , um ,  um I 'm  I 'm going to convert that via a filter , into these tagged uh , subcategorized comments , and same thing with you know , we see you get a subset when you do what you 're saying ,\nMm - hmm .\nyou end up with a s with uh , you 're collapsing across a frequency you just have the tokens\nMm - hmm .\nand you can um , have a filter which more efficiently makes those changes . But the numbers and acronyms have to be handled by hand , because , you know I mean , jus\nYou don't know what they could be .\nYeah .\nYeah now TIMIT 's clear um  and PLP is clear but uh there are things that are not so well known , in  or  or have variant  u u uses like the numbers you can say \" nine two \" or you can say \" ninety - two \" ,\nSo how are you doing the\nand uh I 'd handle the numbers individually .\nHow are you doing the uh , acronyms so if I say PZM what would it appear on the transcript ?\nIt would be separate  The letters would be separated in space\nOK .\nand potentially they 'll have a curly bracket thing afterwards e but I 'm not sure if that 's necessary , clarifying what it is ,\nMm - hmm .\nso gloss of  whatever .\nRight .\nI don't know if that 's really necessary to do that . Maybe it 's a nice thing to do because of it then indicating this is uh , a step away from i indicating that it really is intentional that those spaces are there , and indicating why they 're there to indicate that it 's uh  the you know ,  uh enumerated , or i\nMm - hmm .\nit 's not a good way of saying  but it 's  it 's the  specific uh way of stating these  these letters .\nRight . So it sounds good .\nAnd so anyway , the clean  those are those things and then channelized is to then um , get it into this multichannel format . And at that point then it 's ready for use by Liz and Don . But that 's been my top priority  beyond getting it tanel channelized , the next step is to work on tightening up the boundaries of the time bins .\nYeah .\nRight .\nAnd uh , Thilo had a  e e a breakthrough with this  this last week in terms of getting the channel - based um uh s s speech - nonspeech segmentation um , up and running and I haven't  I haven't been able to use that yet cuz I 'm working s re this is my top priority  get the data clean , and channelized .\nI actually gave\nHave you also been doing spot checks , Jane ?\nOh yes .\nOkay , good .\nWell you see that 's part of the cleaning process . I spent um actually um I have a segment of ten minutes that was transcribed by two of our transcribers ,\nOh good . Good .\nand I went through it last night , it 's  it 's almost spooky how similar these are , word for word . And there are some differences in commas cuz commas I  I left them discretion at commas .\nRight .\nUh  and so because it 's not part of our st of our ne needed conventions .\nMm - hmm .\nAnd um , and  so they 'll be a difference in commas , but it 's word - by - word the same , in  in huge patches of the data . And I have t ten minute stretch where I can  where I can show that . And  and sometimes it turns out that one of these transcribers has a better ear for technical jargon , and the other one has a better ear for colloquial speech . So um , the one i i the colloquial speech person picked up \" gobbledy - gook \" .\nHmm .\nAnd the other one didn't . And on this side , this one 's picking up things like \" neural nets \" and the one that 's good on the sp o on th the vocabulary on the uh colloquial didn't .\nRight .\nWhen  for the person who missed \" gobbledy - gook \" what did they put ?\nIt was an interesting approximation , put in parentheses , cuz I have this convention that , i if they 're not sure what it was , they put it in parentheses .\nOh .\nSo they tried to approximate it , but it was\nOh good .\nit was spelled GABBL\nSort of how it sounds . Yeah .\nYes . More of an attempt to  I mean apparently it was very clear to her that these  the a this  this was a sound  these are the sounds ,\nIt was a technical term that she didn't recognize ,\nYeah .\nbut  Yeah . But she knew that she didn't know it . Maybe it was a technical ter exactly . But she  even though her technical perception is just really  uh you know I 've  I 'm tempted to ask her if she 's taken any courses in this area or if she 's taken cognitive science courses\nRight .\nthen cuz \" neural nets \" and  oh she has some things that are  oh \" downsampled \" , she got that right .\nHmm .\nAnd some of these are rather  uh unexpected .\nObscure , yeah .\nBut ch ten solid uh  m ch s chunk of ten solid minutes where they both coded the same data .\nAnd  and again the main track that you 're working with is elev eleven hours ?\nAnd um\nIs that right ?\nYes exactly .\nYeah , OK .\nAnd that 's part of this  Eleven hours .\nIs that  is that  that including digits ? Yeah .\nYes it is .\nSo let 's say roughly  ten hours or so of\nMm - hmm .\nI mean it 's probably more than that but  but with  of  of non - digits .\nYeah .\nIt 'd be more than that because I  my recollection is the minutes  that da digits don't take more than half a minute . Per person .\nOh , OK .\nBut um  the  the total set that I gave them is twelve hours of tape ,\nOh , I see .\nBut they haven't gotten to the end of that yet .\nOh , I see .\nSo they 're still working  some of them are  Two of them are still working on completing that . Yeah .\nBoy , they 're moving right along .\nYeah .\nYeah . They are . Mm - hmm . They 're very efficient . There 're some who have more hours that they devote to it than others .\nMm - hmm .\nMm - hmm .\nYeah .\nSo what  what  what 's the deal with  with your\nThe channel u thing ?\nYeah .\nOh , it 's just uh , I ran the recognizer  uh , the   speech - nonspeech detector on different channels and , it 's just in uh  in this new multi - channel format and output , and I just gave one  one meeting to  to Liz who wanted to  to try it for  for the recognizer\nOh , I see .\nas uh , apparently the recognizer had problems with those long chunks of speech , which took too much memory or whatever ,\nRight .\nand so  she  she will try that I think\nYeah .\nand  I 'm  I 'm working on it . So , I hope\nIs this anything different than the HMM system you were using before ?\nYeah .\nNo . Uh , I  mmm , use some  some different features but not  not\nMm - hmm .\nThe basic thing is this HMM base .\nSo there 's still no  no knowledge using different channels at the same time .\nThere is some , uh as the energy is normalized across channels\nYou know what I mean ? Across all of them .\nyeah .\nOK .\nSo . But basically that 's one of the main changes .\nMm - hmm .\nMm - hmm . What are some of the other features ? Besides the energy ? You said you 're trying some different features , or something .", "topic_id": 1, "keywords": "recording, recordings, transcribers, transcriber, minutes", "dialogue_id": 8}, {"text": "Oh I just uh   Mmm , I just use um our loudness - based things now as they  before there were  they were some in  in the log domain and I  I changed this to the  to the\nCu - Cube root ?\nYeah . To  No , I changed this to the  to the  to the loudness thingy with the  with the\nHmm .\nAh .\nhow do you call it ? I 'm not sure . With the , uh\nFletcher Munson ? No .\nI 'm not sure about the term .\nOh , OK .\nUh , I 'll look it up . And say it to you .\nYeah , alright .\nUh , OK , and  Yeah . That 's  that 's basically the  the  the thing . Yeah , and I  and I tried t to normalize uh  uh the features , there 's loudness and modified loudness , um , within one channel ,\nOK .\nbecause they 're ,  yeah to  to be able to distinguish between foreground and background speech . And it works quite well . But , not always .\nUh - huh . Uh - huh .\nSo .\nOK .\nGood .\nUm , let 's see . I think the uh  Were  were you basically done with the transcription part ? So I guess the next thing is this uh  bleep editing .\nRight . So the  The idea is that we need to have  We need to provide the transcripts to every participant of every meeting to give them an opportunity to bleep out sections they don't want . So I 've written a bunch of tools that will generate web pages , uh with the transcription in it so that they can click on them and piece  pieces and they can scroll through and read them , and then they can check on each one if they want it excluded . And then , it 's a form , HTML form , so they can submit it and it will end up sending me email with the times that they want excluded . And so , uh , some of the questions on this is what do we do about the privacy issue . And so I thought about this a little bit and I think the best way to do it is every participant will have a password ,\nYeah .\na single password . Each person will have a single password , user name and password . And then each meeting , we 'll only allow the participants who were at that meeting to look at it . And that way each person only has to remember one password .\nI  I can't help but wonder if this is maybe a little more elaborate than is needed . I mean if people have  Uh , I mean , for me I would actually want to have some pieces of paper that had the transcription and I would sort of flip through it . And then  um  if I thought it was OK , I 'd say \" it 's OK \" .\nMm - hmm .\nAnd , I  uh  I mean it depends how this really ends up working out , but I guess my thought was that the occasion of somebody wondering whether something was OK or not and needing to listen to it was gonna be extremely rare .\nRight , I mean so th th th the fact that you could listen to it over the web is a minor thing that I had already done for  other reasons .\nOK .\nAnd so that  that 's a minor part of it , I just wanted some web interface so that people  you didn't actually have to send everyone the text . So m what my intention to do is that as the transcripts become ready , um  I would take them , and generate the web pages and send email to every participant or contact them using the contact method they wanted , and just uh , tell them , \" here 's the web page \" , um , \" you need a password \" . So th th question number one is how do we distribute the passwords , and question number two is how else do we wanna provide this information if they want it .\nThat 's  I think what I was sort of saying is that if you just say  \" here is a  here is  \" I mean this maybe it sounds paleolithic but  but I just thought if you handed them some sheets of paper , that said , uh , \" here 's what was said in this transcription is it OK with you ? and if it is , here 's this other sheet of paper that you sign that says that it 's OK \" .\nI think that um there are a subset of people who will want printouts that we can certainly provide .\nAnd then they 'd hand it back to you .\nBut certainly I wouldn't want a printout . These are big , and I would much rather be  ha be able to just sit and leaf through it .\nYou find it easier to go through a large  I mean how do you read books ?\nWell I certainly read books by hand . But for something like this , I think it 's easier to do it on the web .\nReally ? I mean , it\nCuz you 're gonna get , you know , if I  I 'm  I 'm in a bunch of meetings and I don't wanna get a stack of these . I wanna just be able to go to  go to the web site  and visit it as I want .\nGoing to a web site is easy , but flipping through a hundred pounds  a hundred pages of stuff is not easy on the web .\nWell , I don't think it 's that much harder than , paper . So .\nReally ?\nI have one question . So are you thinking that um the person would have a transcript and go strictly from the transcript ? Because I  I do think that there 's a benefit to being able to hear the tone of voice and the\nSo here 's the way I was imagining it , and maybe I 'm wrong ,\nYeah .\nbut the way I imagined it was that um , the largest set of people is gonna go \" oh yeah , I didn't say anything funny in that meeting just go ahead , where 's the  where 's the release ? \" And then there 'll be a subset of people , right ?  OK there 's  I mean think of who it is we 've been recording mostly .\nYeah .\nOK there 'll be a subset of people , who um , will say uh \" well , yeah , I really would like to see that . \" And for them , the easiest way to flip through , if it 's a really large document , I mean unless you 're searching . Searching , of course , should be electronic , but if you 're not  so if you provide some search mechanism you go to every place they said something or something like that ,\nYeah .\nbut see then we 're getting more elaborate with this thing . Um if  if uh you don't have search mechanisms you just sort of have this really , really long document , I mean whenever I 've had a really , really long document that it was sitting on the web , I 've always ended up printing it out . I mean , so it 's  it 's  I mean , you  you 're  you 're not necessarily gonna be sitting at the desk all the time , you wanna figure you have a train ride , and there 's all these situations where  where I  I mean , this is how I was imagining it , anyway . And then I figured , that out of that group , there would be a subset who would go \" hmm you know I 'm really not sure about this section here , \" and then that group would need it  S It seems like i if I 'm right in that , it seems like you 're setting it up for the most infrequent case , rather than for the most frequent case . So that uh , now we have to worry about privacy ,\nWell , no fre for the most\nwe have to worry about all these passwords , for different people\nFor the most frequent case they just say  \" it 's OK \" and then they 're done . And I think  almost everyone would rather do that by email than any other method .\nMm - hmm .\nThe other thing too is it seems like\nUm , yeah , that 's true .\nGo ahead .\nI mean , cuz you don't have to visit the web page if you don't want to .\nYeah .\nI guess  Yeah , I guess we don't need their signature . I guess an email OK is alright .\nOh that was another thing I  I had assumed that we didn't need their signature , that it  that an email approval was sufficient . But  I don't actually know .\nAre  are people going to be allowed to bleep out sections of a meeting where they weren't speaking ?\nYes . If someone feels strongly enough about it , then I  I  I think they should be allowed to do that .\nI also  mm - hmm .\nSo that means other people are editing what you say ?\nUh  I don't know about that .\nYeah .\nI don't know if I like that .\nWell , the only other choice is that the person would say \" no , don't distribute this meeting at all \" , and I would rather they were able to edit out other people then just say \" don't distribute it at all \" .\nBut th what they signed in the consent form , was something that said you can use my voice .\nWell , but if  if someone is having a conversation , and you only bleep out one side of it , that 's not sufficient .\nRight ? Yeah . Yeah , but that 's our decision then . Right ?\nUm , I don't think so . I mean , because if I object to the conversation .\nI think it is .\nIf I say \" we were having a conversation , and I consider that conversation private , \" and I consider that your side of it is enough for other people to infer , I wanna be able to bleep out your side .\nThe  I agree that the consent forms were  uh , I cons agree with what Adam 's saying , that  um , the consent form did leave open this possibility that they could edit things which they found offensive whe whether they said them or didn't say them .\nI see . OK , well , if that 's what it said .\nAnd the other thing is from the standpoint of the l of the l I 'm not a law lawyer , but it strikes me that  uh , we wouldn't want someone to say \" oh yes , I was a little concerned about it but  it was too hard to access \" . So I think it 's kind of nice to have this facility to listen to it . Now  in terms of like editing it by hand , I mean I think it 's  i some people would find that easier to specify the bleep part by having a document they edited . But  but it seems to me that sometimes um , you know i if a person had a bad day , and they had a tone in their voice that they didn't really like , you know it 's nice  it 's nice to be able to listen to it and be sure that that was OK .\nI mean I can certainly provide a printable version if people want it . Um .\nUm  I mean it 's also a mixture of people , I mean some people are r do their work primarily by sitting at the computer , flipping around the web , and others do not .\nYep .\nOthers would consider it  this uh  a  a set of skills that they would have to gain . You know ?\nWell I think most of the people in the meetings are the former .\nIt depends on what meetings .\nThat 's true .\nSo far .\nSo .\nIn the meetings so far , yeah .\nYep .\nBut we 're trying to expand this , right ?\nRight .\nSo I  I  I actually think that paper is the more universal thing .\nAnd that  Well , but if they want to print it out that 's alright .\nMm - hmm . Yeah .\nI think everyone in the meeting can access the web .\nNo , I think we have to be able to print it out . It 's not just if they want to print it out . I  I think\nOK , so does that mean that I can't use email ? Or what ?\nCuz you could send it through email you 're thinking .\nI  I th\nWell , I don't think I\nwell  we  there was this\nwell I don't think we can send the text through email because of the privacy issues .\nNo .\nGood . For security ?\nYeah .\nYeah , OK good .\nRight .\nUm . So giving them , you think a web site to say , \" if you wanna print it out here it is \" , is not sufficient ?\nGood point .\nYeah . I\nCertainly for everybody who 's been in the meetings so far it would be sufficient .\nYeah , I 'm just thinking for people that that 's not sufficient for , what  the only sufficient thing would be for me to walk up to them and hand it to them .\nI 'm just wondering about\nYou could mail it to them .\nYeah .\nGet an a mailing address .\nEquivalent .\nBut\nBut I think it 's easier to drop in the box .\nJust put the button on  on the web page which say \" please send me the  the scripts \" .\nThat 's right .\nOh that 's interesting .\nYeah .\nWhat um  When you display it on the web page , what are  what are you showing them ? Utterances , or  ?\nMm - hmm .\nAnd so can they bleep within an utterance ?\nNo . Whole utterances only .\nWhole utterances .\nAnd that was just convenience for my sake , that it 's uh , uh it would end up being fairly difficult to edit the transcripts if we would do it at the sub - utterance level . Because this way I can just delete an entire line out of a transcript file rather than have to do it by hand .\nThere 's another aspect to this which maybe  is part of why this is bothering me . Um , I think you 're really trying very hard to make this as convenient as possible for people to do this .\nMmm .\nI mean that 's why I did the web form , because for me that would be my most convenient .\nI  I  I understand .\nI know where you 're going .\nI think that 's the bad idea .\nOh .\nSee because you 're gon you 're  uh  Really . You 're gonna end up with all these little patchy things , whereas really what we want to do is have the  the  the bias towards letting it go . Because nob you know it  There was a  one or twi once or twice , in the re in the meetings we 've heard , where somebody said something that they might be embarrassed by , but overall people are talking about technical topics . Nobody 's gonna get hurt . Nobody 's being l libeled . You know , this is  this  we 're  we 're covering  We 're playing the lawyer 's game , and we 're playing we 're  we 're  we 're looking for the extreme case . If we really orient it towards that extreme case , make it really easy , we 're gonna end up encouraging a headache . That  I think that 's  I 'm sort of psyching myself out here , I  I 'm trying to  uh\nI guess I don't see having a few phrases here and there in a meeting being that mu much of a headache , bleeped out .\nbut I  I think that 's  Well , it 's\nSo .\nI think what Morgan 's saying is the easier it is , the more is gonna be bleeped .\nbut i And  and it really depends on what kind of research you 're doing . I think some researchers who are gonna be working with this corpus years from now are really gonna be cursing the fact that there 's a bunch of stuff in there  that 's missing from the dialogue .\nMm - hmm .\nYou know , it depends on the kind of research they 're doing ,\nYeah .\nbut it might be , uh  it might be really a  a pain . And , you know where it 's really gonna hurt somebody , in some way  the one who said it or someone who is being spoken about ,  we definitely want to allow the option of it being bleeped out . But I really think we wanna make it the rare incidence . And  and uh , I am just a little worried about making it so easy for people to do , and so much fun !  that they 're gonna go through and bleep out stuff .\nSo much fun .\nand they can bleep out stuff they don't like too , right from somebody else , as you say , you know , so \" well I didn't like what he said . \"\nWell I don't see any way of avoiding that . I mean , we have to provi we have promised that we would provide them the transcript and that they can remove parts that they don't like . So that the\nYeah . No , no , I  I  I don't\nThe only question is\nYou - you 've talked me into that , but I  I just think that we should make it harder to do .\nThe problem is if it 's harder for them it 's also harder for me . Whereas this web interface , I just get email , it 's all formatted , it 's all ready to go and I can just insert it .\nSo maybe you don't give them access to the web interface unless they really need it . So  so  so\nWell I guess  Yeah .\nI 'm sorry  so  so  So maybe this is a s a way out of it .\nHmm .\nYou 've provided something that 's useful for you to do  handle , and useful for someone else if they need it . But I think the issue of privacy and ease and so forth should be that uh , they get access to this if they really need it .\nWell\nSo you 're saying the  the sequence would be more like first Adam goes to the contact lists , contacts them via whatever their preferred method is , to see if they want to review the meeting .\nRight .\nAnd then if they don't , you 're done . If they do , then he provides them access to the  the web site .\nWell , to some extent I have to do that anyway because as I said we have to distribute passwords .\nW w\nOr  a printed - out form .\nThere 's  there\nSo ,\ny but you don't necessarily have to distribute passwords is what I 'm saying .\nWell , but\nSo\nOnly if they want it .\nwhat I 'm saying is that I can't just email them the password because that 's not secure . So they have to call me and ask .\nNo , no , no . But you aren't necessarily giving them  Right . But  we don't even necessarily need to end up distributing passwords at all .\nWell , we do because of privacy . We can't just make it openly available on the web .\nNo , no . You 're missing the point .\nMm - hmm .\nWe 're  We 're trying i We 're trying to make it less of an obvious just l l l l uh fall off a log , to do this .\nNot everyone gets a password , unless they ask for it .\nRight ? So th so what I would see , is that first you contact them and ask them if they would like to review it for to check for the\nYeah .\nnot just for fun , OK ? but to  to check this for uh things that they 're worried about having said or if they 're willing to just send an approval of it , at  from their memory . Um  and , uh , and we should think carefully actually we should review  go through how that 's worded , OK ? Then , if someone uh  wants to review it , uh , and I know you don't like this , but I 'm offering this as a suggestion , is that  is that we then give them a print out . And then if they say that \" I have a potential problem with these things , \" then , you  you say \" OK well you might wanna hear this in context to s think if you need that , \" you issue them a password , i in the\nBut the  the problem with what you 're suggesting is it 's not just inconvenient for them , it 's inconvenient for me . Because that means multiple contacts every time  for every single meeting every time anyone wants anything . I would much prefer to have all be automatic , they visit the web site if they want to . Obviously they don't have to .\nI know you 'd prefer it , but the proble\nYeah .\nwe have\nSo I think you 're thinking people are going to arbitrarily start bleeping and I just don't think that 's gonna happen .\nthere 's a problem with it .", "topic_id": 2, "keywords": "utterances, bleeping, loudness, utterance, transcription", "dialogue_id": 8}, {"text": "I 'm also concerned about the spirit of the  of the informed consent thing . Cuz I think if they feel that uh , it 's  I th I th You know , if it turns out that something gets published in this corpus that someone really should have eliminated and didn't detect , then it could have been because of their own negligence that they didn't pursue that next level and get the password and do that , um , but  but they might be able to argue \" oh well it was cumbersome , and I was busy and it was gonna take me too much time to trace it down \" . So it could that the burden would come back onto us . So I 'm a little bit worried about uh , making it harder for them , from the legal standpoint .\nWell you can go too far in that direction , and you need to find somewhere between I think ,\nYeah .\nIt seems to me that sending them email , saying \" if you have an O - OK reply to this email and say OK ,\nbecause  Uh - huh .\nIf you have a problem with it contact me and I 'll give you a password \" , seems like is a perfectly , reasonable compromise . And if they want a printout they can print it out themselves .\nOr we could print it up for them ,\nYeah .\nI mean we could offer that  but  but there 's uh , another aspect to that and that is that in the informed consent form , um , my impression is that they  that we offered them at the very least that they definitely would have access to the transcript . And  and I ha\nYeah .\nI don't know that there 's a chance of really skipping that stage . I mean I  I thought that you were  Maybe I misinterpreted what you said but it 's\nHaving access to it doesn't necessarily mean , that  having it\nHaving it .\nGiving it to them .\nWell the in\nright ? It just means they have the right to have it .\nOK .\nthe consent form is right in there if anyone wants to look at it ,\nAlright . Fine . OK . Fair enough .\nso .\nYeah .\nD you want me to grab one ?\nSh - sh well I could  I 'm closer .\nYeah , but you 're wired\nI could\naren't you ?\nYeah . That is true .\nUm .  Yeah , I mean I don't wanna fool them ,\nI don't know\nI just meant that e every  ev any time you say anything to anyone there is in fact a  a bias that is presented ,\nOh yeah yeah  oh I know .\nright ?\n\" If you agree to participate you 'll have the opportunity to have anything ex anything excised , which you would prefer not to have included in the data set . \"\nof  and\nYeah that 's true . Yeah .\n\" Once a transcript is available we will ask your permission to include the data in the corpus for the r larger research community .\nYeah .\nThere again you will be allowed to indicate any sections that you 'd prefer to have excised from the database , and they will m be removed both from the transcript and the recording . \"\nHmm . Well that 's more open than I realized .\nWell , I mean it  The one question is definitely clear with anything as opposed to just what you said .\nI\nYeah .\nYeah , uh no that  it  tha\nTha - that 's true . That 's more severe , but the next one says the transcript will be around .\nthat 's right .\nAnd it doesn't  really say we 'll send it to you , or wi it 'll be available for you on the web , or anything .\nI think it probably leaves it open how we get it to them .\nI I\nAt least it more often . Yeah . It means also we don't have to g To give it to them . I mean like  like Morgan was saying they  they\nThey just have to make sure that it is available to them .\nIt 's available to them if they ask for it .\nYeah , OK , so . wh um  I think I have an idea that may be sat may satisfy both you and me in this which is , um , it 's a  it  we just go over carefully how these notes to people are worded . So I  I just want it to be worded in such a way where it gives the strong impre it gives very , I mean nothing hidden , v very strongly the bias that we would really like to use all of these data .\nRight .\nThat  that we really would rather it wasn't a patchwork of things tossed out ,\nGood .\nthat it would be better for , um , our , uh , field if that is the case . But if you really think something is gonna  And I don't think there 's anything in the legal aspects that  that is hurt by our expressing that bias .\nGreat . Great , great .\nAnd then  then my concern about  which\nYeah . I agree .\nyou know you might be right , it may be it was just paranoia on my part , uh but people just  See I 'm @ @ worried about this interface so much fun  that people start bleeping stuff out   just as  just because they can .\nIt 's just a check box next to the text , it 's not any fun at all .\nYeah . Well I don't know . I kind of had fun when you played me something that was bleeped out . You know .\nWell , but they won't get that feedback .\nI\nAll  no because it doesn't automatically bleep it at the time .\nOh they won't ?\nIt just sends me\nOh good . So you haven't made it so much fun .\nRight .\nOh good .\nIt just sends me the time intervals .\nOK ,\nAnd then at some point I 'll incorporate them all and put bleeps . I mean I don't wanna have t ha do that yet until we actually release the data\nYeah .\nbecause um , then we have to have two copies of every meeting and we 're already short on disk space .\nYeah .\nSo I  I wanna  I  just keep the times until we actually wanna release the data and then we bleep it .\nOK . Alright , so I think  Yeah so if we have if  i Again let 's you know , sort of circulate the  the wording on each of these things and get it right ,\nWell since you seem to feel heart uh , strongest about it , would you like to do the first pass ?\nbut  but  OK . Uh , fair enough . Turn about is fair play ,\nAl - Also it ther there is this other question , the legal question that  that Adam 's raised , uh about whether we need a concrete signature , or email c i suffices or whatever\nSorry .\nYeah .\nand I don't know how that works . i There 's something down there about \" if you agree to  \"\nI 'm  I 'm  I 'm  I thought  I  I thought about it with one of my background processes\nI don't think so .\nand I  uh it 's  uh it 's uh , it 's fine to do the email .\nAh . Fine .\nYeah because thi th they 're signing here that they 're agreeing to the paragraph which says \" you 'll be given an opportunity . \"\nOK .\nGood . OK .\nYeah .\nAnd so I don't think they need another signature .\nAnd  Well and furthermore I  it 's now fairly routine in a lot of arrangements that I do with people on contracts and so forth that  that uh if it 's  if it 's that sort of thing where you 're you 're saying uh \" OK I agree , we want eighty hours of this person at such - and - such amount , and I agree that 's OK , \" uh if it 's a follow up to some other agreement where there was a signature it 's often done in email now\nRight .\nso it 's  it 's OK .\nGreat .\nUm .\nSo I guess I probably should at the minimum , think about how to present it in a printed form . I 'm not really sure what 's best with that . The problem is a lot of them are really short ,\nWell\nand so I don't necessarily wanna do one per line . But I don't know how else to do it .\nWell I s I also have this  I  I think it 's nice you have it uh , viewab her  hearable on the  on the web for those who might wonder about um , the non nonverbal side , I mean I  I agree that our bias should be as  as expressed here , and  but I  I think it 's nice that a person could check . Cuz sometimes you know you  the words on a  on the page , come out soun sounding different in terms of the  social dynamics if they hear it .\nHmm .\nMm - hmm . Mm - hmm .\nAnd I realize we shouldn't emphasize that people  you know , shouldn't borrow trouble . What it comes down to but\nYeah I think actually  my opinion probably is that the only time someone will need to listen to it is if the transcript is uh not good . You know , if  if there are lots of mumbles and parentheses and things like that .\nOh , you know , or what if there was an error in the transcript that didn't get detected and there was a whole uh  i segment a against some   personal  i th\nRight . That was all mumbled ?\nYeah .\nI think Microsoft is\nYeah exactly\nOh ,\nSorry transcribers .\nOr  or even   or even  there was a  a line you know about how \" hmm - mmm - mmm  Bill Gates duh - duh - duh - duh . \"\nYeah .\nbut  but it was all  the words were all visible , but they didn't end up i some there was a slip in the transcript .\nOh , God .\nThey 're gonna hate this meeting .\nYeah .\nYeah that 's true .\nActually Liz will like it . You know , but .\nLiz will like it . We had a pretty strong disagreement going there .\nYep , yep , that 's right .\nYeah .\nYeah . So I don't know . I mean , I  I guess we 're assuming that the transcript is a close enough approximation and that  that my double checking will be  so close to absolutely perfect that it  that nothing will slip by .\nMm - hmm .\nBut it  the  some something might sometime , and they  uh  if  if it 's something that they said , they might  i i I mean , you might be very accurate in putting down what they actually said ,\nMm - hmm .\nbut , when they hear it , themselves , they may hear something different because they know what they meant .\nI don't know how to notate that .\nSarcasm ,\nYeah , that 's right .\nhow do you  how do you indicate sarcasm ?\nYeah that 's right .\nNo , I 'm serious . So  the  so  i the  so we might  we might get some feedback from people that such - and - such was , you know , not  not really what I said .\nYeah . Well that would be good to get , definitely .\nYeah , but , Yeah , sure .\nJust for corrections .\nYeah .\nSo um , in terms of password distribution , I think phone is really the only way to do it , phone and in person . Or mail , physical mail .\nYeah . Or if for leave it on their voice mail .\nAny sub - word level thing .\nAny sub - wor Yeah , OK . I mean you could do it with PGP or things like that but it 's too complex .\nYou know I just realized something , which is of  e th this question about the  uh the possible mismatch of  I mean i well , and actually also the lawyer saying that um , we shouldn't really have them  have the people believing that they will be cleared by our checks . You know ?\nMm - hmm .\nI mean . So it 's like i in a way it 's  it 's nice to have the responsibility still on them to listen to the tape and  and hear the transcript , to have that be the\nWell yeah , but you can't dep I mean , most people will not wanna take the time to do that , though .\nYeah , OK , fair enough . And they 're s they 're absorbing the responsibility themselves .\nAnd they  they have to\nSo it 's not  it 's not um  Yeah , good .\nBut I mean if you were at a meeting , and  and you  you don't think , at least , that you said anything funny and the meeting was about , you know , some  some funny thing about semantics or something , or uh\nYou probably won't listen to it .\nYeah .\nIt is true that tec that the content is technical , I  and so i and we 're not having these discussions which\nYeah .\nI  I mean , when I listen to these things , I don't find things that are questionable , in other people 's speech or in my own .\nYeah . You would think it would be rare ,\nJust  It should be very rare .\nI mean we 're not talking about the energy crisis or something , people have\nYeah . Yeah , OK .\nHow about them energy crises .\nYeah . I think we 're uh\nDone ?\nKind of done . Actually , I was gonna  Di - Did you have anything n that 's going on , or\nNot really . No . Um ,  my project is going along but um , I 'm really just here to um fill the project uh  the overall progress . I don't really have anything specific to  to talk about .\nYeah . That 's fine . I just didn't wanna go by you , if you had something .\nOh , OK .\nYou don't have anything to say .\nNo .\nNah .\nTranscribers , he was rattling the b marbles in his brain back and forth just then this  this\nShall we do digits ?\nOh yeah .\nUm , oh by the way I did find a bunch\nIt um\nUh , we should count out how many more digits to forms do we have back there ?\nThere were quite a few . Uh .\nThat 's what I thought . I f I was going through them all and I found actually a lot filed in with them , that were blanks , that no one had actually read .\nMmm .\nAnd so we still have more than I thought we did .\nOh good .\nSo , we have a few more digits before we 're done .\nYou know having this headset reminds me of like working at Burger King or something .\nOops .\nOh , did you do that ?\nBurger King\nI 'd like a burger with that ,\nNo I never did .\ndo you want fries with that ?\nWow .\nBut I feel like I could now .\nAnd", "topic_id": 3, "keywords": "consent, password, email, permission, mail", "dialogue_id": 8}, {"text": "Why ?\nUm .\nI 'm known . I\nNo , cuz she already told me it , before she told you .\nNo , she told me a long time ago . She told me  she told me like two weeks ago .\nOh , well , it doesn't matter what time .\nOK . You know how to toggle the display width  function\nWell maybe she hadn't just started transcribing me yet .\nWow .\nAnyway .\nWhat is it ?\nLet me explain something to you .\nUm ,\nMy laugh is better than yours .\nthere .\nI beg to differ .\nYo .\nUm , OK .\nBut you have to say something genuinely funny before you 'll get an example .\nYeah .\nThe thing is I don't know how to get to the next page . Here .\nNo . You should be  at least be self - satisfied enough to laugh at your own jokes .\nActually I thought\nNo , it 's a different laugh .\nThere .\nOoh , wow !\nHow weird .\nOh ! Holy mackerel .\nWow . Whoa !\nWhat ? ! Oh . OK . I wasn't even doing anything .  OK .\nUh .\nEva 's got a laptop , she 's trying to show it off .\nThat was r actually Robert 's idea . But anyhow . Um\nO K . So , here we are .\nOnce again .\nOnce again , right , together . Um , so we haven't had a meeting for a while , and  and probably won't have one next week , I think a number of people are gone . Um , so Robert , why don't you bring us up to date on where we are with EDU ?\nUm , uh in a  in a smaller group we had uh , talked and decided about continuation of the data collection . So Fey 's time with us is almost officially over , and she brought us some thirty subjects and , t collected the data , and ten dialogues have been transcribed and can be looked at . If you 're interested in that , talk to me . Um , and we found another uh , cogsci student who 's interested in playing wizard for us . Here we 're gonna make it a little bit more complicated for the subjects , uh this round . She 's actually suggested to look um , at the psychology department students , because they have to partake in two experiments in order to fulfill some requirements . So they have to be subjected ,   before they can actually graduate . And um , we want to design it so that they really have to think about having some time , two days , for example , to plan certain things and figure out which can be done at what time , and , um , sort of package the whole thing in a  in a re in a few more complicated um , structure . That 's for the data collection . As for SmartKom , I 'm  the last SmartKom meeting I mentioned that we have some problems with the synthesis , which as of this morning should be resolved . And , so ,\nGood .\n\" should be \" means they aren't yet , but  but I think I have the info now that I need . Plus , Johno and I are meeting tomorrow , so maybe uh uh , when tomorrow is over , we 're done . And ha n hav we 'll never have to look at it again Maybe it 'll take some more time , to be realistic , but at least we 're  we 're seeing the end of the tunnel there . That was that . Um , the uh , uh I don't think we need to discuss the formalism that 'll be done officially s once we 're done . Um , something happened , in  on Eva 's side with the PRM that we 're gonna look at today , and um , we have a visitor from Bruchsal from the International University . Andreas , I think you 've met everyone except Nancy .\nSorry . Hi . Hi .\nYeah .\nHi . Hi .\nSo when you said \" Andreas \" I thought you were talking about Stolcke .\nAnd , um ,\nNow I know that we aren't , OK .\nAndy , you actually go by Andy , right ? Oh , OK .\nYeah .\nEh\nCuz there is another Andreas around ,", "topic_id": 0, "keywords": "laugh, jokes, funny, ha, eh", "dialogue_id": 9}, {"text": "Hmm .\nso , to avoid some confusion .\nThat will be  Reuter ? Oh , OK .\nYeah .\nSo my scientific director of the EML is also the dean of the International University , one of his many occupations that just contributes to the fact that he is very occupied . And , um , the  um , he @ @ might tell us a little bit about what he 's actually doing , and why it is s somewhat related , and  by uh using maybe some of the same technologies that we are using . And um . Was that enough of an update ?\nI think so .\nIn what order shall we proceed ?\nOK .\nMaybe you have your on - line\nUh , yeah , sure . Um , so , I 've be just been looking at , um , Ack ! What are you doing ? Yeah . OK . Um , I 've been looking at the PRM stuff . Um , so , this is , sort of like the latest thing I have on it , and I sorta constructed a couple of classes . Like , a user class , a site class , and  and you know , a time , a route , and then  and a query class . And I tried to simplify it down a little bit , so that I can actually um , look at it more . It 's the same paper that I gave to Jerry last time . Um , so basically I took out a lot of stuff , a lot of the decision nodes , and then tried to  The red lines on the , um , graph are the um , relations between the different um , classes . Like , a user has like , a query , and then , also has , you know um , reference slots to its preferences , um , the special needs and , you know , money , and the user interest . And so this is more or less similar to the flat Bayes - net that I have , you know , with the input nodes and all that . And  So I tried to construct the dependency models , and a lot of these stuff I got from the flat Bayes - net , and what they depend on , and it turns out , you know , the CPT 's are really big , if I do that , so I tried to see how I can do , um  put in the computational nodes in between . And what that would look like in a PRM . And so I ended up making several classes  Actually , you know , a class of  with different attributes that are the intermediate nodes , and one of them is like , time affordability money affordability , site availability , and the travel compatibility . And so some of these classes are  s some of these attributes only depend on stuff from , say , the user , or s f just from , I don't know , like the site . S like , um , these here , it 's only like , user , but , if you look at travel compatibility for each of these factors , you need to look at a pair of , you know , what the um , preference of the user is versus , you know , what type of an event it is , or you know , which form of transportation the user has and whether , you know , the onsite parking matters to the user , in that case . And that makes the scenario a little different in a PRM , because , um , then you have one - user objects and potentially you can have many different sites in  in mind . And so for each of the site you 'll come up with this rating , of travel compatibility . And , they all depend on the same users , but different sites , and that makes a  I 'm tr I w I wa have been trying to see whether the PRM would make it more efficient if we do inferencing like that . And so , I guess you end up having fewer number of nodes than in a flat Bayes - net , cuz otherwise you would  c well , it 's probably the same . But um , No , you would definitely have  be able to re - use , like ,  um , all the user stuff , and not  not having to recompute a lot of the stuff , because it 's all from the user side . So if you changed sites , you  you can , you know , save some work on that . But , you know , in the case where , it depends on both the user and the site , then I 'm still having a hard time trying to see how um , using the PRM will help . Um , so anyhow , using those intermediate nodes then , this  this would be the class that represent the intermediate nodes . And that would  basically it 's just another class in the model , with , you know , references to the user and the site and the time . And then , after you group them together this  no the dependencies would  of the queries would be reduced to this . And so , you know , it 's easier to specify the CPT and all . Um , so I think that 's about as far as I 've gone on the PRM stuff .\nWell\nRight .\nNo . So y you didn't yet tell us what the output is .\nThe output .\nSo what decisions does this make ?\nOK . So it only makes two decisions , in this model . And one is basically how desirable a site is meaning , um , how good it matches the needs of a user . And the other is the mode of the visit , whether th It 's the EVA decision . Um , so , instead of um ,  doing a lot of , you know , computation about , you know , which one site it wants of  the user wants to visit , I 'll come  well , try to come up with like , sort of a list of sites . And for each site , you know , where  h how  how well it fits , and basically a rating of how well it fits and what to do with it . So . Anything else I missed ?\nSo that was pretty quick . She 's ac uh uh Eva 's got a little write - up on it that uh , probably gives the  the details to anybody who needs them . Um , so the  You  you didn't look at all yet to see if there 's anybody has a implementation .\nNo , not yet , um\nOK . So one  so one of the questions , you know , about these P R Ms is\nMm - hmm .\nuh , we aren't gonna build our own interpreter , so if  if we can't find one , then we uh , go off and do something else and wait until s one appears . Uh , so one of the things that Eva 's gonna do over the next few weeks is see if we can track that down . Uh , the people at Stanford write papers as if they had one , but , um , we 'll see . So w Anyway . So that 's a  a major open issue . If there is an interpreter , it looks like you know , what Eva 's got should run and we should be able to actually um , try to solve , you know , the problems , to actually take the data , and do it . Uh , and we 'll see . Uh , I actually think it is cleaner , and the ability to instantiate , you know , instance of people and sites and stuff , um , will help in the expression . Whether the inference gets any faster or not I don't know . Uh , it wouldn't surprise me if it  if it doesn't .\nMm - hmm .\nYou know , it 's the same kind of information . I think there are things that you can express this way which you can't express in a normal belief - net , uh , without going to some incredible hacking of  sort of rebuilding it on the fly . I mean , the notion of instantiating your el elements from the ontology and stuff fits this very nicely and doesn't fit very well into the extended belief - net . So that was one of the main reasons for doing it . Um . I don't know . So , uh , people who have thought about the problem , like Robert i it looked to me like if  Eva were able to come up with a  you know , value for each of a number of uh , sites plus its EVA thing , that a travel planner should be able to take it from there . And  you know , with some other information about how much time the person has and whatever , and then plan a route .\nUm - hmm , um ,  well , first of all uh , uh , great looks , mu much cleaner , nnn , nnn , Certain  certain beauty in it , so , um , if beauty is truth , then , uh we 're in good shape . But , the um , as , uh , mentioned before we probably should look at t the details . So if you have a write - up then uh , I 'd love to read it\nMm - hmm .\nand uh  because , um , i Can you go all the way back to the  the very top ?\nYeah .\nUm ,  uh these  @ @  these  w w when these are instantiated they take on the same values ? that we had before ?\nI can't really see the whole thing .\nor are they  have they changed , in a sense ?\nWell I think I basically leave them to similar things .\nUh - huh .\nSome of the things might  that might be different , maybe like  are that the hours for the site .\nHmm .\nAnd , eventually I meant that to mean whether they 're open at this hour or not .\nUh - huh .\nAnd status would be , you know , more or less like , whether they 're under construction , and  and  or stuff like that .\nAnd the , uh , other question I would have is that presumably , from the way the Stanford people talk about it , you can put the probabilities also on the relations . If\nWhich is the structural uncertainty ?\nYeah . Yeah , I  that 's  That I think was actually in the previous  the Ubenth stuff . I don't remember whether they carried that over to this or not ,\nMmm .\nuh , structural uncertainty .\nIt 's sort of in the definition or  in the  in Daphne 's definition of a PRM is that classes and relations ,\nOK .\nand you 're gonna have CPT 's over the classes and their relations .\nAlright .\nMore uncertainty , or  or\nUh ,\nI should say .\nI remember them learning when , you know , you don't know the structure for sure ,\nYeah .\nbut I don't remember reading how you specify\nYeah , that would be exactly my question .\nRight .\nwh to start with . Yeah .\nWell\nYeah .\nYeah . So , uh , the  the plan is  is when Daphne gets back , we 'll get in touch and supposedly , um , we 'll actually get s deep  seriously connected to  to their work and\nYep .\nsomebody 'll  Uh , you know  If it 's a group meeting once a week probably someone 'll go down and , whatever . So , we 'll actually figure all this out .\nOK . OK . Then I think the w  long term perspective is  is pretty clear . We get rocking and rolling on this again , once we get a package , if , when , and how , then this becomes foregrounded\nMm - hmm .\nprofiled , focused , again .\nDesignated ?\nOf course .\nAnd um , until then we 'll come up with a something that 's  @ @  that 's way more complicated for you . Right ?\nOK .\nBecause this was laughingly easy , right ?\nActually I had to take out a lot of the complicated stuff , cuz I  I made it really complicated in the beginning , and Jerry was like ,  \" this is just too much \" .\nYeah . So , um , you could , from this , go on and say suppose there 's a group of people traveling together and you wanted to plan something that somehow , with some Pareto optimal uh ,  uh , thing for\nThat 's good . That 's definitely a job for artificial intelligence .\nuh , or\nExcept for humans can't really solve it either , so .\nWell that 's not  not even something humans  yeah .\nRight . Right . Well that 's the  that would  that would be a  uh , you could sell it , as a\nYeah .\nOK , eh you don't have to fight about this , just give your preferences to the\nAnd then you can blame the computer .\nw Exactly .\nSo .\nHmm . But what does it  uh  Would a pote potential result be to  to split up and never talk to each other again ? You know .\nThat should be one of them .\nYeah .\nYeah . Right .\nThat 'd be nice .\nMmm .\nAnyway . So . So there i there are some  some u uh , you know , uh , elaborations of this that you could try to put in to this structure , but I don't think it 's worth it now . Because we 're gonna see what  what else uh  what else we 're gonna do . Anyway . But uh , it 's good , yeah and  and there were a couple other ideas of  of uh , things for Eva to look at in  in the interim .\nGood . Then , we can move on and see what Andreas has got out his sleeve . Or Andy , for that matter ?", "topic_id": 1, "keywords": "classes, queries, class, eml, prm", "dialogue_id": 9}, {"text": "OK . So uh , uh , well , thanks for having me here , first of all . Um , so maybe just a  a little background on  on my visit . So , uh , I 'm not really involved in any project , that 's uh  that 's relevant to you uh , a at the moment , uh , the  the reason is really for me uh , to have an opportunity to talk to some other researchers in the field . And  and so I 'll just n sort of give you a real quick introduction to what I 'm working on , and um , I just hope that you have some comments or , maybe you 're interested in it to find out more , and  and so I 'll be uh , happy to talk to you and  and uh , I 'd also like to find out some more and  and maybe I 'll just walk around the office and and then  and ask some  some questions , uh , in a couple days . So I 'll be here for uh , tomorrow and then uh , the remainder of uh , next week . OK , so , um , what I started looking at , uh , to begin with is just uh , content management systems uh , i i in general . So um , uh what 's uh  Sort of the state of the art there is to um  uh you have a bunch of  of uh documents or learning units or learning objects , um , and you store meta - data uh , associate to them . So there 's some international standards like the I - triple - E , uh  There 's an I - triple - E , LON standard , and um , these fields are pretty straightforward , you have uh author information , you have uh , size information , format information and so on . Uh , but they 're two uh fields that are um , more interesting . One is uh you store keywords associated with the uh  with the document , and one is uh , you have sort of a , um , well , what is the document about ? So it 's some sort of taxonomic uh , ordering of  of the  of the units . Now , if you sort of put on your semantic glasses , uh you say , well that 's not all that easy , because there 's an implicit um , uh , assumption behind that is that uh , all the users of this system share the same interpretation of the keyword and the same interpretation of uh , whichever taxonomy is used , and uh , I think that 's a  that 's a very  that 's a key point of these systems and they sort of always brush over this real quickly without really elaborating much of that and uh  As a matter of fact , the only thing that m apparently really works out so far are library ordering codes , which are very , very coarse grain , so you have some like , science , biology , and then  But that 's really all that we have at the moment . So I think there 's a huge , um , uh need for improvement there . Now , what this uh  a standard like this would give us is we could um , sort of uh with a search engine just query uh , different repositories all over the world . But we can't really  Um , so what I 'm  what I try to do is um , to have um , uh  So . So the scenario is the following , you you 're working on some sort of project and you encounter a certain problem . Now , what  what we have at our university quite a bit is that uh , students um , try to u program a certain assignment , for example , they always run into the same problems , uh , and they always come running to us , and they 'll say why 's it not  it 's not working , and we always give out the same answer , so we thought , well , it 'd be nice to have a system that could sort of take care of this , and so , what I want to build is basically a  a smart F A Q system . Now , what you uh need to do here is you need to provide some context information which is more elaborate than \" I 'm looking for this and this and this keyword . \" So . And I think that I don't need to tell you this . I 'm  I 'm sure you have the same  when  when somebody utters a sentence in a certain , uh , context it , and  and the same sentence in another context makes a huge difference . So , I want to be able to model information like , um , so in the  in the context of  in the context of developing distributed systems , of a at a computer science school , um , what kind of software is the person using , which homework assignment is he or she working on at the moment , um , maybe what 's the background of that student 's um , which um , which error message was encountered . So this sort of information I think should be transmitted , uh , when a certain document is retrieved . Now , um , basically giving this um  Uh so we somehow need to have a formalized um , way of writing this down basically , and that 's where the shared interpretation of  of certain terms and keywords comes in again . And , using this and some  some uh , knowledge about the domain I think you can do some  some simple inferences . Like you know that when somebody 's working about  uh , working on  on servlets for example , he 's using Java , cuz servlets are used  are written in Java . So some  some inferences like that , now , um , u using this you can infer more information , and you could then match this to the meta - data of um  off the documents you 're  you 're searching against . So , uh what I wanna do is basically have some sort of um  given these inputs , and then I can compute how many documents match , and use this as a metric in the search . Now , what I plan to do is I want to uh sort of do a uh  uh  try to improve the quality of the search results , and I want to do this by having a depth uh , um , um  steepest descent approach . So if I knew which operating system the person was working on , would this improve my search result ? And  and having uh , uh a symbolic formalized model of this I could simply compute that , and find out which um  which questions are worth um , asking . And that 's what I then propagate back to the user , and  and sort of try to optimize the search in this way . Now , the big problem that I 'm facing right now is um , it 's fairly easy to hack up a system uh quickly , that  that works in the small domain , but the problem is obviously the scalability . And uh uh , so Robert was mentioning uh , earlier today is that uh , Microsoft for example with their printer set up program has a Bayesian network , which does exactly this , but there you face a problem that these are very hard to extend . And so , uh what I 'm  What I try to do is basically try to model this uh , in a way that you could really combine uh , knowledge from very different sources , and  and um , sort of looking into some of the ideas that the semantic web community uh , came up with . Trying to  to have uh , an approach how to integrate s uh certain uh  representation of certain concepts and also some computational rules , um , what you can do with those . Um . What I 'm also looking into is a probabilistic approach into this because document retrievals is a very fuzzy procedure , so it 's probably not that easy to simply have a symbolic uh , computational model . That  that probably isn't expressive enough . So . So that 's another thing , um , which I think you 're also uh , uh looking into right now . And then um , uh sort of as an add - on to this whole idea , um , uh that would be now , depending on what the search engine or the content repository  depending on which  um , uh , which uh , rules and which ontologies it  it uses , or basically its view of the world , uh you can get very different results . So it might ma make a lot of sense to actually query a lot of different search engines . And there you could have an idea where you actually have sort of a  a peer to peer approach , where we 're all sort of carrying around our individual bookshelves , and um , if you have a question about a homework , it 's  probably makes sense to ask somebody who 's in your class with you , sort of the guru in the certain area , rather than going to some Yahoo - like uh , search engine . So these are some of the  just in a nutshell , some of the ideas . And I think a lot of the  even though it 's a  it 's a very different domain , but I think a lot of the , um , issues are  are fairly similar . So . OK .\nAnd so some of the  I don't know how much you know about the larger Heidelberg project , I  Are you\nUh I know , yeah I know abou about it .\nSo it seems like a lot of  some of the issues are the same . It 's like , um , you know , the c context - based factors that influence how you interpret ,\nMm - hmm . Mm - hmm .\num , s how to interpret . In  in this case , infer in in knowing  wanting to know what kinds of things to ask . We - we 've kind of talked about that , but we haven't worried too much about that end of the discourse .\nMm - hmm .\nBut maybe you guys had that in the previous models .\nWell , in a  in one  t one s mmm , small difference in a  in a way , is that he doesn't have to come up with an answer , but he wants to point to the places w w\nDocuments that have the answers .\nYeah , so . So I 'm  I 'm not  I 'm not building an expert\nMm - hmm .\nUh , I want to build a smart librarian , basically\nRight . Right .\nthat can point you to the right reference . I don't wanna compute the answer , so it 's a little bit easier for me .\nWell . Uh , you have to s still m understand what the content says about itself , and then match it to what you think the informational needs\nMm - hmm .\nMm - hmm .\nSo you also don't have to figure out what the content is . You 're just taking the keywords as a topic text , as\nI  I assume that  that the there will be learning systems that  that tag their  their content .\nOK . Right .\nAnd um , um , m @ @ and basically what I  what I envision is that you  rather than just supplying a bunch of keywords you could basically  for  for an FAQ for example you could state sort of like a logic condition , when this document applies . So \" this document explains how to set up your uh , mail account on Linux \" or something like this .\nMm - hmm .\nSo . So something  something very specific that you can then  But the  I think that the key point with these uh , learning systems is that uh , a learning system is only as good as uh the amount of content it  it carries .\nMmm , mm - hmm .\nYou can have the best learning system with the best search interface , if there 's no content inside of it , it 's not very useful . So I think ultimately because um , uh developing these  these rules and these inference uh  inferences I think is very costly , so um , uh I think you must be able to reuse some  some existing um , domain  domain information , or  or  or ontologies that  that uh other people wrote and then try to integrate them , and then also search the entire web basically , rather than just the small uh , content management system .\nOK . Mm - hmm .\nSo I think that 's  that 's crucial for  for the success of  or @ @\nSo , you 're not  I guess I 'm trying to figure out how  how it maps to the kinds of things that we 've talked about in this group , and , actually associated groups ,\nMm - hmm .\ncuz some of us do pretty detailed linguistic analyses , and I 'm guessing that you  you won't be doing that ? OK .\nNo .\nJust checking . So ,  OK .\nHmm .\nNo .\nSo , you take the query , and  and\nOn the other hand , uh , FrameNet could well be useful . So do you know the FrameNet story ?\nUm , yeah . Uh , not  not too much ,\nOK .\nbut uh ,\nOh . Th - that 's another thing you might wanna look into while you 're here .\nI have a rough overview .\nBecause , um , you know , the standard story is that keyworks  keywords evoke frames , and the frames may well give you additional keywords or uh , if you know that  that  that a  a bunch of keywords uh , indicate a frame , then you can find documents that actually have the whole frame , rather th than just uh , individual\nMmm . Mmm .\nSo there 's a lot of stuff , and people are looking at that . Most of the work here is just trying to get the frames right . There 's linguists and stuff and there 's a lot of it and they 're  they 're busily working away . But there are some application efforts trying to exploit it . And this looks t it seems to be that this is a place where you might be able to do that .\nYeah . Yeah . Yeah . I 'm sure I could learn a lot about um , yeah , just how to  how to come up with these structures ,\nMmm .\ncuz it 's  it 's very easy to whip up something quickly , but it maybe then makes sense to  to me , but not to anybody else , and  and if we want to share and integrate things , they must  well , they must be well designed really .\nRemember the uh , Prashant story ?\nRight .\nThe absolutely no  no linguistic background person that the IU sent over here .\nRight .\nAnd Andreas and I tried to come up wi or we had come up actually with a eh  with him working on an interface for FrameNet , as it was back then , that would p do some of the work for this machine ,\nRight . Yeah .\nwhich uh , never got done because Prashant found a happy occupation\nW yeah , I know , I mean it  it  he  w he did w what  what he did was much more s sensible for him .\nwhich in the  Absolutely . Yeah .\nI think uh ,\nBut so  I 'm just saying , the uh , we had that idea\nyou know  Yeah . The idea was there . Yeah , OK .\nuh to  to exploit FrameNet there as well .\nYeah .\nHmm .\nAnd um .\nYeah , actually you guys never\nAnd Srini 's doing information extraction also , right ?\nRight .\nwith that FrameNet base .\nMmm .\nYeah .\nMm - hmm .\nSo you  you guys never sent anybody else from I U .\nExcept  except Prashant ?\nYou were y no  Yeah .\nUm ,\nUh , this was supposedly an exchange program , and  I  we  you know , it 's fine . We don't care , but it just  I 'm a little surprised that uh , Andreas didn't come up with anyone else he wanted to send .\nHmm .\nUh I don't know , I mean the uh\nAlright . I mean I had forgotten a I  To be honest with you , I 'd totally forgotten we had a program .\nUh it 's in the program ?\nUh I  I think it 's  it 's really the lack of students uh , at IU at the moment .\nYeah . Yeah . No , no . There was a whole co There was a little contract signed . It was  Yeah .\nYeah , yeah . I think it 's ju it 's more the lack of  of students , really , and w we have all these sponsors that are always sort of eager to get some teams .\nYeah , I know .\nMmm .\nRight .\nBut\nRight .\nWell I mean if  if I were a student , I 'd love to come here , rather than work for some German  {nonvocalsound} company , or\nYeah . Right .\nYou are being recorded right now , so beware .\nOh , right !\nWell , I didn't say anybody to  anything to offend  well , except for the sponsors maybe , but\nRight . Anyway . Right . So I thi tha that 's  that 's one of the things that might be worth looking into while you 're here .\nMm - hmm .\nUh , unfortunately , Srini , who is heavily involved in DAML and all this sort of stuff is himself out of town .\nMm - hmm . Well I 'll go to the uh , Semantic Web Workshop , uh , in two weeks .\nRight , and  Yeah , for  for some reason he 's not doing that .\nYeah . Well , he had other things to do .\nI don't know why he @ @  oh , I , who knows ?\nThe uh\nAnyway , s yeah , you 'll see  you 'll certainly see a lot of the people there .\nThe other person I thought of is Dan Gildea ? because he did some work on topic spotting\nYeah . St - statistical stuff . That would be a very good idea .\nw um , which is , I mean , you  I mean . I don't  Depending on how well you wanna integrate with that end ,\nMm - hmm .\nyou know , like , taking the data and fig you said the learning systems that figure out  We  There 's someone in ICSI who actually has been working on  has worked on that kinda stuff , and he 's worked with frame net , so you could talk to him about , you know , both of those things at once .\nMm - hmm . Mm - hmm .\nSo . And he just finished writing a draft of his thesis . So . I u  Dan Gildea , GILDEA .\nSo , uh , who is that again ?\nAnd , he 's in one of the rooms on the fifth floor and stuff ,\nWho ? I can take you to his office .\nand\nIt 's just around the corner .\nOK , great .\nHmm . Well , if you fal solve the problem ,  hope you can do one for us too .\nAlright , was there anything else for this ? One of these times soon we 're gonna hear about construal .\nYeah . I 'm sure . I have um  I think it was November two thousand three or some  No . Wh - I had something in my calendar .\nOh , OK . Right .\nUm ,\nWait a second . That 's a long way away .\nGood thinking !\nUh well , maybe I can  I can bribe my way out of this . So . So I did some double checking and it seems like spring break in two thousand  one .\nTalk about changing the topic .\nNo .\nWell , no , but he 's  he 's  he 's  he 's  as you said , he 's , like the state legislature , he 's trying to offer us bribes .\nAt least this is a private meeting . Right , exactly , OK , that 's the link .\nThis uh  Oh , they refused the budget again ? Is it  so about CITRIS ? Yeah , still nothing .\nUh , this  this  this  t the s we 're , uh , involved in a literally three hundred million dollar uh , program . Uh , with the State of California . And , the State of California is now a month and a half behind its legis its legally required date to approve a budget . So the budget has not been approved . And two days ago  There 's two l you know , so , two branches of legislature . One branch approved it ,\nMm - hmm .\nand , um , yesterdayday  there was this uh  uh I thought that the other branch would just approve it , but now there 's actually a little back sliding to people who  who approved it got flak from there , eh anyway . So , um  Oh ! I have to tell you a wonderful story about this , OK ? And then we 'll go . So , I  it turns out I wound up having lunch today with a guy named Tom Kalil . KILL  KALIL . And , uh , he now works at Berkeley . In fact he 's hired to run a lot of CITRIS , even though we don't have the money they  So they 've been hiring people right and left , so , uh , they think the money 's coming . So  and he was , I think , the chief staffer to Clinton on technology matters . He was in the White House , I don't remember what he was saying . A anyway , like that . And , is now doing all the politics for CITRIS , but also , has a uh , a lot of interest in uh , actually doing things for society , so digital divide and stuff like that . So that 's s interesting to me but maybe not to you . But the really interesting thing was , he st he s he s said something about , you know I 'm interested in things that have high social multiplier , something that is of great social value . He said , \" for example \" , this was his only example , \" if you had a adult literacy program that was as good as an individual tutor , and as compelling as a video game , then that would have a huge social impact \" . I said , \" Oh great ! That 's a good problem to work on . \" Anyway . So it was nice that uh , he 's got this view , of A , that 's what you should try to do , and B , uh , language would be a good way to do it .\nMmm . Definitely .\nSo that 's  So anyway , that 's the end of the story .\nBut for adults and not for the children .\nThis was  Yeah . I didn't push him on the ch on the child thing ,\nUh - huh .\nbut , uh , you know , a again , if  if you  if you\nOh .\num , and this was  this was literacy , which actually is somewhat different problem .\nMm - hmm .\nMaybe easier . I don't know . So this is reading , rather than teaching  Another project we started on , and  and didn't get funded for was , uh , to try to build an automatic tutoring program , for kids whose first language wasn't English . Which is like half the school population in California . Something like that ,\nMm - hmm .\nisn't it ? Yeah . So , enormous problem in California , and the idea was if we 're so smart about language understanding and speech understanding , couldn't we build  uh , programs that would be tutors for the kids . We think we could . Anyway . So  so  But this is a slightly different problem ,\nMm - hmm .\nand um , I know none of us have the spare time to look at it right now , but it i it 's  it 's interesting and I may um , talk to him some more about is em somebody already doing this , and stuff like that . So anyway , that was  that was today 's little story .\nHmm .\nOK . So I  I did manage to get  pull my head out of the sling by sidetracking into CITRIS ,\nNo , no .\nbut uh or  a temporarily putting it out of the sling\nRight .\nbut , I  I 'll volunteer to put it right back in by stating that I am n uh among some other things in the process of writing up stuff that we have been discussing at our daily meetings ,\nYeah .\nand also revising , thanks for all the comments , the c the original construal proposal . And , if I put one and one together , I may end up with a number that 's greater than one and that I  I can potentially present once you get back .\nGreater than two ?\nYou 're good .\nNnn .  s sometimes , you know the sum is not uh less than the\nUh , right , right .\nRight . Right . Anyway . Yeah , so  OK , so that 'd be great , but I 'd  I think it 's  it 's time again , right ?\nAbsolutely . Yeah .\nYeah . OK .\nBut um , and hopefully all sidetracking um , other things will have disappeared , soon .\nGood . Yep . Done ?", "topic_id": 2, "keywords": "discussing, overview, content, doing, begin", "dialogue_id": 9}, {"text": "OK . So uh , he 's not here ,\nSo .\nso you get to\nYeah , I will try to explain the thing that I did this  this week  during this week .\nYeah .\nWell eh you know that I work  I begin to work with a new feature to detect voice - unvoice .\nMm - hmm .\nWhat I trying two MLP to  to the  with this new feature and the fifteen feature uh from the eh bus base system\nThe  the mel cepstrum ?\nNo , satly the mes the Mel Cepstrum , the new base system  the new base system .\nOh the\nYeah , we\nOK , the Aurora system .\nyeah the Aurora system with the new filter , VAD or something like that .\nOK .\nAnd I 'm trying two MLP , one one that only have t three output , voice , unvoice , and silence ,\nMm - hmm .\nand other one that have fifty - six output . The probabilities of the allophone . And I tried to do some experiment of recognition with that and only have result with  with the MLP with the three output . And I put together the fifteen features and the three MLP output . And , well , the result are li a little bit better , but more or less similar .\nUh , I  I 'm  I 'm slightly confused .\nHmm .\nWhat  what feeds the uh  the three - output net ?\nVoice , unvoice , and si\nNo no , what feeds it ? What features does it see ?\nThe feature  the input ? The inputs are the fifteen  the fifteen uh bases feature .\nUh - huh .\nthe  with the new code . And the other three features are R , the variance of the difference between the two spectrum ,\nUh - huh .\nthe variance of the auto - correlation function , except the  the first point , because half the height value is R - zero\nMm - hmm . Mm - hmm . Mm - hmm . Mm - hmm .\nand also R - zero , the first coefficient of the auto - correlation function . That is like the energy with these three feature ,\nRight .\nalso these three feature .\nYou wouldn't do like R - one over R - zero or something like that ? I mean usually for voiced - unvoiced you 'd do  yeah , you 'd do something  you 'd do energy\nYeah .\nbut then you have something like spectral slope , which is you get like R - one ov over R - zero or something like that .\nUh yeah .\nWhat are the R 's ?\nR correlations .\nI 'm sorry I missed it .\nNo , R c No .\nOh .\nAuto - correlation ? Yes , yes , the variance of the auto - correlation function that uses that\nYe - Well that 's the variance , but if you just say \" what is  \" I mean , to first order , um yeah one of the differences between voiced , unvoiced and silence is energy . Another one is  but the other one is the spectral shape .\nYeah , I I 'll  The spectral shape ,\nYeah , and so R - one over R - zero is what you typically use for that .\nyeah . No , I don't use that  I can't use\nNo , I 'm saying that 's what people us typically use .\nMmm .\nSee , because it  because this is  this is just like a single number to tell you um \" does the spectrum look like that or does it look like that \" .\nMm - hmm .\nOh . R  R  R - zero .\nRight ?\nMm - hmm .\nSo if it 's  if it 's um  if it 's low energy uh but the  but the spectrum looks like that or like that , it 's probably silence .\nMm - hmm .\nUh but if it 's low energy and the spectrum looks like that , it 's probably unvoiced .\nYeah .\nSo if you just  if you just had to pick two features to determine voiced - unvoiced , you 'd pick something about the spectrum like uh R - one over R - zero , um and R - zero\nMm - hmm , OK .\nor i i you know you 'd have some other energy measure and like in the old days people did like uh zero crossing counts .\nYeah , yeah .\nRight . S S\nWell , I can also th use this .\nYeah . Um ,\nBec - because the result are a little bit better but we have in a point that everything is more or less the similar  more or less similar .\nYeah . But um\nIt 's not quite better .\nRight , but it seemed to me that what you were what you were getting at before was that there is something about the difference between the original signal or the original FFT and with the filter which is what  and the variance was one take uh on it .\nYeah , I used this too .\nRight . But it  it could be something else . Suppose you didn't have anything like that . Then in that case , if you have two nets , Alright , and this one has three outputs , and this one has f\nMm - hmm .\nwhatever , fifty - six , or something ,\nMm - hmm .\nif you were to sum up the probabilities for the voiced and for the unvoiced and for the silence here , we 've found in the past you 'll do better at voiced - unvoiced - silence than you do with this one . So just having the three output thing doesn't  doesn't really buy you anything . The issue is what you feed it .\nYeah . Yeah , I have  yeah .\nSo uh\nNo\nSo you 're saying take the features that go into the voiced - unvoiced - silence net and feed those into the other one , as additional inputs , rather than having a separate\nw W well that 's another way .\nYeah .\nThat wasn't what I was saying but yeah that 's certainly another thing to do . No I was just trying to say if you b if you bring this into the picture over this , what more does it buy you ?\nMmm .\nAnd what I was saying is that the only thing I think that it buys you is um based on whether you feed it something different . And something different in some fundamental way . And so the kind of thing that  that she was talking about before , was looking at something uh ab um  something uh about the difference between the  the uh um log FFT uh log power uh and the log magnitude uh F F - spectrum uh and the um uh filter bank .\nYeah .\nAnd so the filter bank is chosen in fact to sort of integrate out the effects of pitch and she 's saying you know trying  So the particular measure that she chose was the variance of this m of this difference , but that might not be the right number .\nMm - hmm . Maybe .\nRight ? I mean maybe there 's something about the variance that 's  that 's not enough or maybe there 's something else that  that one could use , but I think that , for me , the thing that  that struck me was that uh you wanna get something back here , so here 's  here 's an idea . uh What about it you skip all the  all the really clever things , and just fed the log magnitude spectrum into this ?\nAh  I 'm sorry .\nThis is f You have the log magnitude spectrum , and you were looking at that and the difference between the filter bank and  and c c computing the variance .\nYeah . Mm - hmm .\nThat 's a clever thing to do .\nMm - hmm .\nWhat if you stopped being clever ? And you just took this thing in here because it 's a neural net and neural nets are wonderful\nMm - hmm .\nand figure out what they can  what they most need from things , and I mean that 's what they 're good at .\nYeah .\nSo I mean you 're  you 're  you 're trying to be clever and say what 's the statistic that should  we should get about this difference but uh in fact , you know maybe just feeding this in or  or feeding both of them in\nHmm .\nyou know , another way , saying let it figure out what 's the  what is the interaction , especially if you do this over multiple frames ?\nMm - hmm .\nThen you have this over time , and  and both kinds of measures and uh you might get uh something better .\nMm - hmm .\nUm .\nSo  so don't uh  don't do the division , but let the net have everything .\nThat 's another thing you could do yeah . Yeah .\nYeah .\nUm . I mean , it seems to me , if you have exactly the right thing then it 's better to do it without the net because otherwise you 're asking the net to learn this  you know , say if you wanted to learn how to do multiplication .\nMm - hmm .\nI mean you could feed it a bunch of s you could feed two numbers that you wanted to multiply into a net and have a bunch of nonlinearities in the middle and train it to get the product of the output and it would work . But , it 's kind of crazy , cuz we know how to multiply and you  you 'd be you know much lower error usually  if you just multiplied it out . But suppose you don't really know what the right thing is . And that 's what these sort of dumb machine learning methods are good at . So . Um . Anyway . It 's just a thought .\nHow long does it take , Carmen , to train up one of these nets ?\nOh , not too much .\nYeah .\nMmm , one day or less .\nHmm .\nYeah , it 's probably worth it .\nWhat are  what are your f uh frame error rates for  for this ?\nEh fifty - f six uh no , the frame error rate ?\nO\nFifty - six I think .\nIs that  maybe that 's accuracy ?\nPercent .\nFif - fifty - six percent accurate for v voice - unvoice\nThe accuracy . Mm - hmm . No for , yes f I don't remember for voice - unvoice ,\nOh , OK .\nmaybe for the other one .\nOK .\nYeah , voiced - unvoiced hopefully would be a lot better .\nfor voiced . I don't reme\nShould be in nineties somewhere .\nBetter . Maybe for voice - unvoice .\nRight .\nThis is for the other one . I should  I can't show that .\nOK .\nBut I think that fifty - five was for the  when the output are the fifty - six phone .\nMm - hmm .\nThat I look in the  with the other  nnn the other MLP that we have are more or less the same number . Silence will be better but more or less the same .\nI think at the frame level for fifty - six that was the kind of number we were getting for  for uh um reduced band width uh stuff .\nI think that  I  I  I think that for the other one , for the three output , is sixty sixty - two , sixty three more or less .\nMm - hmm .\nThat 's all ?\nIt 's  Yeah .\nThat 's pretty bad .\nYeah , because it 's noise also .\nOh yeah .\nAha !\nAnd we have\nAha ! Yeah . Yeah . OK .\nI know .\nBut even i in  Oh yeah , in training . Still , Uh . Well actually , so this is a test that you should do then . Um , if you 're getting fifty - six percent over here , uh that 's in noise also , right ?\nYeah , yeah , yeah .\nOh OK . If you 're getting fifty - six here , try adding together the probabilities of all of the voiced phones here and all of the unvoiced phones\nwill be\nand see what you get then .\nYeah .\nI bet you get better than sixty - three .\nWell I don't know , but  I th I  I think that we  I have the result more or less . Maybe . I don't know . I don't  I 'm not sure but I remember @ @ that I can't show that .\nOK , but that 's a  That is a  a good check point , you should do that anyway ,\nYeah .\nOK ? Given this  this uh regular old net that 's just for choosing for other purposes , uh add up the probabilities of the different subclasses and see  see how well you do . Uh and that  you know anything that you do over here should be at least as good as that .\nMm - hmm .\nOK .\nI will do that . But\nThe targets for the neural net , uh , they come from forced alignments ?\nUh ,  no .\nTIMIT canonical ma mappings .\nTIMIT .\nOh . So , this is trained on TIMIT .\nAh ! OK .\nYeah , noisy TIMIT .\nYeah .\nOK .\nYeah this for TIMIT .\nBut noisy TIMIT ?\nRight .\nNoisy TIMIT . We have noisy TIMIT with the noise of the  the TI - digits . And now we have another noisy TIMIT also with the noise of uh Italian database .\nI see . Yeah . Well there 's gonna be  it looks like there 's gonna be a noisy uh  some large vocabulary noisy stuff too . Somebody 's preparing .\nReally ?\nYeah . I forget what it 'll be , resource management , Wall Street Journal , something . Some  some read task actually , that they 're  preparing .\nHmm !\nFor what  For Aurora ?\nYeah .\nOh !\nYeah , so the uh  Uh , the issue is whether people make a decision now based on what they 've already seen , or they make it later . And one of the arguments for making it later is let 's make sure that whatever techniques that we 're using work for something more than  than connected digits .\nHmm .\nSo .\nWhen are they planning  When would they do that ?\nMmm , I think late  uh I think in the summer sometime .\nHmm .\nSo . OK , thanks .", "topic_id": 0, "keywords": "mlp, aurora, detect, recognition, feature", "dialogue_id": 10}, {"text": "This is the work that I did during this date\nUh - huh .\nand also mmm I  H Hynek last week say that if I have time I can to begin to  to study well seriously the France Telecom proposal\nMm - hmm .\nto look at the code and something like that to know exactly what they are doing because maybe that we can have some ideas\nMm - hmm .\nbut not only to read the proposal . Look insi look i carefully what they are doing with the program @ @ and I begin to  to work also in that . But the first thing that I don't understand is that they are using R - the uh log energy that this quite  I don't know why they have some constant in the expression of the lower energy . I don't know what that means .\nThey have a constant in there , you said ?\nYeah .\nOh , at the front it says uh \" log energy is equal to the rounded version of sixteen over the log of two \"\nThis  Yeah .\nUh . uh times the\nThen maybe I can understand .\nWell , this is natural log , and maybe it has something to do with the fact that this is  I  I have no idea .\nIs that some kind of base conversion , or  ?\nYeah , that 's what I was thinking , but  but um , then there 's the sixty - four , Uh ,  I don't know .\nBecause maybe they 're  the threshold that they are using on the basis of this value\nExperimental results .\nMc - McDonald 's constant .\nI don't know exactly , because well th I thought maybe they have a meaning . But I don't know what is the meaning of take exactly this value .\nYeah , it 's pretty funny looking .\nSo they 're taking the number inside the log and raising it to sixteen over log base two .\nI don't know . Yeah , I  um Right . Sixteen over  two .\nDoes it have to do with those sixty - fours , or  ?\nUm . If we ignore the sixteen , the natural log of t one over the natural log of two times the natu I don't know . Well , maybe somebody 'll think of something ,\nbut this is uh  It may just be that they  they want to have  for very small energies , they want to have some kind of a\nYeah , the e The effect I don't  @ @ I can understand the effect of this , no ? because it 's to  to do something like that .\nWell , it says , since you 're taking a natural log , it says that when  when you get down to essentially zero energy , this is gonna be the natural log of one , which is zero .\nNo ? Mm - hmm .\nSo it 'll go down to uh to {nonvocalsound} the natural log being  So the lowest value for this would be zero . So y you 're restricted to being positive . And this sort of smooths it for very small energies . Uh , why they chose sixty - four and something else , that was probably just experimental . And the  the  the constant in front of it , I have no idea .\nYeah .\num\nWell . I  I will look to try if I move this parameter in their code what happens , maybe everything is  Maybe they tres hole are on basis of this .\nuh  I mean  it   they  they probably have some fi particular s fixed point arithmetic that they 're using ,\nI don't know .\nand then it just\nYeah , I was just gonna say maybe it has something to do with hardware ,\nYeah .\nsomething they were doing .\nYeah , I mean that  they 're s probably working with fixed point or integer or something . I think you 're supposed to on this stuff anyway , and  and so maybe that puts it in the right realm somewhere .\nWell it just , yeah , puts it in the right range , or\nYeah . I think , given at the level you 're doing things in floating point on the computer , I don't think it matters , would be my guess ,\nMm - hmm .\nbut .\nI  this more or less anything\nYeah . OK , and wh when did Stephane take off ? He took off\nI think that Stephane will arrive today or tomorrow .\nOh , he was gone these first few days , and then he 's here for a couple days before he goes to Salt Lake City .\nMm - hmm .\nOK .\nHe 's  I think that he is in Las Vegas or something like that .\nYeah . Yeah . So he 's  he 's going to ICASSP which is good . I  I don't know if there are many people who are going to ICASSP\nYeah .\nso  so I thought , make sure somebody go .\nYeah .\nDo  have  Have people sort of stopped going to ICASSP in recent years ?\nUm , people are less consistent about going to ICASSP and I think it 's still  it 's still a reasonable forum for students to  to present things . Uh , it 's  I think for engineering students of any kind , I think it 's  it 's if you haven't been there much , it 's good to go to , uh to get a feel for things , a range of things , not just speech . Uh . But I think for  for sort of dyed - in - the - wool speech people , um I think that ICSLP and Eurospeech are much more targeted .\nMm - hmm .\nUh . And then there 's these other meetings , like HLT and  and uh ASRU\nso there 's  there 's actually plenty of meetings that are really relevant to  to uh computational uh speech processing of one sort or another .\nMm - hmm .", "topic_id": 1, "keywords": "energy, energies, log, base, conversion", "dialogue_id": 10}, {"text": "Um . So . I mean , I mostly just ignored it because I was too busy and  didn't get to it . So uh Wanna talk a little bit about what we were talking about this morning ?\nOh ! um  uh  Yeah .\nJust briefly , or  Or anything else ?\nSo . I  I guess some of the progress , I  I 've been getting a  getting my committee members for the quals . And um so far I have Morgan and Hynek ,  Mike Jordan , and I asked John Ohala and he agreed . Yeah . Yeah .\nCool .\nSo I 'm  I  I just need to ask um Malek . One more . Um . Tsk . Then uh I talked a little bit about  um continuing with these dynamic ev um acoustic events , and um   we 're  we 're  we 're  thinking about a way to test the completeness of a  a set of um dynamic uh events . Uh , completeness in the  in the sense that  um if we  if we pick these X number of acoustic events ,  do they provide sufficient coverage  for the phones that we 're trying to recognize  or  or the f the words that we 're gonna try to recognize later on . And so Morgan and I were uh discussing  um s uh s a form of a cheating experiment  where we get   um we have uh  um a chosen set of features , or acoustic events , and we train up a hybrid  um system to do phone recognition on TIMIT . So i i the idea is if we get good phone recognition results ,  using um these set of acoustic events ,  then  um that  that says that these acoustic events are g sufficient to cover  a set of phones , at least found in TIMIT . Um so i it would be a   a measure of \" are we on the right track with  with the  the choices of our acoustic events \" . Um ,  So that 's going on . And  also , just uh working on my  uh final project for Jordan 's class , uh which is\nActually , let me\nYeah .\nHold that thought .\nOK , sure .\nLet me back up while we 're still on it . The  the other thing I was suggesting , though , is that given that you 're talking about binary features , uh , maybe the first thing to do is just to count and uh count co - occurrences and get probabilities for a discrete HMM cuz that 'd be pretty simple because it 's just  Say , if you had ten  ten events , uh that you were counting , uh each frame would only have a thousand possible values for these ten bits , and uh so you could make a table that would  say , if you had thirty - nine phone categories , that would be a thousand by thirty - nine , and just count the co - occurrences and divide them by the  the uh  uh uh occ uh count the co - occurrences between the event and the phone and divide them by the number of occurrences of the phone , and that would give you the likelihood of the  of the event given the phone . And um then just use that in a very simple HMM and uh you could uh do phone recognition then and uh wouldn't have any of the issues of the uh training of the net or  I mean , it 'd be on the simple side , but\nMm - hmm .\nuh um you know , if  uh uh the example I was giving was that if  if you had um onset of voicing and  and end of voicing as being two kinds of events , then if you had those a all marked correctly , and you counted co - occurrences , you should get it completely right .\nMm - hmm .\nSo . um  But you 'd get all the other distinctions , you know , randomly wrong . I mean there 'd be nothing to tell you that . So um  uh If you just do this by counting , then you should be able to find out in a pretty straightforward way whether you have a sufficient uh set of events to  to do the kind of level of   of uh classification of phones that you 'd like . So that was  that was the idea . And then the other thing that we were discussing was  was um  OK , how do you get the  your training data .\nMm - hmm .\nCuz uh the  Switchboard transcription project uh uh you know was half a dozen people , or so working off and on over a couple years , and uh similar   similar amount of data  to what you 're talking about with TIMIT training . So , it seems to me that the only reasonable starting point is uh to automatically translate the uh current TIMIT markings into the markings you want . And uh  it won't have the kind of characteristic that you 'd like , of catching funny kind of things that maybe aren't there from these automatic markings ,\nMm - hmm .\nbut  but uh it 's uh\nIt 's probably a good place to start .\nYeah .\nYeah .\nYeah and a short  short amount of time , just to  again , just to see if that information is sufficient to uh determine the phones .\nMm - hmm . Hmm .\nSo .\nYeah , you could even then  to  to get an idea about how different it is , you could maybe take some subset and you know , go through a few sentences , mark them by hand and then see how different it is from you know , the canonical ones ,\nRight .\njust to get an idea  a rough idea of h if it really even makes a difference .\nYou can get a little feeling for it that way , yeah that is probably right .\nYeah .\nI mean uh my  my guess would be that this is  since TIMIT 's read speech that this would be less of a big deal ,\nMm - hmm .\nif you went and looked at spontaneous speech it 'd be more  more of one .\nRight . Right .\nAnd the other thing would be , say , if you had these ten events , you 'd wanna see , well what if you took two events or four events or ten events or t and you know , and  and hopefully there should be some point at which  having more information doesn't tell you really all that much more about what the phones are .\nMm - hmm . You could define other events as being sequences of these events too .\nUh , you could , but the thing is , what he 's talking about here is a uh  a translation to a per - frame feature vector , so there 's no sequence in that , I think . I think it 's just a\nUnless you did like a second pass over it or something after you 've got your\nYeah , but we 're just talking about something simple here , yeah , to see if\nYeah . Yeah , yeah . Yeah . I 'm adding complexity .\nYeah . Just  You know . The idea is with a  with a very simple statistical structure , could you  could you uh at least verify that you 've chosen features that  are sufficient .\nYeah .", "topic_id": 2, "keywords": "events, event, discussing, acoustic, briefly", "dialogue_id": 10}, {"text": "OK , and you were saying something  starting to say something else about your  your class project , or  ?\nOh . Yeah th Um .\nYeah .\nSo for my class project I 'm  um   I 'm tinkering with uh support vector machines ? something that we learned in class , and uh um basically just another method for doing classification . And so I 'm gonna apply that to  um compare it with the results by um King and Taylor who did  um these um using recurrent neural nets , they recognized  um  a set of phonological features um and made a mapping from the MFCC 's to these phonological features , so I 'm gonna  do a similar thing with   with support vector machines and see if\nSo what 's the advantage of support vector machines ? What\nUm . So , support vector machines are  are good with dealing with a less amount of data\nHmm .\nand um so if you  if you give it less data it still does a reasonable job  in learning the  the patterns .\nHmm .\nUm and  um\nI guess it  yeah , they 're sort of succinct , and  and they  uh\nYeah .\nDoes there some kind of a distance metric that they use or how do they  for cla what do they do for classification ?\nUm . Right . So ,  the  the simple idea behind a support vector machine is  um ,  you have  you have this feature space , right ? and then it finds the optimal separating plane , um between these two different um classes ,\nMm - hmm . Mm - hmm . Mm - hmm .\nand um  and so  um , what it  i at the end of the day , what it actually does is  it picks  those examples of the features that are closest to the separating boundary , and remembers those\nMm - hmm .\nand   and uses them to recreate the boundary for the test set . So , given these  um these features , or  or these  these examples ,  um ,  critical examples ,  which they call support f support vectors ,  then um  given a new example ,  if the new example falls  um away from the boundary in one direction then it 's classified as being a part of this particular class\nOh .\nand otherwise it 's the other class .\nSo why save the examples ? Why not just save what the boundary itself is ?\nMm - hmm . Um . Hmm . Let 's see . Uh . Yeah , that 's a good question . I  yeah .\nThat 's another way of doing it . Right ? So  so it  I mean I  I guess it 's\nMmm . Sort of an equivalent .\nYou know , it  it goes back to nearest - neighbor  sort of thing ,\nMm - hmm .\nright ? Um , i i if  is it eh w When is nearest - neighbor good ? Well , nearest - neighbor good  is good if you have lots and lots of examples . Um but of course if you have lots and lots of examples , then it can take a while to  to use nearest - neighbor . There 's lots of look ups . So a long time ago people talked about things where you would have uh a condensed nearest - neighbor , where you would  you would  you would pick out uh some representative examples which would uh be sufficient to represent  to  to correctly classify everything that came in .\nOh . Mm - hmm .\nI  I think s I think support vector stuff sort of goes back to   to that kind of thing . Um .\nI see . So rather than doing nearest neighbor where you compare to every single one , you just pick a few critical ones , and\nYeah .\nHmm .\nAnd th the You know , um neural net approach uh or Gaussian mixtures for that matter are sort of  fairly brute force kinds of things , where you sort of   you predefine that there is this big bunch of parameters and then you  you place them as you best can to define the boundaries , and in fact , as you know ,  these things do take a lot of parameters and  and uh  if you have uh only a modest amount of data , you have trouble  uh learning them . Um , so I  I guess the idea to this is that it  it is reputed to uh be somewhat better in that regard .\nMm - hmm .\nRight . I it can be a  a reduced um  parameterization of  of the  the model by just keeping  certain selected examples .\nHmm .\nYeah . So .\nBut I don't know if people have done sort of careful comparisons of this on large tasks or anything . Maybe  maybe they have . I don't know .\nYeah , I don't know either .\nYeah .\nS do you get some kind of number between zero and one at the output ?\nActually you don't get a  you don't get a nice number between zero and one . You get  you get either a zero or a one . Um , uh there are  there are pap Well , basically , it 's  it 's um  you  you get a distance measure at the end of the day , and then that distance measure is  is um   is translated to a zero or one . Um .\nBut that 's looking at it for  for classification  for binary classification ,\nThat 's for classification , right .\nright ?\nAnd you get that for each class , you get a zero or a one .\nRight .\nBut you have the distances to work with .\nYou have the distances to work with ,\nCuz actually Mississippi State people did use support vector machines for uh uh speech recognition and they were using it to estimate probabilities .\nyeah . Yeah . Yeah , they   they had a  had a way to translate the distances into  into probabilities with the  with the simple  um  uh sigmoidal function .\nYeah , and d did they use sigmoid or a softmax type thing ?\nUm   Yeah ,\nAnd didn't they like exponentiate or something\nthere 's some  there 's like one over one plus the exponential or something like that .\nand then  divide by the sum of them , or  ? Oh it  i Oh , so it is a sigmoidal .\nYeah .\nOK . Alright .\nDid the  did they get good results with that ?\nI mean , they 're OK , I  I don't  I don't think they were earth  earth shattering , but I think that  uh this was a couple years ago ,\nHmm .\nI remember them doing it at some meeting , and  and um I don't think people were very critical because it was interesting just to  to try this and you know , it was the first time they tried it , so   so the  you know , the numbers were not incredibly good\nHmm .\nbut there 's you know , it was th reasonable .\nMm - hmm .\nI  I don't remember anymore . I don't even remember what the task was , it  was Broadcast News , or  something . I don't know .\nHmm .\nRight .\nUh s So Barry , if you just have zero and ones , how are you doing the speech recognition ?\nOh I 'm not do I 'm not planning on doing speech recognition with it . I 'm just doing  detection of phonological features .\nOh . OK .\nSo uh for example ,  this  this uh feature set called the uh sound patterns of English  um is just a bunch of  um  binary valued features . Let 's say , is this voicing , or is this not voicing , is this  sonorants , not sonorants , and  stuff like that .\nOK .\nSo .\nDid you find any more mistakes in their tables ?\nOh ! Uh I haven't gone through the entire table ,  yet . Yeah , yesterday I brought Chuck  the table and I was like , \" wait , this  is  Is the mapping from N to  to this phonological feature called um \" coronal \" , is  is  should it be  shouldn't it be a one ? or should it  should it be you know coronal instead of not coronal as it was labelled in the paper ? \" So I ha haven't hunted down all the  all the mistakes yet ,\nUh - huh .\nbut\nBut a as I was saying , people do get probabilities from these things ,\nOK .\nand  and uh we were just trying to remember how they do , but people have used it for speech recognition , and they have gotten probabilities . So they have some conversion from these distances to probabilities .\nOK .\nRight , yeah .\nThere 's  you have  you have the paper , right ? The Mississippi State paper ?\nMm - hmm . Mm - hmm .\nYeah , if you 're interested y you could look ,\nAnd  OK . OK .\nYeah , I can  I can show you  I\nyeah .\nyeah , our\nSo in your  in  in the thing that you 're doing , uh you have a vector of ones and zeros for each phone ?\nMm - hmm . Uh , is this the class project , or  ?\nYeah .\nOK . um\nIs that what you 're\nRight ,  Right , right f so for every phone there is  there is a um  a vector of ones and zeros  f uh corresponding to whether it exhibits a particular phonological feature or not .\nMm - hmm . Mm - hmm . And so when you do your wh I 'm  what is the task for the class project ? To come up with the phones ?\nUm\nor to come up with these vectors to see how closely they match the phones ,\nOh . Right , um to come up with a mapping from um MFCC 's or s some feature set ,  um to  uh w to whether there 's existence of a particular phonological feature .\nor  ? Mm - hmm .\nAnd um yeah , basically it 's to learn a mapping  from   from the MFCC 's to  uh phonological features . Is it  did that answer your question ?\nI think so .\nOK . C\nI guess  I mean , uh  I 'm not sure what you  what you 're  what you get out of your system . Do you get out a uh  a vector of these ones and zeros and then try to find the closest matching phoneme to that vector ,\nMm - hmm . Oh .\nor  ?\nNo , no . I 'm not  I 'm not planning to do any  any phoneme mapping yet . Just   it 's  it 's basically  it 's  it 's really simple , basically a detection  of phonological features .\nUh - huh .\nYeah ,\nI see .\nand um   cuz the uh  So King and  and Taylor  um did this with uh recurrent neural nets ,\nYeah .\nand this i their  their idea was to first find  a mapping from MFCC 's to  uh phonological features\nMm - hmm .\nand then later on , once you have these  phonological features ,  then uh map that to phones .\nMm - hmm .\nSo I 'm  I 'm sort of reproducing phase one of their stuff .\nMmm . So they had one recurrent net for each particular feature ?\nRight . Right . Right . Right .\nI see . I wo did they compare that  I mean , what if you just did phone recognition and did the reverse lookup .\nUh .\nSo you recognize a phone and which ever phone was recognized , you spit out it 's vector of ones and zeros .\nMm - hmm . Uh .\nI expect you could do that .\nI mean uh\nThat 's probably not what he 's going to do on his class project . Yeah .\nYeah . No .\nYeah .", "topic_id": 3, "keywords": "classification, classify, phonological, classes, recognition", "dialogue_id": 10}, {"text": "So um have you had a chance to do this um thing we talked about yet with the uh  um\nInsertion penalty ?\nUh . No actually I was going a different  That 's a good question , too , but I was gonna ask about the   the um  changes to the data in comparing PLP and mel cepstrum for the SRI system .\nUh . Well what I 've been  \" Changes to the data \" , I 'm not sure I\nRight . So we talked on the phone about this , that  that there was still a difference of a  of a few percent\nYeah . Right .\nand  you told me that there was a difference in how the normalization was done . And I was asking if you were going to do   redo it uh for PLP with the normalization done as it had been done for the mel cepstrum .\nMm - hmm . Uh right , no I haven't had a chance to do that .\nOK .\nWhat I 've been doing is  uh  trying to figure out  it just seems to me like there 's a um  well it seems like there 's a bug , because the difference in performance is  it 's not gigantic but it 's big enough that it  it seems wrong .\nYeah , I agree , but I thought that the normalization difference was one of the possibilities ,\nand  Yeah , but I don't  I 'm not\nright ?\nYeah , I guess I don't think that the normalization difference is gonna account for everything .\nOK .\nSo what I was working on is um just going through and checking the headers of the wavefiles , to see if maybe there was a um  a certain type of compression or something that was done that my script wasn't catching . So that for some subset of the training data , uh the  the  the features I was computing were junk .\nOK .\nWhich would you know cause it to perform OK , but uh , you know , the  the models would be all messed up . So I was going through and just double - checking that kind of think first , to see if there was just some kind of obvious bug in the way that I was computing the features .\nMm - hmm . I see . OK .\nLooking at all the sampling rates to make sure all the sampling rates were what  eight K , what I was assuming they were ,\nYeah .\num\nYeah , that makes sense , to check all that .\nYeah . So I was doing that first , before I did these other things , just to make sure there wasn't something\nAlthough really , uh uh , a couple three percent uh difference in word error rate uh  could easily come from some difference in normalization , I would think . But\nYeah , and I think , hhh   I 'm trying to remember but I think I recall that Andreas was saying that he was gonna run sort of the reverse experiment . Uh which is to try to emulate the normalization that we did but with the mel cepstral features . Sort of , you know , back up from the system that he had . I thought he said he was gonna  I have to look back through my  my email from him .\nYeah , he 's probably off at  at uh his meeting now ,\nYeah , he 's gone now .\nyeah .\nUm .\nYeah . But yeah\nBut\nthe  I sh think they should be  roughly equivalent , um I mean again the Cambridge folk found the PLP actually to be a little better . Uh So it 's   um\nRight .\nI mean the other thing I wonder about was whether there was something just in the  the bootstrapping of their system which was based on  but maybe not , since they\nYeah see one thing that 's a little bit um  I was looking  I 've been studying and going through the logs for the system that um Andreas created . And um his uh  the way that the    S R I system looks like it works is that it reads the wavefiles directly , uh and does all of the cepstral computation stuff on the fly .\nRight . Right .\nAnd , so there 's no place where these  where the cepstral files are stored , anywhere that I can go look at and compare to the PLP ones , so whereas with our features , he 's actually storing the cepstrum on disk , and he reads those in .\nRight .\nBut it looked like he had to give it  uh even though the cepstrum is already computed , he has to give it uh a front - end parameter file . Which talks about the kind of uh com computation that his mel cepstrum thing does ,\nUh - huh .\nso i I  I don't know if that  it probably doesn't mess it up , it probably just ignores it if it determines that it 's already in the right format or something but  the  the  the two processes that happen are a little different .\nYeah .\nSo .\nSo anyway , there 's stuff there to sort out .\nYeah . Yeah .\nSo , OK . Let 's go back to what you thought I was asking you .\nYeah no and I didn't have a chance to do that .\nHa ! Oh ! You had the sa same answer anyway .\nYeah . Yeah . I 've been um ,  I 've been working with um Jeremy on his project and then I 've been trying to track down this bug in uh the ICSI front - end features .\nUh - huh .\nSo one thing that I did notice , yesterday I was studying the um  the uh RASTA code\nUh - huh .\nand it looks like we don't have any way to um control the frequency range that we use in our analysis . We basically  it looks to me like we do the FFT , um and then we just take all the bins and we use everything . We don't have any set of parameters where we can say you know , \" only process from you know a hundred and ten hertz to thirty - seven - fifty \" .\nUm\nAt least I couldn't see any kind of control for that .\nYeah , I don't think it 's in there , I think it 's in the uh uh uh the filters . So , the F F T is on everything , but the filters um , for instance , ignore the  the lowest bins and the highest bins . And what it does is it  it copies\nThe  the filters ? Which filters ?\num The filter bank which is created by integrating over F F T bins .\nMm - hmm .\num\nWhen you get the mel  When you go to the mel scale .\nRight . Yeah , it 's bark scale , and it 's  it  it um  it actually copies the uh um  the second filters over to the first . So the first filters are always  and you can s you can specify a different number of  uh features  different number of filters , I think , as I recall . So you can specify a different number of filters , and whatever  um uh you specify , the last ones are gonna be ignored . So that  that 's a way that you sort of change what the  what the bandwidth is . Y you can't do it without I think changing the number of filters , but\nI saw something about uh  that looked like it was doing something like that , but I didn't quite understand it . So maybe\nYeah , so the idea is that the very lowest frequencies and  and typically the veriest  highest frequencies are kind of junk .\nUh - huh .\nAnd so um you just  for continuity you just approximate them by   by the second to highest and second to lowest . It 's just a simple thing we put in .\nMm - hmm .\nAnd  and so if you h\nBut  so the  but that 's a fixed uh thing ?\nYeah ,  I think that 's a fixed thing .\nThere 's nothing that lets you\nBut see  see my point ? If you had   If you had ten filters ,  then you would be throwing away a lot at the two ends .\nMm - hmm .\nAnd if you had  if you had fifty filters , you 'd be throwing away hardly anything .\nMm - hmm .\nUm , I don't remember there being an independent way of saying \" we 're just gonna make them from here to here \" .\nUse this analysis bandwidth or something .\nBut I  I  I don't know , it 's actually been awhile since I 've looked at it .\nYeah , I went through the Feacalc code and then looked at you know just calling the RASTA libs  and thing like that . And I didn't  I couldn't see any wh place where that kind of thing was done . But um I didn't quite understand everything that I saw ,\nYeah , see I don't know Feacalc at all .\nso  Mm - hmm .\nBut it calls RASTA with some options , and um\nRight .\nBut I  I think in  I don't know . I guess for some particular database you might find that you could tune that and tweak that to get that a little better , but I think that  in general it 's not that critical . I mean there 's\nYeah .\nYou can  You can throw away stuff below a hundred hertz or so and it 's just not going to affect phonetic classification at all .\nAnother thing I was thinking about was um is there a  I was wondering if there 's maybe um  certain settings of the parameters when you compute PLP which would basically cause it to output mel cepstrum . So that , in effect , what I could do is use our code but produce mel cepstrum and compare that directly to\nWell , it 's not precisely . Yeah . I mean ,\nHmm .\num ,  um what you can do is um you can definitely change the  the filter bank from being uh a uh trapezoidal integration to a  a  a triangular one ,\nMm - hmm .\nwhich is what the typical mel  mel cepstral uh filter bank does .\nMm - hmm .\nAnd some people have claimed that they got some better performance doing that , so you certainly could do that easily . But the fundamental difference , I mean , there 's other small differences\nThere 's a cubic root that happens , right ?\nYeah , but , you know , as opposed to the log in the other case . I mean  the fundamental d d difference that we 've seen any kind of difference from before , which is actually an advantage for the P L P i uh , I think , is that the  the smoothing at the end is auto - regressive instead of being cepstral  uh ,  from cepstral truncation . So um it 's a little more noise robust .\nHmm .\nUm , and that 's  that 's why when people started getting databases that had a little more noise in it , like  like uh um Broadcast News and so on , that 's why c Cambridge switched to PLP I think .\nMm - hmm .\nSo um That 's a difference that I don't  think we put any way to get around , since it was an advantage . um  uh\nMm - hmm .\nbut we did  eh we did hear this comment from people at some point , that  um it uh they got some better results with the triangular filters rather than the trapezoidal . So that is an option in RASTA .\nHmm .\nUh and you can certainly play with that . But I think you 're probably doing the right thing to look for bugs first . I don't know .\nYeah just  it just seems like this kind of behavior could be caused by you know s some of the training data being messed up .\nCould be .\nYou know , you 're sort of getting most of the way there , but there 's a  So I started going through and looking  One of the things that I did notice was that the um log likelihoods coming out of the log recognizer from the PLP data were much lower , much smaller , than for the mel cepstral stuff , and that the average amount of pruning that was happening was therefore a little bit higher for the PLP features .\nOh - huh !\nSo , since he used the same exact pruning thresholds for both , I was wondering if it could be that we 're getting more pruning .\nOh ! He  he   He used the identical pruning thresholds even though the s the range of p of the likeli\nYeah .\nOh well that 's   That 's a pretty good  point right there .\nRight . Right .\nYeah .\nYeah ,\nI would think that you might wanna do something like uh you know , look at a few points to see where you are starting to get significant search errors .\nso  That 's  Right . Well , what I was gonna do is I was gonna take um a couple of the utterances that he had run through , then run them through again but modify the pruning threshold and see if it you know , affects the score .\nYeah . Yeah . But I mean you could  uh if  if  if that looks promising you could , you know , r uh run  the overall test set with a  with a few different uh pruning thresholds for both ,\nSo . Mm - hmm .\nand presumably he 's running at some pruning threshold that 's  that 's uh , you know  gets very few search errors\nRight .\nbut is  is relatively fast\nMm - hmm . Right . I mean , yeah , generally in these things you  you turn back pruning really far ,\nand\nso I  I didn't think it would be that big a deal because I was figuring well you have it turned back so far that you know it\nBut you may be in the wrong range for the P L P features for some reason .\nYeah . Yeah . Yeah . And the uh the  the run time of the recognizer on the PLP features is longer which sort of implies that the networks are bushier , you know , there 's more things it 's considering which goes along with the fact that the matches aren't as good . So uh , you know , it could be that we 're just pruning too much .\nYeah .\nSo .\nYeah , maybe just be different kind of distributions and  and\nMm - hmm .\nyeah so that 's another possible thing . They  they should  really shouldn't\nMm - hmm .\nThere 's no particular reason why they would be exactly  behave exactly the same .\nMm - hmm . Right . Right .\nSo .\nSo . There 's lots of little differences .\nYeah .\nSo . Uh .\nYeah .\nTrying to track it down .\nYeah . I guess this was a little bit off topic , I guess , because I was  I was thinking in terms of th this as being a  a  a  a core  item that once we  once we had it going we would use for a number of the front - end things also .\nYeah\nSo .\nMm - hmm .\num Wanna\nThat 's  as far as my stuff goes ,", "topic_id": 4, "keywords": "plp, normalization, cepstral, performance, cepstrum", "dialogue_id": 10}, {"text": "What 's  what 's on\nyeah , well I  tried this mean subtraction method .\nYeah .\nUm . Due to Avendano ,  I 'm taking s um  six seconds of speech , um  I 'm using two second  FFT analysis frames ,  stepped by a half second so it 's a quarter length step and I   I take that frame and four f the four  I take  Sorry , I take the current frame and the four past frames and the  four future frames and that adds up to six seconds of speech . And I calculate um  the spectral mean ,  of the log magnitude spectrum  over that N . I use that to normalize the s the current center frame  by mean subtraction . And I then  then I move to the next frame and I   I do it again . Well , actually I calculate all the means first and then I do the subtraction . And um  the  I tried that with HDK , the Aurora setup of HDK training on clean TI - digits , and um  it  it helped um in a phony reverberation case um  where I just used the simulated impulse response um  the error rate went from something like eighty it was from something like eighteen percent  to um four percent . And on meeting rec recorder far mike digits , mike  on channel F , it went from um   forty - one percent error to eight percent error .\nOn  on the real data , not with artificial reverb ?\nRight .\nUh - huh .\nAnd that  that was um  trained on clean speech only , which I 'm guessing is the reason why the baseline was so bad . And\nThat 's ac actually a little side point is I think that 's the first results that we have uh uh uh of any sort on the far field uh  on  on the far field data uh for  recorded in  in meetings .\nOh um actually um Adam ran the SRI recognizer .\nDid he ? On the near field , on the ne\nOn the far field also . He did one PZM channel and one PDA channel .\nOh did he ? Oh ! I didn't recall that . What kind of numbers was he getting with that ?\nI   I 'm not sure , I think it was about five percent error for the PZM channel .\nFive .\nf I think . Yeah .\nSo why were you getting forty - one here ? Is this\nUm . I  I 'm g I 'm guessing it was the  the training data . Uh , clean TI - digits is , like , pretty pristine  training data , and if they trained  the SRI system on this TV broadcast type stuff , I think it 's a much wider range of channels and it\nNo , but wait a minute . I  I  I th  I think he  What am I saying here ? Yeah , so that was the SRI system . Maybe you 're right . Yeah . Cuz it was getting like one percent   So it 's still this kind of ratio . It was  it was getting one percent or something on the near field . Wasn't it ?\nMm - hmm , or it wa a it was around one .\nYeah . Yeah . I think it was getting around one percent for the near  for the n for the close mike .\nYeah .\nHuh ? OK .\nSo it was like one to five  So it 's still this kind of ratio . It 's just  yeah , it 's a lot more training data . So So probably it should be something we should try then is to  is to see if  is  at some point just to take  i to transform the data and then   and then uh use th use it for the SRI system .\nb You me you mean um ta\nSo you 're  so you have a system which for one reason or another is relatively poor ,\nYeah .\nand  and uh you have something like forty - one percent error uh and then you transform it to eight by doing  doing this  this work . Um . So here 's this other system , which is a lot better , but there 's still this kind of ratio . It 's something like five percent error  with the  the distant mike , and one percent with the close mike .\nOK .\nSo the question is  how close to that one can you get  if you transform the data using that system .\nr Right , so  so I guess this SRI system is trained on a lot of s Broadcast News or Switchboard data . Is that right ?\nYeah .\nDo you know which one it is ?\nIt 's trained on a lot of different things . Um . It 's trained on uh a lot of Switchboard , Call Home ,\nUh - huh .\num a bunch of different sources , some digits , there 's some digits training in there .\nOK .\nHmm .\nO one thing I 'm wondering about is what this mean subtraction method  um will do if it 's faced with additive noise . Cuz I  I  it 's cuz I don't know what log magnitude spectral subtraction is gonna do to additive noise .\nYeah ,\nThat 's  that 's the\nwell , it 's  it 's not exactly the right thing\nUh - huh .\nbut  uh  but you 've already seen that cuz there is added noise here .\nThat 's  that 's  Yeah , that 's true . That 's a good point .\nYeah . So um\nOK , so it 's then  then it 's  it 's  it 's reasonable to expect it would be helpful if we used it with the SRI system and\nYeah , I mean , as helpful  I mean , so that 's the question . Yeah , w we 're often asked this when we work with a system that  that isn't  isn't sort of industry  industry standard great ,\nUh - huh .\nuh and we see some reduction in error using some clever method , then , you know , will it work on a   on a  on a good system . So uh you know , this other one 's  it was a pretty good system . I think , you know , one  one percent word error rate on digits is  uh digit strings is not  uh you know stellar , but  but given that this is real  digits , as opposed to uh sort of laboratory\nMm - hmm .\nWell .\nAnd it wasn't trained on this task either .\nAnd it wasn't trained on this task . Actually one percent is sort of  you know , sort of in a reasonable range .\nMm - hmm .\nPeople would say \" yeah , I could  I can imagine getting that \" . And uh so the  the four or five percent or something is  is  is quite poor .\nMm - hmm .\nUh , you know , if you 're doing a uh   a sixteen digit uh credit card number you 'll basically get it wrong almost all the time .\nHmm .\nSo . So . Uh ,  um a significant reduction in the error for that would be great .\nHuh , OK .\nAnd  and then , uh Yeah . So . Yeah . Cool .\nSounds good .\nYeah . Alright , um , I actually have to run . So I don't think I can do the digits , but um ,  I guess I 'll leave my microphone on ?\nUh , yeah .\nYeah . Thank you .\nYep . Yeah . That 'll work .\nI can be out of here quickly .     That 's I just have to run for another appointment . OK , I t Yeah . I left it on . OK .", "topic_id": 5, "keywords": "reverberation, fft, spectrum, subtraction, hdk", "dialogue_id": 10}, {"text": "OK .\nHow about channel\nYeah , go ahead .\nWe 're recording .\nAlright .\nAlright , and no crash .\nHmm .\nI pre - crashed it .\nYeah .\nPre - crashed !\nIt never crashes on me .\nI think it 's actually\nWhat is  what is that ?\nit depends on if the temp files are there or not , that  at least that 's my current working hypothesis ,\nAh .\nthat I think what happens is it tries to clear the temp files and if they 're too big , it crashes .\nAh .\nWhen the power went out the other day and I restarted it , it crashed the first time .\nOh , that 's right .\nAfter the power out\nSo then there would be no temp files .\nYeah .\nOK .  Hmm .\nUh , no , it doesn't  it doesn't clear those necessarily ,\nOh wait  It  it doesn't clear them , OK .\nso .\nHmm , no connection .\nIt 's  i they 're called temp files , but they 're not actually in the temp directory they 're in the scratch , so . They 're not backed up , but they 're not erased either on power failure .\nBut that 's usually the meeting that I recorded , and it neve it doesn't crash on me .\nWell this wasn't  Actually , this wasn't a before your meeting , this was , um , Tuesday afternoon when , um , uh , Robert just wanted to do a little recording ,\nOh well .\nOh  Oh , right .\nand the power had gone out earlier in the day .\nOK . Huh , OK .\nI don't know when would be a good excuse for it , but I just can't wait to be giving a talk t and  and  and use the example from last week with everybody t doing the digits at once .\nYeah .\nThat was fun .\nI 'd love to play somebody that .\nThat was fun .\nIt was quick .\nIt was . It was really efficient .\nTalk about a good noise shield . You know ? You wanted to pe keep people from listening in , you could like have that playing outside the room . Nobody could listen in .\nYeah .\nWell , I had this idea we could make our whole meeting faster that way .\nYeah . Everybody give the reports about what they were doing at exactly the same time ,\nAnd we 'll just all leave ,\nAnd then we 'll  we 'll go back later and review the individual channels ,\nyeah .\nand\nYep , and then everyone can listen to it later .\nright ?\nYes . Absolutely .\nIf you wanna know what\nActually isn't that what we have been doing ?\nYeah .\nIt 's what it sounds like .\nPractically , huh . With all the overlaps .\nYeah .\nWhat are we doing ?\nI  Since I 've been gone all week , I didn't send out a reminder for an agenda , so .\nYeah , and I 'm just\nDo we have anything to talk about or should we just read digits and go ?\nI wouldn't mind hearing how the conference was .\nWhat conference ?\nUh , I had one question about\nYeah , really . It 's all a blur .\nAren't the UW folks coming this weekend ?\nYep .\nNo . The next ,\nNext weekend ?\nNext weekend , week from\nright ?\nThat is right . The next weekend .\nSorry , not  not  not the days coming up , but\nIt 's like the\nA week from Saturday .\nYeah ,\nThat 's when they 're coming .\nwithin ten days .\nThat 's correct .\nSo , are we  do we have like an agenda or anything that we should be\nNo , but that would be a good idea .\nOK .\nWhy don't we w\nSo  so the deal is that I can , um ,  uh , I can be available after , uh , like ten thirty or something . I don't know how s how early you wanted to\nThey 're not even gonna be here until eleven or so .\nThat 's good .\nOh , OK . So\nCuz they 're flying up that day .\nWait , this is on  on Sunday ?\nSaturday .\nOr Saturday ?\nSaturday .\nSaturday .\nS Saturday .\nOK .\nWell , y\nYeah .\nMm - hmm .\nEurospeech is due on Friday and then I 'm going down to San  uh , San Jose Friday night , so , if  you know , if we start nice and late Saturday that 's a good thing .\nNo , I mean , they 're flying up from  from\nSeattle .\ndown from Seattle .\nThey 're flying from somewhere to somewhere ,\nYeah , and they 'll end up here . So b and also Brian Kingsbury is actually flying from , uh , the east coast on that  that morning .\nExcellent .\nSo , i I  I will be  I mean , he 's taking a very early flight\nOh .\nand we do have the time work difference running the right way , but I still think that there 's no way we could start before eleven . It might end up really being twelve . So when we get closer we 'll find people 's plane schedules , and let everybody know . Uh , So . That 's good .\nBut , uh , yeah maybe an agenda , or at least some things to talk about would be a good idea .\nWell we can start gathering those  those ideas , but then we  we should firm it up by next  next Thursday 's meeting .\nWill we have time to , um , to prepare something that we  in the format we were planning for the IBM transcribers by then , or  ?\nOh yeah . Absolutely .\nOK .\nSo have you heard back from Brian about that , Chuck ?\nYes , um , he 's  I  I 'm sorry , I should have forwarded that along . Uh ,  oh I  I think I mentioned at the last meeting , he said that , um , he talked to them and it was fine  with the beeps they would be  That 's easy for them to do .\nGreat . OK . So , uh , oh , though Thi - Thilo isn't here , um , but , uh , I  I have the program to insert the beeps . What I don't have is something to parse the output of the channelized transcripts to find out where to put the beeps , but that should be really easy to do . So do we have a meeting that that 's been done with ,\nHe 's  he 's\nthat we 've tightened it up to the point where we can actually give it to IBM and have them try it out ?\nHe generated , um , a channel - wise presegmented version of a meeting , but it was Robustness rather than EDU so I guess depends on whether we 're willing to use Robustness ?\nWell for this experiment I think we can use pre pretty much anything .\nMm - hmm .\nOK .\nThis experiment of just\nWell we had  we had talked about doing maybe EDU as a good choice , though . Well ,  whatever we have .\nWell we 've talked about that as being the next ones we wanted to transcribe .\nRight .\nOK .\nBut for the purpose of sending him a sample one to  f\nYeah , maybe it doesn't matter .\nGreat .\nI  I don't think it matte\nI 'll  I 'll  I 'll , um , get  make that available .\nOK , and has it been corrected ?\nOh , well , wait . Um\nHand - checked ? Cuz that was one of the  processes we were talking about as well .\nRight , so we need to run Thilo 's thing on it ,\nThat 's right .\nand then we go in and adjust the boundaries .\nYeah that 's right . Yeah , we haven't done that . I  I could set someone on that tomorrow .\nRight .\nAnd time how long it takes .\nOK .\nI think they 're coming\nAnd we probably don't have to do necessarily a whole meeting for that if we just wanna send them a sample to try .\nOK . What would be a good number of minutes ?\nI don't know , maybe we can figure out how long it 'll take @ @ to  to do .\nUm , I don't know , it seems to me w we probably should go ahead and do a whole meeting because we 'll have to transcribe the whole meeting anyway sometime .\nYes except that if they had  if there was a choice between having fifteen minutes that was fully the way you wanted it , and having a whole meeting that didn't get at what you wanted for them  It 's just dependent of how much\nLike I  I mean I guess if we have to do it again anyway , but , uh\nYeah .\nI guess , the only thing I 'm not sure about is , um , how quickly can the transcribers scan over and fix the boundaries ,\nMm - hmm .\nand  I mean , is it pretty easy ?\nI think it 's gonna be one or two times real time at  Wow , excuse me , two or more times real time , right ? Cuz they have to at least listen to it .\nCan we pipeline it so that say there 's , uh , the transcriber gets done with a quarter of the meeting and then we  you run it through this other  other stuff ? Uh ,\nWell the other stuff is I B I 'm just thinking that from a data  keeping - track - of - the - data point of view , it may be best to send them whole meetings at a time and not try to send them bits and pieces .\nOK , so . Oh , that 's right . So the first thing is the automatic thing , and then it 's  then it 's  then it 's the transcribers tightening stuff up ,\nRight .\nMm - hmm .\nand then it 's IBM .\nMm - hmm , mm - hmm .\nRight .\nOK , so you might as well ha run the automatic thing over the entire meeting , and then  and then , uh , you would give IBM whatever was fixed .\nAnd have them fix it over the entire meeting too ?\nRight .\nWell , yeah , but start from the beginning and go to the end , right ? So if they were only half way through then that 's what you 'd give IBM .\nOK .\nRight ?\nAs of what point ? I mean . The  I guess the question on my mind is do we wait for the transcribers to adjust the marks for the whole meeting before we give anything to IBM , or do we go ahead and send them a sample ? Let their\nWhy wouldn't we s @ @ w i if they were going sequentially through it , why wouldn't we give them  I mean i are we trying to get something done by the time Brian comes ?\nWell I  I  I mean , I don't know .\nThat was the question . Though .\nSo if we  if we were , then it seems like giving them something , whatever they had gotten up to , would be better than nothing .\nYeah . Uh . That  I agree . I agree .\nWell , I don't think  I mean , h they  they typically work for what , four hours , something like that ?\nHmm , I gue hmm .\nI think the they should be able to get through a whole meeting in one sitting . I would think , unless it 's a lot harder than we think it is , which it could be , certainly .\nIf it 's got like for speakers then I guess  I mean if\nWe 're just doing the individual channels ,\nOr seven or eight .\nright ?\nIndividual channels . Yeah .\nSo it 's gonna be , depending on the number of people in the meeting , um ,\nI guess there is this issue of , you know , if  if the segmenter thought there was no speech on  on a particular stretch , on a particular channel ,\nWell\nand there really was , then , if it didn't show up in a mixed signal to verify , then it might be overlooked , so , I mean , the question is \" should  should a transcriber listen to the entire thing or can it g can it be based on the mixed signal ? \" And I th eh so far as I 'm concerned it 's fine to base it on the mixed signal at this point , and\nThat 's what it seems to me too , in that if they need to , just like in the other cases , they can listen to the individual , if they need to .\nAnd that cuts down the time . Yeah .\nBut they don't have to for most of it .\nYeah , that 's good . So . Yeah . Good , good , good .\nI don't see how that will work , though .\nWhat  what aspect ?\nSo you 're talking about tightening up time boundaries ?\nYeah .\nSo how do you\nSo , they have the normal channeltrans interface where they have each individual speaker has their own line ,\nYeah .\nbut you 're listening to the mixed signal and you 're tightening the boundaries , correcting the boundaries . You shouldn't have to tighten them too much because Thilo 's program does that .\nShould be pretty good , yeah .\nExcept for  it doesn't do well on short things , remember .\nRight , so  so you 'll have to I\nIt will miss them . It will miss most of the really short things .\nUh - huh .\nLike that .\nBut those would be  those would be\nUh - huh . It will  it will miss\nUh - huh !\nYeah , you have to say \" uh - huh \" more slowly to  to get c\nSorry .\nNo , I 'm s I 'm actually serious .\nI 'll work on that .\nSo it will miss stuff like that which\nI\nWell , so  so that 's something that the transcribers will have to  have to do .\nYeah , but presumably , most of those they should be able to hear from the mixed signal unless they 're embedded in the heavil heavy overlap section when  in which case they 'd be listening to the channels anyway .\nThat 's  that 's what I 'm  I 'm concerned about the part .\nRight , and that 's what I 'm not sure about .\nYeah , I am too . And I think it 's an empirical question .\nCan't we  uh couldn't we just have , um , I don't know , maybe this just doesn't fit with the software , but I guess if I didn't know anything about Transcriber and I was gonna make something to let them adjust boundaries , I would just show them one channel at a time , with the marks , and let them adju\nOh they can\nWell , but then they have to do  but then they  for this meeting they would have to do seven times real time , and it would probably be more than that .\nYeah , that 's it . Yeah .\nRight ? Because they 'd have to at least listen to each channel all the way through .\nAnd if\nBut i but it 's very quick ,\nUh - huh .\nright ? I mean , you scan  I mean , if you have a display of the waveform .\nYeah .\nOh , you 're talking about visually .\nw Well , the other problem is the breaths\nI just don't think\ncuz you also see the breaths on the waveform . I 've  I 've looked at the int uh , s I 've tried to do that with a single channel , and  and you do see all sorts of other stuff besides just the voice .\nUh - huh .\nYeah , and I  I think that they 're going much more on acoustics than they are on visuals .\nWell that  that I 'm not sure .\nSo .\nWhat you  the digital  what the digital task that you had your interface ? Um , I know for a fact that one of those  sh she could really well  she could judge what th what the number was based on the  on the waveform .\nYeah , that 's actually true . Yeah , you 're right . You 're absolutely right . Yeah , I found the same thing that when I was scanning through the wave form  I could see when someone started to read digits just by the shapes .\nYeah , she could tell which one was seven .\nUm , maybe .\nYeah .\nSo I don't  I 'm  I 'm now entirely confused about what they do .\nBut\nSo , they 're  they 're looking at a mixed signal , or they 're looking  what  what are they looking at visually ?\nWell , they have a choice . They could choose any signal to look at . I 've tried lookin but usually they look at the mixed . But I 've  I 've tried looking at the single signal and  and in order to judge when it  when it was speech and when it wasn't ,\nOh .\nbut the problem is then you have breaths which  which show up on the signal .\nBut the procedure that you 're imagining , I mean , people vary from this , is that they have the mixed signal wave form in front of them ,\nYes .\nYes .\nand they have multiple , uh , well , let 's see , there isn't  we don't have transcription yet . So  but there 's markers of some sort that have been happening automatically ,\nYes .\nRight .\nand those show up on the mixed signal ?\nOh ,\nThere 's a @ @ clicks ?\nN the t\nthey show up on the separate ribbons . So you have a separate ribbon for each channel ,\nThere 're separate ribbons .\nRight .\nand  and i i it 'll be  because it 's being segmented as channel at a time with his  with Thilo 's new procedure , then you don't have the correspondence of the times across the bins  uh across the ribbons uh you could have\nAnd is there a line moving across the waveform as it goes ?\nYes .\nYes .\nOK , so The way you 're imaging is they kind of play it , and they see oh this happened , then this happened , then  and if it 's about right , they just sort of let it slide ,\nYeah .\nRight . Right .\nand if it  if it  there 's a question on something , they stop and maybe look at the individual wave form .\nOh , well not  not \" look \" .\nRight . Well , they wouldn't look at it  at this point . They would just listen .\nThey  they might look at it , right ?\nWell , the problem is that the  the interface doesn't really allow you to switch visuals .\nNot very quickly .\nThe problem is that  that  the Tcl - TK interface with the visuals , it 's very slow to load waveforms .\nYou can but it takes time . That 's it .\nUh - huh .\nAnd so when I tried  that  that was the first thing I tried when I first started it ,\nOh , oh . Visually . You can  you can switch quickly between the audio ,\nright ?\nbut you just can't get the visual display to show quickly . So you have to  It takes , I don't know , three , four minutes to  Well , I mean , it takes  it takes long enough\nYeah , it 's very slow to do that .\nIt takes long enough cuz it has to reload the I  I don't know exactly what it 's doing frankly cuz  but it t it takes long enough that it 's just not a practical alternative .\nThat w\nWell it  it does some sort of shape pre - computation so that it can then scroll it quickly ,\nBut you can cancel that .\nYeah .\nyeah . But then you can't change the resolution or scroll quickly .\nOh , really ?\nNow you could set up multiple windows , each one with a different signal showing , and then look between the windows .\nSo .\nHuh !\nMaybe that 's the solution .\nI mean , we  we could do different interfaces ,\nWhat if you preload them all ?\nright ? I mean , so  so we could use like X Waves instead of Transcriber ,\nYeah .\nand it loads faster , certainly .\nWhat if you were to preload all the channels or  or initially\nWell that 's what I tried originally .\nlike doesn't\nSo I  I actually before , uh , Dave Gelbart did this , I did an interface which showed each waveform and ea a ribbon for each waveform ,\nMm - hmm .\nbut the problem with it is even with just three waveforms it was just painfully slow to scroll . So you just scroll a screen and it would , you know go \" kur - chunk ! \"\nOh , OK .\nMm - hmm .\nAnd so it just was not doable with the current interface .\nYou know , I am thinking if we have a meeting with only four speakers and , you know , you could fire up a Transcriber interface for , y you know , in different windows , multiple ones , one for each channel . And it 's sort of a  a hack but I mean it would be one way of seeing the visual form .\nI think that if we decide that we need  that they need to see the visuals , we need to change the interface so that they can do that .\nYeah . Yeah .\nSo\nThat 's actually what I thought of , loading the chopped up waveforms , I mean , you know , that  that would make it faster\nAn But isn't\nHmm .\nThe chopped up waveforms .\nThe problem is if  if anything 's cut off , you can't expand it from the chopped up\nSo .\nIsn't that\nRight .\nRight , but if you a at some point\nAnd wouldn't that be the same  as the mixed signal ?\nNo , I mean the individual channels that were chopped up that  it 'd be nice to be able to go back and forth between those short segments .\nMm - hmm .\nCuz you don't really nee like nine tenths of the time you 're throwing most of them out , but what you need are tho that particular channel , or that particular location ,\nYeah .\nand ,\nYeah .\num , might be nice , cuz we save those out already ,  um , to be able to do that . But it won't work for IBM of course , it only works here cuz they 're not saving out the individual channels .\nWell , I  I do think that this  this will be a doable procedure ,\nYeah .\nand have them starting with mixed\nOK .\nand , um , then when they get into overlaps , just have them systematically check all the channels to be sure that there isn't something hidden from  from audio view .\nYeah . Yeah , hopefully , I mean  The mixed signal , the overlaps are pretty audible because it is volume equalized . So I think they should be able to hear . The only problem is  is , you know , counting how many and if they 're really correct or not . So , I don't know .\nI don't know that you can locate them very well from the mixed signal ,\nRight but  but once  once you know that they happen , you can at least listen to the close talking ,\nbut you would know that they were there , and then you would switch . Right . And then you would switch into the other\nso .\nBut right now , to do this limitation , the switching is going to be switching of the audio ? Is what she 's saying .\nYeah .\nRight .\nSo\nRight , so  so\nso they 're using their ears to do these markings anyway .\ndid Dave  Did Dave do that change where you can actually just click rather than having to go up to the menu to listen to the individual channels ?\nYes . Yes .\nYeah .\nClick  Um ,\nI had suggested it before . I just don't know whether he did it or not .\nI 'm not sure what  click what  click on the ribbon ? Yeah , you can get that\nYeah .\noh , oh , get  you can get the , uh  you can get it to switch audio ? Uh , not last I tried ,\nYeah .\nbut , um , maybe he 's changed it again .\nWe should get him to do that because , uh , I think that would be much , much faster than going to the menu .\nI disagree . There 's a reason I disagree , and that is that , uh , you  it 's very good to have a dissociation between the visual and the audio . There 're times when I wanna hear the mixed signal , bu but I want to transcribe on the single channel . So right now\nThen maybe just buttons down at the bottom next to it .\nMaybe , I just don't  I don't see that it 's a\nJust something so that it 's not in the menu option so that you can do it much faster .\nWell , I mean , that 's the i I  I think that might be a personal style thing . I find it really convenient the way  the way it 's set up right now .\nWell it just seems to me that if you wanna quickly  \" well was that Jane , no , was that Chuck , no , was that Morgan \" , right now , you have to go up to the menu , and each time , go up to the menu , select it , listen to that channel then click below , and then go back to the menu , select the next one , and then click below .\nThat 's fine . Yeah , it 's true .\nSo you can definitely streamline that with the i with the interface .\nYeah , it could be faster , but , you know , I mean , th in the ideal world  Yeah .\nWhat ?\nNo I  I agree that 'd be nice . Yeah . OK .\nOK .\nSo , um , Done with that ? Does any  I forget , does anybody , uh , working on any  any Eurospeech submission related to this ?\nI would like to try to do something on digits but I just don't know if we have time . I mean , it 's due next Friday so we have to do the experiments and write the paper . So , I 'm gonna try , but , uh , we 'll just have to see . So actually I wanna get together with both Andreas and , uh , uh , Stephane with their respective systems .\nYeah . Yeah there was that  we that 's right , we had that one conversation about , uh , what  what  what did it mean for , uh , one of those speakers to be pathological , was it a\nRight , and I haven't had s chance to sit down and listen .\nOh , I haven't  I haven't listened to them either ,\nI was going to do that this afternoon .\nbut there must be something wrong , I mean ,\nWell , Morgan and I were  were having a debate  about that .\nunless our\nWhereas I think it it 's probably something pathologic and actually Stephane 's results , I think confirm that . He s he did the Aurora system also got very lousy average error , like fifteen or  or , uh , fifteen to twenty percent average ? But then he ran it just on the lapel , and got about five or six percent word error ? So that  that means to me that somewhere in the other recordings there are some pathological cases . But , you know , we  th that may not be true . It may be just some of the segments they 're just doing a lousy job on . So I 'll  I 'll listen to it and find out since you 'd actually split it up by segment .\nRight .\nSo I can actually listen to it .\nYeah .\nDid you run the  Andreas  the r SRI recognizer on the digits ?\nOh , I thought he had sent that around to everyone ,\nYeah .\ndid you just sent that to me ?\nNo , I d I didn't .\nOh .\nSince I considered those preliminary , I didn't .\nI it wasn't\nBut , yeah , if you take\nIt was bimodal .\nSo if you  Yeah , it 's actually , um , it  uh  it was trimodal , actually\nOh , was it trimodal , OK .\nYeah .\ntrimodal , so\nThere 's zero , a little bit , and a lot .\nthere were   t there was  there was one h one bump at ze around zero , which were the native speakers ,\nYeah .\nZero percent error ?\nYeah .\nthe non - pathological native speakers .\nY yeah .\nThen there was another bump at , um ,   oh , like fifteen or something .\nThis is error you 're talking about ?\nOh was it fifteen ?\nwhe\nOK .\nYeah .\nYeah .\nYeah . Those were the non - natives . And then there was another distinct bump at , like , a hundred ,  which must have been some problem .\nOh , wow ! Oh , OK .\nI can't imagine that\nWhat is patho what do you mean by pathological ?\nJust  just something really wrong with\nI 'm sorry , I don't\nA bug is what I mean ,\nIn the recording\nOh .\nso that it 's like\nOh , OK .\nAnd there was this one meeting , I forget which one it was , where like , uh , six out of the eight channels were all , like  had a hundred percent error .\nI see .\nWhich probably means like there was a  th the recording interface crashed ,\nRight .\nor there was a short  you know , someone was jiggling with a cord\nBut\nor , uh , I extracted it incorrectly ,\nBut\nit was labeled\nMm - hmm .\nit was transcribed incorrectly , something really bad happened , and I just haven't listened to it yet to find out what it was .\nOK .\nSo , if I excluded the pathological ones ,  by definition , those that had like over ninety - five percent error rate ,  and the non - natives , then the average error rate was like one point four or something ,\nWhat we 're calling .\nOh . Oh .\nwhich  which seemed reasonable given that , you know , the models weren't tuned for   for it .\nHmm !\nYeah .\nAnd the grammar wasn't tuned either .\nAnd it didn't matter whether it was the lapel or whether it was the\nIt was just a @ @ . I haven't split it up that way ,\nBut there 's no overlap during the digit readings , so it shouldn't really matter .\nbut it would be\nYeah .\nRight .\nRight .\nNo , but there 's a little difference ,\nSo it should\nThere 's a lot .\nand we haven't looked at it for digits ,\nYeah .\nright ?\nYeah , so I was curious about that .\nAnd so , cuz  because what he was  what I was saying when I looked at those things is it  it  I was almost gonna call it quadrimodal because   because there was a whole lot of cases where it was zero percent .\nMm - hmm .\nThey just plain got it all right . And then there  and then there was another bunch that were couple percent or something .\nYeah . But if you p if you actually histogrammed it , and  it was a nice  uh , you know , it  it was  zero was the most of them ,\nYeah .\nA normal . Yeah .\nbut then there were  the others were sort of decaying from there .\nYeah , yeah .\nAnd then there was the bump for the non - natives and then the pathological ones ,\nI see . I see .\nso .\nYeah , cuz some of our non - natives are pretty non - native . So .\nYou  did you have , uh , something in the report about , uh ,  about , uh , for f uh , forced alignment ?\nYeah .\nHave you  have you started on that ?\nOh , well , yeah , so I 've been struggling with the forced alignments . Um .   So the scheme that I drew on the board last time where we tried to , um  allow reject models for the s speech from other speakers , um ,   most of the time it doesn't work very well . So ,  um ,  and the  I haven't done  I mean , the only way to check this right now was for me to actually  load these into X Waves and , you know , plus the alignments , and s play them and see where the\nHmm .\nAnd it looks  And so I looked at all of the utterances from you , Chuck , in that one conversation , I don't know which  You probably know which one I mean , it 's where you were on the lapel  and Morgan was sitting next to you and we can hear everything Morgan says .\nHmm .\nBut  and  and some of what you  I mean , you also appear quite a bit in that cross - talk . So ,  I actually went through all of those , there were I think fifty - five segments ,  um , in  in X Waves , and  and sort of did a crude check , and  more often than not , it  it gets it wrong . So there 's either the beginning , mostly the beginning word ,  where th you , um , you know , Chuck talks somewhere into the segment , but the first , um , word of what he says , often \" I \" but it 's very reduced \" I , \" that 's just aligned  to the beginning of someone else 's speech , uh in that segment , which is cross - talk . So ,  um ,  I 'm still tinkering with it , but it might well be that we can't get clean alignments out of this  out of those , uh ,  channels , so .\nUnless maybe we do this , uh , um , cancellation business .\nRight , but that 's  I mean , that was our plan ,\nYeah , right .\nbut it 's clear from Dan that this is not something you can do in a short amount of time .", "topic_id": 0, "keywords": "crash, crashes, crashed, files, recordings", "dialogue_id": 11}, {"text": "Oh , the short amount of time thing , right .\nSo  so we  you know , we had spent a lot of time , um , writing up the HLT paper and we wanted to use that , uh , kind of analysis ,\nYeah .\nbut the HLT paper has , you know , it 's a very crude measure of overlap . It 's not really something you could scientifically say is overlap , it 's just whether or not the , um , the segments that were all synchronized , whether there was some overlap somewhere .\nc High correlation .\nAnd , you know , that pointed out some differences , so he thought well if we can do something quick and dirty because Dan said the cross - cancellation , it 's not straight - forward . If it were straight - forward then we would try it , but  so , it 's sort of good to hear that it was not straight - forward , thinking if we can get decent forced alignments , then at least we can do sort of a overall report of what happens with actual overlap in time , but , um\nI didn't think that his message said it wasn't straight - forward .\nWell if we 'd just\nWell\nI thought he 's just saying you have to look over a longer time window when you do it .\nUm - hmm .\nand the  but there are some issues of this timing , um , in the recordings\nYeah .\nRight .\nand\nSo you just have to look over longer time when you 're trying to align the things , you can't  you can't just look\nWell . are you talking about the fact that the recording software doesn't do time - synchronous ? Is that what you 're referring to ?\nThat seems to me you can do that over the entire file and get a very accurate\nI don't thi I d I don't think that was the issue .\nI  yeah , that was sort of a side issue .\nI didn't think so either .\nThe issue was that you have  to  you have have  you first have to have a pretty good speech detection on the individual channels .\nAnd it 's dynamic , so I guess it was more dynamic than some simple models would be able t to  so  so there are some things available , and I don't know too much about this area where if people aren't moving around much than you could apply them , and it should work pretty well if you took care of this recording time difference .\nRight , which should be pretty straight forward .\nWhich a at least is well defined , and\nYeah .\num , but then if you add the dynamic aspect of adapting distances , then it wasn't  I guess it just wasn't something that he could do quickly  and not  in time for us to be able to do something by two weeks from now , so . Well less than a week . So  um , so I don't know what we can do if anything , that 's sort of worth , you know , a Eurospeech paper at this point .\nWell , Andreas , how well did it work on the non - lapel stuff ?\nYeah . That 's what I was gonna say .\nI haven't checked those yet .\nC\nIt 's very tedious to check these .\nMmm .\nUm , we would really need , ideally , a transcriber  to time mark the  you know , the be at least the beginning and s ends  of contiguous speech . Um ,   and , you know , then with the time marks , you can do an automatic comparison of your  of your forced alignments .\nBecause  really the  the  at least in terms of how we were gonna use this in our system was to get an ideal  an idea , uh , for each channel about the start and end boundaries .\nOh , MNCM .\nMm - hmm .\nWe don't really care about like intermediate word boundaries , so\nNo , that 's how I 've been looking at it .\nYeah .\nRight .\nI mean , I don't care that the individual words are aligned correctly ,\nYeah .\nbut  you don't wanna , uh , infer from the alignment that someone spoke who didn't .\nRight , exactly . So that 's why I was wondering if it\nso , so\nI mean , maybe if it doesn't work for lapel stuff , we can just not use that\nYeah .\nand\nI haven't  I ha just haven't had the time to , um , do the same procedure on one of the  so I would need a k I would need a channel that has  a speaker whose  who has a lot of overlap but s you know , is a non - lapel mike . And , um ,   where preferably , also there 's someone sitting next to them who talks a lot .\nHmm !\nSo , I\nSo a meeting with me in it .\nmaybe someone can help me find a good candidate and then I would be willing to\nWe c you know what ? Maybe the best way to find that would be to look through these .\nyou know , hand\nCuz you can see the seat numbers , and then you can see what type of mike they were using . And so we just look for , you know , somebody sitting next to Adam at one of the meetings\nActually y we can tell from the data that we have ,\nFrom the insertions , maybe ?\num , yeah , there 's a way to tell .\nfr fr from the\nIt might not be a single person who 's always overlapping that person but any number of people ,\nRight .\nand , um , if you align the two hypothesis files across the channels , you know , just word alignment , you 'd be able to find that . So  so I guess that 's sort of a last  ther there 're sort of a few things we could do . One is just do like non - lapels if we can get good enough alignments . Another one was to try to get  somehow align Thilo 's energy segmentations with what we have . But then you have the problem of not knowing where the words are because these meetings were done before that segmentation . But maybe there 's something that could be done .\nWhat  what is  why do you need the , um , the forced alignment for the HLT  I mean for the Eurospeech paper ?\nWell , I guess I  I wanted to just do something not on recognition experiments because that 's ju way too early , but to be able to report , you know , actual numbers . Like if we  if we had hand - transcribed pe good alignments or hand - checked alignments , then we could do this paper . It 's not that we need it to be automatic . But without knowing where the real words are , in time\nSo it was to get  it was to get more data and better  to  to squeeze the boundaries in .\nTo  to know what an overlap really  if it 's really an overlap , or if it 's just a  a  a segment correlated with an overlap ,\nAh , OK . Yeah .\nand I guess that 's the difference to me between like a real paper and a sort of , promissory paper . So , um , if we d it might be possible to take Thilo 's output and like if you have , um , like right now these meetings are all ,\nUgh ! I forgot the digital camera again .\num ,\nEvery meeting !\nyou know , they 're time - aligned , so if these are two different channels and somebody 's talking here and somebody else is talking here , just that word , if Thilo can tell us that there 're boundaries here , we should be able to figure that out\nMm - hmm .\nbecause the only thing transcribed in this channel is this word . But , um , you know , if there are things\nTwo words .\nYeah , if you have two and they 're at the edges , it 's like here and here , and there 's speech here , then it doesn't really help you , so , um\nThilo 's won't put down two separate marks in that case\nWell it w it would , but , um , we don't know exactly where the words are because the transcriber gave us two words in this time bin\nThilo 's will . But .\nand we don't really know , I mean ,\nWell it 's a merging problem . If you had a  if you had a s if you had a script which would\nyeah it 's\nI 've thought about this , um , and I 've discussed  I 've discussed it with Thilo ,\nI mean , if you have any ideas . I would\num , the , I mean , I  I  in principle I could imagine writing a script which would approximate it to some degree , but there is this problem of slippage ,\nWell maybe  Maybe that will get enough of the cases to be useful .\nyeah .\nRight . I mean , that  that would be really helpful . That was sort of another possibility .\nYou know s cuz it seemed like most of the cases are in fact the single word sorts , or at least a single phrase\nWell they  they can be stretched .\nin most of the bins .\nMmm .\nI wouldn't make that generalization cuz sometimes people will say , \" And then I \" and there 's a long pause\nYeah .\nand finish the sentence and  and sometimes it looks coherent and  and the  I mean it 's  it 's not a simple problem . But it 's really  And then it 's coupled with the problem that sometimes , you know , with  with a fricative you might get the beginning of the word cut off and so it 's coupled with the problem that Thilo 's isn't perfect either . I mean , we 've i th it 's like you have a merging problem plus  so merging plus this problem of , uh , not\nRight . Hmm !\ny i i if the speech - nonspeech were perfect to begin with , the detector , that would already be an improvement , but that 's impossible , you know , i that 's too much to ask .\nRight .\nYes .\nAnd so i and may you know , I mean , it 's  I think that there always  th there would have to be some hand - tweaking , but it 's possible that a script could be written to merge those two types of things . I 've  I 've discussed it with Thilo and I mean  in terms of not him doing it , but we  we discussed some of the parameters of that and how hard it would be to  in principle  to write something that would do that .\nI mean , I guess in the future it won't be as much as an issue if transcribers are using the tightened boundaries to start with , then we have a good idea of where the forced alignment is constrained to .\nWell , it 's just , you know , a matter of we had the revolution  we had the revolution of improved , uh , interface , um , one month too late ,\nSo I 'm no I don't know if this\nOh . Tools .\nbut it 's like , you know , it 's wonderful to have the revolution ,\nOh it 's  it 's a\nso it 's just a matter of  of , you know , from now on we 'll be able to have things channelized to begin with .\nyeah .\nRight . And we 'll just have to see how hard that is .\nYeah , that 's right .\nSo  so whether the corrections take too much time .\nThat 's right .\nI was just thinking about the fact that if Thilo 's missed these short segments , that might be quite time - consuming for them to insert them .\nYeah .\nGood point .\nBut he  he also can adjust this minimum time duration constraint and then what you get is noises mostly ,\nYeah .\nSpurious .\nbut that might be OK , an\nIt might be easier to delete something that 's wrong than to insert something that 's missing .\nRight . And you can also see in the waveform  exac\nWhat do you think , Jane ?\nyeah .\nIf you can feel confident that what the  yeah , that there 's actually something\nYeah .\nthat you 're not gonna miss something ,\nYeah . Cuz then  then you just delete it , and you don't have to pick a time .\nyeah .\nI think it 's\nWell the problem is I  you know  I  I  it 's a  it 's a really good question , and I really find it a pain in the neck to delete things because you have to get the mouse up there on the t on the text line and i and otherwise you just use an arrow to get down  I mean , i it depends on how lar th there 's so many extra things that would make it one of them harder than the other , or  or vice versa . It 's not a simple question . But , you know , I mean , in principle , like , you know , if one of them is easier then to bias it towards whichever one 's easier .\nYeah , I guess the semantics aren't clear when you delete a segment , right ? Because you would say  You would have to determine what the surroundings were .\nYou could just say it 's a noise , though , and write , you know , a post - processor will just  all you have to do is just\nIf it 's really a noise .\nor just say it 's  just put \" X , \" you know , like \" not speech \" or something ,\nI think it 's easier to add than delete , frankly ,\nand then you can get  Yeah , or\nbecause you have to , uh , maneuver around on the  on both windows then .\nTo add or to delete ?\nTo delete .\nAnyways , so I  I guess\nOK . That  Maybe that 's an interface issue that might be addressable .\nIt 's possible .\nBut I think it 's the semantics that are  that are questionable to me , that you delete something  So let 's say someone is talking to here , and then you have a little segment here . Well , is that part of the speech ? Is it part of the nonspeech ? I mean , w what do you embed it in ?\nThere 's something nice , though , about keeping , and this is probably another discussion , keeping the stuff that Thilo 's detector detected as possible speech and just marking it as not speech than deleting it . Because then when you align it , then the alignment can  you can put a reject model or whatever ,\nOh , I see . So then they could just like put  Oh that 's what you meant by just put an \" X \" there .\nand you 're consistent with th the automatic system ,\nUh , that 's an interesting idea .\nwhereas if you delete it\nSo  so all they  So that all they would have to do is put like an \" X \" there .\nYeah , or some , you know , dummy reject mod\nSo blank for  blank for silence , \" S \" \" S \" for speech , \" X \" \" X \" for something else .\nwhatever , yeah . That 's actually a better way to do it cuz the a the forced alignment will probably be more consistent than\nWell , like , I think there 's a complication which is that  that you can have speech and noise in s\nI mean if it 's just as easy , but\nuh , you know , on the same channel , the same speaker , so now sometimes you get a ni microphone pop and , uh , I mean , there 're these fuzzy hybrid cases , and then the problem with the boundaries that have to be shifted around . It 's not a simple  not a simple problem .\nAnyway , quick question , though , at a high level do people think , let 's just say that we 're moving to this new era of like using the , um , pre - segmented t you know , non - synchronous conversations , does it make sense to try to take what we have now , which are the ones that , you know , we have recognition on which are synchronous and not time - tightened , and try to get something out of those for sort of purposes of illustrating the structure and the nature of the meetings , or is it better to just , you know , forget that and tr I mean , it 's\nWell , I think we 'll have to , eventually . And my hope was that we would be able to use the forced alignment to get it .\nRight . That was everybody 's hope .\nBut if we can't\nAnd maybe we can for the non - lapel , but\nBut if we can't , then maybe we just have to\nis it worth  if we can't then we can fake it even if we 're  we report , you know , we 're wrong twenty percent of the time or ten percent of the time .\nWell , I 'm thinking  are you talking about for a paper , or are talking about for the corpus .\nUh  uh , that 's a good question actually .\nI mean cuz for the corpus it would be nice if everything were\nActually that 's a good question because we 'd have to completely redo those meetings , and we have like ten of them now .\nWe wouldn't have to re - do them , we would just have to edit them .\nWell , and also , I mean , I still haven't  I still haven't given up on forced alignment .\nNo , you 're right , actually\nI think that when Brian comes , this 'll be uh an interesting aspect to ask him as well b\nWhen\nwhen Brian Kingsbury comes .\nOh , Brian . You s I thought you said Ryan . And it 's like , \" Who 's Ryan ? \"\nYeah , good question .\nOK .\nWell , Ryan could come .\nUh , no , that 's a good point , though , because for feature extraction like for prosody or something , I mean , the meetings we have now , it 's a good chunk of data\nYep .\nwe need to get a decent f OK .\nThat 's what my hope has been ,\nSo we should at least try it even if we can't ,\nand that 's what  that 's what  you know , ever since the  the February meeting that I transcribed from last year , forced alignment has been on the  on the table as a way of cleaning them up later .\nright ?\nOn the table , right ?\nAnd  and so I 'm hopeful that that 's possible . I know that there 's complication in the overlap sections and with the lapel mikes ,\nThere 's\nbut\nYeah .\nI mean , we might be able , at the very worst , we can get transcribers to correct the cases where  I mean , you sort of have a good estimate where these places are because the recognition 's so poor . Right ?\nYeah , we were never just gonna go with these as the final alignments .\nAnd so you 're\nI agree . I agree .\nWe were always gonna run them past somebody .\nYeah .\nAbsolutely .\nSo we need some way to push these first chunk of meetings into a state where we get good alignments .\nI 'm probably going to spend another day or so trying to improve things by , um ,   by using , um , acoustic adaptation . Um , the   Right now I 'm using the unadapted models for the forced alignments , and it 's possible that you get considerably better results if you , uh , manage to adapt the ,  uh , phone models to the speaker and the reject model to the  to  to all the other speech . Um , so\nCould you  could you at the same time adapt the reject model to the speech from all the other channels ?\nThat 's what he just said .\nThat 's what he was saying .\nYeah .\nThat 's what I just said .\nOh , not just the speech from that  of the other people from that channel ,\nRight .\nbut the speech from the a actual other channels .\nRight .\nOh , oh , I see . Um ,\nOh .\nI don't think so . I don't think that would work ,\nNo , it\nright ? Because you 'd  A lot of it 's dominated by channel properties .\nth Exactly .\nBut what you do wanna do is take the , even if it 's klugey , take the segments  the synchronous segments , the ones from the HLT paper , where only that speaker was talking .\nSo you want to u\nUse those for adaptation , cuz if you  if you use everything , then you get all the cross - talk in the adaptation , and it 's just sort of blurred .\nThat 's a good point .\nIf you\nYep .\nAnd that we know , I mean , we have that . And it 's about roughly two - thirds , I mean , very roughly averaged .\nYeah .\nThat 's not completely negligible . Like a third of it is bad for adaptation or so .\nMm - hmm .\nCool . I thought it was higher than that , that 's pr\nIt really  it depends a lot . This is just sort of an overall\nSo .\nWell I know what we 're not turning in to Eurospeech , a redo of the HLT paper .\nRight .\nThat  I don't wanna do that ,\nYeah , I 'm doing that for AVIOS .\nbut .\nYeah . But I think we 're  oh , Morgan 's talk went very well , I think .\nBleep .\nUh , \" bleep \" . Yeah , really .\nI think Morgan 's talk went very well it woke\nExcellent .\nyou know , it was really a well presented  and got people laughing\nYeah .\nSome good jokes in it ?\nEspecially the batteried meter popping up ,\nYeah .\nthat was hilarious . Right when you were talking about that .\nYou know , that wa that was the battery meter saying that it was fully charged ,\nIt 's full . Yeah .\nyeah .\nYou said , \" Speaking about energy \" , or  something .\nBut that was funny .\nThat was very nice .\nYeah .\nHe  he  he was onto the bullet points about talking about the  you know  the little hand - held , and trying to get lower power and so on ,\nPo - low power\nand Microsoft pops up a little window saying \" Your batteries are now fully charged . \"\nThat 's great .\nYeah , yeah , yeah .\nI 'm thinking about scripting that for my talk , you know , put  put a little script in there to say \" Your batteries are low \" right when I 'm saying that .\nYeah . Yeah . No I mean , i in  in your case , I mean , you were joking about it , but , I mean , your case the fact that your talking about similar things at a couple of conferences , it 's not  these are conferences that have d really different emphases . Whereas HLT and  and Eurospeech , pretty  pretty  pretty similar , so I  I  I can't see really just putting in the same thing ,\nAre too close , yeah .\nNo , I d I don't think that paper is really\nbut\nthe HLT paper is really more of a introduction - to - the - project paper , and , um\nYeah .\nYeah , for Eurospeech we want some results if we can get them .\nWell , yeah , it  it 's  probably wouldn't make sense ,\nOr some  or some  I mean , I would see Eurospeech  if we have some Eurospeech papers , these will be paper p p uh , submissions .\nbut\nThese will be things that are particular things , aspects of it that we 're looking at , rather than , you know , attempt at a global paper about it .\nRight , right .\nDetail , yeah . Overall .\nI did go through one of these meetings . I had , uh , one of the transcribers go through and tighten up the bins on one of the , uh , NSA meetings , and then I went through afterwards and double - checked it so that one is really very  very accurate .\nOh .\nI men I mentioned the link . I sent  You know that one ?\nOh , so\nThe  which one ? I 'm sorry .\nUm , I 'm trying to remember  I don't remember the number off hand .\nThose are all\nIt 's one of the NSA 's . I sent email before the conference , before last week .\nOh , OK .\nBef - What I mean is Wednesday , Thursday .\nThat might  might have been the one  one of the ones that we did .\nMm - hmm .\nI 'm sure that that one 's accurate , I 've been through it  myself .\nSo that might actually be useful but they 're all non - native speakers .\nSo we could compare before and after\nOK .\nand see\nYeah . Yeah , that 's what I was gonna say . The problem with those , they 're all German .\noh , Darn !", "topic_id": 1, "keywords": "overlap, overlapping, alignments, synchronized, coupled", "dialogue_id": 11}, {"text": "Yeah , that 's the problem with the NSA speakers .\nAnd e and e and extremely hard to follow , like word - wise ,\nSo .\nI bet the transcri I mean , I have no idea what they 're talking about ,\nYeah .\nI corrected it for a number of the words .\nso ,\nI 'm sure that , um , they 're  they 're accurate now .\num ,\nUh , actually I have to   to go .\nI mean , this is tough for a language model probably\nRight .\nbut  but that might be useful just for speech .\nWell .\nOK , Andreas is leaving  leaving the building . Mm - hmm .\nYeah .\nSee ya .\nSee ya . I don't think we 'll go much longer .\nUm , oh , before you l go  I guess it 's alright for you to talk a little without the mike  I noticed you adjusting the mike a lot , did it not fit you well ? Oh .\nWell I won I noticed when you turned your head , it would  it would tilt .\nMaybe it wasn't just tightened enough , or\nMaybe the  yeah , the s thing that you have tightened @ @ ,\nActually if  if you have a larger head , that mike 's gotta go farther away which means the  the balance is gonna make it wanna tip down .\noh .\nOK . Anyway .\nYeah . OK , see ya .\nCuz , I 'm just thinking , you know , we were  we 're  we 've been talking about changing the mikes , uh , for a while ,\nYeah .\nand if these aren't  acoustically they seem really good , but if they 're not comfortable , we have the same problems we have with these stupid things .\nI think it 's com This is the first time I 've worn this , I find it very comfortable .\nI find it very comfortable too , but , uh , it looked like Andreas was having problems , and I think Morgan was saying it\nWell , but I had it on  I had it on this morning and it was fine .\nCan I see that ?\nOh , oh you did wear it this morning ?\nYeah .\nOK , it 's off , so you can put it on .\nI  yeah , I don't want it on , I just  I just want to , um , say what I think is a problem with this . If you are wearing this over your ears and you 've got it all the way out here , then the balance is gonna want to pull it this way .\nYeah .\nRight .\nWhere as if somebody with a smaller head has it back here ,\nIt 's more balanced .\nright ? Yeah .\nOh !\nThen it  then it falls back this way so it 's\nSo we have to\nWell wh what it 's supposed to do is the backstrap is supposed to be under your crown , and so that should be  should be\nAh .\nif it 's right against your head there , which is what it 's supposed to be , that balances it so it doesn't slide up .\nSo this is supposed to be under that little protuberance .\nYep , right  right below  if you feel the back of your head , you feel a little lump ,\nYeah .\num , and so it 's supposed to be right under that .\nSo it 's really supposed to go more like this than like this .\nYes , exactly .\nBut then isn't that going to  Well , I guess you can control that .\nThat  that  that tilts , right ? In lots and lots of different ways .\nSo I 'm not saying anything about bias towards small headsize ,\nAbout heads ?\nbut does seem , uh\nIt would be an advantage .\nWell , wonder if it 's  if  if he was wearing it over his hair instead of under his hair .\nWell , we should  We shou we should work on compressing the heads , and\nI think probably it was  Yeah . It probably just wasn't tight enough to the back of his head . I mean , so the directions do talk about bending it to your size , which is not really what we want .\nThe other thing that would do it would be to hang a five pound weight off the back .\nYeah\nRight .\nthat 's good !\nWhat did you say ?\nA little ,\nwh\nHang a five pound weight off the  off the back .\nHang a five pound weight off the back .\num ,\nWe did that\nWeight .\nWe  at Boeing I used  I was doing augmented reality so they had head - mounts on , and we  we had a little jury - rigged one with a welder 's helmet ,\nCounter - balance .\nand we had just a bag with a bunch of marbles in it  as a counter - balance .\nOr maybe this could be helpful just for evening the conversation between people . If people  those who talk a lot have to wear heavier weights or something , and\nYeah !\nand  um ,\nAnyway .\num , so , uh , what was I gonna say ? Oh , yeah , I was gonna say , uh , I had these , uh , conversations with NIST folks also while I was there and  and , uh , um , so they  they have their  their plan for a room , uh , with , um , mikes in the middle of the table , and , uh , close - mounted mikes ,\nYep .\nand they 're talking about close - mounted and lapels , just cuz\nAnd arrays ,\nsort of  and the array .\nAnd arrays ,\nYeah , so they were\nwhich is the i interesting\nyep . And cameras .\nAnd yeah , like multiple  multiple video cameras coverin covering every  everybody  every place in the room ,\nand video , right .\nuh , the  yeah  the  the mikes in the middle , the head - mounted mikes , the lapel mikes , the array , uh , with  well , there 's some discussion of fifty - nine ,\nFifty - nine elements .\nthey might go down to fifty - seven Because , uh , there is , uh , some pressure from a couple people at the meeting for them to use a KEMAR head . I forget what KEMAR , uh , stands for ,\nMm - hmm .\nbut what it is is it 's dummy head that is very specially designed ,\nOh , that 's right .\nand  and  and , so what they 're actually doing is they 're really  there 's really two recording systems .\nRight .\nYep .\nThat 's a great idea .\nSo they may not be precisely synchronous , but the but there 's two  two recording systems , one with , I think , twenty - four channels , and one with sixty - four channels . And the sixty - four channel one is for the array , but they 've got some empty channels there , and anyway they  like they 're saying they may give up a couple or something if  for  for the KEMAR head if they go  go with that .\nRight . Yeah , it is a good idea .\nSo .\nYeah , h uh , J Jonathan Fiscus did say that , uh , they have lots of software for doing calibration for skew and offset between channels\nMm - hmm\nand that they 've found that 's just not a big deal .\nYeah .\nSo .\nYeah , I 'm not  too worried about that . I was thinking\nBut they 're still planning to do like fake\nScenario - based .\nthey have to do something like that ,\nY right .\nright .\nTheir  their legal issues won't allow them to do otherwise .\nYeah .\nBut it sounded like they were  pretty well thought out\nYeah , th that 's true .\nand they 're  they 're gonna be real meetings ,\nMm - hmm .\nit 's just that they 're with str with people who would not be meeting otherwise .\nDid  did they give a talk on this or was this informal ?\nMm - hmm .\nSo .\nNo .\nNo .\nNo , we just had some discussions , various discussions with them .\nIt 's just informal .\nMm - hmm . Mm - hmm . Yeah .\nYeah , I also sat and chatted with several of the NIST folks . They seemed like a good group .\nWhat was the , um  the paper by , um , Lori Lamel that you mentioned ?\nUm , yeah , we sh we should just have you  have you read it , but , I mea ba i i uh , we 've all got these little proceedings ,\nMmm , yeah .\nbut , um , basically , it was about , um , uh , going to a new task where you have insufficient data and using  using data from something else , and adapting , and how well that works . Uh , so in  in fact it was pretty related to what Liz and Andreas did , uh , except that this was not with meeting stuff , it was with\nRight .\nuh , like I think they s didn't they start off with Broadcast News system ? And then they went to\nThe - their Broadcast News was their acoustic models and then all the other tasks were much simpler .\nYeah .\nSo they were command and control and that sort of thing .\nTI - digits was one of them , and , uh , Wall Street Journal .\nYep .\nWhat was their rough  what was their conclusion ?\nYeah , read Wall Street Journal . It works .\nYeah .\nWell , it 's  it 's a good paper , I mean\nYeah , yeah .\nYeah . Yeah , that was one of the ones that I liked .\nBring the\nThat  It not only works , in some cases it was better , which I thought was pretty interesting , but that 's cuz they didn't control for parameters . So .\nProbably .\nYou know , the Broadcast News nets were  not nets ,\nRight .\nDid they ever try going  going the other direction from simpler task to more complicated tasks ,\nacoustic models  were a lot more complex .\nor  ?\nn Not in that paper .\nThat might be hard .\nYeah , well , one of the big problems with that is  is often the simpler task isn't fully  doesn't have all the phones in it ,\nYeah .\nand that  that makes it very hard .\nMm - hmm .\nYeah .\nBut I 've done the same thing . I 've been using Broadcast News nets for digits ,\nYeah .\nlike for the spr speech proxy thing that I did ? That 's what I did .\nYeah , sure .\nSo . It works .\nYeah . Yeah , and they have  I mean  they have better adaptation than we had than that  that system ,\nYep .\nso they  um ,\nYou mean they have some .\nyeah , we should probably what would  actually what we should do , uh , I haven't said anything about this , but probably the five of us should pick out a paper or two that  that , uh , you know , got our interest , and we should go around the room at one of the Tuesday lunch meetings and say , you know , what  what was good about the conference ,\nPresent . Yep . Do a trip report .\nyeah .\nWell , the summarization stuff was interesting , I mean , I don't know anything about that field , but for this proposal on meeting summarization , um , I mean , it 's sort of a far cry because they weren't working with meeting type data , but he got sort of an overview on some of the different approaches ,\nRight .\nDo you remember who the groups were that we 're doing ?\nso . Well there 're  this was the last day ,\nA lot of different ones .\nR I think  Mm - hmm .\nbut , I mean , there 's  that 's a huge field and probably the groups there may not be representative of the field , I  I don't know exactly that everyone submits to this particular conference ,\nWas  were there folks from BBN presenting ?\nbut yet there was , let 's see , this was on the last day , Mitre , BBN , and , um , Prager\nMitre , BBN , IBM . Uh ,\nMaryland .\num , I wo it was\nColumbia have anything ? No .\nno it was\nWasn't  Who  who  who did the order one ?\nthis was Wednesday morning . The sentence ordering one , was that Barselou , and these guys ?\nUgh !  I 'm just so bad at that .\nOh .\nAnyway , I  I  it 's in the program , I should have read it to remind myself , but that 's sort of useful and I think like when Mari and Katrin and Jeff are here it 'd be good to figure out some kinds of things that we can start doing maybe just on the transcripts cuz we already have\nMm - hmm .\nYeah , we do have word transcripts .\nyou know , yeah .\nSo .\nWell , I like the idea that Adam had of  of , um , z maybe generating minutes based on some of these things that we have because it would be easy to  to  to do that just , you know , and  and\nRight .\nit has to be , though , someone from this group because of the technical nature of the thing .\nSomeone who actually does take notes , um ,  I 'm very bad at note - taking .\nBut I think what 's interesting is there 's all these different evaluations , like  just , you know , how do you evaluate whether the summary is good or not ,\nI always write down the wrong things .\nI do take notes .\nand that 's what 's  was sort of interesting to me is that there 's different ways to do it ,\nA judge .\nand\nWas SRA one of the groups talking about summarization , no ?\nYep .\nHm - umm . No .\nIt was an interesting session . One of those w\nAnd as I said , I like the Microsoft talk on  scaling issues in , uh , word sense disambiguation ,\nYeah .\nthat was interesting .\nYeah , that was an interesting discussion ,\nThe\nuh , I\nIt  it  it was the only one  It was the only one that had any sort of real disagreement about .\nThe data issue comes up all the ti\nWell , I didn't have as much disagreement as I would have liked ,\nSo .\nbut I didn't wanna  I wouldn I didn't wanna get into it because , uh , you know , it was the application was one I didn't know anything about ,\nYep .\nuh , it just would have been , you know , me getting up to be argumentative , but  but , uh , I mean , the missing thi so  so what they were saying  it 's one of these things  is  you know , all you need is more data , sort of  But I mea i wh it  @ @ that 's  that 's dissing it , uh , improperly , I mean , it was a nice study . Uh , they were doing this  it wasn't word - sense disambiguation , it was\nYeah  yeah  yeah\nWell , it sort of was .\nwas it w was it word - sense ? Yes .\nBut it was  it was a very simple case of \" to \" versus \" too \" versus \" two \" and \" there \" , \" their \" , \" they 're \"\nAnd there and their and\nYeah , yeah . OK .\nand that you could do better with more data , I mean , that 's clearly statistically\nRight .\nYeah .\nAnd so , what they did was they had these different kinds of learning machines , and they had different amounts of data , and so they did like , you know , eight different methods that everybody , you know , uh , argues about  about , \" Oh my  my kind of learning machine is better than your kind of learning machine . \" And , uh , they were  started off with a million words that they used , which was evidently a number that a lot of people doing that particular kind of task had been using . So they went up , being Microsoft , they went up to a billion . And then they had this log scale showing a  you know , and  and naturally everything gets\nThem being beep ,  they went off to a billion .\nthey  well , it 's a big company , I didn't  I didn't mean it as a ne anything negative ,\nYeah .\nbut i i i\nYou mean the bigger the company the more words they use for training ?\nWell , I think the reason they can do that , is that they assumed that text that they get off the web , like from Wall Street Journal , is correct , and edit it .\nYeah .\nSo that 's what they used as training data . It 's just saying if it 's in this corpus it 's correct .\nOK . But , I mean , yes . Of course there was the kind of effect that , you know , one would expect that  uh  that you got better and better performance with more and more data . Um , but the  the real point was that the  the different learning machines are sort of all over the place , and  and by  by going up significantly in data you can have much bigger effect then by switching learning machines and furthermore which learning machine was on top kind of depended on where you were in this picture , so ,\nThis was my concern about the recognizer in Aurora .\nuh , That\nThat the differences we 're seeing in the front - end is b\nYeah .\nAre irrelevant .\nare irrelevant once you get a real recognizer at the back - end .\nYeah .\nIf you add more data ? Or\nYou know ?\nYeah .\nHuh .\nYeah , could well be . So  so , I mean , that was  that was kind of , you know , it 's a good point , but the problem I had with it was that the implications out of this was that , uh , the kind of choices you make about learning machines were therefore irrelevant which is not at  n t as for as I know in  in tasks I 'm more familiar with @ @ is not at all true . What i what is  is true is that different learning machines have different properties , and you wanna know what those properties are . And someone else sort of implied that well we s you know , a all the study of learning machine we still don't know what those properties are . We don't know them perfectly , but we know that some kinds use more memory and  and some other kinds use more computation and some are  are hav have limited kind of discrimination , but are just easy to use , and others are\nBut doesn't their conclusion just sort of  you could have guessed that before they even started ? Because if you assume that these learning things get better and better and better ,\nYou would guess\nthen as you approach  there 's a point where you can't get any better , right ? You get everything right .\nYeah .\nIt 's just no\nBut\nSo they 're all approaching .\nNo , but there was still a spread . They weren't all up They weren't converging .\nBut what I 'm saying is that th they have to , as they all get better , they have to get closer together .\nIt w\nThey were all still spread . But they  Right , right . Sure . But they hadn't even come close to that point . All the tasks were still improving when they hit a billion .\nYeah .\nBut they 're all going the same way , right ? So you have to get closer .\nEventually . O one would\nBut they didn't get closer .\nOh they didn't ?\nWell\nThey just switched position .\nwell that 's getting cl I mean , yeah , the spread was still pretty wide that 's th that 's true ,\nYep .\nbut  but , uh , I think it would be irntu intu intuition that this would be the case , but , uh , to really see it and to have the intuition is quite different , I mean , I think somebody w w let 's see who was talking about earlier that the effect of having a lot more data is quite different in Switchboard than it is in  in Broadcast News ,\nWell it 's different for different tasks .\nYeah . It was Liz . Yeah .\nyeah .\nSo it depends a lot on whether , you know , it  disambiguation is exactly the case where more data is better , right ? You 're  you 're  you can assume similar distributions ,\nYeah .\nbut if you wanted to do disambiguation on a different type of , uh , test data then your training data , then that extra data wouldn't generalize ,\nRight .\nso .\nRight .\nBut , I think one of their p They  they had a couple points . w  Uh , I think one of them was that \" Well , maybe simpler algorithms and more data are  is better \" . Less memory , faster operation , simpler . Right ? Because their simplest , most brain - dead algorithm did pretty darn well\nMm - hmm .\nwhen you got  gave it a lot more data . And then also they were saying , \" Well , m You have access to a lot more data . Why are you sticking with a million words ? \" I mean , their point was that this million - word corpus that everyone uses is apparently ten or fifteen years old . And everyone is still using it , so .\nYeah . But anyway , I  I  I think it 's  it 's just the  the i it 's  it 's  it 's not really the conclusion they came to so much , as the conclusion that some of the , uh , uh , commenters in the crowd  came up with\nBut we could talk about this stuff , I think this would be fun to do . Right .\nthat , uh , you know , this therefore is further evidence that , you know , more data is really all you should care about , and that I thought was just kind of going too far the other way ,\nMachine - learning .\nand  and the  the , uh , one  one person ga g g got up and made a  a brief defense , uh , but it was a different kind of grounds , it was that  that , uh , i w the reason people were not using so much data before was not because they were stupid or didn't realize data was important , but in fact th they didn't have it available . Um , but the other point to make a again is that , uh , machine learning still does matter , but it  it matters more in some situations than in others , and it  and also there 's  there 's not just mattering or not mattering , but there 's mattering in different ways . I mean , you might be in some situation where you care how much memory you 're using , or you care , you know , what recall time is ,\nRight .\nor you care , you know , and  and\nOr you only have a million words  for your  some new task .\nYeah , or  or , uh\nOr done another language , or  I mean , you  so there 's papers on portability and rapid prototyping and blah - blah - blah ,\nYep .\nYeah .\nRight .\nYeah .\nand then there 's people saying , \" Oh , just add more data . \"\nAnd there 's cost !\nSo , these are like two different religions , basically .\nMm - hmm . Cost .\nThere 's just plain cost ,\nYeah . That 's a big one .\nyou know , so  so these , I mean th the  in the  in the speech side , the thing that @ @ always occurs to me is that if you  if you  uh  one person has a system that requires ten thousand hours to train on , and the other only requires a hundred , and they both do about the same because the hundred hour one was smarter , that 's  that 's gonna be better . because people , I mean , there isn't gonna be just one system that people train on\nYep .\nand then that 's it for the r for all of time . I mean , people are gonna be doing other different things , and so it  these  these things matters  matter .\nYeah , that 's it .\nYeah , so that 's one of the slides they put up .\nSo , I mean , this was a very provocative slide . She put this up , and it was like this is  this p people kept saying , \" Can I see that slide again ? \"\nYeah .\nYeah ,\nand then they 'd make a comment , and one person said , well - known person said , um , you know , \" Before you dismiss forty - five years including my work  \"\nyeah .\nForty - five years of research .\nYeah .\nYeah .\nBut th you know , the same thing has happened in computational linguistics , right ? You look at the ACL papers coming out , and now there 's sort of a turn back towards , OK we 've learned statistic  you know , we 're basically getting what we expect out of some statistical methods , and , you know , the there 's arguments on both sides ,\nYep .\nso\nI think the matters is the thing that  that was misleading .\nThat was very offending , very offending .\nYeah , yeah .\nIs that  all  all of them are based on all the others , right ? Just , you  you can't say\nMaybe they should have said \" focus \" or something .\nRight .\nYeah . I mean , so .  And I 'm saying the same thing happened with speech recognition , right ? For a long time people were hand - c coding linguistic rules and then they discovered machine - learning worked better . And now they 're throwing more and more data and worrying  perhaps worrying less and less about , uh , the exact details of the algorithms .\nAnd  and then you hit this\nExcept when they have a Eurospeech paper .\nYeah .\nYeah .\nAnyway .\nAnyway , tea is  tea is , uh , starting .\nShall we read some digits ? Are we gonna do one at a time ? Or should we read them all agai at once again .\nLet 's do it all at once .\nYeah , that 's good .\nWe  @ @  let 's try that again .\nYes ! So , and maybe we won't laugh this time also .\nOK . So remember to read the transcript number so that , uh , everyone knows that  what it is . And ready ?\nYeah .\nThree , two , one .\nBoy , is that ever efficient .\nYep . That 's really fast .\nYeah . Yeah .", "topic_id": 2, "keywords": "speech, nsa, conversations, conversation, speakers", "dialogue_id": 11}, {"text": "It 's not very significant .\nUh , channel one . Yes .\nChannel three .\nOK .\nMm - hmm .\nChannel three .\nTa\nChannel three . Alright .\nOK , did you solve speech recognition last week ?\nAlmost .\nAlright ! Let 's do image processing .\nYes , again .\nGreat .\nWe did it again , Morgan .\nAlright !\nDoo - doop , doo - doo .\nWhat 's wrong with  ?\nOK . It 's April fifth . Actually , Hynek should be getting back in town shortly if he isn't already .\nIs he gonna come here ?\nUh . Well , we 'll drag him here . I know where he is .\nSo when you said \" in town \" , you mean  Oregon .\nU u u u uh , I meant , you know , this end of the world , yeah ,  is really what I meant ,\nOh .\nDoo , doo - doo .\nuh , cuz he 's been in Europe .\nDoo - doo .\nSo .\nI have something just fairly brief to report on .\nMmm .\nUm , I did some  experim uh , uh , just a few more experiments before I had to ,  uh , go away for the w well , that week .\nGreat !\nWas it last week or whenever ? Um , so what I was started playing with was the  th again , this is the HTK back - end . And , um , I was curious because the way that they train up the models ,  they go through about four sort of rounds of  of training . And in the first round they do  uh , I think it 's three iterations , and for the last three rounds e e they do seven iterations of re - estimation in each of those three . And so , you know , that 's part of what takes so long to train the  the  the back - end for this .\nI 'm sorry , I didn't quite get that . There 's  there 's four and there 's seven and  I  I 'm sorry .\nYeah . Uh , maybe I should write it on the board . So ,  there 's four rounds of training . Um , I g I g I guess you could say iterations . The first one is three , then seven , seven , and seven . And what these numbers refer to is the number of times that the , uh , HMM re - estimation is run . It 's this program called H E\nBut in HTK , what 's the difference between , uh , a  an inner loop and an outer loop in these iterations ?\nOK . So what happens is , um , at each one of these points , you increase the number of Gaussians in the model .\nYeah . Oh , right ! This was the mix up stuff .\nYeah . The mix up .\nThat 's right .\nRight .\nI remember now .\nAnd so , in the final one here , you end up with , uh  for all of the  the digit words , you end up with , uh , three  mixtures per state ,\nYeah .\neh , in the final  thing . So I had done some experiments where I was  I  I want to play with the number of mixtures .\nMm - hmm .\nBut , um , uh , I wanted to first test to see if we actually need to do  this many iterations early on .\nUh , one , two ,\nMm - hmm .\nAnd so , um , I  I ran a couple of experiments where I  reduced that to l to be three , two , two ,  uh , five , I think , and I got almost the exact same results .\nMm - hmm .\nAnd  but it runs much much faster . So , um , I  I think m  it only took something like , uh , three or four hours to do the full training ,\nAs opposed to  ?\nGood .\nas opposed to wh what , sixteen hours or something like that ? I mean , it takes  you have to do an overnight basically , the way it is set up now .\nYeah . It depends .\nMm - hmm .\nMm - hmm .\nSo , uh , even we don't do anything else , doing something like this could allow us to turn experiments around a lot faster .\nAnd then when you have your final thing , do a full one , so it 's\nAnd when you have your final thing , we go back to this .\nYeah .\nSo , um , and it 's a real simple change to make . I mean , it 's like one little text file you edit and change those numbers , and you don't do anything else .\nOh , this is a\nMm - hmm .\nAnd then you just run .\nOK .\nSo it 's a very simple change to make and it doesn't seem to hurt all that much .\nSo you  you run with three , two , two , five ? That 's a\nSo I  Uh , I  I have to look to see what the exact numbers were .\nYeah .\nI  I thought was , like , three , two , two , five ,\nMm - hmm .\nbut I I 'll  I 'll double check . It was  over a week ago that I did it ,\nOK . Mm - hmm .\nso I can't remember exactly .\nOh .\nBut , uh\nMm - hmm .\num , but it 's so much faster . I it makes a big difference .\nHmm .\nSo we could do a lot more experiments and throw a lot more stuff in there .\nYeah .\nThat 's great .\nUm . Oh , the other thing that I did was , um ,  I compiled  the HTK stuff for the Linux boxes . So we have this big thing that we got from IBM , which is a five - processor machine . Really fast , but it 's running Linux . So , you can now run your experiments on that machine and you can run five at a time and it runs ,  uh , as fast as , you know , uh , five different machines .\nMm - hmm .\nMm - hmm .\nSo , um , I 've forgotten now what the name of that machine is but I can  I can send email around about it .\nYeah .\nAnd so we 've got it  now HTK 's compiled for both the Linux and for , um , the Sparcs . Um , you have to make  you have to make sure that in your dot CSHRC ,  um , it detects whether you 're running on the Linux or a  a Sparc and points to the right executables . Uh , and you may not have had that in your dot CSHRC before , if you were always just running the Sparc . So , um ,\nMm - hmm .\nuh , I can  I can tell you exactly what you need to do to get all of that to work . But it 'll  it really increases what we can run on .\nHmm . Cool .\nSo ,  together with the fact that we 've got these  faster Linux boxes and that it takes less time to do  these , um , we should be able to crank through a lot more experiments .\nMm - hmm .\nSo .\nHmm .\nSo after I did that , then what I wanted to do  was try  increasing the number of mixtures , just to see , um  see how  how that affects performance .\nYeah .\nSo .\nYeah . In fact , you could do something like  keep exactly the same procedure and then add a fifth thing onto it\nMm - hmm .\nthat had more .\nExactly .\nYeah .\nRight . Right .\nSo at  at the middle o where the arrows are showing , that 's  you 're adding one more mixture per state ,\nUh - huh . Uh ,\nor  ?\nlet 's see , uh . It goes from this  uh , try to go it backwards  this  at this point it 's two mixtures  per state . So this just adds one . Except that , uh , actually for the silence model , it 's six mixtures per state .\nMm - hmm .\nUh , so it goes to two .\nOK .\nUm . And I think what happens here is\nMight be between , uh , shared , uh  shared variances or something ,\nYeah . I think that 's what it is .\nor\nUh , yeah . It 's , uh  Shoot . I  I  I can't remember now what happens at that first one . Uh , I have to look it up and see .\nOh , OK .\nUm , there  because they start off with , uh , an initial model which is just this global model , and then they split it to the individuals . And so ,  it may be that that 's what 's happening here . I  I   I have to look it up and see . I  I don't exactly remember .\nOK .\nOK .\nSo . That 's it .\nAlright . So what else ?", "topic_id": 0, "keywords": "channel, brief, speech, little, htk", "dialogue_id": 12}, {"text": "Um . Yeah . There was a conference call this Tuesday . Um . I don't know yet the   what happened  Tuesday , but  the points that they were supposed to discuss is still ,  uh , things like  the weights , uh\nOh , this is a conference call for , uh , uh , Aurora participant sort of thing .\nFor\nYeah . Yeah .\nI see .\nMmm .\nDo you know who was  who was  since we weren't in on it , uh , do you know who was in from OGI ? Was   was  was Hynek involved or was it Sunil\nI have no idea .\nor  ?\nMmm , I just\nOh , you don't know . OK .\nYeah .\nAlright .\nUm , yeah . So the points were the  the weights  how to weight the different error rates  that are obtained from different language and  and conditions . Um , it 's not clear that they will keep the same kind of weighting . Right now it 's a weighting on  on improvement .\nMm - hmm .\nSome people are arguing that it would be better to have weights on uh  well , to  to combine error rates  before computing improvement . Uh , and the fact is that for  right now for  the English , they have weights  they  they combine error rates , but for the other languages they combine improvement . So it 's not very consistent . Um\nMm - hmm .\nYeah . The , um  Yeah . And so  Well ,  this is a point . And right now actually there is a thing also ,  uh , that happens with the current weight is that a very non - significant improvement  on the well - matched case result in  huge differences in   in the final number .\nMm - hmm .\nAnd so , perhaps they will change the weights to\nHmm .\nYeah .\nHow should that be done ? I mean , it  it seems like there 's a simple way\nMm - hmm .\nUh , this seems like an obvious mistake or something .\nWell , I mean , the fact that it 's inconsistent is an obvious mistake .\nTh - they 're\nBut the  but , um , the other thing\nIn\nI don't know I haven't thought it through , but one  one would think that  each  It  it 's like if you say what 's the  what 's the best way to do an average , an arithmetic average or a geometric average ?\nMm - hmm .\nIt depends what you wanna show .\nMm - hmm .\nEach  each one is gonna have a different characteristic .\nYeah .\nSo\nWell , it seems like they should do , like , the percentage improvement or something , rather than the  absolute improvement .\nTha - that 's what they do .\nWell , they are doing that .\nYeah .\nNo , that is relative . But the question is , do you average the relative improvements  or do you average the error rates and take the relative improvement maybe of that ?\nYeah . Yeah .\nAnd the thing is it 's not just a pure average because there are these weightings .\nOh .\nIt 's a weighted average . Um .\nYeah . And so when you average the  the relative improvement it tends to   to give a lot of  of , um ,  importance to the well - matched case because  the baseline is already very good and , um , i it 's\nWhy don't they not look at improvements but just look at your av your scores ? You know , figure out how to combine the scores\nMm - hmm .\nwith a weight or whatever , and then give you a score  here 's your score . And then they can do the same thing for the baseline system  and here 's its score . And then you can look at\nMm - hmm .\nWell , that 's what he 's seeing as one of the things they could do .\nYeah .\nIt 's just when you  when you get all done , I think that they pro I m I  I wasn't there but I think they started off this process with the notion that  you should be  significantly better than the previous standard .\nMm - hmm .\nAnd , um , so they said \" how much is significantly better ? what do you  ? \" And  and so they said \" well ,  you know , you should have half the errors , \" or something , \" that you had before \" .\nMm - hmm . Hmm .\nMm - hmm .\nYeah .\nSo it 's , uh , But it does seem like\nHmm .\ni i it does seem like it 's more logical to combine them first and then do the\nCombine error rates and then\nYeah .\nYeah . Well\nYeah .\nBut there is this  this  is this still this problem of weights . When  when you combine error rate it tends to  give more importance to the difficult cases , and some people think that\nOh , yeah ?\nwell , they have different ,  um , opinions about this . Some people think that  it 's more important to look at   to have ten percent imp relative improvement on  well - matched case than to have fifty percent on the m mismatched , and other people think that it 's more important to improve a lot on the mismatch and  So , bu\nIt sounds like they don't really have a good idea about what the final application is gonna be .\nl de fff ! Mmm .\nWell , you know , the  the thing is  that if you look at the numbers on the  on the more difficult cases ,  um , if you really believe that was gonna be the predominant use ,  none of this would be good enough .\nYeah . Mmm . Yeah .\nNothing anybody 's\nMm - hmm .\nwhereas  you sort of with some reasonable error recovery could imagine in the better cases that these  these systems working . So , um , I think the hope would be that it would   uh , it would work well  for the good cases and , uh , it would have reasonable  reas  soft degradation as you got to worse and worse conditions . Um .\nYeah . I  I guess what I 'm  I mean , I  I was thinking about it in terms of , if I were building the final product and I was gonna test to see which front - end I 'd   I wanted to use , I would  try to  weight things depending on the exact environment that I was gonna be using the system in .\nBut  but  No .\nIf I\nWell , no  well , no . I mean ,  it isn't the operating theater . I mean , they don they  they don't  they don't really  know , I think .\nYeah .\nI mean , I th\nSo if  if they don't know , doesn't that suggest the way for them to go ? Uh , you assume everything 's equal . I mean , y y I mean , you\nWell , I mean , I  I think one thing to do is to just not rely on a single number  to maybe have two or three numbers ,\nYeah .\nyou know ,\nRight .\nand  and  and say  here 's how much you , uh  you improve  the , uh  the  the relatively clean case and here 's  or  or well - matched case , and here 's how  here 's how much you ,\nMm - hmm .\nuh\nSo not\nSo .\nSo not try to combine them .\nYeah . Uh , actually it 's true .\nYeah .\nUh , I had forgotten this , uh , but , uh , well - matched is not actually clean . What it is is just that , u uh , the training and testing are similar .\nThe training and testing .\nMmm .\nSo , I guess what you would do in practice is you 'd try to get as many ,  uh , examples of similar sort of stuff as you could , and then ,\nYeah .\nuh  So the argument for that being the  the  the more important thing ,  is that you 're gonna try and do that ,  but you wanna see how badly it deviates from that when  when  when the , uh  it 's a little different .\nSo\nUm ,\nso you should weight those other conditions v very  you know , really small .\nBut  No . That 's a  that 's a  that 's an arg\nI mean , that 's more of an information kind of thing .\nthat 's an ar Well , that 's an argument for it , but let me give you the opposite argument . The opposite argument is you 're never really gonna have a good sample of all these different things .\nUh - huh .\nI mean , are you gonna have w uh , uh , examples with the windows open , half open , full open ? Going seventy , sixty , fifty , forty miles an hour ? On what kind of roads ?\nMm - hmm .\nWith what passing you ? With  uh , I mean ,\nMm - hmm .\nI  I  I think that you could make the opposite argument that the well - matched case is a fantasy .\nMm - hmm .\nYou know , so ,\nUh - huh .\nI think the thing is is that if you look at the well - matched case versus the po you know , the  the medium and the  and the fo and then the mismatched case ,  um , we 're seeing really , really big differences in performance . Right ? And  and y you wouldn't like that to be the case . You wouldn't like that as soon as you step outside  You know , a lot of the  the cases it 's  is\nWell , that 'll teach them to roll their window up .\nI mean , in these cases , if you go from the  the , uh  I mean , I don't remember the numbers right off , but if you  if you go from the well - matched case to the medium ,  it 's not an enormous difference in the  in the  the training - testing situation , and  and  and it 's a really big  performance drop .\nMm - hmm .\nYou know , so , um  Yeah , I mean the reference one , for instance  this is back old on , uh  on Italian  uh , was like  six percent error for the well - matched and eighteen for the medium - matched and sixty for the   for highly - mismatched . Uh , and , you know , with these other systems we  we  helped it out quite a bit , but still there 's  there 's something like a factor of two or something between well - matched and medium - matched . And  so I think that  if what you 're   if the goal of this is to come up with robust features , it does mean  So you could argue , in fact , that the well - matched is something you shouldn't be looking at at all , that  that the goal is to come up with features  that will still give you reasonable performance , you know , with again gentle degregra degradation , um , even though the  the testing condition is not the same as the training .\nHmm .\nSo , you know , I  I could argue strongly that something like the medium mismatch , which is you know not compl pathological but  I mean , what was the  the medium - mismatch condition again ?\nUm ,  it 's  Yeah . Medium mismatch is everything with the far  microphone , but trained on , like , low noisy condition , like low speed and  or  stopped car and tested on  high - speed conditions , I think , like on a highway and\nRight .\nSo\nSo it 's still the same  same microphone in both cases ,\nSame microphone but  Yeah .\nbut , uh , it 's  there 's a mismatch between the car conditions . And that 's  uh , you could argue that 's a pretty realistic situation\nYeah .\nMm - hmm .\nand , uh , I 'd almost argue for weighting that highest . But the way they have it now ,  it 's  I guess it 's  it 's  They  they compute the relative improvement first and then average that with a weighting ?\nYeah .\nAnd so then the  that  that makes the highly - matched the really big thing .\nMm - hmm .\nUm , so , u i since they have these three categories , it seems like the reasonable thing to do  is to go across the languages  and to come up with an improvement for each of those .\nMm - hmm .\nJust say \" OK , in the  in the highly - matched case this is what happens , in the   m the , uh  this other m medium if this happens , in the highly - mismatched  that happens \" .\nMm - hmm .\nAnd , uh , you should see , uh , a gentle degradation  through that .\nMmm .\nUm . But  I don't know .\nYeah .\nI think that  that  I  I  I gather that in these meetings it 's  it 's really tricky to make anything  ac  make any  policy change because   everybody has  has , uh , their own opinion\nMm - hmm .\nand  I don't know .\nYeah .\nYeah .\nUh , so  Yeah . Yeah , but there is probably a  a big change that will  be made is that the  the baseline  th they want to have a new baseline , perhaps , which is , um , MFCC but with  a voice activity detector . And apparently ,  uh , some people are pushing to still keep this fifty percent number . So they want  to have at least fifty percent improvement on the baseline , but w which would be a much better baseline .\nMm - hmm . Mm - hmm .\nAnd if we look at the result that Sunil sent ,  just putting the VAD in the baseline improved , like , more than twenty percent ,\nMm - hmm .\nwhich would mean then  then  mean that fifty percent on this new baseline is like , well , more than sixty percent improvement on  on  o e e uh\nSo nobody would  be there , probably . Right ?\nRight now , nobody would be there , but  Yeah .\nGood . Work to do .\nUh - huh .", "topic_id": 1, "keywords": "weights, weightings, weighting, weighted, performance", "dialogue_id": 12}, {"text": "So whose VAD is  Is  is this a  ?\nUh , they didn't decide yet . I guess i this was one point of the conference call also , but  mmm , so I don't know . Um , but  Yeah .\nOh .\nOh , I  I think th that would be  good . I mean , it 's not that the design of the VAD isn't important , but it 's just that it  it  it does seem to be i uh , a lot of  work to do a good job on  on that and as well as being a lot of work to do a good job on the feature  design ,\nYeah .\nso\nYeah .\nif we can  cut down on that maybe we can make some progress .\nM Yeah .\nHmm .\nBut I guess perhaps  I don't know w  Yeah . Uh , yeah . Per - e s s someone told that perhaps it 's not fair to do that because the , um  to make a good VAD  you don't have enough to  with the  the features that are  the baseline features . So  mmm , you need more features . So you really need to put more  more in the  in  in the front - end .\nYeah .\nSo i\nUm ,\nS\nsure . But i bu\nWait a minute . I  I 'm confused .\nYeah .\nWha - what do you mean ?\nYeah , if i\nSo y so you m s Yeah , but  Well , let 's say for ins see , MFCC for instance doesn't have anything in it , uh , related to the pitch . So just  just for example . So suppose you 've  that  what you really wanna do is put a good pitch detector on there and if it gets an unambiguous\nOh , oh . I see .\nMm - hmm .\nif it gets an unambiguous result then you 're definitely in a  in a  in a voice in a , uh , s region with speech . Uh .\nSo there 's this assumption that the v the voice activity detector can only use the MFCC ?\nThat 's not clear , but this   e\nWell , for the baseline .\nYeah .\nSo  so if you use other features then y But it 's just a question of what is your baseline . Right ? What is it that you 're supposed to do better than ?\nI g Yeah .\nAnd so having the baseline be the MFCC 's  means that people could  choose to pour their ener their effort into trying to do a really good VAD\nI don't s But they seem like two  separate issues .\nor tryi They 're sort of separate .\nRight ? I mean\nUnfortunately there 's coupling between them , which is part of what I think Stephane is getting to , is that  you can choose your features in such a way as to improve the VAD .\nYeah .\nAnd you also can choose your features in such a way as to prove  improve recognition . They may not be the same thing .\nBut it seems like you should do both .\nYou should do both\nRight ?\nand  and I  I think that this still makes  I still think this makes sense as a baseline . It 's just saying , as a baseline , we know\nMmm .\nyou know , we had the MFCC 's before , lots of people have done voice activity detectors ,\nMm - hmm .\nyou might as well pick some voice activity detector and make that the baseline , just like you picked some version of HTK and made that the baseline .\nYeah . Right .\nAnd then  let 's try and make everything better . Um , and if one of the ways you make it better is by having your features  be better features for the VAD then that 's  so be it .\nMm - hmm .\nBut , uh , uh , uh , at least you have a starting point that 's  um , cuz i i some of  the some of the people didn't have a VAD at all , I guess . Right ? And  and\nYeah .\nthen they  they looked pretty bad and  and in fact what they were doing wasn't so bad at all .\nMm - hmm . Mm - hmm .\nBut , um .\nYeah . It seems like you should try to make your baseline as good as possible . And if it turns out that  you can't improve on that , well , I mean , then , you know , nobody wins and you just use MFCC . Right ?\nYeah . I mean , it seems like , uh , it should include sort of the current state of the art  that you want  are trying to improve , and MFCC 's , you know , or PLP or something  it seems like  reasonable baseline for the features , and anybody doing this task ,  uh , is gonna have some sort of voice activity detection at some level , in some way . They might use the whole recognizer to do it  but  rather than  a separate thing , but   but they 'll have it on some level . So , um .\nIt seems like whatever they choose they shouldn't ,  you know , purposefully brain - damage a part of the system to  make a worse baseline , or\nWell , I think people just had\nYou know ?\nit wasn't that they purposely brain - damaged it . I think people hadn't really thought through  about the , uh  the VAD issue .\nMmm .\nMm - hmm .\nAnd  and then when the  the  the proposals actually came in and half of them had V A Ds and half of them didn't , and the half that did did well and the  half that didn't did poorly .\nMm - hmm .\nSo it 's\nMm - hmm . Um .\nUh .\nYeah . So we 'll see what happen with this . And  Yeah . So what happened since , um ,  last week is  well , from OGI , these experiments on  putting VAD on the baseline . And these experiments also are using , uh , some kind of noise compensation , so spectral subtraction , and putting on - line normalization , um , just after this . So I think spectral subtraction , LDA filtering , and on - line normalization , so which is similar to  the pro proposal - one , but with  spectral subtraction in addition , and it seems that on - line normalization doesn't help further when you have spectral subtraction .\nIs this related to the issue that you brought up a couple of meetings ago with the  the  musical tones\nI\nand  ?\nI have no idea , because the issue I brought up was with a very simple spectral subtraction approach ,\nMmm .\nand the one that  they use at OGI is one from  from  the proposed  the  the  the Aurora prop uh , proposals , which might be much better . So , yeah . I asked  Sunil for more information about that , but , uh , I don't know yet . Um . And what 's happened here is that we  so we have this kind of new , um , reference system which  use a nice  a  a clean downsampling - upsampling , which use a new filter  that 's much shorter and which also cuts the frequency below sixty - four hertz ,\nRight .\nwhich was not done on our first proposal .\nWhen you say \" we have that \" , does Sunil have it now , too ,\nI No .\nor  ?\nNo .\nOK .\nBecause we 're still testing . So we have the result for ,  uh , just the features\nOK .\nand we are currently testing with putting the neural network in the KLT . Um , it seems to improve on the well - matched case , um ,  but it 's a little bit worse on the mismatch and highly - mismatched  I mean when we put the neural network . And with the current weighting I think it 's sh it will be better because the well - matched case is better . Mmm .\nBut how much worse  since the weighting might change  how  how much worse is it on the other conditions , when you say it 's a little worse ?\nIt 's like , uh , fff , fff    um ,     ten percent relative . Yeah .\nOK . Um .\nMm - hmm .\nBut it has the , uh  the latencies are much shorter . That 's\nUh - y w when I say it 's worse , it 's not  it 's when I  I  uh , compare proposal - two to proposal - one , so , r uh , y putting neural network  compared to n not having any neural network . I mean , this new system is  is  is better ,\nUh - huh .\nbecause it has  um , this sixty - four hertz cut - off , uh , clean  downsampling , and , um  what else ? Uh , yeah , a good VAD . We put the good VAD . So . Yeah , I don't know . I  I  j uh , uh  pr\nBut the latencies  but you 've got the latency shorter now .\nLatency is short  is  Yeah .\nYeah .\nIsn't it\nAnd so\nSo it 's better than the system that we had before .\nYeah . Mainly because   of  the sixty - four hertz and the good VAD .\nOK .\nAnd then I took this system and ,  mmm , w uh , I p we put the old filters also . So we have this good system , with good VAD , with the short filter and with the long filter , and , um , with the short filter it 's not worse . So  well , is it\nOK .\nit 's in\nSo that 's  that 's all fine .\nYes . Uh\nBut what you 're saying is that when you do these  So let me try to understand . When  when you do these same improvements  to proposal - one ,\nMm - hmm .\nthat , uh , on the  i things are somewhat better , uh , in proposal - two for the well - matched case and somewhat worse for the other two cases .\nYeah .\nSo does , uh  when you say , uh  So  The th now that these other things are in there , is it the case maybe that the additions of proposal - two over proposal - one are  less im important ?\nYeah . Probably , yeah .\nI get it .\nUm  So , yeah . Uh . Yeah , but it 's a good thing anyway to have  shorter delay . Then we tried , um ,  to do something like proposal - two but having , um , e using also MSG features . So there is this KLT part , which use just the standard features ,\nMm - hmm . Right .\nand then two neura two neural networks .\nMm - hmm .\nMmm , and it doesn't seem to help . Um , however , we just have  one result , which is the Italian mismatch , so . Uh . We have to wait for that to fill the whole table , but", "topic_id": 2, "keywords": "vad, features, feature, improvements, effort", "dialogue_id": 12}, {"text": "OK . There was a  start of some effort on something related to voicing or something . Is that  ?\nYeah . Um ,  yeah . So basically we try to ,   uh , find  good features that could be used for voicing detection , uh , but it 's still , uh  on the , um  t\nOh , well , I have the picture .\nwe  w basically we are still playing with Matlab to   to look at  at what happened ,\nWhat sorts of\nYeah .\nand\nwhat sorts of features are you looking at ?\nWe have some\nSo we would be looking at , um , the  variance of the spectrum of the excitation ,\nuh , um , this , this , and this .\nsomething like this , which is  should be high for voiced sounds . Uh , we\nWait a minute . I  what does that mean ? The variance of the spectrum of excitation .\nYeah . So the  So basically the spectrum of the excitation  for a purely periodic sig signal shou sh\nOK . Yeah , w what yo what you 're calling the excitation , as I recall , is you 're subtracting the  the , um  the mel  mel   mel filter , uh , spectrum from the FFT spectrum .\ne That 's right . Yeah . So\nRight .\nYeah .\nMm - hmm .\nSo we have the mel f filter bank , we have the FFT , so we  just\nSo it 's  it 's not really an excitation ,\nNo .\nbut it 's something that hopefully tells you something about the excitation .\nYeah , that 's right .\nYeah , yeah .\nUm  Yeah .\nWe have here some histogram ,\nE yeah ,\nbut they have a lot of overlap .\nbut it 's  it 's still  Yeah . So , well , for unvoiced portion we have something tha  that has a mean around O point three , and for voiced portion the mean is O point fifty - nine . But the variance seem quite  high .\nHow do you know  ?\nSo  Mmm .\nHow did you get your  voiced and unvoiced truth data ?\nWe used , uh , TIMIT and we used canonical mappings between the phones\nYeah . We , uh , use  TIMIT on this ,\nand\nfor\nth Yeah .\nBut if we look at it in one sentence , it  apparently it 's good , I think .\nYeah , but  Yeah . Uh , so it 's noisy TIMIT . That 's right . Yeah .\nIt 's noisy TIMIT .\nYeah .\nIt seems quite robust to noise , so when we take  we draw its parameters across time for a clean sentence and then nois the same noisy sentence , it 's very close .\nMm - hmm .\nYeah . So there are  there is this . There could be also the , um   something like the maximum of the auto - correlation function or  which\nIs this a  a s a trained system ? Or is it a system where you just pick some thresholds ? Ho - how does it work ?\nRight now we just are trying to find some features . And ,\nMm - hmm .\nuh  Yeah . Hopefully , I think what we want to have is to put these features in s some kind of , um  well , to  to obtain a statistical model on these features and to  or just to use a neural network and hopefully these features w would help\nBecause it seems like what you said about the mean of the  the voiced and the unvoiced    that seemed pretty encouraging .\nMm - hmm .\nWell , yeah , except the variance was big .\nRight ?\nYeah . Except the variance is quite high .\nRight ?\nWell , y\nYeah .\nWell , y I  I don't know that I would trust that so much because you 're doing these canonical mappings from TIMIT labellings .\nUh - huh .\nRight ? So , really that 's sort of a cartoon picture about what 's voiced and unvoiced . So that could be giving you a lot of variance .\nYeah .\nI mean , i it  it may be that  that you 're finding something good and that the variance is sort of artificial because of how you 're getting your truth .\nMm - hmm .\nYeah . But another way of looking at it  might be that  I mean , what w we we are coming up with feature sets after all . So another way of looking at it is that  um , the mel cepstru mel  spectrum , mel cepstrum ,  any of these variants , um , give you the smooth spectrum . It 's the spectral envelope . By going back to the FFT ,  you 're getting something that is  more like the raw data . So the question is , what characterization  and you 're playing around with this  another way of looking at it is what characterization  of the difference between  the raw data  and this smooth version  is something that you 're missing that could help ? So , I mean , looking at different statistical measures of that difference , coming up with some things and just trying them out and seeing if you add them onto the feature vector does that make things better or worse in noise , where you 're really just i i the way I 'm looking at it is not so much you 're trying to f find the best  the world 's best voiced - unvoiced , uh , uh , classifier ,\nMm - hmm .\nMmm .\nbut it 's more that ,  you know , uh , uh , try some different statistical characterizations of that difference back to the raw data\nRight .\nand  and m maybe there 's something there that  the system can use .\nRight .\nYeah . Yeah , but ther more obvious is that  Yeah . The  the more obvious is that  that  well , using the  th the FFT , um ,  you just  it gives you just information about if it 's voiced or not voiced , ma mainly , I mean . But  So ,\nYeah .\nthis is why we  we started to look  by having sort of voiced phonemes\nWell , that 's the rea w w what I 'm arguing is that 's Yeah . I mean , uh , what I 'm arguing is that that  that 's givi you  gives you your intuition .\nand  Mm - hmm .\nBut in  in reality , it 's  you know , there 's all of this  this overlap and so forth ,\nOh , sorry .\nand  But what I 'm saying is that may be OK , because what you 're really getting is not actually voiced versus unvoiced , both for the fac the reason of the overlap and  and then , uh , th you know , structural reasons , uh , uh , like the one that Chuck said , that  that in fact , well , the data itself is   that you 're working with is not perfect .\nYeah . Mm - hmm .\nSo , what I 'm saying is maybe that 's not a killer because you 're just getting some characterization , one that 's driven by your intuition about voiced - unvoiced certainly ,\nMm - hmm .\nbut it 's just some characterization  of something back in the  in the  in the almost raw data , rather than the smooth version .\nMm - hmm .\nAnd your intuition is driving you towards particular kinds of ,  uh , statistical characterizations of , um , what 's missing from the spectral envelope .\nMm - hmm .\nUm , obviously you have something about the excitation , um , and what is it about the excitation , and , you know  and you 're not getting the excitation anyway , you know . So  so I  I would almost take a  uh , especially if  if these trainings and so forth are faster , I would almost just take a  uh , a scattershot at a few different  ways of look of characterizing that difference and , uh , you could have one of them but  and  and see , you know , which of them helps .\nMm - hmm . OK .\nSo i is the idea that you 're going to take  whatever features you develop and  and just add them onto the future vector ? Or , what 's the use of the  the voiced - unvoiced detector ?\nUh , I guess we don't know exactly yet . But ,  um  Yeah . Th\nIt 's not part of a VAD system that you 're doing ?\nNo .\nUh , no . No .\nOh , OK .\nNo , the idea was , I guess , to  to use them as  as features .\nFeatures . I see .\nUh  Yeah , it could be , uh  it could be  a neural network that does voiced and unvoiced detection ,\nMm - hmm .\nbut it could be in the  also the big neural network that does phoneme classification .\nMm - hmm .\nMmm . Yeah .\nBut each one of the mixture components  I mean , you have , uh , uh , variance only , so it 's kind of like you 're just multiplying together these , um , probabilities from the individual features  within each mixture . So it 's  so , uh , it seems l you know\nI think it 's a neat thing . Uh , it seems like a good idea .\nYeah . Um . Yeah . I mean ,  I know that , um , people doing some robustness things a ways back were  were just doing  just being gross and just throwing in the FFT and actually it wasn't  wasn't  wasn't so bad . Uh , so it would s and  and you know that i it 's gotta hurt you a little bit to not have a   a spectral , uh  a s a smooth spectral envelope , so there must be something else that you get  in return for that\nMm - hmm .\nthat , uh  uh  So .\nSo how does  uh , maybe I 'm going in too much detail , but  how exactly do you make the difference between the FFT and the smoothed  spectral envelope ? Wha - wh i i uh , how is that , uh  ?\nUm , we just  How did we do it up again ?\nUh , we distend the  we have the twenty - three coefficient af after the mel f  filter ,\nMm - hmm .\nand we extend these coefficient between the  all the frequency range .\nMm - hmm .\nAnd i the interpolation i between the point  is  give for the triang triangular filter , the value of the triangular filter and of this way we obtained this mode this model speech .\nS\nSo you essentially take the values that  th that you get from the triangular filter and extend them to sor sort of like a rectangle , that 's at that m value .\nYeah .\nYeah . I think we have linear interpolation .\nMm - hmm .\nSo we have  we have one point for  one energy for each filter bank ,\nmmm Yeah , it 's linear .\nMmm .\nOh .\nwhich is  the energy  that 's centered on  on  on the triangle\nYeah . At the n at the center of the filter\nSo you  you end up with a vector that 's the same length as the FFT  vector ?\nYeah . That 's right .\nYeah .\nAnd then you just , uh , compute differences\nYeah . I have here one example if you  if you want see something like that .\nThen we compute the difference .\nand ,\nYeah . Uh - huh .\nOK .\nuh , sum the differences ?\nSo . And I think the variance is computed only from , like , two hundred hertz to  one  to fifteen hundred .\nOh ! OK .\nMm - hmm .\nTwo thou two   fifteen hundred ?\nMm - hmm .\nBecause\nNo .\nRight .\nTwo hundred and fifty thousand .\nFifteen hundred . Because  Yeah .\nYeah . Two thousand and fifteen hundred .\nAbove , um   it seems that  Well , some voiced sound can have also ,  like , a noisy  part on high frequencies , and  But\nYeah .\nWell , it 's just\nNo , it 's  makes sense to look at  low frequencies .\nSo this is  uh , basically this is comparing  an original version of the signal to a smoothed version of the same signal ?\nYeah .\nRight . So i so i i this is  I mean , i you could argue about whether it should be linear interpolation or  or  or  or zeroeth order , but  but\nUh - huh .\nat any rate something like this  is what you 're feeding your recognizer , typically .\nLike which of the  ?\nNo . Uh , so the mel cepstrum is the  is the  is the cepstrum of this   this , uh , spectrum or log spectrum ,\nSo this is  Yeah .\nYeah . Right , right .\nwhatever it  You - you 're subtracting in  in  in  power domain or log domain ?\nIn log domain . Yeah .\nLog domain .\nOK . So it 's sort of like division , when you do the  yeah , the spectra .\nYeah .\nUh , yeah .\nIt 's the ratio .\nUm . Yeah . But , anyway , um  and that 's\nSo what 's th uh , what 's the intuition behind this kind of a thing ? I  I don't know really know the signal - processing well enough to understand what   what is that doing .\nSo . Yeah . What happen if  what we have  have  what we would like to have is  some spectrum of the excitation signal ,\nYeah . I guess that makes sense . Yeah .\nwhich is for voiced sound ideally a  a pulse train\nUh - huh .\nand for unvoiced it 's something that 's more flat .\nUh - huh . Right .\nAnd the way to do this  is that  well , we have the  we have the FFT because it 's computed in  in the  in the system , and we have  the mel  filter banks ,\nMm - hmm . Mm - hmm .\nand so if we  if we , like , remove the mel filter bank from the FFT ,  we have something that 's  close to the  excitation signal .\nOh .\nIt 's something that 's like  a  a a train of p a pulse train for voiced sound\nOK .\nYeah .\nOh ! OK . Yeah .\nand that 's  that should be flat for\nYeah .\nI see . So do you have a picture that sh ?\nSo - It 's  Y\nIs this for a voiced segment ,\nyeah .\nthis picture ? What does it look like for unvoiced ?\nYeah .\nYou have several  some unvoiced ?\nThe dif No . Unvoiced , I don't have\nOh .\nfor unvoiced .\nYeah . So , you know , all\nI 'm sorry .\nBut  Yeah .\nYeah .\nYeah . This is the  between\nThis is another voiced example . Yeah .\nNo . But it 's this ,\nOh , yeah . This is\nbut between the frequency that we are considered for the excitation\nRight . Mm - hmm .\nfor the difference and this is the difference .\nYeah .\nThis is the difference . OK .\nSo , of course , it 's around zero ,\nYeah .\nSure looks\nbut\nHmm .\nWell , no .\nHmm .\nIt is\nYeah . Because we begin ,  uh , in fifteen  point  the fifteen point .\nSo , does  does the periodicity of this signal say something about the  the\nFifteen p\nSo it 's  Yeah .\nPitch .\nIt 's the pitch .\nthe pitch ?\nYeah . Mm - hmm .\nYeah .\nOK .\nThat 's like fundamental frequency .\nMm - hmm .\nSo , I mean , i t t\nOK . I see .\nI mean , to first order  what you 'd  what you 're doing  I mean , ignore all the details and all the ways which is  that these are complete lies . Uh , the  the  you know , what you 're doing in feature extraction for speech recognition is you have ,  uh , in your head a  a  a  a simplified production model for speech ,\nMm - hmm .\nin which you have a periodic or aperiodic source that 's driving some filters .\nMm - hmm .\nYeah . This is the  the auto - correlation  the R - zero energy .\nDo you have the mean  do you have the mean for the auto - correlation  ?\nUh , first order for speech recognition , you say \" I don't care about the source \" .\nFor  Yeah .\nWell , I mean for the  the energy .\nI have the mean .\nRight ?\nRight .\nAnd so you just want to find out what the filters are .\nRight .\nYeah .\nThe filters  roughly act like a , um   a , uh   a an overall resonant  you know , f some resonances and so forth that th that 's processing excitation .\nHere .\nThey should be more close .\nAh , no . This is this ? More close . Is this ? And this .\nMm - hmm .\nYeah .\nMm - hmm .\nSo they are  this is  there is less difference .\nMm - hmm .\nSo if you look at the spectral envelope , just the very smooth properties of it ,  you get something closer to that .\nThis is less  it 's less robust .\nLess robust . Yeah .\nOh , yeah .\nAnd the notion is if you have the full spectrum , with all the little nitty - gritty details ,  that that has the effect of both ,\nYeah .\nand it would be a multiplication in  in frequency domain\nMm - hmm .\nso that would be like an addition in log   power spectrum domain .\nMm - hmm . Mm - hmm .\nAnd so this is saying , well , if you really do have that  sort of vocal tract envelope , and you subtract that off , what you get is the excitation . And I call that lies because you don't really have that , you just have some kind of  signal - processing trickery to get something that 's kind of smooth . It 's not really what 's happening in the vocal tract\nYeah .\nso you 're not really getting the vocal excitation .\nRight .\nThat 's why I was going to the  why I was referring to it in a more   a more , uh ,  uh ,  conservative way , when I was saying \" well , it 's  yeah , it 's the excitation \" . But it 's not really the excitation . It 's whatever it is that 's different between\nOh . This moved in the\nSo  so , stand standing back from that , you sort of say there 's this very detailed representation .\nYeah .\nYou go to a smooth representation .\nMm - hmm .\nYou go to a smooth representation cuz this typically generalizes better .\nMm - hmm .\nUm , but whenever you smooth you lose something , so the question is have you lost something you can you use ?\nRight .\nUm , probably you wouldn't want to go to the extreme of just ta saying \" OK , our feature set will be the FFT \" , cuz we really think we do gain something in robustness from going to something smoother , but maybe there 's something that we missed .\nMm - hmm .\nSo what is it ?\nYeah .\nAnd then you go back to the intuition that , well , you don't really get the excitation , but you get something related to it .\nMm - hmm .\nAnd it  and as you can see from those pictures , you do get something  that shows some periodicity , uh , in frequency ,\nMm - hmm .\nyou know , and  and  and also in time .\nHmm .\nSo\nThat 's  that 's really neat .\nso ,\nSo you don't have one for unvoiced  picture ?\nUh , not here .\nOh .\nNo , I have s\nMm - hmm .\nYeah .\nBut not here .\nBut presumably you 'll see something that won't have this kind of , uh , uh , uh , regularity in frequency , uh , in the\nBut  Yeah . Well .\nNot here .\nI would li I would like to see those  pictures .\nWell , so .\nYeah .\nI can't see you  now .\nYeah .\nYeah .\nYeah .\nMm - hmm .\nI don't have .\nAnd so you said this is pretty  doing this kind of thing is pretty robust to noise ?\nIt seems , yeah . Um ,\nHuh .\nPfft . Oops . The mean is different  with it , because the   the histogram for the   the classifica\nNo , no , no . But th the kind of robustness to noise\nOh !\nSo if  if you take this frame ,  uh , from the noisy utterance and the same frame from the clean utterance\nHmm .\nYou end up with a similar difference\nY y y yeah . We end up with\nover here ?\nYeah .\nOK . Cool !\nI have here the same frame for the  clean speech\nOh , that 's clean .\nthe same cle\nOh , OK\nBut they are a difference .\nYeah , that 's\nBecause here the FFT is only with  two hundred fifty - six point\nOh .\nand this is with five hundred  twelve .\nYeah . This is kind of inter interesting also\nOK .\nbecause if we use the standard ,  uh , frame length of  of , like , twenty - five milliseconds ,  um ,  what happens is that for low - pitched voiced , because of the frame length , y you don't really have   you don't clearly see this periodic structure ,\nMm - hmm .\nbecause of the first lobe of  of each  each of the harmonics .\nSo this one inclu is a longer  Ah .\nSo , this is like  yeah , fifty milliseconds or something like that .\nFifty millis Yeah .\nYeah , but it 's the same frame and\nOh , it 's that time - frequency trade - off thing .\nYeah .\nRight ? I see . Yeah .\nSo , yeah .\nMm - hmm .\nOh . Oh , so this i is this the difference here , for that ?\nNo . This is the signal . This is the signal .\nI see that . Oh , yeah .\nThe frame .\nOh , that 's the f the original .\nYeah .\nThis is the fra the original frame .\nSo with a short frame basically you have only two periods\nYeah .\nand it 's not  not enough to  to have this kind of neat things .\nMm - hmm .\nMm - hmm .\nYeah .\nBut\nAnd here  No , well .\nYeah . So probably we 'll have to use ,  like , long f long frames . Mm - hmm .\nMm - hmm .\nHmm .\nOh .\nMmm .\nThat 's interesting .\nYeah , maybe . Well , I mean it looks better , but , I mean , the thing is if  if , uh  if you 're actually asking  you know , if you actually j uh , need to do  place along an FFT , it may be  it may be pushing things .\nYeah .\nAnd  and , uh\nWould you  would you wanna do this kind of , uh , difference thing  after you do spectral subtraction ?\nUh ,  maybe .\nNo . Maybe we can do that .\nMmm .\nHmm . The spectral subtraction is being done at what level ? Is it being done at the level of FFT bins or at the level of , uh , mel spectrum or something ?\nUm , I guess it depends .\nI mean , how are they doing it ?\nHow they 're doing it ? Yeah . Um , I guess Ericsson is on the , um , filter bank ,\nFFT . Filter bank ,\nno ? It 's on the filter bank ,\nyeah .\nso . So , yeah , probably  I i it  Yeah .\nSo in that case , it might not make much difference at all .\nSeems like you 'd wanna do it on the FFT bins .\nMaybe . I mean , certainly it 'd be better .\nI I mean , if you were gonna  uh , for  for this purpose , that is .\nMm - hmm .\nYeah .\nMm - hmm .\nYeah . OK .\nMmm .\nWhat else ?\nUh .  Yeah , that 's all . So we 'll perhaps    try to convince OGI people to use the new   the new filters and  Yeah .\nOK . Uh , has  has anything happened yet on this business of having some sort of standard , uh , source ,\nUh , not yet\nor  ?\nbut I wi I will  call them and\nOK .\nnow they are  I think they have more time because they have this  well , Eurospeech deadline is  over", "topic_id": 3, "keywords": "spectrum, spectral, spectra, voiced, voicing", "dialogue_id": 12}, {"text": "When is the next , um , Aurora  deadline ?\nand  It 's , um , in June . Yeah .\nJune .\nEarly June , late June , middle June ?\nI don't know w\nHmm .\nHmm .\nOK . Um , and  he 's been doing all the talking but  but  these   he 's  he 's , uh\nYeah .\nThis is  this by the way a bad thing . We 're trying to get , um , m more female voices in this record as well . So . Make sur make sure Carmen  talks as well . Uh , but has he pretty much been talking about what you 're doing also , and  ?\nOh , I  I am doing this .\nYes .\nYeah , yeah . I don't know . I 'm sorry , but I think that for the recognizer for the meeting recorder that it 's better that I don't speak .\nYeah , well .\nBecause\nYou know , uh , we 'll get  we 'll get to , uh , Spanish voices sometime , and  we do  we want to recognize ,  uh , you too .\nAfter the  after , uh , the result for the TI - digits  on the meeting record there will be foreigns people .\nYeah , but\nOh , no .\nY\nWe like  we  we 're  we 're  w we are  we 're in the , uh , Bourlard - Hermansky - Morgan , uh , frame of mind . Yeah , we like high error rates . It 's\nYeah .\nThat way there 's lots of work to do . So it 's  Uh , anything to talk about ?\nN um , not not not much is new . So when I talked about what I 'm planning to do last time ,  I said I was , um , going to use Avendano 's method of , um ,  using a transformation , um ,  to map from long analysis frames which are used for removing reverberation to short analysis frames for feature calculation . He has a trick for doing that  involving viewing the DFT as a matrix . Um , but , uh , um , I decided  not to do that after all because I  I realized to use it I 'd need to have these short analysis frames get plugged directly into the feature computation somehow\nMm - hmm .\nand right now I think our feature computation is set to up to , um ,  take , um , audio as input , in general . So I decided that I  I 'll do the reverberation removal on the long analysis windows and then just re - synthesize audio and then send that .\nThis is in order to use the SRI system or something . Right ?\nUm , or  or even if I 'm using our system , I was thinking it might be easier to just re - synthesize the audio ,\nYeah ?\nbecause then I could just feacalc as is and I wouldn't have to change the code .\nOh , OK . Yeah . I mean , it 's  um , certainly in a short  short - term this just sounds easier .\nUh - huh .\nYeah . I mean , longer - term if it 's   if it turns out to be useful , one  one might want to do something else ,\nRight . That 's true .\nbut  Uh , uh , I mean , in  in other words , you  you may be putting other kinds of errors in  from the re - synthesis process .\nBut  e u From the re - synthesis ? Um ,\nYeah .\nO - OK . I don't know anything about re - synthesis . Uh , how likely do you think that is ?\nUh , it depends what you  what you do . I mean , it 's  it 's  it 's , uh , um  Don't know . But anyway it sounds like a reasonable way to go for a  for an initial thing , and we can look at   at exactly what you end up doing and  and then figure out if there 's some   something that could be  be hurt by the end part of the process .\nOK .\nOK . So that 's  That was it , huh ?\nThat  Yeah , e That 's it , that 's it .\nOK . OK .\nUh - huh .\nUm , anything to  add ?\nUm . Well , I 've been continuing reading . I went off on a little tangent this past week , um , looking at , uh ,  uh , modulation s spectrum stuff , um , and  and learning a bit about what  what , um  what it is , and , uh , the importance of it in speech recognition . And I found some   some , uh , neat papers ,  um , historical papers from ,  um ,  Kanedera , Hermansky , and Arai .\nYeah .\nAnd they  they did a lot of experiments where th where ,  um , they take speech  and , um , e they modify  the , uh  they  they  they measure the relative importance of having different , um , portions of the modulation spectrum intact .\nYeah .\nAnd they find that the  the spectrum between one and sixteen hertz in the modulation  is , uh  is im important for speech recognition .\nSure . I mean , this sort of goes back to earlier stuff by Drullman .\nUm .\nAnd  and , uh , the  the MSG features were sort of built up  with this notion\nYeah . Right .\nBut , I guess , I thought you had brought this up in the context of , um , targets somehow .\nRight .\nBut i m\nUm\ni it 's not  I mean , they 're sort of not in the same kind of category as , say , a phonetic target or a syllabic target\nMmm . Mm - hmm .\nor a\nUm , I was thinking more like using them as  as the inputs to  to the detectors .\nor a feature or something . Oh , I see . Well , that 's sort of what MSG does .\nYeah . Yeah .\nRight ? So it 's\nMm - hmm .\nBut  but , uh\nS\nYeah .\nYeah .\nAnyway , we 'll talk more about it later .", "topic_id": 4, "keywords": "meeting, voices, recognizer, talks, talking", "dialogue_id": 12}, {"text": "OK .\nYeah .\nWe can talk more about it later .\nYeah . Yeah .\nYeah .\nSo maybe ,  le\nShould we do digits ?\nlet 's do digits . Let you  you start .\nOh , OK .\nL fifty .\nRight .", "topic_id": 5, "keywords": "digits, le, let, maybe, start", "dialogue_id": 12}, {"text": "Alright . We 're on .\nTest , um . Test , test , test . Guess that 's me . Yeah . OK .\nOoh , Thursday .\nSo . There 's two sheets of paper in front of us .\nWhat are these ?\nYeah . So .\nThis is the arm wrestling ?\nUh . Yeah , we formed a coalition actually .\nYeah . Almost .\nWe already made it into one .\nOh , good .\nYeah .\nExcellent .\nYeah .\nThat 's the best thing .\nMm - hmm .\nSo , tell me about it .\nSo it 's  well , it 's  spectral subtraction or Wiener filtering , um , depending on if we put  if we square the transfer function or not .\nRight .\nAnd then with over - estimation of the noise , depending on the , uh  the SNR , with smoothing along time , um , smoothing along frequency .\nMm - hmm .\nIt 's very simple , smoothing things .\nMm - hmm .\nAnd , um ,  the best result is  when we apply this procedure on FFT bins , uh , with a Wiener filter .\nMm - hmm .\nAnd there is no noise addition after  after that .\nOK .\nSo it 's good because   it 's difficult when we have to add noise to  to  to find the right level .\nOK .\nAre you looking at one in  in particular of these two ?\nYeah . So the sh it 's the sheet that gives fifty - f three point sixty - six .\nMm - hmm .\nUm ,  the second sheet is abo uh , about the same . It 's the same , um , idea but it 's working on mel bands ,  and it 's a spectral subtraction instead of Wiener filter , and there is also a noise addition after , uh , cleaning up the mel bins . Mmm . Well , the results are similar .\nYeah . I mean ,  it 's   it 's actually , uh , very similar .\nMm - hmm .\nI mean ,  if you look at databases , uh , the , uh , one that has the smallest  smaller overall number is actually better on the Finnish and Spanish , uh , but it is , uh , worse on the , uh , Aurora\nIt 's worse on\nI mean on the , uh , TI - TI - digits ,\non the multi - condition in TI - digits . Yeah .\nuh , uh . Um .\nMmm .\nSo , it probably doesn't matter that much either way . But , um , when you say u uh , unified do you mean , uh , it 's one piece of software now , or  ?\nSo now we are , yeah , setting up the software .\nMm - hmm .\nUm , it should be ready , uh , very soon . Um , and we", "topic_id": 0, "keywords": "noise, spectral, smoothing, snr, transfer", "dialogue_id": 13}, {"text": "So what 's  what 's happened ? I think I 've missed something .\nOK . So a week ago  maybe you weren't around when  when  when Hynek and Guenther and I  ?\nHynek was here .\nYeah . I didn't .\nOh , OK . So  Yeah , let 's summarize . Um  And then if I summarize somebody can tell me if I 'm wrong , which will also be possibly helpful . What did I just press here ? I hope this is still working .\np - p - p\nWe , uh  we looked at , {nonvocalsound} uh  anyway we   after coming back from QualComm we had , you know , very strong feedback and , uh , I think it was  Hynek and Guenter 's and my opinion also that , um , you know , we sort of spread out to look at a number of different ways of doing noise suppression . But given the limited time , uh , it was sort of time to  choose one .\nMm - hmm . Mmm .\nUh , and so , uh , th the vector Taylor series hadn't really worked out that much . Uh , the subspace stuff , uh , had not been worked with so much . Um , so it sort of came down to spectral subtraction versus Wiener filtering .\nHmm .\nUh , we had a long discussion about how they were the same and how they were d uh , completely different .\nMm - hmm .\nAnd , uh , I mean , fundamentally they 're the same sort of thing but the math is a little different so that there 's a  a   there 's an exponent difference in the index  you know , what 's the ideal filtering , and depending on how you construct the problem .\nUh - huh .\nAnd , uh , I guess it 's sort  you know , after  after that meeting it sort of made more sense to me because  um , if you 're dealing with power spectra then how are you gonna choose your error ? And typically you 'll do  choose something like a variance . And so that means it 'll be something like the square of the power spectra . Whereas when you 're  when you 're doing the  the , uh , um ,  looking at it the other way , you 're gonna be dealing with signals\nMm - hmm .\nand you 're gonna end up looking at power  uh , noise power that you 're trying to reduce . And so , eh  so there should be a difference  of  you know , conceptually of  of , uh , a factor of two in the exponent .\nMm - hmm .\nBut there 're so many different little factors that you adjust in terms of  of , uh ,  uh , over - subtraction and  and  and  and  and so forth , um , that  arguably , you 're c and  and  and the choice of do you  do you operate on the mel bands or do you operate on the FFT beforehand . There 're so many other choices to make that are  are almost  well , if not independent , certainly in addition to  the choice of whether you , uh , do spectral subtraction or Wiener filtering , that , um ,  @ @ again we sort of felt the gang should just sort of figure out which it is they wanna do and then let 's pick it , go forward with it . So that 's  that was  that was last week . And   and , uh , we said , uh , take a week , go arm wrestle , you know ,\nOh .\nfigure it out . I mean , and th the joke there was that each of them had specialized in one of them .\nOh , OK .\nAnd  and so they  so instead they went to Yosemite and bonded , and  and they came out with a single  single piece of software . So it 's  another  another victory for international collaboration . So .\nSo  so you guys have combined  or you 're going to be combining the software ?\nUh .\nWell , the piece of software has , like , plenty of options ,\nOh boy .\nlike you can parse command - line arguments . So depending on that , it  it becomes either spectral subtraction or Wiener filtering .\nOh , OK .\nSo , ye\nThey 're close enough .\nWell , that 's fine , but the thing is  the important thing is that there is a piece of software that you  that we all will be using now .\nYeah . Yeah .\nYes .\nThere 's just one piece of software .\nYeah .\nYeah .\nI need to allow it to do everything and even more  more than this .\nRight .\nWell , if we want to , like , optimize different parameters of\nParameters . Yeah .\nSure .\nYeah , we can do it later . But , still  so , there will be a piece of software with ,   uh , will give this system , the fifty - three point sixty - six , by default and\nMm - hmm .\nHow  how is  how good is that ?\nMm - hmm .\nI  I  I don't have a sense of\nIt 's just one percent off of the  best proposal .\nBest system .\nIt 's between  i we are second actually if we take this system .\nOK .\nYeah .\nYeah .\nRight ?\nCompared to the last evaluation numbers ? Yeah .\nBut , uh  w which we sort of were before\nYeah .\nMm - hmm . Yeah .\nbut we were considerably far behind . And the thing is , this doesn't have neural net in yet for instance . You know ?\nMm - hmm .\nHmm .\nSo it  so , um , it 's  it it 's not using our full bal bag of tricks , if you will .\nMm - hmm .\nAnd , uh , and it  it is , uh , very close in performance to the best thing that was there before . Uh , but , you know , looking at it another way , maybe more importantly , uh ,  we didn't have any explicit noise , uh , handling  stationary  dealing with  e e we didn't explicitly have anything to deal with stationary noise .\nMm - hmm .\nAnd now we do .\nSo will the  neural net operate on the output from either the Wiener filtering or the spectral subtraction ? Or will it operate on the original ?\nWell , so  so  so argu arguably , I mean , what we should do  I mean , I gather you have  it sounds like you have a few more days of  of nailing things down with the software and so on . But  and then  but , um ,  arguably what we should do is , even though the software can do many things , we should for now pick a set of things , th these things I would guess , and not change that .\nMm - hmm .\nAnd then focus on  everything that 's left . And I think , you know , that our goal should be by next week , when Hynek comes back ,  uh , to  uh , really just to have a firm path , uh , for the  you know , for the time he 's gone , of  of , uh , what things will be attacked . But I would  I would  I would thought think that what we would wanna do is not futz with this stuff for a while because what 'll happen is we 'll change many other things in the system ,\nMm - hmm .\nand then we 'll probably wanna come back to this and possibly make some other choices . But , um .", "topic_id": 1, "keywords": "hynek, noise, qualcomm, nonvocalsound, suppression", "dialogue_id": 13}, {"text": "But just conceptually , where does the neural net go ? Do  do you wanna h run it on the output of the spectrally subtracted  ?\nMmm .\nWell , depending on its size  Well , one question is , is it on the , um , server side or is it on the terminal side ? Uh , if it 's on the server side , it  you probably don't have to worry too much about size .\nMm - hmm .\nSo that 's kind of an argument for that . We do still , however , have to consider its latency . So the issue is  is , um ,  for instance , could we have a neural net that only looked at the past ?\nRight .\nUm , what we 've done in uh  in the past is to use the neural net , uh , to transform ,  um , all of the features that we use . So this is done early on . This is essentially ,  um , um  I guess it 's  it 's more or less like a spee a speech enhancement technique here\nMm - hmm .\nright ?  where we 're just kind of creating  new  if not new speech at least new  new FFT 's that  that have  you know , which could be turned into speech  uh , that  that have some of the noise removed .\nMm - hmm .\nMm - hmm .\nUm , after that we still do a mess of other things to  to produce a bunch of features .\nRight .\nAnd then those features are not now currently transformed  by the neural net . And then the  the way that we had it in our proposal - two before , we had the neural net transformed features and we had  the untransformed features , which I guess you  you actually did linearly transform with the KLT ,\nYeah . Yeah . Right .\nbut  but  but  uh , to orthogonalize them  but   but they were not , uh , processed through a neural net . And Stephane 's idea with that , as I recall , was that  you 'd have one part of the feature vector that was very discriminant and another part that wasn't ,\nMm - hmm .\nuh , which would smooth things a bit for those occasions when , uh , the testing set was quite different than what you 'd trained your discriminant features for . So , um , all of that is  is , uh  still seems like a good idea . The thing is now we know some other constraints . We can't have unlimited amounts of latency . Uh , y you know , that 's still being debated by the  by people in Europe but ,  uh , no matter how they end up there , it 's not going to be unlimited amounts ,\nYeah .\nso we have to be a little conscious of that . Um . So there 's the neural net issue . There 's the VAD issue . And , uh , there 's the second stream  thing . And I think those that we  last time we agreed that those are the three things that have to get , uh , focused on .\nWhat was the issue with the VAD ?\nWell , better  ones are good .\nAnd so the w the default , uh , boundaries that they provide are  they 're OK , but they 're not all that great ?\nI guess they still allow two hundred milliseconds on either side or some ? Is that what the deal is ?\nMm - hmm . Uh , so th um , they keep two hundred milliseconds at the beginning and end of speech . And they keep all the\nOutside the beginnings and end .\nYeah .\nUh - huh .\nAnd all the speech pauses , which is  Sometimes on the SpeechDat - Car you have pauses that are more than one or two seconds .\nWow .\nMore than one second for sure . Um .\nHmm .\nYeah . And , yeah , it seems to us that this way of just dropping the beginning and end is not  We cou we can do better , I think ,\nMm - hmm .\nbecause , um ,  with this way of dropping the frames they improve  over the baseline by fourteen percent and  Sunil already showed that with our current VAD we can improve by more than twenty percent .\nOn top of the VAD that they provide ?\nNo .\nJust using either their VAD or our current VAD .\nOur way .\nOh , OK .\nSo , our current VAD is  is more than twenty percent , while their is fourteen .\nTheirs is fourteen ? I see .\nYeah .\nHuh .\nSo . Yeah . And  another thing that we did also is that we have all this training data for  let 's say , for SpeechDat - Car . We have channel zero which is clean , channel one which is far - field microphone . And if we just take only the , um , VAD probabilities computed on the clean signal and apply them on the far - field , uh , test utterances ,  then results are much better .\nMm - hmm .\nIn some cases it divides the error rate by two .\nWow .\nSo it means that there are stim  still\nHow  how much latency does the , uh  does our VAD add ?\nIf  if we can have a good VAD , well , it would be great .\nIs it significant ,\nUh , right now it 's , um , a neural net with nine frames .\nor  ?\nSo it 's forty milliseconds plus , um , the rank ordering , which , uh , should be\nLike another ten frames .\nten  Yeah .\nRank . Oh .\nSo , right now it 's one hundred and forty  milliseconds .\nWith the rank ordering  ? I 'm sorry .\nThe  the  the smoothing  the m the  the filtering of the probabilities .\nThe  The , um\non the R .\nYeah . It 's not a median filtering . It 's just  We don't take the median value . We take something  Um , so we have eleven , um , frames .\nOh , this is for the VAD .\nYeah .\nAnd  for the VAD , yeah\nOh , OK .\nYeah .\nand we take th the third .\nYeah .\nDar\nUm .\nYeah . Um . So   Yeah , I was just noticing on this that it makes reference to delay .\nMmm .\nSo what 's the  ? If you ignore  Um , the VAD is sort of in  in parallel , isn't i isn't it , with  with the  ? I mean , it isn't additive with the  the , uh , LDA and the Wiener filtering , and so forth .\nThe LDA ?\nRight ?\nYeah . So  so what happened right now , we removed the delay of the LDA .\nMm - hmm .\nYeah .\nSo we  I mean , if  so if we  if  so which is like if we reduce the delay of VA So , the f the final delay 's now ba is f determined by the delay of the VAD , because the LDA doesn't have any delay . So if we re if we reduce the delay of the VAD , I mean , it 's like effectively reducing the delay .\nHow  how much , uh , delay was there on the LDA ?\nSo the LDA and the VAD both had a hundred millisecond delay . So and they were in parallel , so which means you pick either one of them\nMmm .\nthe  the biggest , whatever .\nI see .\nMm - hmm .\nSo , right now the LDA delays are more .\nAnd there\nOh , OK .\nAnd there didn't seem to be any , uh , penalty for that ? There didn't seem to be any penalty for making it causal ?\nPardon ? Oh , no . It actually made it , like , point one percent better or something , actually .\nOK . Well , may as well , then .\nOr something like that\nAnd he says Wiener filter is  is forty milliseconds delay .\nand\nSo is it  ?\nYeah . So that 's the one which Stephane was discussing , like\nMmm .\nThe smoothing ?\nYeah . The  you smooth it and then delay the decision by  So .\nRight . OK . So that 's  that 's really not  not bad . So we may in fact  we 'll see what they decide . We may in fact have ,  um , the  the , uh , latency time available for  to have a neural net . I mean , sounds like we probably will . So .\nMm - hmm .\nThat 'd be good . Cuz I  cuz it certainly always helped us before . So .\nWhat amount of latency are you thinking about when you say that ?\nUh . Well , they 're  you know , they 're disputing it .\nMmm .\nYou know , they 're saying , uh  one group is saying a hundred and thirty milliseconds and another group is saying two hundred and fifty milliseconds . Two hundred and fifty is what it was before actually . So ,\nOh .\nuh , some people are lobbying  lobbying  to make it shorter .\nHmm .\nUm . And , um .\nWere you thinking of the two - fifty or the one - thirty when you said we should  have enough for the neural net ?\nWell , it just  it  when we find that out it might change exactly how we do it , is all .\nOh , OK .\nI mean , how much effort do we put into making it causal ? I mean ,  I think the neural net will probably do better if it looks at a little bit of the future .\nMm - hmm .\nBut , um , it will probably work to some extent to look only at the past . And we ha you know , limited machine and human time , and  effort . And , you know , how  how much time should we put into  into that ? So it 'd be helpful if we find out from the  the standards folks whether , you know , they 're gonna restrict that or not .\nMm - hmm .\nUm . But I think , you know , at this point our major concern is making the performance better and  and , um ,  if , uh , something has to take a little longer in latency in order to do it that 's  you know , a secondary issue .\nMm - hmm .\nBut if we get told otherwise then , you know , we may have to c clamp down a bit more .\nMmm .\nSo , the one  one  one difference is that  was there is like we tried computing the delta and then doing the frame - dropping .\nS\nMm - hmm .\nThe earlier system was do the frame - dropping and then compute the delta on the\nUh - huh .\nSo this\nWhich could be a kind of a funny delta . Right ?\nYeah .\nOh , oh . So that 's fixed in this . Yeah , we talked about that .\nYeah . So we have no delta . And then\nYeah . Uh - huh .\nGood .", "topic_id": 2, "keywords": "neural, utterances, latency, speechdat, net", "dialogue_id": 13}, {"text": "So the frame - dropping is the last thing that we do . So , yeah , what we do is we compute the silence probability , convert it to that binary flag ,\nUh - huh .\nand then in the end you c up upsample it to  match the final features number of\nMm - hmm .\nDid that help then ?\nIt seems to be helping on the well - matched condition . So that 's why this improvement I got from the last result . So . And it actually r reduced a little bit on the high mismatch , so in the final weightage it 's b b better because the well - matched is still weighted more than\nSo , @ @ I mean , you were doing a lot of changes . Did you happen to notice how much ,  uh , the change was due to just this frame - dropping problem ? What about this ?\nUh , y you had something on it . Right ?\nJust the frame - dropping problem . Yeah . But it 's  it 's difficult . Sometime we  we change two  two things together and  But it 's around  maybe  it 's less than one percent .\nUh - huh .\nYeah .\nIt\nWell .  But like we 're saying , if there 's four or five things like that then  pretty sho soon you 're talking real improvement .\nYeah . Yeah . And it  Yeah . And then we have to be careful with that also  with the neural net\nYeah .\nbecause in  the proposal the neural net was also , uh , working on  after frame - dropping .\nMm - hmm .\nUm .\nOh , that 's a real good point .\nSo . Well , we 'll have to be  to do the same kind of correction .\nIt might be hard if it 's at the server side . Right ?\nMmm . Well , we can do the frame - dropping on the server side or we can just be careful at the terminal side to send a couple of more frames before and after , and  So . I think it 's OK .\nOK .\nYou have , um  So when you  Uh , maybe I don't quite understand how this works , but , um , couldn't you just send all of the frames , but mark the ones that are supposed to be dropped ? Cuz you have a bunch more bandwidth . Right ?\nWell , you could . Yeah . I mean , it  it always seemed to us that it would be kind of nice to  in addition to , uh , reducing insertions , actually use up less bandwidth .\nYeah . Yeah .\nBut nobody seems to have  cared about that in this  evaluation .\nAnd that way the net could use\nSo .\nIf the net 's on the server side then it could use all of the  frames .\nYes , it could be . It 's , like , you mean you just transferred everything and then finally drop the frames after the neural net .\nMm - hmm .\nRight ? Yeah . That 's  that 's one thing which\nMm - hmm .\nBut you could even mark them , before they get to the server .\nYeah . Right now we are  Uh , ri Right now what  wha what we did is , like , we just mark  we just have this additional bit which goes around the features ,  saying it 's currently a  it 's a speech or a nonspeech .\nOh , OK .\nSo there is no frame - dropping till the final features , like , including the deltas are computed .\nI see .\nAnd after the deltas are computed , you just pick up the ones that are marked silence and then drop them .\nMm - hmm . I see . I see .\nSo it would be more or less the same thing with the neural net , I guess , actually .\nMm - hmm .\nSo . Yeah , that 's what  that 's what  that 's what , uh , this is doing right now .\nI see . OK .\nYeah .\nMm - hmm .\nUm . OK . So , uh , what 's , uh  ? That 's  that 's a good set of work that  that , uh\nJust one more thing . Like , should we do something f more for the noise estimation , because we still  ?\nYeah . I was wondering about that . That was  I  I had written that down there .\nYeah .\nMm - hmm .\nUm\nSo , we , uh  actually I did the first experiment . This is  with just fifteen frames . Um . We take the first fifteen frame of each utterance to it ,\nYeah .\nand average their power spectra . Um . I tried just plugging the , um ,  uh , Guenter noise estimation on this system , and it  uh , it got worse . Um , but of course I didn't play  with it .\nUh - huh .\nBut  Mm - hmm . Uh , I didn't  do much more  for noise estimation . I just tried this ,\nHmm . Yeah . Well , it 's not surprising it 'd be worse the first time .\nand\nBut , um ,\nMm - hmm .\nit does seem like , you know , i i i i some compromise between always depending on the first fifteen frames and a a always depending on a  a pause is  is  is a good idea . Uh , maybe you have to weight the estimate from the first - teen  fifteen frames more heavily than  than was done in your first attempt . But\nMm - hmm .\nbut\nYeah , I guess .\nYeah . Um . No , I mean  Um , do you have any way of assessing how well or how poorly the noise estimation is currently doing ?\nMmm . No , we don't .\nYeah .\nWe don't have nothing  that\nIs there  was there any experiment with  ? Well , I  I did  The only experiment where I tried was I used the channel zero VAD for the noise estimation and frame - dropping . So I don't have a   I don't have a split , like which one helped more .\nYeah .\nSo . It  it was the best result I could get .\nMm - hmm .\nSo , that 's the\nSo that 's something you could do with , um , this final system . Right ? Just do this  everything that is in this final system except ,  uh , use the channel zero .\nMm - hmm . For the noise estimation .\nYeah .\nYeah . We can try something .\nAnd then see how much better it gets .\nMm - hmm . Sure .\nIf it 's , you know , essentially not better , then  it 's probably not worth\nYeah .\nany more .\nYeah . But the Guenter 's argument is slightly different . It 's , like , ev even  even if I use a channel zero VAD , I 'm just averaging the   the s power spectrum . But the Guenter 's argument is , like , if it is a non - stationary  segment , then he doesn't update the noise spectrum . So he 's , like  he tries to capture only the stationary part in it . So the averaging is , like ,  different from  updating the noise spectrum only during stationary segments . So , th the Guenter was arguing that , I mean , even if you have a very good VAD , averaging it , like , over the whole thing is not a good idea .\nI see .\nBecause you 're averaging the stationary and the non - stationary , and finally you end up getting something which is not really the s because , you  anyway , you can't remove the stationary part fr I mean , non - stationary part from  the signal .\nNot using these methods anyway . Yeah .\nSo  Yeah . So you just  update only doing  or update only the stationary components . Yeah . So , that 's  so that 's still a slight difference from what Guenter is trying\nWell , yeah . And  and also there 's just the fact that , um , eh , uh , although we 're trying to do very well on this evaluation , um , we actually would like to have something that worked well in general . And , um , relying on having fifteen frames at the front or something is  is pretty\nYeah , yeah .\nI mean , you might , you might not .\nMmm .\nMm - hmm .\nSo , um . Um , it 'd certainly be more robust to different kinds of input if you had at least some updates . Um .", "topic_id": 3, "keywords": "frames, weighted, frame, improvement, reducing", "dialogue_id": 13}, {"text": "Mm - hmm .\nBut , um . Well , I don't know . What  what do you , uh  what do you guys see as  as being what you would be doing in the next week , given wha what 's  happened ?\nCure the VAD ?\nYeah .\nWhat was that ?\nVAD .\nOh .\nAnd\nOK .\nSo , should we keep the same  ? I think we might try to keep the same idea of having a neural network , but  training it on more data and adding better features , I think , but  because the current network is just PLP features . Well , it 's trained on noisy  PLP\nJust the cepstra . Yeah .\nPLP features computed on noisy speech . But   there is no nothing particularly robust in these features .\nSo , I I uh\nNo .\nThere 's no RASTA , no\nSo , uh , I  I don't remember what you said  the answer to my , uh , question earlier . Will you  will you train the net on  after you 've done the spectral subtraction or the Wiener filtering ?\nThis is a different net .\nOh .\nSo we have a VAD which is like neur that 's a neural net .\nOh , yeah . Hmm .\nOh , you 're talking about the VAD net . OK .\nYeah .\nMm - hmm .\nI see .\nSo that  that VAD was trained on the noisy features .\nMm - hmm .\nSo , right now we have , like , uh  we have the cleaned - up features , so we can have a better VAD by training the net on  the cleaned - up speech .\nMm - hmm . I see . I see .\nYeah , but we need a VAD for uh noise estimation also . So it 's , like , where do we want to put the VAD ? Uh , it 's like\nCan you use the same net to do both , or  ?\nFor\nCan you use the same net that you  that I was talking about to do the VAD ?\nMm - hmm . Uh , it actually comes at v at the very end .\nMm - hmm .\nSo the net  the final net  I mean , which is the feature net  so that actually comes after a chain of , like , LDA plus everything . So it 's , like , it takes a long time to get a decision out of it . And   and you can actually do it for final frame - dropping , but not for the VA - f noise estimation .\nMm - hmm .\nYou see , the idea is that the , um , initial decision to  that  that you 're in silence or speech happens pretty quickly .\nOh , OK .\nHmm .\nCuz that 's used by some of these other  ?\nAnd that  Yeah . And that 's sort of fed forward , and  and you say \" well , flush everything , it 's not speech anymore \" .\nOh , OK . I see .\nYeah .\nI thought that was only used for doing frame - dropping later on .\nUm , it is used , uh  Yeah , it 's only used f Well , it 's used for frame - dropping . Um , it 's used for end of utterance\nMmm .\nbecause , you know , there 's   if you have  more than five hundred milliseconds of  of  of nonspeech then you figure it 's end of utterance or something like that .\nMm - hmm .\nSo , um .\nAnd it seems important for , like , the on - line normalization . Um . We don't want to update the mean and variance during silen long silence portions . Um . So it  it has to be done before\nOh . I see .\nthis mean and variance normalization . Um .\nUm . Yeah . So probably the VAD and  and maybe testing out the noise  estimation a little bit . I mean , keeping the same method but  but , uh ,  seeing if you cou but , um noise estimation could be improved . Those are sort of related issues .\nMm - hmm .\nIt probably makes sense to move from there . And then , uh ,  later on in the month I think we wanna start including the  neural net at the end . Um . OK . Anything else ?\nThe Half Dome was great .\nGood . Yeah . You didn't  didn't fall . That 's good .\nWell , yeah .\nOur e our effort would have been devastated if you guys had   run into problems .\nSo , Hynek is coming back next week , you said ?\nYeah , that 's the plan .\nHmm .\nI guess the week after he 'll be , uh , going back to Europe , and so we wanna\nIs he in Europe right now or is he up at  ?\nNo , no . He 's  he 's  he 's dropped into the US . Yeah . Yeah .\nOh . Hmm .\nSo . Uh .  So , uh . Uh , the idea was that , uh , we 'd  we 'd sort out where we were going next with this  with this work before he , uh , left on this next trip . Good .   Uh , Barry , you just got through your  quals , so I don't know if you  have much to say . But , uh .\nMmm . No , just , uh , looking into some  some of the things that , um ,  uh , John Ohala and Hynek , um , gave as feedback , um , as  as a starting point for the project . Um . In  in my proposal , I  I was thinking about starting from a set of , uh , phonological features ,  or a subset of them . Um , but that might not be necessarily a good idea according to , um , John .\nMm - hmm .\nHe said , uh , um , these  these phonological features are  are sort of figments of imagination also .\nMm - hmm .\nUm . S\nIn conversational speech in particular . I think you can  you can put them in pretty reliably in synthetic speech .\nYe\nBut  we don't have too much trouble recognizing synthetic speech since we create it in the first place . So , it 's\nRight . Yeah . So , um , a better way would be something more  more data - driven ,\nMm - hmm .\njust looking at the data and seeing what 's similar and what 's not similar .\nMm - hmm .\nSo , I 'm  I 'm , um , taking a look at some of , um ,  Sangita 's work on  on TRAPS . She did something where , um   w where the TRAPS learn She clustered the  the temporal patterns of , um , certain  certain phonemes in  in m averaged over many , many contexts . And , uh , some things tended to cluster .\nMm - hmm .\nRight ? You know , like stop  stop consonants clustered really well .\nHmm .\nUm , silence was by its own self .\nMm - hmm .\nAnd , uh , um ,  v vocalic was clustered .\nMm - hmm .\nAnd ,  um , so ,  those are  interesting things to\nSo you 're  now you 're sort of looking to try to gather a set of these types of features ?\nRight .\nMm - hmm .\nYeah . Just to see where  where I could start off from ,\nMm - hmm .\nuh , you know ? A  a  a set of small features and continue to iterate and find , uh , a better set .\nMm - hmm .\nYeah .\nOK . Well , short meeting . That 's OK .\nYeah .\nOK . So next week hopefully we 'll  can get Hynek here to  to join us and , uh , uh .\nShould we do digits ?\nDigits , digits . OK , now .\nGo ahead , Morgan . You can start .\nAlright . Let me get my glasses on so I can  see them . OK .\nOK . And we 're off .", "topic_id": 4, "keywords": "neural, vad, net, features, network", "dialogue_id": 13}, {"text": "Mm", "topic_id": 5, "keywords": "mm", "dialogue_id": 13}, {"text": "Alright .\nSo , uh\nUm , so I wanted to discuss digits briefly , but that won't take too long .\nOh good . Right . OK , agenda items , Uh , we have digits , What else we got ?\nNew version of the presegmentation .\nNew version of presegmentation .\nUm , do we wanna say something about the , an update of the , uh , transcript ?\nYeah , why don't you summarize the\nUpdate on transcripts .\nAnd I guess that includes some  the filtering for the , the ASI refs , too .\nMmm .\nFiltering for what ?\nFor the references that we need to go from the  the  fancy transcripts to the sort of {nonvocalsound} brain - dead .\nIt 'll  it 'll be  basically it 'll be a re - cap of a meeting that we had jointly this morning .\nUh - huh .\nWith Don , as well .\nMm - hmm .\nGot it . Anything else more pressing than those things ? So  So , why don't we just do those . You said yours was brief , so\nOK . OK well , the , w uh as you can see from the numbers on the digits we 're almost done . The digits goes up to  about four thousand . Um , and so , uh , we probably will be done with the TI - digits in , um , another couple weeks . um , depending on how many we read each time . So there were a bunch that we skipped . You know , someone fills out the form and then they 're not at the meeting and so it 's blank . Um , but those are almost all filled in as well . And so , once we 're  it 's done it would be very nice to train up a recognizer and actually start working with this data .\nSo we 'll have a corpus that 's the size of TI - digits ?\nAnd so  One particular test set of TI - digits .\nTest set , OK .\nSo , I  I extracted , Ther - there was a file sitting around which people have used here as a test set . It had been randomized and so on\nand that 's just what I used to generate the order . of these particular ones .\nOh ! Great . Great .\nSo , I 'm impressed by what we could do , Is take the standard training set for TI - digits , train up with whatever , you know , great features we think we have , uh for instance , and then test on uh this test set .\nUm\nAnd presumably uh it should do reasonably well on that , and then , presumably , we should go to the distant mike , and it should do poorly .\nYeah .\nAnd then we should get really smart over the next year or two , and it  that should get better .\nRight . And inc increase it by one or two percent , yeah .\nYeah ,  Yeah .\nUm , but , in order to do that we need to extract out the actual digits .\nRight .\nUm , so that  the reason it 's not just a transcript is that there 're false starts , and misreads , and miscues and things like that . And so I have a set of scripts and X Waves where you just select the portion , hit R , um , it tells you what the next one should be , and you just look for that . You know , so it  it 'll put on the screen , \" The next set is six nine , nine two two \" . And you find that , and , hit the key and it records it in a file in a particular format .\nSo is this\nAnd so the  the question is , should we have the transcribers do that or should we just do it ? Well , some of us . I 've been do I 've done , eight meetings , something like that , just by hand . Just myself , rather . So it will not take long . Um\nUh , what  what do you think ?\nMy feeling is that we discussed this right before coffee and I think it 's a  it 's a fine idea partly because , um , it 's not un unrelated to their present skill set , but it will add , for them , an extra dimension , it might be an interesting break for them . And also it is contributing to the , uh , c composition of the transcript cuz we can incorporate those numbers directly and it 'll be a more complete transcript . So I 'm  I think it 's fine , that part .\nThere is  there is\nSo you think it 's fine to have the transcribers do it ?\nMm - hmm .\nYeah , OK .\nThere 's one other small bit , which is just entering the information which at s which is at the top of this form , onto the computer , to go along with the  where the digits are recorded automatically .\nGood .\nYeah .\nAnd so it 's just , you know , typing in name , times  time , date , and so on . Um , which again either they can do , but it is , you know , firing up an editor , or , again , I can do . Or someone else can do .\nAnd , that , you know , I 'm not , that  that one I 'm not so sure if it 's into the  the , things that , I , wanted to use the hours for , because the , the time that they 'd be spending doing that they wouldn't be able to be putting more words on .\nMmm .\nBut that 's really your choice , it 's your\nSo are these two separate tasks that can happen ? Or do they have to happen at the same time before\nNo they don't have  this  you have to enter the data before , you do the second task , but they don't have to happen at the same time .\nOK .\nSo it 's  it 's just I have a file whi which has this information on it , and then when you start using my scripts , for extracting the times , it adds the times at the bottom of the file . And so , um , I mean , it 's easy to create the files and leave them blank , and so actually we could do it in either order .\nOh , OK .\nUm , it 's  it 's sort of nice to have the same person do it just as a double - check , to make sure you 're entering for the right person . But , either way .\nYeah . Yeah just by way of uh , uh , a uh , order of magnitude , uh , um , we 've been working with this Aurora , uh data set . And , uh , the best score , on the , nicest part of the data , that is , where you 've got training and test set that are basically the same kinds of noise and so forth , uh , is about , uh  I think the best score was something like five percent , uh , error , per digit .\nPer digit .\nSo , that\nPer digit .\nYou 're right . So if you were doing  ten digit , uh , recognition ,  you would really be in trouble . So  So the  The point there , and this is uh car noise uh , uh things , but  but real  real situation ,\nMm - hmm .\nwell , \" real \" , Um , the  uh there 's one microphone that 's close , that they have as  as this sort of thing , close versus distant . Uh but in a car , instead of  instead of having a projector noise it 's  it 's car noise . Uh but it wasn't artificially added to get some  some artificial signal - to - noise ratio . It was just people driving around in a car . So , that 's  that 's an indication , uh that was with , many sites competing , and this was the very best score and so forth , so . More typical numbers like\nAlthough the models weren't , that good , right ? I mean , the models are pretty crappy ?\nYou 're right . I think that we could have done better on the models , but the thing is that we got  this  this is the kind of typical number , for all of the , uh , uh , things in this task , all of the , um , languages . And so I  I think we 'd probably  the models would be better in some than in others . Um , so , uh . Anyway , just an indication once you get into this kind of realm even if you 're looking at connected digits it can be pretty hard .\nHmm .\nHmm . It 's gonna be fun to see how we , compare at this . Very exciting . s @ @ .\nYeah .\nHow did we do on the TI - digits ?\nWell the prosodics are so much different s it 's gonna be , strange . I mean the prosodics are not the same as TI - digits , for example .\nYeah .\nSo I 'm  I 'm not sure how much of effect that will have .\nH how do\nWhat do you mean , the prosodics ?\nUm , just what we were talking about with grouping . That with these , the grouping , there 's no grouping at all , and so it 's just  the only sort of discontinuity you have is at the beginning and the end .\nSo what are they doing in Aurora , are they reading actual phone numbers ,\nAurora I don't know . I don't know what they do in Aurora .\nor , a  a digit at a time , or  ?\nUh , I 'm not sure how\nCuz it 's\nno , no I mean it 's connected  it 's connected , uh , digits ,\nConnected .\nyeah . But .\nBut  Right .\nSo there 's also the  not just the prosody but the cross  the cross - word modeling is probably quite different .\nH How\nBut in TI - digits , they 're reading things like zip codes and phone numbers and things like that ,\nRight .\ndo we do on TI - digits ?\nso it 's gonna be different . I don't remember . I mean , very good , right ?\nYeah , I mean we were in the .\nOne and a half percent , two percent , something like that ?\nUh , I th no I think we got under a percent , but it was  but it 's  but I mean . The very best system that I saw in the literature was a point two five percent or something that somebody had at  at Bell Labs , or . Uh , but . But , uh , sort of pulling out all the stops .\nOh really ?\ns @ @ . It s strikes me that there are more  each of them is more informative because it 's so , random ,\nOK . Alright .\nHmm .\nBut I think a lot of systems sort of get half a percent , or three - quarters a percent ,\nRight .\nand we 're  we 're in there somewhere .\nBut that  I mean it 's really  it 's  it 's close - talking mikes , no noise , clean signal , just digits , I mean , every everything is good .\nYeah .\nIt 's the beginning of time in speech recognition .\nYes , exactly .\nYeah .\nAnd we 've only recently got it to anywhere near human .\nIt 's like the , single cell , you know , it 's the beginning of life ,\nPre - prehistory .\nyeah .\nAnd it 's still like an order of magnitude worse than what humans do .\nRight .\nYeah .\nSo .\nWhen  When they 're wide awake , yeah . Um ,\nYeah . After coffee .\nafter coffee , you 're right . Not after lunch .\nOK , so , um , what I 'll do then is I 'll go ahead and enter , this data . And then , hand off to Jane , and the transcribers to do the actual extraction of the digits .\nYeah . Yeah . One question I have that  that I mean , we wouldn't know the answer to now but might , do some guessing , but I was talking before about doing some model modeling of arti uh , uh , marking of articulatory , features , with overlap and so on .\nHmm .\nAnd , and , um , On some subset . One thought might be to do this uh , on  on the digits , or some piece of the digits . Uh , it 'd be easier , uh , and so forth . The only thing is I 'm a little concerned that maybe the kind of phenomena , in w i i The reason for doing it is because the  the argument is that certainly with conversational speech , the stuff that we 've looked at here before , um , just doing the simple mapping , from , um , the phone , to the corresponding features that you could look up in a book , uh , isn't right . It isn't actually right . In fact there 's these overlapping processes where some voicing some up and then some , you know , some nasality is  comes in here , and so forth . And you do this gross thing saying \" Well I guess it 's this phone starting there \" . So , uh , that 's the reasoning . But , It could be that when we 're reading digits , because it 's  it 's for such a limited set , that maybe  maybe that phenomenon doesn't occur as much . I don't know . Di - an anybody  ?  Do you have any  ?  Anybody have any opinion about that ,\nand that people might articulate more , and you that might end up with more  a closer correspondence .\nMm - hmm . Yeah .\nYeah  that 's  I  I agree .\nSort of less predictability ,\nThat  it 's just\nMm - hmm .\nYeah .\nand  You hafta\nIt 's a  Well  Would , this corpus really be the right one to even try that on ?\nWell it 's definitely true that , when people are , reading , even if they 're re - reading what , they had said spontaneously , that they have very different patterns . Mitch showed that , and some , dissertations have shown that .", "topic_id": 0, "keywords": "transcripts, transcript, presegmentation, brief, corpus", "dialogue_id": 14}, {"text": "Right .\nSo the fact that they 're reading , first of all , whether they 're reading in a room of , people , or rea you know , just the fact that they 're reading will make a difference .\nYeah .\nAnd , depends what you 're interested in .\nSee , I don't know . So , may maybe the thing will be do  to take some very small subset , I mean not have a big , program , but take a small set , uh , subset of the conversational speech and a small subset of the digits , and  look and  and just get a feeling for it . Um , just take a look . Really .\nH That could  could be an interesting design , too , cuz then you 'd have the com the comparison of the , uh , predictable speech versus the less predictable speech\nCuz I don't think anybody is , I at least , I don't know , of anybody , uh , well , I don't know ,  the answers .\nHey .\nYeah .\nand maybe you 'd find that it worked in , in the , case of the pr of the , uh , non - predictable .\nYeah .\nHafta think about , the particular acoustic features to mark , too , because , I mean , some things , they wouldn't be able to mark , like , uh , you know , uh , tense lax .\nMm - hmm .\nSome things are really difficult . You know ,\nWell .\njust listening .\nM I think we can get Ohala in to , give us some advice on that .\nYeah .\nAlso I thought you were thinking of a much more restricted set of features , that\nYeah , but I  I  I  I was , like he said ,  I was gonna bring John in and ask John what he thought .\nYeah , sure . Sure . Yeah .\nRight . But I mean you want  you want it be restrictive but you also want it to  to  to have coverage .\nRight .\nYeah\nYou know i you should . It should be such that if you , if you , uh , if you had o um , all of the features , determined that you  that you were uh ch have chosen , that that would tell you , uh , in the steady - state case , uh , the phone . So , um .\nOK .\nEven , I guess with vowels that would be pretty hard , wouldn't it ? To identify actually , you know , which one it is ?\nIt would seem to me that the points of articulation would be m more , g uh , I mean that 's  I think about articulatory features , I think about , points of articulation , which means , uh , rather than vowels .\nYeah .\nPoints of articulation ? What do you mean ?\nSo , is it , uh , bilabial or dental or is it , you know , palatal .\nMm - hmm .\nWhich  which are all like where  where your tongue comes to rest .\nPlace , place .\nPlace of ar place of articulation .\nUvular .\nPlace .\nPlace . Thank you , what  whatev whatever I s said , that 's\nYeah .\nOK .\nI really meant place .\nYeah .\nOK , I see .\nYeah . OK we got our jargon then , OK .\nYeah .\nUh .\nWell it 's also , there 's , really a difference between , the pronunciation models in the dictionary , and , the pronunciations that people produce . And , so , You get , some of that information from Steve 's work on the  on the labeling\nRight .\nRight .\nand it really , I actually think that data should be used more . That maybe , although I think the meeting context is great , that he has transcriptions that give you the actual phone sequence . And you can go from  not from that to the articulatory features , but that would be a better starting point for marking , the gestural features , then , data where you don't have that , because , we  you wanna know , both about the way that they 're producing a certain sound , and what kinds of , you know what kinds of , phonemic , differences you get between these , transcribed , sequences and the dictionary ones .\nWell you might be right that mi might be the way at getting at , what I was talking about , but the particular reason why I was interested in doing that was because I remember , when that happened , and , John Ohala was over here and he was looking at the spectrograms of the more difficult ones . Uh , he didn't know what to say , about , what is the sequence of phones there . They came up with some compromise . Because that really wasn't what it look like . It didn't look like a sequence of phones\nRight .\nRight .\nit look like this blending thing happening here and here and here .\nYeah , so you have this feature here , and , overlap , yeah .\nRight .\nYeah .\nThere was no name for that .\nBut  Right .\nYeah .\nBut it still is  there 's a  there are two steps . One  you know , one is going from a dictionary pronunciation of something , like , \" gonna see you tomorrow \" ,\nAnd  Or \" gonta \" .\nRight . Yeah .\nit could be \" going to \" or \" gonna \" or \" gonta s \" you know .\nRight .\nAnd , yeah . \" Gonna see you tomorrow \" , uh , \" guh see you tomorrow \" . And , that it would be nice to have these , intermediate , or these  some  these reduced pronunciations that those transcribers had marked or to have people mark those as well .\nMm - hmm .\nBecause , it 's not , um , that easy to go from the , dictionary , word pronuncia the dictionary phone pronunciation , to the gestural one without this intermediate or a syllable level kind of , representation .\nWell I don't think Morgan 's suggesting that we do that , though .\nDo you mean ,\nYeah .\nYeah , I mean , I I I 'm jus at the moment of course we 're just talking about what , to provide as a tool for people to do research who have different ideas about how to do it . So for instance , you might have someone who just has a wor has words with states , and has uh  uh , comes from articulatory gestures to that . And someone else , might actually want some phonetic uh intermediate thing . So I think it would be  be best to have all of it if we could . But  um ,\nBut  What I 'm imagining is a score - like notation , where each line is a particular feature .\nYeah .\nRight ,\nYeah .\nso you would say , you know , it 's voiced through here , and so you have label here , and you have nas nasal here , and , they  they could be overlapping in all sorts of bizarre ways that don't correspond to the timing on phones .\nI mean this is the kind of reason why  I remember when at one of the Switchboard , workshops , that uh when we talked about doing the transcription project , Dave Talkin said , \" can't be done \" .\nRight .\nHe was  he was , what  what he meant was that this isn't , you know , a sequence of phones , and when you actually look at Switchboard that 's , not what you see , and , you know . And . It ,\nAnd in  in fact the inter - annotator agreement was not that good , right ? On the harder ones ?\nyeah I mean it was\nIt depends how you look at it , and I  I understand what you 're saying about this , kind of transcription exactly ,\nYeah .\nbecause I 've seen  you know , where does the voicing bar start and so forth .\nYeah .\nAll I 'm saying is that , it is useful to have that  the transcription of what was really said , and which syllables were reduced . Uh , if you 're gonna add the features it 's also useful to have some level of representation which is , is a reduced  it 's a pronunciation variant , that currently the dictionaries don't give you\nMm - hmm .\nbecause if you add them to the dictionary and you run recognition , you , you add confusion .\nRight . Right .\nSo people purposely don't add them . So it 's useful to know which variant was  was produced , at least at the phone level .\nSo it would be  it would be great if we had , either these kind of , labelings on , the same portion of Switchboard that Steve marked , or , Steve 's type markings on this data , with these .\nRight . That 's all , I mean . Exactly .\nYeah .\nExactly .\nYeah , no I  I don't disagree with that .\nAnd Steve 's type is fairly  it 's not that slow , uh , uh , I dunno exactly what the , timing was , but .\nYeah u I don't disagree with it the on the only thing is that , What you actually will end  en end up with is something , i it 's all compromised , right , so , the string that you end up with isn't , actually , what happened . But it 's  it 's the best compromise that a group of people scratching their heads could come up with to describe what happened .\nAnd it 's more accurate than , phone labels .\nMm - hmm .\nBut . And it 's more accurate than the  than the dictionary or , if you 've got a pronunciation uh lexicon that has three or four ,\nThe word .\nYeah .\nthis might be have been the fifth one that you tr that you pruned or whatever ,\nSo it 's like a continuum .\nRight .\nso sure .\nIt 's  you 're going all the way down ,\nRight . Right .\nYeah .\nyeah .\nThat 's what I meant is\nYeah .\nan and in some places it would fill in , So  the kinds of gestural features are not everywhere .\nWell\nRight .\nSo there are some things that you don't have access to either from your ear or the spectrogram ,\nMm - hmm .\nbut you know what phone it was and that 's about all you can  all you can say .\nRight .\nAnd then there are other cases where , nasality , voicing\nIt 's basically just having , multiple levels of  of , information and marking , on the signal .\nRight . Right .\nYeah .\nWell the other difference is that the  the features , are not synchronous ,\nRight .\nright . They overlap each other in weird ways .\nMm - hmm . Mm - hmm .\nSo it 's not a strictly one - dimensional signal .\nRight .\nSo I think that 's sorta qualitatively different .\nRight . You can add the features in , uh , but it 'll be underspecified .\nHmm .\nTh - there 'll be no way for you to actually mark what was said completely by features .\nWell not with our current system but you could imagine designing a system , that the states were features , rather than phones .\nAnd i if you 're  Well , we  we 've probably have a  separate , um , discussion of , uh  of whether you can do that .\nThat 's  Well ,  isn't that  I thought that was , well but that  wasn't that kinda the direction ?\nYeah .\nI thought\nYeah , so I mean , what , what  where this is , I mean , I I want would like to have something that 's useful to people other than those who are doing the specific kind of research I have in mind , so it should be something broader . But , The  but uh where I 'm coming from is , uh , we 're coming off of stuff that Larry Saul did with  with , um , uh , John Dalan and Muzim Rahim in which , uh , they , uh , have , um , a m a multi - band system that is , uh , trained through a combination of gradient learning an and EM , to  um , estimate , uh ,  the , uh , value for m for  for a particular feature . OK . And this is part of a larger , image that John Dalan has about how the human brain does it in which he 's sort of imagining that , individual frequency channels are coming up with their own estimate , of  of these , these kinds of  something like this . Might not be , you know , exact features that , Jakobson thought of or something . But I mean you know some , something like that . Some kind of low - level features , which are not , fully , you know , phone classification . And the  the  th this particular image , of how thi how it 's done , is that , then given all of these estimates at that level , there 's a level above it , then which is  is making , some kind of sound unit classification such as , you know , phone and  and , you know . You could argue what , what a sound unit should be , and  and so forth . But that  that 's sort of what I was imagining doing , um , and  but it 's still open within that whether you would have an intermediate level in which it was actually phones , or not . You wouldn't necessarily have to . Um , but , Again , I wouldn't wanna , wouldn't want what we  we produced to be so , know , local in perspective that it  it was matched , what we were thinking of doing one week , And  and , and , you know , what you 're saying is absolutely right . That , that if we , can we should put in , uh , another level of , of description there if we 're gonna get into some of this low - level stuff .\nWell , you know , um  I mean if we 're talking about , having the , annotators annotate these kinds of features , it seems like , You know , you  The  the question is , do they do that on , meeting data ? Or do they do that on , Switchboard ?\nThat 's what I was saying ,\nW Well it seems like you could do both .\nmaybe meeting data isn't the right corpus .\nI mean , I was thinking that it would be interesting , to do it with respect to , parts of Switchboard anyway , in terms of ,\nMm - hmm .\nuh  partly to see , if you could , generate first guesses at what the articulatory feature would be , based on the phone representation at that lower level .\nMm - hmm .\nIt might be a time gain . But also in terms of comparability of , um ,\nMm - hmm .\nWell cuz the yeah , and then also , if you did it on Switchboard , you would have , the full continuum of transcriptions .\nwhat you gain Yep .\nYou 'd have it , from the lowest level , the ac acoustic features , then you 'd have the , you know , the phonetic level that Steve did ,\nMm - hmm .\nYeah that  that 's all I was thinking about .\nAnd you could tell that\nand , yeah .\nit is telephone band , so , the bandwidth might be\nIt 'd be a complete , set then .\nAnd you get the relative gain up ahead .\nIt 's so it 's a little different . So I mean i we 'll see wha how much we can , uh , get the people to do , and how much money we 'll have and all this sort of thing ,\nYeah .\nMm - hmm . Mm - hmm .\nBut it  it might be good to do what Jane was saying uh , you know , seed it , with , guesses about what we think the features are , based on , you know , the phone or Steve 's transcriptions or something . to make it quicker .\nbut , Might be do both .\nAlright , so based on the phone transcripts they would all be synchronous , but then you could imagine , nudging them here and there .\nAdjusting ? Yeah , exactly .\nYeah .\nScoot the voicing over a little , because\nRight .\nWell I think what  I mean I 'm  I 'm a l little behind in what they 're doing , now , and , uh , the stuff they 're doing on Switchboard now . But I think that , Steve and the gang are doing , something with an automatic system first and then doing some adjustment . As I re as I recall . So I mean that 's probably the right way to go anyway , is to  is to start off with an automatic system with a pretty rich pronunciation dictionary that , that , um , you know , tries , to label it all . And then , people go through and fix it .\nSo in  in our case you 'd think about us s starting with maybe the regular dictionary entry , and then ? Or  would we\nWell , regular dictionary , I mean , this is a pretty rich dictionary . It 's got , got a fair number of pronunciations in it\nBut\nOr you could start from the  if we were gonna , do the same set , of sentences that Steve had , done , we could start with those transcriptions .\nMm - hmm . So I was thinking\nYeah .\nThat 's actually what I was thinking , is tha\nYeah .\nRight .\nthe problem is when you run , uh , if you run a regular dictionary , um , even if you have variants , in there , which most people don't , you don't always get , out , the actual pronunciations ,\nYeah .\nso that 's why the human transcriber 's giving you the  that pronunciation ,\nYeah . Oh .\nActually maybe they 're using phone recognizers .\nand so y they  they  I thought that they were\nIs that what they 're doing ?\nThey are .\nOh , OK .\nwe should catch up on what Steve is ,\nYeah .\nuh  I think that would be a good i good idea .\nYeah , so I think that i i we also don't have , I mean , we 've got a good start on it , but we don't have a really good , meeting , recorder or recognizer or transcriber or anything yet , so . So , I mean another way to look at this is to , is to , uh , do some stuff on Switchboard which has all this other , stuff to it .\nYeah .\nAnd then , um , As we get , further down the road and we can do more things ahead of time , we can , do some of the same things to the meeting data .\nMm - hmm .\nOK .\nYeah .\nAnd I 'm  and these people might  they  they are , s most of them are trained with IPA .\nYeah\nThey 'd be able to do phonetic - level coding , or articulatory .\nAre they busy for the next couple years , or  ?\nWell , you know , I mean they , they  they 're interested in continuing working with us , so  I mean  I , and this would be up their alley , so , we could  when the  when you d meet with , with John Ohala and find , you know what taxonomy you want to apply , then , they 'd be , good to train onto it .\nYeah . Yeah . Anyway , this is , not an urgent thing at all ,\nYeah .\njust it came up .\nIt 'd be very interesting though , to have  that data .\nI think so , too .\nI wonder , how would you do a forced alignment ?\nYeah . Might\nInteresting idea .\nTo  to  I mean , you 'd wanna iterate , somehow . Yeah . It 's interesting thing to think about .\nHmm .\nIt might be\nI mean you 'd  you 'd want models for spreading .\nI was thinking it might be n\nOf the f acoustic features ?\nYeah .\nMm - hmm .\nMm - hmm .\nYeah .\nWell it might be neat to do some , phonetic , features on these , nonword words . Are  are these kinds of words that people never  the \" huh \"s and the \" hmm \"s and the \" huh \"  and the uh  These k No , I 'm serious . There are all these kinds of  functional , uh , elements . I don't know what you call  them . But not just fill pauses but all kinds of ways of  interrupting  and so forth .\nUh - huh .\nAnd some of them are ,  yeah , \" uh - huh \"s , and \" hmm \"s , and , \" hmm ! \" \" hmm \"  \" OK \" , \" uh \"  Grunts , uh , that might be interesting .\nHe 's got lip   lipsmacks .\nIn the meetings .\nWe should move on .\nYeah .\nUh , new version of , uh , presegmentation ?\nUh , oh yeah , um ,  I worked a little bit on the  on the presegmentation to  to get another version which does channel - specific , uh , speech - nonspeech detection . And , what I did is I used some normalized features which , uh , look in into the  which is normalized energy , uh , energy normalized by the mean over the channels and by the , minimum over the , other . within each channel . And to  to , mm , to , yeah , to normalize also loudness and  and modified loudness and things and that those special features actually are in my feature vector .\nOh .\nAnd , and , therefore to be able to , uh , somewhat distinguish between foreground and background speech in  in the different  in  each channel . And , eh , I tested it on  on three or four meetings and it seems to work , well yeah , fairly well , I  I would say . There are some problems with the lapel mike .\nOf course .\nYeah . Uh , yeah .\nWow that 's great .\nAnd .\nSo I  I understand that 's what you were saying about your problem with , minimum .\nYeah . And . Yeah , and  and I had  I had , uh , specific problems with .\nI get it . So new use ninetieth quartile , rather than , minimum .\nYeah . Yeah .\nWow .\nYeah  yeah , then  I  I did some  some  some things like that ,\nInteresting .\nas there  there are some  some problems in , when , in the channel , there  they  the the speaker doesn't  doesn't talk much or doesn't talk at all . Then , the , yeah , there are  there are some problems with  with  with n with normalization , and , then , uh , there the system doesn't work at all . So , I 'm  I 'm glad that there is the  the digit part , where everybody is forced to say something ,\nRight .\nso , that 's  that 's great for  for my purpose . And , the thing is I  I , then the evaluation of  of the system is a little bit hard , as I don't have any references .\nWell we did the hand  the one by hand .\nYeah , that 's the one  one wh where I do the training on so I can't do the evaluation on So the thing is , can the transcribers perhaps do some , some  some meetings in  in terms of speech - nonspeech in  in the specific channels ?\nUh .\nWell , I have\nWell won't you have that from their transcriptions ?\nWell , OK , so , now we need\nNo , cuz we need is really tight .\nYeah .\nso , um , I think I might have done what you 're requesting , though I did it in the service of a different thing .\nOh , great .\nI have thirty minutes that I 've more tightly transcribed with reference to individual channels .\nOK . OK , that 's great . That 's great for me . Yeah , so .\nAnd I could  And  And\nHopefully that 's not the same meeting that we did .\nNo , actually it 's a different meeting .\nGood .\nOK .\nSo , um , e so the , you know , we have the , th they transcribe as if it 's one channel with these  with the slashes to separate the overlapping parts .", "topic_id": 1, "keywords": "speech, conversational, corpus, talking, speaker", "dialogue_id": 14}, {"text": "Yeah .\nAnd then we run it through  then it  then I 'm gonna edit it and I 'm gonna run it through channelize which takes it into Dave Gelbart 's form format .\nYeah .\nAnd then you have , all these things split across according to channel , and then that means that , if a person contributed more than once in a given , overlap during that time bend that  that two parts of the utterance end up together , it 's the same channel ,\nOK .\nand then I took his tool , and last night for the first thirty minutes of one of these transcripts , I , tightened up the , um , boundaries on individual speakers ' channels ,\nOK . Yeah .\ncuz his  his interface allows me to have total flexibility in the time tags across the channels .\nYeah .\nAnd  um , so .\nso , yeah  yeah , that  that  that 's great , but what would be nice to have some more meetings , not just one meeting to  to be sure that  that , there is a system ,\nSo , current  This week .\nYes . Might not be what you need .\nYeah , so if we could get a couple meetings done with that level of precision I think that would be a good idea .\nOK . Yeah .\nOh , OK . Uh , how  how m much time  so the meetings vary in length , what are we talking about in terms of the number of minutes you 'd like to have as your  as your training set ?\nIt seems to me that it would be good to have , a few minutes from  from different meetings , so . But I 'm not sure about how much .\nOK , now you 're saying different meetings because of different speakers or because of different audio quality or both or  ?\nBoth  both . Different  different number of speakers , different speakers , different  conditions .\nOK .\nYeah , we don't have that much variety in meetings yet , uh , I mean we have this meeting and the feature meeting and we have a couple others that we have uh , couple examples of . But  but , uh ,\nYeah , m Yeah .\nMm - hmm .\nEven probably with the gains  differently will affect it , you mean\nUh , not really as\nPoten - potentially .\nuh , because of the normalization , yeah .\nOh , cuz you use the normalization ? OK .\nYeah .\nOh , OK .\nWe can try running  we haven't done this yet because , um , uh , Andreas an is  is gonna move over the SRI recognizer . i basically I ran out of machines at SRI ,\nOK .\ncuz we 're running the evals and I just don't have machine time there . But , once that 's moved over , uh , hopefully in a  a couple days , then , we can take , um , what Jane just told us about as , the presegmented ,  {nonvocalsound} the  the segmentations that you did , at level eight or som  at some , threshold that Jane , tha  right , and try doing , forced alignment . um , on the word strings .\nOh , shoot !\nYeah . Yeah .\nThe pre presegment\nYeah .\nyeah .\nWith the recognizer ? Yeah .\nAnd if it 's good , then that will  that may give you a good boundary . Of course if it 's good , we don't  then we 're  we 're fine ,\nYeah . M\nbut , I don't know yet whether these , segments that contain a lot of pauses around the words , will work or not .\nI  I would quite like to have some manually transcribed references for  for the system , as I 'm not sure if  if it 's really good to compare with  with some other automatic , found boundaries .\nYeah . Right .\nWell , no , if we were to start with this and then tweak it h manually , would that  that would be OK ?\nYeah .\nRight .\nYeah  sure .\nThey might be OK .\nOK .\nIt  you know it really depends on a lot of things ,\nYeah .\nbut , I would have maybe a transciber , uh , look at the result of a forced alignment and then adjust those .\nYeah . To a adjust them , or , yeah . Yeah , yeah .\nThat might save some time .\nYeah , great .\nIf they 're horrible it won't help at all , but they might not be horrible .\nYeah .\nSo  but I 'll let you know when we , uh , have that .\nOK , great .\nHow many minutes would you want from  I mean , we could  easily , get a section , you know , like say a minute or so , from every meeting that we have so f from the newer ones that we 're working on , everyone that we have . And then , should provide this .\nIf it 's not the first minute of  of the meeting , that  that 's OK with me , but , in  in the first minute , uh , Often there are some  some strange things going on which  which aren't really , well , for , which  which aren't re re really good . So . What  what I 'd quite like , perhaps , is , to have , some five minutes of  of  of different meetings , so .\nSomewhere not in the very beginning , five minutes , OK .\nYeah .\nAnd , then I wanted to ask you just for my inter information , then , would you , be trai cuz I don't quite unders so , would you be training then , um , the segmenter so that , it could , on the basis of that , segment the rest of the meeting ? So , if I give you like  five minutes is the idea that this would then be applied to , uh , to , providing tighter time  bands ?\nI  I could do a  a retraining with that , yeah .\nWow , interesting .\nThat 's  but  but I hope that I  I don't need to do it .\nOK .\nSo , uh it c can be do in an unsupervised way .\nUh - huh .\nSo .\nExcellent . Excellent , OK .\nI 'm  I 'm not sure , but , for  for  for those three meetings whi which I  which I did , it seems to be , quite well , but , there are some  some  as I said some problems with the lapel mike , but , perhaps we can do something with  with cross - correlations to , to get rid of the  of those . And . Yeah . That 's  that 's what I  that 's my  future work . Well  well what I want to do is to  to look into cross - correlations for  for removing those , false overlaps .\nWonderful .\nAre the , um , wireless , different than the wired , mikes , at all ? I mean , have you noticed any difference ?\nI 'm  I 'm not sure , um , if  if there are any wired mikes in those meetings , or , uh , I have  have to loo have a look at them but , I 'm  I 'm  I think there 's no difference between ,\nSo it 's just the lapel versus everything else ?\nYeah . Yeah .\nOK , so then , if that 's five minutes per meeting we 've got like twelve minutes , twelve meetings , roughly , that I 'm  that I 've been working with , then\nOf  of  of the meetings that you 're working with , how many of them are different , tha\nNo .\nare there any of them that are different than , these two meetings ?\nWell  oh wa in terms of the speakers or the conditions or the ?\nYeah , speakers . Sorry .\nYeah , that\nUm , we have different combinations of speakers .\nSo .\nI mean , just from what I 've seen , uh , there are some where , um , you 're present or not present , and , then  then you have the difference between the networks group and this group\nYeah , I know , some of the NSA meetings , yeah .\nYeah . So I didn't know in the group you had if you had\nYeah .\nso you have the networks meeting ?\nYeah .\nYep , we do .\nDo you have any of Jerry 's meetings in your , pack , er ,\nUm , no .\nNo ?\nWe could , I mean you  you recorded one last week or so . I could get that new one in this week  I get that new one in .\nYep . u\nWe 're gonna be recording them every  Monday ,\nYeah . Cuz I think he really needs variety ,\nso\nYeah .\nGreat .\nand  and having as much variety for speaker certainly would be a big part of that I think .\nYeah .\nOK , so if I , OK , included  include , OK , then , uh , if I were to include all together samples from twelve meetings that would only take an hour and I could get the transcribers to do that right  I mean , what I mean is , that would be an hour sampled , and then they 'd transcribe those  that hour , right ? That 's what I should do ?\nYeah . And .\nThat 's  that 's .\nI don't mean transcribe\nRight . Ye - But you 're  y\nI mean  I mean adjust . So they get it into the multi - channel format and then adjust the timebands so it 's precise .\nSo that should be faster than the ten times kind of thing ,\nAbsolutely . I did  I did , um , uh , so , last night I did , uh ,\nyeah .\nOh gosh , well , last night , I did about half an hour in , three hours , which is not , terrific ,\nYeah .\nbut , um , anyway , it 's an hour and a half per\nYeah . Well , that 's probably .\nSo .\nWell , I can't calculate on my ,  on my feet .\nDo the transcribers actually start wi with , uh , transcribing new meetings , or  are they ?\nWell , um they 're still working  they still have enough to finish that I haven't assigned a new meeting ,\nOK .\nbut the next , m m I was about to need to assign a new meeting and I was going to take it from one of the new ones ,\nOK .\nand I could easily give them Jerry Feldman 's meeting , no problem . And , then\nOK .\nSo they 're really running out of , data , prett I mean that 's good .\nMm - hmm . Uh , that first set .\nUm , OK .\nThey 're running out of data unless we s make the decision that we should go over and start , uh , transcribing the other set .\nSo\nThere  the first  the first half .\nYeah .\nAnd so I was in the process of like editing them but this is wonderful news .\nOK .\nAlright .\nWe funded the experiment with , uh  also we were thinking maybe applying that that to getting the , Yeah , that 'll be , very useful to getting the overlaps to be more precise all the way through .\nSo this , blends nicely into the update on transcripts .\nYes , it does . So , um ,  um , Liz , and  and Don , and I met this morning , in the BARCO room , with the lecture hall ,\nOK .\nYeah , please . Go ahead . And this afternoon .\nand this afternoon , it drifted into the afternoon ,   uh , concerning this issue of , um , the , well there 's basically the issue of the interplay between the transcript format and the processing that , they need to do for , the SRI recognizer . And , um , well , so , I mentioned the process that I 'm going through with the data , so , you know , I get the data back from the transcri Well , s uh , metaphorically , get the data back from the transcriber , and then I , check for simple things like spelling errors and things like that . And , um , I 'm going to be doing a more thorough editing , with respect to consistency of the conventions . But they 're  they 're generally very good . And , then , I run it through , uh , the channelize program to get it into the multi - channel format , OK . And  the , what we discussed this morning , I would summarize as saying that , um , these units that result , in a  a particular channel and a particular timeband , at  at that level , um , vary in length . And , um , {nonvocalsound} their recognizer would prefer that the units not be overly long . But it 's really an empirical question , whether the units we get at this point through , just that process I described might be sufficient for them . So , as a first pass through , a first chance without having to do a lot of hand - editing , what we 're gonna do , is , I 'll run it through channelize , give them those data after I 've done the editing process and be sure it 's clean . And I can do that , pretty quickly , with just , that minimal editing , without having to hand - break things .\nMm - hmm .\nAnd then we 'll see if the units that we 're getting , uh , with the  at that level , are sufficient . And maybe they don't need to be further broken down . And if they do need to be further broken down then maybe it just be piece - wise , maybe it won't be the whole thing . So , that 's  that 's what we were discussing , this morning as far as I  Among\nRight .\nalso we discussed some adaptational things ,\nThen lots of\nso it 's like ,\nRight .\nuh  You know I hadn't , uh , incorporated , a convention explicitly to handle acronyms , for example , but if someone says , PZM it would be nice to have that be directly interpretable from , the transcript what they said ,\nMm - hmm .\nor Pi - uh Tcl  TCL I mean . It 's like y it 's  and so , um , I 've  I 've incorporated also convention , with that but that 's easy to handle at the post editing phase , and I 'll mention it to , transcribers for the next phase but that 's OK . And then , a similar conv uh , convention for numbers . So if they say one - eighty - three versus one eight three . Um , and also I 'll be , um , encoding , as I do my post - editing , the , things that are in curly brackets , which are clarificational material . And eh to incorporate , uh , keyword , at the beginning . So , it 's gonna be either a gloss or it 's gonna be a vocal sound like a , laugh or a cough , or , so forth . Or a non - vocal sound like a doors door - slam , and that can be easily done with a , you know , just a  one little additional thing in the , in the general format .\nYeah we j we just needed a way to , strip , you know , all the comments , all the things th the  that linguist wants but the recognizer can't do anything with . Um , but to keep things that we mapped to like reject models , or , you know , uh , mouth noise , or , cough . And then there 's this interesting issue Jane brought up which I hadn't thought about before but I was , realizing as I went through the transcripts , that there are some noises like , um , well the  good example was an inbreath , where a transcriber working from , the mixed , signal , doesn't know whose breath it is ,\nRight .\nand they 've been assigning it to someone that may or may not be correct . And what we do is , if it 's a breath sound , you know , a sound from the speaker , we map it , to , a noise model , like a mouth - noise model in the recognizer , and , yeah , it probably doesn't hurt that much once in a while to have these , but , if they 're in the wrong channel , that 's , not a good idea . And then there 's also , things like door - slams that 's really in no one 's channel , they 're like  it 's in the room .\nYeah .\nRight .\nAnd  uh , Jane had this nice , uh , idea of having , like an extra , uh couple tiers ,\nAn extra channel .\nYeah . I 've been  I 've been adding that to the ones I 've been editing .\nyeah . And we were thinking , that is useful also when there 's uncertainties . So if they hear a breath and they don't know who breath it is it 's better to put it in that channel than to put it in the speaker 's channel because maybe it was someone else 's breath , or  Uh , so I think that 's a good  you can always clean that up , post - processing .\nYeah .\nSo a lot of little details , but I think we 're , coming to some kinda closure , on that . So the idea is then , uh , Don can take , uh , Jane 's post - processed channelized version , and , with some scripts , you know , convert that to  to a reference for the recognizer and we can , can run these . So  when that 's , ready  you know , as soon as that 's ready , and as soon as the recognizer is here we can get , twelve hours of force - aligned and recognized data . And , you know , start , working on it ,\nAnd\nso we 're , I dunno a coup a week or two away I would say from , uh , if  if that process is automatic once we get your post - process , transcript .\nMm - hmm . And that doesn't  the amount of editing that it would require is not very much either . I 'm just hoping that the units that are provided in that way , {nonvocalsound} will be sufficient cuz I would save a lot of , uh , time , dividing things .\nYeah , some of them are quite long . Just from  I dunno how long were  you did one ?\nI saw a couple ,  around twenty seconds , and that was just without looking too hard for it , so , I would imagine that there might be some that are longer .\nRight .\nWell n One question , e w would that be a single speaker or is that multiple speakers overlapping ?\nNo . No , but if we 're gonna segment it , like if there 's one speaker in there , that says \" OK \" or something , right in the middle , it 's gonna have a lot of dead time around it ,\nRight . It 's not the  it 's not the fact that we can't process a twenty second segment , it 's the fact that , there 's twenty seconds in which to place one word in the wrong place\nso it 's not\nYeah .\nYeah .\nYou know , if  if someone has a very short utterance there , and that 's where , we , might wanna have this individual , you know , ha have your pre pre - process input .\nYep . Yeah . Sure .\nThat 's very important .\nI  I  I thought that perhaps the transcribers could start then from the  those mult multi - channel , uh , speech - nonspeech detections , if they would like to .\nAnd I just don't know , I have to run it .\nIn  in doing the hand - marking ?\nRight .\nYeah .\nYeah that 's what I was thinking , too .\nRight .\nYeah .\nSo that 's probably what will happen , but we 'll try it this way and see .\nYeah .\nI mean it 's probably good enough for force - alignment . If it 's not then we 're really  then we def definitely\nYeah .\nuh , but for free recognition I 'm  it 'll probably not be good enough . We 'll probably get lots of errors because of the cross - talk , and , noises and things .\nYep .\nGood s I think that 's probably our agenda , or starting up there .\nOh I wanted to ask one thing , the microphones  the new microphones ,\nYeah ? K .\nwhen do we get , uh ?\nUh , they said it would take about a week .\nOh , exciting . K . K .\nK .\nYou ordered them already ?\nMm - hmm .\nGreat .\nSo what happens to our old microphones ?\nThey go where old microphones go .\nUm\nDo we give them to someone , or  ?\nWell the only thing we 're gonna have extra , for now ,\nWe don't have more receivers , we just have\nRight , we don so the only thing we 'll have extra now is just the lapel .\nRight .\nNot  not the , bodypack , just the lapel .\nJust the lapel itself .\nUm , and then one of the  one of those . Since , what I decided to do , on Morgan 's suggestion , was just get two , new microphones , um , and try them out . And then , if we like them we 'll get more .\nMm - hmm .\nYeah .\nOK .\nSince they 're  they 're like two hundred bucks a piece , we won't , uh , at least try them out .\nSo it 's a replacement for this headset mike ?\nYep . Yep .\nYeah .\nAnd they 're gonna do the wiring for us .\nWhat 's the , um , style of the headset ?\nIt 's , um , it 's by Crown , and it 's one of these sort of mount around the ear thingies , and , uh , when I s when I mentioned that we thought it was uncomfortable he said it was a common problem with the Sony . And this is how apparently a lot of people are getting around it .\nHmm .\nAnd I checked on the web , and every site I went to , raved about this particular mike . It 's apparently comfortable and stays on the head well , so we 'll see if it 's any good . But , uh , I think it 's promising .\nYou said it was used by aerobics instructors ?\nYep . Yep , so it was  it was advertised for performers\nThat says a lot .\nHmm .\nFor the recor for the record Adam is not a paid employee or a consultant of Crown .\nand  Excuse me ?\nOh .\nI said \" For the record Adam is  is not a paid consultant or employee of Crown \" .\nExcuse me ?\nRight .\nThat 's right .\nHowever , he may be solicited after these meetings are distributed .\nWell we 're using the Crown P Z\nYeah .\nDon't worry about finishing your dissertation .\nThese are Crown aren't they ?\nRight .\nThe P Z Ms are Crown , aren't they ?\nYeah .\nYeah , I thought they were .\nYou bet . You bet .\nAnd they work very well .\nYes .\nSo if we go to a workshop about all this  this it 's gonna be a meeting about meetings about meetings . OK . So .\nAnd then it  we have to go to the planning session for that workshop .\nOh , yeah , what  Which 'll be the meeting about the meeting about the meeting .\nOh , god .\nCuz then it would be a meeting about the meeting about the meeting about meetings .\nYeah ? Just start saying \" M four \" . Yeah , OK .\nYeah . M to the fourth .\nShould we do the digits ?\nYep , go for it .\nOK .\nS  s\nPause between the lines , remember ?\nExcuse me .\nOK .\nOK .\nHuh .", "topic_id": 2, "keywords": "channelized, channelize, meetings, timebands, timeband", "dialogue_id": 14}, {"text": "Time .\nThanks .\nAre you Fey ?\nI am Fey , yeah .\nOh .\nWhat day is today ?\nHi .\nHi . I think we 've met before , like , I remember talking to you about Aspect or something like that at some point or other .\nA couple times yeah .\nIt 's the uh twenty  nineteenth .\nNineteenth ?\nThat 's right , yeah .\nSo .\nAnd you were my GSI briefly , until I dropped the class .\nRight , right .\nOh that 's right .\nBut .\nWell .\nOK , wh wh\nNo offense .\nYeah .\nLike .\nOK . Some in some introductions are in order .\nOh , OK sorry .\nOK .\nGetting ahead of myself .\nSo . Um . For those who don't know  Everyone knows me , this is great . Um , apart from that , sort of the old gang , Johno and Bhaskara have been with us from  from day one\nYay !\nHi .\nand um they 're engaged in  in various activities , some of which you will hear about today . Ami is um our counselor and spiritual guidance and um also interested in problems concerning reference of the more complex type ,\nWell .\nOh wow .\nand um he sits in as a interested participant and helper . Is that a good characterization ?\nu That 's pretty good , I think .\nI don't know .\nYeah . Thanks .\nOK . Keith is not technically one of us yet ,\nNot yet .\nha - ha . but um it 's too late for him now .\n\" One of us . \"\nSo .\nYeah right . I 've got the headset on after all .\nUm . Officially I guess he will be joining us in the summer .\nyes .\nAnd um hopefully it is by  by means of Keith that we will be able to get a b a better formal and a better semantic um idea of what a construction is and um how we can make it work for us . Additionally his interest um surpasses um English because it also entails German , an extra capability of speaking and writing and understanding and reading that language . And um , is there anyone who doesn't know Nancy ? Do you  do you know Nancy ?\nMe ?\nI know Nancy .\nMm - hmm .\nI made that joke already , Nancy , sadly .\nOK .\nWhat ?\nThe \" I don't know myself \" joke .\nYou did ? When ?\nUh before you came in .\nOh .\nMan !\nAbout me or you ?\nAbout me .\nOK .  OK .\nYou could do it about you .\nYeah .\nWell I didn't know . I didn't mean to be humor copying , but OK , sorry . Yes , I know myself . It 's OK .\nOK .\nIt 's a\nAnd um Fey is with us as of six days ago officially ?\nOfficially ,\nOfficially ,\nyeah .\nbut in reality already um much much longer and um um next to some  some more or less bureaucratic uh stuff with the  the data collection she 's also the wizard in the data collection Um ,\nOf Oz .\nIt 's very exciting .\nwe 're sticking with the term \" wizard \" ,\nYes .\nOK .\nYes .\nand um\nNot witch - like .\nWizardette .\nWizard .\nWizardess .\nSorceress , I think .\nOK .\nWizard .\nwizard uh by by popular vote\nOK .\num\nDidn't take a vote ? OK .\nOK , um , why don't we get started on that subject anyways . Um , so we 're about to collect data and um the uh s the following things have happened since we last met . When will we three meet again ? And um\nMore than three of us .\nwhat happened is that um , \" A \" ,  there was some confusion between you and Jerry with the  that leading to your talking to Catherine Snow , and he was uh he  he agreed completely that some something confusing happened . Um his idea was to get sort of the l the lists of mayors of the department , the students . It  it 's exactly how you interpreted it , sort of s\nThe list of majors in the department ?\nM m Majors ?\nMa - majors , majors .\nMajors ?\n\" Mayors \" .\nOK , mayor\nMajors .\nSomething I don't know about these\nThe department has many mayors .\nMajors and um just sending the  the little write - up that we did on to those email lists\nOK . OK . Yeah , yeah , yeah . But  Yeah .\nuh\nSo it was really Carol Snow who was confused , not me and not Jerry .\nYep , yep , yep . OK . So . So , that is uh\nThat 's good . So I should still do that .\nYep .\nOK .\nAnd\nAnd using the thing that you wrote up .\nYep .\nOK .\nWonderful . And um we have a little description of asking peop subjects to contact Fey for you know recruiting them for our thing and um there was some confusion as to the consent form , which is basically that  that what what you just signed\nRight .\nand since we have one already um\nDid Jerry talk to you about maybe using our class ? the students in the undergrad class that he 's teaching ?\nUm well he said um we  definitely \" yes \" ,\ne\nhowever there is always more people in a  in a facul uh in a department than are just taking his class or anybody else 's class at the moment\nYeah .\nand one should sort of reach out and try and get them all .\nOK , but th I guess it 's that um people in his class cover a different set so  than the c is the CogSci department that you were talking about ?\nI guess . See\nuh reaching out to ?\nthat 's what I suggested to him , that people like  like Jerry and George and et cetera just\nCuz we have you know people from other areas\nYeah .\nadvertise in their classes as well .\nYeah or even I could  you know I could do the actual\nMm - hmm .\nCuz I mean I  I know how to contact our students ,\nThat 's generally the way it 's done .\nso if there 's something that you 're sending out you can also s um send me a copy ,\nYeah .\nme or Bhaskara could  either of us could post it to uh is it\nA mailing list .\nif it 's a general solicitation that you know is just contact you then we can totally pro post it to the news group\nMm - hmm . Yeah .\nYeah .\nso .\nDo it . Yeah .\nThat 's\nOK , so you 'll send it or something so .\nAs a matter of fact , if you\nI can send it .\nif\nI 'll send it ,\nYou can send it to me .\nNow , i\nyeah .\nOK . Don't worry , we  this doesn't concern you anymore , Robert .\nHow  however I suggest that if you  if you look at your email carefully you may think  you may find that you already have it .\nIt 's fine . Oops . Already ? Really ?\nMaybe .\nProbab\nOops .\nOK . W we 'll see .\nI don't remember getting anything .\nAnyhow , um the uh Yeah , not only Also we will talk about Linguistics and of course Computer Science .\nMm - hmm .\nUm and then , secondly , we had , you may remember , um the problem with the re - phrasing , that subject always re - phrase sort of the task that uh we gave them ,", "topic_id": 0, "keywords": "fey, subjects, introductions, linguistics, meet", "dialogue_id": 15}, {"text": "Right .\nand so we had a meeting on Friday talking about how to avoid that , and it proved finally fruitful in the sense that we came up with a new scenario for how to get the  the subject m to really have intentions and sort of to act upon those , and um there the idea is now that next actually we  we need to hire one more person to actually do that job because it  it 's getting more complicated . So if you know anyone interested in  in what i 'm about to describe , tell that person to  to write a mail to me or Jerry soon , fast . Um  the idea now is to sort of come up with a high level of sort of abstract tasks \" go shopping \" um \" take in uh a batch of art \" um \" visit  do some sightseeing \" blah - blah - blah - blah - blah , sort of analogous to what Fey has started in  in  in compiling  compiling here and already  she has already gone to the trouble of  of anchoring it with specific um o  um entities and real world places you will find in Heidelberg . And um . So out of these f s these high level categories the subject can pick a couple , such as if  if there is a cop uh a category in emptying your roll of film , the person can then decide \" OK , I wanna do that at this place \" , sort of make up their own itinerary a and  and tasks and the person is not allowed to take sort of this h high level category list with them , but uh the person is able to take notes on a map that we will give him and the map will be a tourist 's sort of schematic representation with  with symbols for the objects . And so , the person can maybe make a mental note that \" ah yeah I wanted to go shopping here \" and \" I wanted to maybe take a picture of that \" and \" maybe um eat here \" and then goes in and solves the task with the system , IE  Fey , and um and we 're gonna try out that  Any questions ?\nso um y you 'll have those say somewhere what their intention was  so you still have the  the nice thing about having data where you know what the actual intention was ?\nMm - hmm . Yeah .\nBut they will um  There 's nothing that says you know \" these are the things you want to do \" so they 'll say \" well these are the things I want to do \" and  Right , so they 'll have a little bit more natural interaction ?\nHopefully .\nOK . Mm - hmm .\nSo they 'll be given this map , which means that they won't have to like ask the system for in for like high level information about where things are ?\nYeah it 's a schematic tourist map . So it 'll be uh i it 'll still require the  that information and An\nIt w it doesn't have like streets on it that would allow them to figure out their way\nN not  not  not really the street network . Nuh .\nOK .\nSo you 're just saying like what part of town the things are in or whatever ?\nYeah a and um the map is more a means for them to have the buildings and their names and maybe some ma ma major streets and their names\nMm - hmm .\nand we want to maybe ask them , if you have  get it sort of isolated street the  the , whatever , \" River Street \" , and they know that  they have decided that , yes , that 's where they want to do this kind of action um that they have it with them and they can actually read them or sort of have the label for the object because it 's too hard to memorize all these st strange German names . And then we 're going to have another  we 're gonna have w another trial run IE the first with that new setup tomorrow at two and we have a real interesting subject which is Ron Kay for who  those who know him , he 's the founder of ICI . So he 'll  he 's around seven seventy years old , or something .\nI didn't know he was the founder . That 's  OK .\nAnd he also approached me and he offered to help  um our project and he was more thinking about some high level thinking tasks and  I said \" sure we need help you can come in as a subject \" and he said \" OK \" . So that 's what 's gonna happen , tomorrow , data .\nUsing this new  new um plan ,\nNew  new set up .\nOK .\nYeah . Which I 'll hopefully sort of scrape together t But , thanks to Fey , we already have sort of a nice blueprint and I can work with that . Questions ? Comments on that ? If not , we can move on . No ? No more questions ?\nI 'm not sure I totally understand this\nSo what 's the s this is what you made , Fey ?\nHmm ?\nbut  I 'm not sure I totally understand everything that 's being talked about\nLike so  So it 's just based on like the materials you had about Heidelberg .\nUm are you familiar with  with the  with the very rough setup of the data ?\nbut I  I imagine I 'll c just catch on .\nBased on the web site , yeah , at the\nOh OK there 's a web site\nexperiment ?\nRight .\nand then you could like um figure out what the cate\nIt 's a tourist information web site ,\nUh , this is where they 're supposed to\nso .\nOK .\nTalk to a machine and it breaks down and then the human comes on .\nOK .\nYeah . Yeah .\nThe question is just sort of how do we get the tasks in their head that they have an intention of doing something and have a need to ask the system for something without giving them sort of a clear wording or phrasing of the task .\nOK . OK . OK .\nBecause what will happen then is that people repeat  repeat ,  or as much as they can , of that phrasing .\nOK .\nHmm . Um , are you worried about being able to identify\nOK .\nUm . The  The goals that we 've d you guys have been talking about are this  these you know identifying which of three modes um their question uh concerns .\nMm - hmm .\nSo it 's like the Enter versus View\nYeah , we  we  we will sort of get a protocol of the prior interaction ,\nUh - huh .\nright ? That 's where the instructor , the person we are going to hire , um and the subjects sit down together with these high level things\nUh - huh . Mm - hmm .\nand so th the q first question for the subject is , \" so these are things , you know , we thought a tourist can do . Is there anything that interests you ? \"\nMm - hmm .\nAnd the person can say \" yeah , sure sh this is something I would do . I would go shopping \" . Yeah ? and then we can sort of  this s instructor can say \" well , uh then you  you may want to find out how to get over here\nMm - hmm .\nbecause this is where the shopping district is \" .\nSo the interaction beforehand will give them hints about how specific or how whatever though the kinds of questions that are going to ask during the actual session ?\nNo . Just sort of  OK , what  what  what would you like to buy and then um OK there you wanna buy a whatever cuckoos clocks\nYeah .\nOK and the there is a store there .\nMm - hmm .\nSo the task then for that person is t finding out how to get there , right ?\nMm - hmm .\nThat 's sort of what 's left .\nMm - hmm .\nAnd we know that the intention is to enter because we know that the person wants to buy a cuckoos clock .\nOK , that 's what I mean so like those tasks are all gonna be um unambiguous about which of the three modes .\nHopefully .\nRight . OK . So .\nWell , so the idea is to try to get the actual phrasing that they might use and try to interfere as little as possible with their choice of words .\nHopefully .\nt             That they 'll be here ?\nYes . In a sense that 's exactly the  the  the idea ,\nuh uh\nwhich is never possible in a  in a s in a lab situation ,\nWell , u u the one experiment th that  that  that I 've read somewhere , it was  they u used pictures .\nnuh ?\nSo to  to uh actually um uh specify the  the tasks .\nYep .\nMm - hmm .\nUh , but you know i i\nYeah . We had exactly that on our list of possible way things so we  uh I even made a sort of a silly thing how that could work , how you control you are here you  you want to know how to get someplace , and this is the place and it 's a museum and you want to do some and  and  and there 's a person looking at pictures . So , you know , this is exactly getting someplace with the intention of entering and looking at pictures .\nRight .\nHowever , not only was  the common census were  among all participants of Friday 's meeting was it 's gonna be very laborious to  to make these drawings for each different things ,\nRight .\nall the different actions , if at all possible , and also people will get caught up in the pictures . So all of a sudden we 'll get descriptions of pictures in there .\nRight .\nAnd people talking about pictures and pictorial representations\nHmm .\nand  um\nRight .\nI would s I would still be willing to try it .\nI mean , I I 'm  I 'm not saying it 's necessary but  but uh i uh uh i  you might be able to combine you know text uh and  and some sort of picture and also uh I think it  it will be a good idea to show them the text and kind of chew the task and then take the test away  the  the  the  the  the text away\nMm - hmm . Yeah .\nso that they are not uh guided by  by by what you wrote ,\nWe will\nbut can come up with their  with their own\nYeah , they will have no more linguistic matter in front of them when they enter this room .", "topic_id": 1, "keywords": "tasks, sightseeing, interests, subjects, act", "dialogue_id": 15}, {"text": "Right .\nOK . Then I suggest we move on to the  to we have um uh the EDU Project , let me make one more general remark , has sort of two  two side uh um actions , its um action items that we 're do dealing with , one is modifying the SmartKom parser and the other one is modifying the SmartKom natural language generation module . And um this is not too complicated but I 'm just mentioning it  put it in the framework because this is something we will talk about now . Um , I have some news from the generation , do you have news from the parser ?\nUm , not\nBy that look I\nYes , uh , I would really p It would be better if I talked about it on Friday .\nOK .\nIf that 's OK .\nYeah , wonderful . Um , did you run into problems or did you run into not h having time ?\nYeah . But not  not any time part .\nOK , so that 's good . That 's better than running into problems .\nOK .\nAnd um I  I do have some good news for the natural language generation however . And the good news is I guess it 's done . Uh , meaning that Tilman Becker , who does the German one , actually took out some time and already did it in English for us . And so the version he 's sending us is already producing the English that 's needed to get by in version one point one .\nSo I take it that was similar to the  what  what we did for the parsing ?\nYeah . I  I  it  even though the generator is a little bit more complex and it would have been , not changing one hundred words but maybe four hundred words ,\nOK .\nbut it would have been\nOK .\nbut this  this is I guess good news , and the uh  the time and especially Bhaskara and uh  and um  Oh do I have it here ? No . The time is now pretty much fixed . It 's the last week of April until the fourth of May so it 's twenty - sixth through fourth . That they 'll be here . So it 's  it 's extremely important that the two of you are also present in this town during that time .\nWait , what  what are the days ? April twenty - sixth to the  May fourth ?\nYeah , something like that .\nI 'll probably be here .\nIt 's\nYeah .\nYou will be here .\nThere is a d Isn't finals coming up then pretty much after that ?\nFinals was that .\nYeah w it doesn't really have much meaning to grad students but final projects might .\nOK .\nYeah actually , that 's true .\nThat\nAnyway , so this is\nWell I 'll be here working on something . Guaranteed , it 's just uh will I be here , you know , in uh  I 'll be here too actually but\nHmm .\nNo it 's just um you know they 're coming for us so that we can bug them\nYe\nand ask them more questions and sit down together and write sensible code and they can give some nice talks and stuff . But uh\nBut it 's not like we need to be with them twenty - four hours a day s for the seven days that they 're here .\njust make a  Not  not unless you really really want to .\nThey 're very dependent\nNot unless you really want to . And they 're both nice guys so you may  may want to . OK , that much from the parser and generator side , unless there are more questions on that .\nSo , no sample generator output yet ?\nNo . It  Just a mail that , you know , he 's sending me the  the  the stuff soon\nOK . This is being sent , mm - hmm . OK .\nand I was completely flabbergasted here\nMm - hmm .\nand I  and that 's also it 's  it 's going to produce the concept - to - speech uh blah - blah - blah information for  necessary for one point one in English  based on the English , you know , in English . So . I was like \" OK ,\nWe 're done .\nwe 're done ! \"\nSo that was like one of the first l You know , the first task was getting it working for English . So that 's basically over now . Is that right ?\nYeah .\nSo the basic requirement fulfilled .\nUm , the basic requirement is fulfilled almost . When Andreas Stolcke and  and his gang ,\nMm - hmm .\nwhen they have um changed the language model of the recognizer and the dictionary , then we can actually a put it all together\nMm - hmm . So the speech recognizer also works . Uh - huh . Mm - hmm .\nand you can speak into it and ask for TV and movie information\nToll .\nand then when if  if something actually happens and some answers come out , then we 're done .\nMm - hmm . If  and they 're kind of correct .\nSo it 's not done basically .\nHmm ?\nAnd they kind of are  are correct .\nRight . Perhaps if the answers have something to do with the questions for example .\nIt 's not just like anything . And they 're mostly in English . So .\nThen um\nAre they  is it using the database ? the German TV movie .\nYeah .\nOK . So  all the actual data might be German names ?\nUm well actually th um\nOr are they all like American TV programs ?\num well\nI want to see \" Die Dukes Von Hazard \"\nThe  OK , so you don't know how the German dialogue  uh the German  the demo dialogue actually works . It works  the first thing is what 's , you know , showing on TV , and then the person is presented with what 's running on TV in Germany on that day , on that evening\nMm - hmm , mm - hmm .\nand so you take one look at it and then you say \" well that 's really nothing  there 's nothing for me there \" \" what 's running in the cinemas ? \" So maybe there 's something better happening there .\nMm - hmm .\nAnd then you get  you 're shown what movies play which films , and it 's gonna be of course all the Heidelberg movies and what films they are actually showing .\nMm - hmm .\nAnd most of them are going to be Hollywood movies . So , \" American Beauty \" is \" American Beauty \" ,\nHmm .\nright ? Yeah .\nMm - hmm .\nRight .\nAnd um .\nBut they 're shown like on a screen .\nN\nIt 's a  I mean so would the generator , like the English language sentence of it is  \" these are the follow you know the following films are being shown \" or something like that ?\nYeah , but it in that sense it doesn't make  In that case uh it doesn't really make sense to read them out loud .\nS Right .\nif you 're displaying them .\nSo it 'll just display  OK .\nBut uh it 'll tell you that this is what 's showing in Heidelberg and there you go .\nSo we don't have to worry about um  Yeah .\nAnd the presentation agent will go \" Hhh ! \"  Nuh ?\nOK .\nLike that  the avatar .\nOK .\nAnd um . And then you pick  pick a movie and  and  and it show shows you the times and you pick a time and you pick seats and all of this . So .\nOK .\nPretty straightforward .\nOK .\nBut it 's  so this time we  we are at an advantage because it was a problem for the German system to incorporate all these English movie titles .\nYeah .\nNuh ? But in English , that 's not really a problem ,\nRight . Mm - hmm .\nunless we get some  some topical German movies that have just come out and that are in their database . So the person may select \" Huehner Rennen \" or whatever .\nRight .\n\" Chicken Run \" .\nOK . Then uh on to the modeling . Right ?\nYeah , yeah , I guess .\nUm then modeling , there it is .\nYep .\nOK . What 's the next thing ?\ne\nThis is very rough but this is sort of what um Johno and I managed to come up with . The idea here is that\nThis is the uh s the schema of the XML here , not an example or something like that .\nYeah this is not an XML this is sort of towards an  a schema ,\nOK .\nRight .\nnuh ? definition . The idea is , so , imagine we have a library of schema such as the Source - Path - Goal and then we have forced uh motion , we have cost action ,\nMm - hmm .\nwe have a whole library of schemas .\nMm - hmm .\nAnd they 're gonna be , you know , fleshed out in  in their real ugly detail , Source - Path - Goal , and there 's gonna be s a lot of stuff on the Goal and blah - blah - blah , that a goal can be and so forth . What we think is  And all the names could  should be taken \" cum grano salis \" . So . This is a  the fact that we 're calling this \" action schema \" right now should not entail that we are going to continue calling this \" action schema \" . But what that means  is we have here first of all on the  in the  in the first iteration a stupid list of Source - Path - Goal actions\nActions that can be categorized with  or that are related to Source - Path - Goal .\nwi to that schema\nOK .\nMm - hmm .\nand we will have you know forced motion and cost action actions .\nAnd then those actions can be in multiple categories at the same time if necessary .\nSo a push may be in  in  in both you know push uh in this or this uh\nForced motion and caused action for instance ,\nExactly . Yeah .\nOK .\nAlso , these things may or may not get their own structure in the future . So this is something that , you know , may also be a res As a result of your work in the future , we may find out that , you know , there 're really s these subtle differences between um even within the domain of entering in the light of a Source - Path - Goal schema , that we need to put in  fill in additional structure up there . But it gives us a nice handle . So with this we can basically um you know s slaughter the cow any anyway we want . Uh . It  it is  It was sort of a  it gave us some headache , how do we avoid writing down that we have sort of the Enter Source - Path - Goal that this  But this sort of gets the job done in that respect and maybe it is even conceptually somewhat adequate in a sense that um we 're talking about two different things . We 're talking more on the sort of intention level , up there , and more on the  this is the  your basic bone um schema , down there .", "topic_id": 2, "keywords": "smartkom, parsing, language, dialogue, remark", "dialogue_id": 15}, {"text": "Uh one question , Robert . When you point at the screen is it your shadow that I 'm supposed to look at ?\nYeah . It 's the shadow .\nOK . Whereas I keep looking where your hand is , and it doesn't\nWell , that wouldn't have helped you at all .\nYeah .\nRight .\nBasically , what this is  is that there 's an interface between what we are doing and the action planner\nSpit right here .\nand right now the way the interface is \" action go \" and then they have the  what the person claimed was the source and the person claimed as the goal passed on .\nMm - hmm .\nAnd the problem is , is that the current system does not distinguish between goes of type \" going into \" , goes of type \" want to go to a place where I can take a picture of \" , et cetera .\nSo this is sort of what it looks like now , some simple \" Go \" action from it  from an object named \" Peter 's Kirche \" of the type \" Church \" to an object named \" Powder - Tower \" of the type \" Tower \" . Right ?\nThis is the uh  what the action planner uses ?\nRight . Currently .\nThis is  OK .\nCurrently .\nAnd is that  and tha that 's changeable ? or not ?\nYeah , well\nLike are we adapting to it ?\nNo .\nOr\nWe  This is the output , sort of , of the natural language understanding ,\nOh , yeah .\nright ?\nUh - huh .\nthe input into the action planning , as it is now .\nMm - hmm . Mm - hmm .\nAnd what we are going to do , we going to  and you can see here , and again for Johno please  please focus the shadow ,\nOK .\num we 're gon uh uh here you have the action and the domain object and w and on  on\nWhat did you think he was doing ?\nI just\nOK , sorry .\nA laser pointer would be most appropriate here I think .\nYeah I  I um have  I have no\nEee .\nRobert likes to be abstract and that 's what I just thought he was doing .\nYou look up here .\nSort of between here and here ,\nOK .\nso as you can see this is on one level and we are going to add another um \" Struct \" , if you want , IE a rich action description on that level .\nMm - hmm .\nSo in the future\nSo it 's just an additional information\nExactly . In the future though , the content of a hypothesis will not only be an object and an  an action and a domain object but an action , a domain object , and a rich action description ,\nRight ? that doesn't hurt the current way . Mm - hmm . Mm - hmm .\nWhich  which we 're abbreviating as \" RAD \" .\nwhich is\nGood .\nRad !\nHmm .\nSo um you had like an action schema and a Source - Path - Goal schema ,\nHmm . Hmm . Mm - hmm .\nright ? So how does this Source - Path - Goal schema fit into the uh action schema ? Like is it one of the tags there ?\nYeah can you go back to that one ?\nSo the Source - Path - Goal schema in this case , I 've  if I understand how we described  we set this up , um cuz we 've been arguing about it all week , but uh we 'll hold the  the  Well in this case it will hold the   I mean the  the features I guess . I 'm not  it 's hard for me to exactly s So basically that will store the  the object that is w the Source will store the object that we 're going from , the Goal will store the  the f\nMm - hmm .\nSo the fillers of the role source .\nwe 'll fill those in fill those roles in , right ?\nOK .\nYeah .\nThe S Action - schemas basically have extra  See we  so those are  schemas exist because in case we need extra information instead of just making it an attribute and which  which is just one thing we  we decided to make it 's own entity so that we could explode it out later on in case there is some structure that  that we need to exploit .\nOK , so th sorry I just don't kn um um um  This is just uh XML mo notational but um the fact that it 's action schema and then sort of slash action schema that 's a whole entit\nThat 's a block , yeah .\nThat 's a block , whereas source is just an attribute ?\nNo , no , no .\nIs that\nSource is just not spelled out here . Source meaning  Source will be uh will have a name , a type , maybe a dimensionality ,\nOh , OK , OK .\nmaybe canonical uh orientation\nUh - huh , uh - huh . OK could it  it could also be blocked out then as\nYeah , the  So\nOK .\nYeah .\ns Source it will be , you know we 'll f we know a lot about sources so we 'll put all of that in Source .\nOK .\nBut it 's independent whether we are using the SPG schema in an Enter , View , or Approach mode , right ?\nMm - hmm .\nThis is just properties of the SPG  schema . We can talk about Paths being the fastest , the quickest , the nicest and so forth , uh or  or  and the Trajector should be coming in there as well .\nOK .\nAnd then G the same about Goals .\nOK . So I guess the question is when you actually fill one of these out , it 'll be under action schema ? Those are  It 's gonna be one  y you 'll pick one of those for\nRight .\nOK these are  this is just a layout of the possible that could go  play that role .\nRight , so the  the  the roles will be filled in with the schema\nHmm ?\nOK , go it . Uh - huh .\nand then what actual a action is chosen is  will be in the  in the action schema section .\nOK . OK . S S OK , so one question . This was  in this case it 's all um clear , sort of obvious , but you can think of the Enter , View and Approach as each having their roles , right ? the  I mean it 's  it 's implicit that the person that 's moving is doing entering viewing and approaching , but you know the usual thing is we have bindings between sort of  they 're sort of like action specific roles and the more general Source - Path - Goal specific roles . So are we worrying about that or not for now ?\nYes , yes . Since you bring it up now , we will worry about it .\nOK .\nTell us more about it .\nOK .\nWhat do you  what do you\nWhat 's that ? Oh I guess it  I  I may be just um reading this and interpreting it into my head in the way that I 've always viewed things\nHmm .\nHmm .\nand  that  that may or may not be what you guys intended . But if it is , then the top block is sort of like um , you know , you have to list exactly what X - schema or in this action schema , there 'll be a certain one , that has its own s structure and maybe it has stuff about that specific to entering or viewing or approaching , but those could include roles like the thing that you 're viewing , the thing that you 're entering , the thing that you 're\nSo very specific role names are \" viewed thing \" , \" entered thing \"\nwhatever , you know , that  which are  think  think of enter , view and approach as frames\nMm - hmm .\nYeah .\nand they have frame - specific parameters and  and roles\nYeah .\nand you can also describe them in a general way as Source - Path - Goal schema and maybe there 's other image schemas that you could you know add after this that you know , how do they work in terms of you know a force dynamics\nMm - hmm . Mm - hmm , Mm - hmm , Mm - hmm .\nor how do they work in f terms of other things . So all of those have um basically f either specific  frame specific roles or more general frame specific roles that might have binding . So the question is are um  how to represent when things are linked in a certain way . So we know for Enter that there 's Container potentially involved\nMm - hmm .\nand it 's not  uh I don't know if you wanna have in the same level as the action schema SPG schema it  it 's somewhere in there that you need to represent that there is some container and the interior of it corresponds to some part of the Source - Path - Goal um you know goal  uh goal I guess in this case .\nMm - hmm .\nSo uh is there an easy way in this notation to show when there 's identity basically between things\nYeah .\nand I di don't know if that 's something we need to invent or you know just\nThe  wa wasn't there supposed to be a link in the\nRight .\nI don't know if this answers your question , I was just staring at this while you were talking , sorry .\nIt 's OK .\nUh a link between the action schema , a field in the s in the schema for the image schemas that would link us to which action schema we were supposed to use so we could\nYeah . Um , well that 's  that 's one  one thing is that we can link up , think also that um we can have one or m as many as we want links from  from the schema up to the s action um description of it .\nHmm .\nBut the notion I got from Nancy 's idea was that we may f find sort of concepts floating around i in the a action description of the action f \" Enter \" frame up there that are , e when you talk about the real world , actually identical to the goal of the  the S Source - Path - Goal schema ,\nExactly . Right , right .\nand do we have means of  of telling it within that a and the answer is absolutely .\nRight .\nThe way  we absolutely have those means that are even part of the M - three - L A API ,\nYeah . Oh great . s Uh - huh .\nmeaning we can reference . So meaning\nGreat . That 's exactly what is necessary .\nYeah . St\nAnd um . This referencing thing however is of temporary nature because sooner or later the W - three - C will be finished with their X - path , uh , um , specification and then it 's going to be even much nicer . Then we have real means of pointing at an individual instantiation of one of our elements here\nMm - hmm .\nand link it to another one , and this not only within a document but also via documents ,\nMm - hmm .\nMm - hmm .\nOK .\nand  and all in a v very easy e homogenous framework .\nSo you know  happen to know how  what  what \" sooner or later \" means like in practice ?\nThat 's but it 's soon .\nOr estimated . OK , OK .\nSo it 's g it 's  the spec is there and it 's gonna part of the M - three - L AP  API filed by the end of this year so that this means we can start using it basically now . But this is a technical detail .\nMm - hmm . So a pointer  a way to really say pointers .\nBasically references from the roles in the schema  the bottom schemas to the action schemas is wha uh I 'm assuming .\nYeah . OK , yeah .\nYeah . Yeah , I mean personally , I 'm looking even more forward to the day when we 're going to have X forms , which l is a form of notation where it allows you to say that if the SPG action up there is Enter , then the goal type can never be a statue .\nOK . Uh - huh . Right .\nMm - hmm .\nSo you have constraints that are dependent on the c actual s specific filler , uh , of some attribute .\nMm - hmm , yeah . W Yeah e exactly . Um , you know this , of course , does not make sense in light of the Statue of Liberty ,\nUh - huh .\nhowever  it is uh you know sort of  these sort of things are imaginable .\nRight .\nTsk . Yeah .\nYeah ?\nS So um , like are you gonna have similar schemas for FM\nOr the Gateway Arch in St .\nYeah .\nLouis . So .\nlike forced motion and caused action and stuff like you have for SPG ?\nYeah .\nAnd if so like can  are you able to enforce that you know if  if it 's  if it 's SPG action then you have that schema , if it 's a forced motion then you have the other schema present in the\nUm we have absolute  No . We have absolutely no means of enforcing that , so it would be considered valid if we have an SPG action \" Enter \" and no SPG schema , but a forced action schema . Could happen .\nWhi - which is not bad , because I mean , that there 's multiple sens I mean that particular case , there 's mult there  there 's a forced side of  of that verb as well .\nHmm . It  maybe it means we had nothing to say about the Source - Path - Goal .\nOK .\nWhat 's also nice , and for a i for me in my mind it 's  it 's crucially necessary , is that we can have multiple schemas and multiple action schemas in parallel .\nRight .\nAnd um we started thinking about going through our bakery questions , so when I say \" is there a bakery here ? \" you know I do ultimately want our module to be able to first of all f tell the rest of the system \" hey this person actually wants to go there \" and \" B \" ,  that person actually wants to buy something to eat there . Nuh ? And if these are two different schemas , IE the Source - Path - Goal schema of getting there and then the buying snacks schema , nuh ?\nWould they both be listed here in\nYes .\nOK . Under so o under action schema there 's a list that can include both  both things .\nRight .\nye Yeah , they they would  both schemas would appear , so what is the uh is  is there a \" buying s snacks \" schema ?\nSnack action .\nThat 's interesting .\nWhat is the uh   have\nWhat ?\nthe buying snack schema ?\nSee .\nBuying   buying his food\nI 'm sure there 's a commercial event schema in there somewhere .\nOop . I  d f\nYeah , a \" commercial event \" or something .\nYeah I  I\nYeah ? So uh   so we would  we would instantiate the SPG schema with a Source - Path - Goal blah - blah - blah\nI see .\nand the buying event you know at which  however that looks like , the place f thing to buy .\nUh - huh . Uh - huh . Interesting . Would you say that the  like  I mean you could have a flat structure and just say these are two independent things , but there 's also this sort of like causal , well , so one is really facilitating the other and it 's part of a compound action of some kind , which has structure .\nYeah . Now it 's technically possible that you can fit schema within schema , and schema within schemata\nuh I  I think that 's nicer for a lot of reasons but might be a pain so uh\num Well , for me it seems that uh  r Yes .\nI mean there are truly times when you have two totally independent goals that they might express at once , but in this case it 's really like there 's a purpo means that you know f for achieving some other purpose .\nWell , if I 'm  if I 'm recipient of such a message and I get a Source - Path - Goal where the goal is a bakery and then I get a commercial action which takes place in a bakery , right ? and  and  and they  they are obviously , via identifiers , identified to be the same thing here .\nUh - huh . Yeah . See that  that bothers me that they 're the same thing .\nNo , no , just the  Yeah ?\nYeah because they 're two different things one of which is l you could think of one a sub you know pru whatever pre - condition for the second .\nYeah , yeah !\nRight . Yeah , yeah . So . So . OK . So there 's like levels of granularity . So uh there 's  there 's um a single event of which they are both a part . And they 're  independently they  they are events which have very different characters as far as Source - Path - Goal whatever .\nMm - hmm , yeah .\nSo when you identify Source - Path - Goal and whatever , there 's gonna to be a desire , whatever , eating , hunger , whatever other frames you have involved , they have to match up in  in nice ways . So it seems like each of them has its own internal structure and mapping to these schemas\nMm - hmm .\nyou know from the other  But you know that 's just  That 's just me .\nWell , I think we 're gonna hit a lot of interesting problems\nLike   I  I\nand as I prefaced it this is the result of one week of arguing  about it\nMm - hmm . Between you guys\nYeah .\nuh\nand um  and so\nOK .\nYeah I mean I  I still am not entirely sure that I really fully grasp the syntax of this .\nWell it 's not  it 's not actually a very  actually , it doesn't actually\nUm it occur  it occurs to me that I mean ne\nYou know , like what  Right . Or the intended interpretation of this .\num well I should have  we should have added an ano an XML example ,\nYeah .\nor some XML examples\nYeah .\nyeah that would be  that would be nice .\nand  and this is on  on a  on  on my list of things until next  next week .\nOK .\nIt 's also a question of the recursiveness and  and a hier hierarchy um in there .\nYeah . Yeah .\nDo we want the schemas just blump blump blump blump ? I mean it 's  if we can actually you know get it so that we can , out of one utterance , activate more than one schema , I mean , then we 're already pretty good ,\nMm - hmm .\nright ?\nWell  well you have to be careful with that uh uh thing because uh  I mean many actions presuppose some  um almost  infinitely many other actions . So if you go to a bakery  you have a general intention of uh not being hungry .\nYeah . Mayb - yeah .\nYou have a specific intentions to cross the traffic light to get there .\nYeah .\nMm - hmm .\nYou have a further specific intentions to left  to lift your right foot\nHmm ?\nand so uh uh I mean y you really have to focus on on  on\nRight .\nand decide the level of  of abstraction that  that you aim at it kind of zero in on that ,\nYeah .\nRight .\nand more or less ignore the rest , unless there is some implications that  that you want to constant draw from  from sub - tasks um that are relevant uh I mean but very difficult .\nM Th The other thing that I just thought of is that you could want to go to the bakery because you 're supposed to meet your friend there or som\nYeah .\nMm - hmm .\nyou know so you  like being able to infer the second thing is very useful and probably often right .\nWell the  the  the utterance was \" is there a bakery around here ? \" ,\nBut having them separate\nnot \" I want to go to a bakery . \"\nWell maybe their friend said they were going to meet them in a bakery around the area .\nRight .\nAnd I 'm , yeah  I 'm  I 'm inventing contexts which are maybe unlikely ,\nRight .\nSure it  OK . Yeah .\nbut yeah I mean like  but it 's still the case that um you could  you could override that default by giving extra information\nMm - hmm , yeah .\nwhich is to me a reason why you would keep the inference of that separate from the knowledge of \" OK they really want to know if there 's a bakery around here \" ,\nYeah .\nwhich is direct .\nWell there  there  there should never be a hard coded uh  shortcut from  the bakery question to the uh double schema thing ,\nRight .\nhow uh  And , as a matter of fact , when I have traveled with my friends we make these  exactly these kinds of appointments .\nMm - hmm .\nWe o o\nMm - hmm .\nYeah . Exactly . It 's  I met someone at the bakery you know in the Victoria Station t you know  train station London before ,\nRight .\nMm - hmm . Yep .\nWell . I have a question about the slot of the SPG action .\nyeah . It 's like\nSo  the Enter - View - Approach the  the  the EVA um , those are fixed slots in this particular action . Every action of this kind will have a choice . Or  or  or  or will it just um uh  is it change\nEvery SPG  every SPG action either is an Enter or a View or an Approach ,\nRight , right .\nMm - hmm .\nright ?\nSo  so I  I mean for  for each particular action that you may want to characterize you would have some number of slots that define uh uh uh you know in some way what this action is all about .\nOK .\nIt can be either A , B or C . Um . So is it a fixed number or  or do you leave it open  it could be between one and fifteen uh  it 's  it 's  it 's flexible .\nUm , the uh  Well , it sort of depends on  on if you actually write down the  the schema then you have to say it 's either one of them or it can be none , or it can be any of them . However the uh  it seems to be sensible to me to r to view them as mutually exclusive um maybe even not .\nJ Do you mean within the Source - Path - Goal actions ?\nuh  ye uh uh b I uh I  u I understand\nYeah .\nThose three ?\nuh but\nAnd um how  how where is the end ? So that 's\nNo , no . There  a a actually by I think my question is simpler than that , um  is  OK , so you have an SPG action and  and it has three different um uh aspects um because you can either enter a building or view it or  or approach it and touch it or something . Um now you define uh another action , it 's  it 's called um uh s S P G - one\nForced action or forced motion . Yeah .\naction a different action . Um and this  uh action - two would have various variable possibilities of interpreting what you would like to do . And  i in  in a way similar to either Enter - View - Approach you may want to send a letter , read a letter , or dictate a letter , let 's say . So , h\nOh the  OK uh maybe I 'd  The uh  These actions  I don't know if I 'm gonna answer your question or not with this , but the categories inside of action schemas , so , SPG action is a category . Real although I think what we 're specifying here is this is a category where the actions \" enter , view and approach \" would fall into because they have a related Source - Path - Goal schema in our tourist domain . Cuz viewing in a tourist domain is going up to it and  or actually going from one place to another to take a picture , in this  in a\nRight . Oh , s so it 's sort of automatic derived fr from the structure that  that is built elsewhere .\nderived I don't know if I u\nThis is a cate this a category structure here ,\nRight .\nright ? Action schema . What are some types of action schemas ? Well one of the types of action schemas is Source - Path - Goal action . And what are some types of that ? And an Enter , a View , an Approach .\nRight .\nHmm .\nThose are all Source - Path - Goal actions .\nInside of Enter there will be roles that can be filled basically . So if I want to go from outside to inside  then you 'd have the roles that need to filled , where you 'd have a Source - Path - Goal set of roles . So you 'd the Source would be outside and Path is to the door or whatever , right ?\nRight .\nSo if you wanted to have a new type of action you 'd create a new type of category . Then this category would  we would put it  or not necessarily  We would put a new action in the m uh in the categories that  in which it has the um  Well , every action has a set of related schemas like Source - Path - Goal or force , whatever , right ?\nMm - hmm .\nRight .\nSo we would put \" write a letter \" in the categories uh that  in which it had  it w had uh schemas u\nThere could be a communication event action or something like that\nExactly .\nMm - hmm .\nSchemas uh that of that type .\nand you could write it .\nAnd then later , you know , there  the  we have a communication event action where we 'd define it down there as\nHmm . So there 's a bit a redundancy , right ? in  in which the things that go into a particular  You have categories at the top under action schema and the things that go under a particular category are um supposed to have a corresponding schema definition for that type . So I guess what 's the function of having it up there too ? I mean I guess I 'm wondering whether  You could just have under action schema you could just sort of say whatever you know it 's gonna be Enter , View or Approach or whatever number of things\nMm - hmm .\nand pos partly because you need to know somewhere that those things fall into some categories . And it may be multiple categories as you say which is um the reason why it gets a little messy\nYeah .\num but if it has  if it 's supposed to be categorized in category X then the corresponding schema X will be among the structures that  that follow .\nRight . Well , this is one of things we were arguing about .\nYeah .\nThat 's like\nth this is  this r\nOK , sorry .\nthis is  this is more  this is probably the way that th that 's the way that seemed more intuitive to Johno I guess\nYou didn't tell me to\nalso for a while  for\nUh - huh . But now you guys have seen the light .\nNo , no , no . Uh we have not  we have not seen the light .\nNo .\nSo .\nThe  the reason  One reason we 're doing it this way is in case there 's extra structure that 's in the Enter action that 's not captured by the schemas ,\nI it 's easy to go back and forth isn't it ? Uh - huh . I agree . Right . Right .\nright ?\nWhich is why I would think you would say Enter and then just say all the things that are relevant specifically to Enter . And then the things that are abstract will be in the abstract things as well . And that 's why the bindings become useful .\nRight , but\nRi - You 'd like  so you 're saying you could practically turn this structure inside out ? or something , or  ?\nUm Ye - I see what you mean by that ,\nNo basically w\nbut I  I don't if I would  I would need to have t have that .\nGet  get rid of the sort of SPG slash something uh or the sub - actions category ,\nRight .\nbecause what does that tell us ?\nUh - huh . Yeah .\nUm and I agree that you know this is something we need to discuss ,\nI in fact what you could say is for Enter ,\nyeah .\nyou could say \" here , list all the kinds of schemas that  on the category that\nList all the parent categories .\nyou know i list all the parent categories \" . It 's just like a frame hierarchy ,\nYeah .\nright ?\nMm - hmm .\nlike you have these blended frames . So you would say enter and you 'd say my parent frames are such - and - such , h and then those are the ones that actually you then actually define and say how the roles bind to your specific roles which will probably be f richer and fuller and have other stuff in there .\nYeah . This sounds like a paper I 've read around here recently in terms of\nYeah it could  be not a coincidence . Like I said , I 'm sure I 'm just hitting everything with a hammer that I developed ,\nYeah .\nbut I mean you know uh it 's  I 'm just telling you what I think , you just hit the button and it 's like\nAnd , I guess fr uh\nYeah I mean but there 's a good question here . Like , I mean uh do you  When do you need  Damn this headset ! When you this uh , eh\nMetacomment .\nYeah .  That 's all recorded . Um . Why do you\n\" Damn this project . \" No just kidding .\nI don't know . Like  How do I  how do I come at this question ? Um . I just don't see why you would  I mean does th Who uses this uh  this data structure ? You know ? Like , do you say \" alright I 'm going to uh   do an SPG action \" . And then you know somebody ne either the computer or the user says \" alright , well , I know I want to do a Source - Path - Goal action so what are my choices among that ? \" And \" oh , OK , so I can do an Enter - View - Approach \" . It 's not like that , right ? It 's more like you say \" I want to , uh   I want to do an Enter . \"\nWell only one of\nAnd then you 're more interested in knowing what the parent categories are of that . Right ? So that the um  the uh sort of representation that you were just talking about seems more relevant to the kinds of things you would have to do ?\nI 'd  I\nHmm .\nI think I 'd  I 'm not sure if I understand your question . Only one of those things are gonna be lit up when we pass this on . So only Enter will be\nOK .\nif we  if our  if our module decided that Enter is the case , View and Approach will not be there .\nOK . OK .\nWell  uh it 's  it sort of came into my mind that sometimes even two could be on , and would be interesting .\nYeah .\num nevertheless um\nMayb - Well maybe I 'm not understanding where this comes from and where this goes to .\nWell in that case , we can't  we can't w if  if\nl let 's  let 's not\nOK .\nwell the thing is if that 's the case we  our  I don't think our system can handle that currently .\nWhat are we doing with this ?\nNo , not at all . But  U s  t So\nIn principle .\n\" Approach and then enter . \"\nthe  I think the  in some sense we  we ex get the task done extremely well\nRun like this uh\nbecause this is exactly the discussion we need  need .\nMm - hmm .\nPeriod . No more qualifiers than that . So .\nNo , this is the useful ,\nand um and  and I th I hope\nyou know , don don't worry .\num uh let 's make a  a  a  a sharper claim . We will not end this discussion anytime soon .\nYeah , I can guarantee that .\nAnd it 's gonna get more and more complex the  the l complexer and larger our domains get .\nSigh .", "topic_id": 3, "keywords": "action, actions, planning, motion, representation", "dialogue_id": 15}, {"text": "And I think um we will have all of our points in writing pretty soon . So this is nice about being being recorded also . The um\nRight .\nThat 's true .\nThe r uh the  in terms of why is  it 's laid out like this versus some other\nthe people\nYeah . Yeah .\num that 's kind of a contentious point between the two of us but  this is one wa so this is a way to link uh the way these roles are filled out to the action .\nIn my view .\nBecause if we know that Enter is a t is an SPG action ,\nMm - hmm .\nright ?\nMm - hmm .\nwe know to look for an SPG schema and put the appropriate  fill in the appropriate roles later on .\nMm - hmm . Yeah .\nAnd you could have also indicated that by saying \" Enter , what are the kinds of action I am ? \"\nMm - hmm , yeah .\nRight .\nYeah .\nRight ? So there 's just like sort of reverse organization , right ? So like unless @ @  Are there reasons why one is better than the other I mean that come from other sources ?\nAgain\nYes because nobod no the modules don't\nYeah . uh\nThis is  this is a schema that defines XML messages that are passed from one module to another ,\nMm - hmm .\nmainly meaning from the natural language understanding , or from the deep language understanding to the action planner .\nMm - hmm .\nNow the  the reason for  for not using this approach is because you always will have to go back , each module will try  have to go back to look up which uh you know entity can have which uh , you know , entity can have which parents , and then  So you always need the whole body of  of y your model um to figure out what belongs to what . Or you always send it along with it ,\nMm - hmm . Mm - hmm .\nnuh ? So you always send up \" here I am  I am this person , and I can have these parents \" in every message .\nMm - hmm .\nwhich e\nOK , so it 's just like a pain to have to send it .\nIt may or may not be a just a pain it 's  it 's  I 'm completely willing to  to  to throw all of this away\nOK , I understand .\nand completely redo it ,\nWell\nyou know and  and  and it after some iterations we may just do that .\nMm - hmm .\nI  I would just like to ask um like , if it could happen for next time , I mean , just beca cuz I 'm new\nMm - hmm .\nand I don't really just  I just don't know what to make of this and what this is for , and stuff like that , you know , so if someone could make an example of what would actually be in it ,\nYeah .\nlike first of all what modules are talking to each other using this ,\nYeah , we  I will promise for the next time to have fleshed out N  XML examples for a  a run through and  and see how this  this then translates ,\nright ? And  OK .\nand how this can come about ,\nBe great .\nnuh ? including the sort of \" miracle occurs here \" um part .\nRight .\nAnd um is there more to be said ? I think um  In principle what I  I think that this approach does , and e e whether or not we take the Enter - View and we all throw up  up the ladder um wha how do how does Professor Peter call that ?\nYeah .\nThe uh hhh ,  silence su sublimination ? Throwing somebody up the stairs ? Have you never read the Peter 's Principle anyone here ?\nNope .\nOh , uh\nPeople reach their level of uh max their level of  at which they 're incompetent or whatever .\nYeah .\nMaximum incompetence\nYeah . Right , right .\nand then you can throw them up the stairs\nAlright .\nOh !\num . Yeah .\nPromote them , yeah .\nOK , so we can promote Enter - View all  all up a bit and and get rid of the uh blah - blah - X - blah uh asterisk sub - action item altogether . No  no problem with that\nOK .\nand we  w we  we will play around with all of them but the principal distinction between having the  the pure schema and their instantiations on the one hand , and adding some whatever , more intention oriented specification um on parallel to that  that  this approach seems to be uh workable to me . I don't know . If you all share that opinion then that made my day much happier .\nThis is a simple way to basically link uh roles to actions .\nUh yeah wait  R Yeah , yeah . That 's fine .\nThat 's the  that was the intent of  of it , basically .\nSure . Sure .\nUh that 's true .\nYeah .\nAlthough um roles\nSo I  I do I 'm  I 'm not\nI 'm  I 'm never happy when he uses the word \" roles \" ,\nYeah I  I\nI 'm\nYeah . I was going to\nI b I mean ROLLS so\nBread rolls ?\nOh you meant pastries , then ?\nYeah , pastries is what I 'm talking about .\nPastry oh ba oh the bak bakery example .\nBakery . Bakery .\nThis is the bakery example . Got it . Alright .\nI see . Right . OK .\nHelp !\nI guess I 'll agree to that , then .\nOK . That 's all I have for today . Oh no , there 's one more issue . Bhaskara brought that one up . Meeting time rescheduling .", "topic_id": 4, "keywords": "actions, schema, action, roles, intention", "dialogue_id": 15}, {"text": "I n Didn't you say something about Friday ,\nYeah .\nor  ? Hmm .\nSo it looks like you have not been partaking , the Monday at three o ' clock time has turned out to be not good anymore . So people have been thinking about an alternative time and the one we came up with is Friday two - thirty ? three ? What was it ?\nYou have class until two , right ? so if we don't want him  if we don't want him to run over here\nMm - hmm .\nTwo - th Two - thirty - ish or three or Friday at three or something around that time .\nSo do I . Yeah .\ntwo thirty - ish or three is\nMm - hmm .\nYeah . Yeah . e\nUm how  how are your\nThat would be good .\nuh Friday uh Yeah , that 's fine .\nAnd I know that you have until three  You 're busy ?\nUh\nYeah .\nYeah .\nSo three is  sounds good ?\nYeah .\nI 'll be free by then .\nI could do that . Yeah I mean earlier on Friday is better but three  you know I mean  if it were a three or a three thirty time then I would take the three or whatever ,\nMm - hmm .\nbut yeah sure three is fine .\nYeah , and you can always make it shortly after three probably .\nI mean .\nYeah , and I don't need to be here particularly deeply .\nOften , no , but uh ,\nYeah .\nwhenever .\nBut yeah .\nYou are more than welcome if you think that this kind of discussion gets you anywhere in  in your life then uh you 're free to c\nIt 's fascinating .\n\" That 's the right answer . \"\nI 'm just glad that I don't have to work it out\nbecause .\nYeah .\nHmm ?\nI 'm just glad that don't have to work it out myself , that I 'm not involved at all in the working out of it because .\nUh but you 're a linguist .\nYeah .\nYou should\nOh yeah . That 's why I 'm glad that I 'm not involved in working it out .\nOK .\nSo it 's at Friday at three ? there that 's\nAnd um\nSo already again this week ,\nHow diligent do we feel ?\nhuh ?\nYeah . Do feel that we have done our chores for this week or\nYeah . So I mean clearly there 's  I can talk about the um the parser changes on Friday at least ,\nOK , Bhaskara will do the big show on Friday .\nso .\nAnd you guys will argue some more ?\nAnd between now and then yeah .\nYeah . Between now and then .\nand have some ?\nWe will  r\nPromise ?\nprobably .\nYeah .\nWe will . Don't worry .\nYeah .\nYeah .\nAnd we 'll get the summary like , this  the c you know , short version , like\nAn - and I would like to second Keith 's request .\nS\nAn example wo would be nice t to have kind of a detailed example .\nYes .\nYeah .\nYes . I 've  I 've  I 've  I guess I 'm on record for promising that now .\nOK .\nSo um\nLike have it  we 'll have it in writing . So . or , better , speech . So .\nThis is it and um\nThe other good thing about it is Jerry can be on here on Friday and he can weigh in as well .\nYeah . and um if you can get that binding point also maybe with a nice example that would be helpful for Johno and me .\nOh yeah uh OK . let 's uh yeah they 're\nGive us\nNo problem ,\nI think you 've got one on hand ,\nyeah .\nhuh ?\nI have several in my head , yeah . Always thinking about binding .\nWell the  the  the binding is technically no problem but it 's  it  for me it seems to be conceptually important that we find out if we can s if  if there  if there are things in there that are sort of a general nature , we should distill them out and put them where the schemas are .\nMm - hmm .\nIf there are things that you know are intention - specific , then we should put them up somewhere , a\nSo , in general they 'll be bindings across both intentions and the actions .\nYep . That 's wonderful .\nSo  Yeah . So it 's gen it 's general across all of these things\nYeah .\nit 's like  I mean Shastri would say you know binding is like  an essential cognitive uh process . So .  Um .\nOK .\nSo I don't think it will be isolated to one or the two , but you can definitely figure out where  Yeah , sometimes things belong and  So actually I 'm not sure  I would be curious to see how separate the intention part and the action part are in the system . Like I know the whole thing is like intention lattice , or something like that ,\nMm - hmm .\nright ? So is the ri right now are the ideas the rich  rich the RAD or whatever is one you know potential block inside intention . It 's still  it 's still mainly intention hypothesis\nYeah . Yeah .\nand then that 's just one way to describe the  the action part of it .\nYeah .\nOK .\nIt 's an a attempt to refine it basically .\nIt 's  And yeah ,\nOK , great uh - huh .\nit 's an  an  it 's  it 's sort of\nNot just that you want to go from here to here , it 's that the action is what you intend\nYeah .\nand this action consists of all com complicated modules and image schemas and whatever .\nYeah . And  and there will be a  a  a relatively high level of redundancy\nSo .\nin the sense that um ultimately one\nMm - hmm . which is , yeah , It 's fine\nso th so that if we want to get really cocky we we will say \" well if you really look at it , you just need our RAD . \" You can throw the rest away , right ?\nMm - hmm .\nBecause you 're not gonna get anymore information out of the action a as you find it there in the domain object .\nRight . Right . Mm - hmm .\nBut then again um in this case , the domain object may contain information that we don't really care about either . So .\nMm - hmm .\nH But w we 'll see that then , and how  how it sort of evolves .\nMm - hmm .\nI mean if  if people really like our  our RAD , I mean w what might happen is that they will get rid of that action thing completely , you know , and leave it up for us to get the parser input um\nMmm . We know the things that make use of this thing so that we can just change them so that they make use of RAD .\nYeah . Yeah .\nYou don't have to use the acronym .\nI can't believe we 're using this term . So I 'm like RAD ! Like every time I say it , it 's horrible . OK .\nMm - hmm .\nI see what you mean .\nRAD 's a great term .\nIs the  But what is the \" why \" ?\nIt 's rad , even !\nWhy ?\nWhy ?\nIt happened to c be what it stands for .\nIt just happened to be the acronym .\nWell\nYeah . That 's  doesn't make it a great term . It 's just like those jokes where you have to work on both levels .\nye no but i\nJust think of it as  as \" wheel \" in German .\nbut if you  if you  if you work in th in that XML community it is a great acronym\nDo you see what I mean ? Like\nbecause it e evokes whatever RDF\nOh .\nRDF is the biggest thing right ? That 's the rich  sort of \" Resource Description Framework \"\nOh \" rich de \"\nOh .\nand um  and also  So , description , having the word d term \" description \" in there is wonderful ,\nMm - hmm .\nuh \" rich \" is also great , rwww .\nHmm .\nWho doesn't like to be a\nEverybody likes action .\nOh .\nYeah .\nYeah . OK .\nPlus it 's hip . The kids 'll like it .\nBut what if it 's not an action ?\nIt 's  it 's rad ,\nYeah all the kids 'll love it .\nHmm .\nyeah .\nAnd intentions will be \" RID \" ? Like , \" OK \" . Um are the  are the sample data that you guys showed sometime ago  like the things  maybe  maybe you 're gonna run a trial tomorrow . I mean , I 'm just wondering whether the ac some the actual sentences from this domain will be available . Cuz it 'd be nice for me to like look if I 'm thinking about examples I 'm mostly looking at child language which you know will have some overlap but not total with the kinds of things that you guys are getting . So you showed some in this  here before\nMm - hmm .\nand maybe you 've posted it before but where would I look if I want to see ?\nOh I  You want audio ?\nYou know .\nor do you want transcript ?\nNo just  just transcript .\nYeah , well just transcript is just not available because nobody has transcribed it yet .\nSorry .\nUm I can e I can uh I 'll transcribe it though .\nOh , OK . I take that back then .\nIt 's no problem .\nOK , well don't  don't make it a high priority\nYeah .\nI  In fact if you just tell me like you know like two examples\nMm - hmm .\nI mean , y The  the  the representational problems are  I 'm sure , will be there ,", "topic_id": 5, "keywords": "friday, chores, clock, thinking, sentences", "dialogue_id": 15}, {"text": "OK .\nlike enough for me to think about . So .\nOK , so Friday , whoever wants and comes , and can .\nOK .\nOK .\nThis Friday .\nHere . OK .\nThe big parser show . Now you can all turn off your", "topic_id": 6, "keywords": "parser, friday, comes, ok, turn", "dialogue_id": 15}, {"text": "Yeah .\nUm , so . If we can't , we can't . But uh we 're gonna try to make this an abbreviated meeting cuz the  the next  next occupants were pushing for it , so . Um . So . Agenda is  according to this , is transcription status , DARPA demos XML tools , disks , backups , et cetera and\nDoes anyone have anything to  add to the agenda ?\nOK . Should we just go in order ? Transcription status ? Who 's  that 's probably you .\nI can do that quickly . Um I hired several more transcribers , They 're making great progress .\nSeven ?\nSeve - several , several .\nOh .\nAnd uh  and uh , uh I 've been uh finishing up the uh double checking . I hoped to have had that done by today but it 's gonna take one more week .\nUm\nI g\nas a somewhat segue into the next topic , um could I get a hold of uh the data even if it 's not really corrected yet just so I can get the data formats and make sure the information retrieval stuff is working ?\nCertainly . Yeah I mean , it 's in the same place it 's been .\nSo can you just  Oh , it is .\nUh - huh . No change .\nOK . Just  So , \" transcripts \" is the sub - directory ?\nUh  Yes . Uh - huh .\nOK . So I 'll  I 'll probably just make some copies of those rather than use the ones that are there .\nOK .\nUm and then just  we 'll have to remember to delete them once the corrections are made .\nOK .\nOK , wh\nI also got anot a short remark to the transcription . I 've uh just processed the first five EDU meetings and they are chunked up so they would  they probably can be sent to IBM whenever they want them .\nCool .\nWell the second one of those\nYep . It 's already at IBM ,\nis already at IBM .\nbut the other ones\nThat 's the one that  we 're waiting to hear from them on .\nYeah . Yeah .\nOK .\nYeah .\nThese are separate from the ones that\nAs soon as\nI mean , these are\nThey 're the IBM set .\nYep .\nIt 's this one .\nExcellent . Good .\nYeah . And so as soon as we hear from Brian that this one is OK\nIs my mike on ? Yeah .\nand we get the transcript back and we find out that hopefully there are no problems matching up the transcript with what we gave them , then uh we 'll be ready to go and we 'll just send them the next four as a big batch ,\nExcellent .\nand let them work on that .\nAnd so we 're doing those as disjoint from the ones we 're transcribing here ?\nYes , exactly .\nOK , good .\nWe 're sort of doing things in parallel , that way we can get as much done a at once .\nYeah , I think that 's the right way to do it ,\nYeah .\nespecially for the information retrieval stuff . Anything else on transcription status ?\nHm - mmm .\nOK .\nDARPA demos , we had the submeeting the other day .", "topic_id": 0, "keywords": "agenda, progress, transcribers, transcripts, transcript", "dialogue_id": 16}, {"text": "Right , which uh  So I 've been working on using the THISL tools to do information retrieval on meeting data and the THISL tools are  there 're two sets , there 's a back - end and a front - end , so the front - end is the user interface and the back - end is the indexing tool and the querying tool . And so I 've written some tools to convert everything into the right for file formats . And the command line version of the indexing and the querying is now working . So at least on the one meeting that I had the transcript for uh conveniently you can now do information retrieval on it , do  type in a  a string and get back a list of start - end times for the meeting ,\nWhat  what kind of uh  what does that look like ? The string that you type in .\nuh of hits .\nWhat are you  are you  are they keywords , or are they  ?\nKeywords .\nOK . I see .\nRight ? And so  and then it munges it to pass it to the THISL IR which uses an SGML - like format for everything .\nI see .\nAnd then does it play something back or that 's something you 're having to program ?\nUm , right now , I have a tool that will do that on a command line using our standard tools ,\nYeah .\nbut my intention is to do a prettier user interface based either  So  so that 's the other thing I wanted to discuss , is well what should we do for the user interface ? We have two tools that have already been written . Um the SoftSound guys did a web - based one ,\nMm - hmm .\num , which I haven't used , haven't looked at . Dan says it 's pretty good\nMm - hmm .\nbut it does mean you need to be running a web server .\nMm - hmm .\nAnd so it  it 's pretty big and complex . Uh and it would be difficult to port to Windows because it means porting the web server to Windows .\nMm - hmm .\nUh the other option is Dan did the Tcl - TK THISL GUI front - end for Broadcast News\nYeah .\nwhich I think looks great . I think that 's a nice demo . Um and that would be much easier to port to Windows . And so I think that 's the way we should go .\nI  Can I ask a question ? So um as it stands within the  the Channeltrans interface , it 's possible to do a find and a play .\nMm - hmm .\nYou can find a searched string and play . So e Are you  So you 're adding like um , I don't know , uh are they fuzzy matches or are they  uh  ?\nIt 's a sort of standard , text - retrieval - based  So it 's uh term frequency , inverse document frequency scoring .\nOK .\nUm and then there are all sorts of metrics for spacing how far apart they have to be and things like that . So it  it 's\nIt 's a lot more sophisticated than the uh the basically Windows - based\ni it 's like doing a Google query or anyth anything else like that .\nOK .\nSo i it uses  So it pr produces an index ahead of time so you don't  you 're not doing a linear search through all the documents . Cuz you can imagine if  with  if we have the sixty hours ' worth you do  wouldn't wanna do a search .\nHm - mmm . Good .\nUm you have to do preindexing and so that  these tools do all that . And so the work to get the front - end to work would be porting it  well  uh to get it to work on the UNIX systems , our side is just rewriting them and modifying them to work for meetings .\nMm - hmm .\nSo that it understands that they 're different speakers and that it 's one big audio file instead of a bunch of little ones and just sorta things like that .\nMm - hmm .\nMm - hmm .\nSo what does the user see as the result of the query ?\nOn which tool ?\nTHISL .\nThe THISL GUI tool which is the one that Dan wrote , Tcl - TK\nYeah .\num you type in a query and then you get back a list of hits and you can type on them and listen to them . Click on them rather  with a mouse .\nAh .\nMmm\nSo if you typed in \" small heads \" or something you could\nRight , you 'd get\nget back a uh uh  something that would let you click and listen to some audio where that phrase had occurred\nsomething  You  you 'd get to listen to \" beep \" .\nor some\nThat was a really good look . It 's too bad that that couldn't  come into the\nYou couldn't get a video .\nGuess who I practice on ?\nAt some point we 're gonna have to say what that private joke is , that keeps coming up .\nYeah . And then again , maybe not . So ,  uh  Yeah , that soun that sounds reasonable . Yeah , it loo it  my  my recollection of it is it 's  it 's a pretty reasonable uh demo sort of format .\nRight .\nYeah that sounds good .\nAnd so I think there 'd be minimal effort to get it to work , minimally\nThat sounds really neat .\nand then we 'd wanna add things like query by speaker and by meeting and all that sort of stuff . Um Dave Gelbart expressed some interest in working on that so I 'll work with him on it . And it  it 's looking pretty good , you know , the fact that I got the query system working . So if we wanna just do a video - based one I think that 'll be easy .\nMm - hmm .\nIf we wanna get it to Windows it 's gonna be a little more work because the THISL IR , the information retrieval tool 's  um , I had difficulty just compiling them on Solaris .\nMm - hmm .\nSo getting them to compile on Windows might be challenging .\nMm - hmm .\nBut you were saying that  that the uh  that there 's that set of tools , uh , Cygnus tools , that\nSo . It certainly helps .\nUh - huh .\nUm , I mean without those I wouldn't even attempt it .\nMm - hmm .\nYeah .\nBut what those  they  what those do is provide sort of a BSD compatibility layer ,\nMm - hmm .\nso that the normal UNIX function calls all work .\nMm - hmm .\nAnd you have to have all the o\nUm , But the problem is that  that the THISL tools didn't use anything like Autoconf and so you have the normal porting problems of different header files and th some things are defined and some things aren't and uh different compiler work - arounds and so on . So the fact that um it took me a day to get it c to compile under Solaris means it 's probably gonna take me s significantly more than that to get it to compile under Windows .\nHow about having it run under free BSD ?\nWell what you need\nFree BSD would probably be easier .\nAll you need to do is say to Dan \" gee it would be nice if this worked under Autoconf \" and it 'll be done in a day .\nThat 's true .\nUh\nRight ?\nActually you know I should check because he did port it to SPRACHcore\nRight .\nso he might have done that already .\nI  I  I wouldn't be surprised .\nSo\nI 'll check at that\nBut it would  what would serve  would serve both purposes , is if you contact him and ask him if he 's already done it .\nWhat I\nHow does it play ?\nYeah , right .\nIf he has then you learn , if he hasn't then he 'll do it .\nRight .\nWow .\nI hope he never listens to these meetings .\nThat 's right . So , and I 've been corresponding with Dan and also with uh uh , SoftSound guy , uh\nIt 's amazing .\nYeah .\nBlanking on his name .\nTony Robinson ?\nTony Robinson ?\nDo I mean Tony ? I guess I do .\nYeah .\nJames Christie .\nOr S or Steve Renals .\nSteve Renal - Steve Renals .\nWhich one do I mean ?\nSteve Renals is not SoftSound , is he ?\nNo .\nMy brain is not working ,\nOK .\nI don't remember who I 've been corresponding with .\nSteve wro i it 's Ste - Steve Renals wrote THISL IR .\nThen it 's Steve Renals .\nOh , OK .\nOK .\nSo uh just getting documentation and uh and f and formats ,\nYeah .\nso that 's all going pretty well ,\nAssuming we 're\nRight .\nWhat about issues of playing sound files @ @ between the two platforms ?\nI think we 'll be OK with that . Um we have  Well , that 's a good point too .\nHere 's a  here 's a crazy idea  actually .\nI don't know .\nWhy don't you try and merge  Transcriber  and THISL IR ? They 're both Tcl interfaces .\nWell this is one of the reasons  This is the  one of the reasons that I 'm gonna have uh Dave Gelbart  Gelbart  Having him volunteer to work on it is a really good thing because he 's worked on the Transcriber stuff\nRight .\nand he 's more familiar with Tcl - TK than I am .\nAnd then you get  they  then you get the Windows media playing for free .\nWell that 's Snack , not  not Transcriber .\nRight . But the point is that the Transcriber uses Snack and then you can  but you can use a  a lot of the same functionality and it 's\nYeah , yeah , I mean , I  I think THISL  THISL GUI probably uses Snack . And so my intention was just to base it on that .\nYeah . Well my thought was is that it would be nice  it would be nice to have the running transcripts um eh you know , from speaker to speaker .\nAnd if it doesn't\nRight ? Do you have  you have , you know , a speaker mark here and a speaker mark here ?\nRight , we 'll have to figure out a user interface for that , so .\nRight . Well that  eh my thought was if you had like Multitrans or whatever do it . Or whatever .\nYeah . It might be fairly difficult to get that to work in  the little short segments we 'd be talking about and having the search tools and so on . We  we can look into it ,\nYeah .\nbut\nThe thing I was asking about with , um , free BSD is that it might be easier to get PowerPoint shows running in free BSD than to get this other package running in\nYeah , I mean we have to  I have to sit down and try it before I make too many judgments ,\nYeah .\nso uh Um My experience with the Gnu compatibility library is really it 's just as hard and just as easy to port to any system . Right ? The Windows system isn't any harder because it  it looks like a BSD system .\nMm - hmm .\nIt 's just , you know , just like all of them , the \" include \" files are a little different and the function calls are a little different .\nRight .\nSo I  it might be a little easier but it 's not gonna be a lot easier .\nOK . So there was that demo , which was one of the main ones , then we talked about um some other stuff which would basically be um showing off the  the Transcriber interface itself and as you say , maybe we could even merge those in some sense , but  but um , uh  and part of that was showing off what the speech - non uh nonspeech  stuff that Thilo has done  s  looks like .\nYeah .\nCan I ask one more thing about THISL ? So with the IR stuff then you end up with a somewhat prioritized um  ?\nMm - hmm . Mm - hmm ,\nExcellent .\nranked .\nExcellent . Yeah .\nSo another idea I w t had just now actually for the demo was whether it might be of interest to sh to show some of the prosody uh  work that Don 's been doing .\nMm - hmm .\nUm actually show some of the features and then show for instance a task like finding sentence boundaries or finding turn boundaries . Um , you know , you can show that graphically , sort of what the features are doing . It , you know , it doesn't work great but it 's definitely giving us something .\nWell I think at  at the very least we 're gonna want something illustrative with that\nI don't know if that would be of interest or not .\ncuz I 'm gonna want to talk about it and so i if there 's something that shows it graphically it 's much better than me just having a bullet point\nYeah .\npointing at something I don't know much about ,\nI mean , you 're looking at this now\nso .\nAre you looking at Waves or Matlab ?\nUm yeah I 'm starting to and um  Yeah we can probably find some examples of different type of prosodic events going on .\nYeah def\nS so when we here were having this demo meeting , what we 're sort of coming up with is that we wanna have all these pieces together , to first order , by the end of the month\nI\nand then that 'll give us a week or so .\nOoo . The end of\nOh , the end of this month or next month ? Oh , you mean like today ?\nThis month .\nJu\nOh .\nJune . June . June .\nNext month .\nOh sorry , next month .\nYeah .\nSorry .\nToday isn't June first ,\nThere 's another one .\nis it .\nUh  that 'll  that 'll give us  that 'll give us a week or so to uh  to port things over to my laptop and make sure that works ,\nExactly .\nSorry .\nyeah .\nI think , I mean eh where\nYeah , I mean I 'll be here .\nYeah if d if Don can sort of talk to whoever 's\nYeah .\ncuz we 're doing this anyway as part of our  you know , the research , visualizing what these features are doing\nYeah .\nand so either  it might not be integrated but it  it could potentially be in it .\nYeah . Well , this is to an audience of researchers\nCould find some .\nso I mean , you know , to let s the goal is to let them know what it is we 're doing .\nI mean it 's different .\nSo that 's\nI don't think anyone has done this on meeting data so it might be neat , you know .\nYeah . Good . Done with that . XML tools ?", "topic_id": 1, "keywords": "querying, retrieval, indexing, formats, unix", "dialogue_id": 16}, {"text": "Um . So I 've been doing a bunch of XML tools where you  we 're sort of moving to XML as the general format for everything and I think that 's definitely the right way to go because there are a lot of tools that let you do extraction and reformatting of XML tools . Um . So yet again we should probably meet to talk about transcription formats in XML because I 'm not particularly happy with what we have now . I mean it works with Transcriber but it  it 's a pain to use it in other tools uh because it doesn't mark start and end .\nStart and end of each  ?\nYeah .\nUh  Utterance .\nUtterance . Just marks  ?\nSo it 's implicit in  in there\nYeah .\nbut you have to do a lot of processing to get it .\nRight . Right .\nAnd so  and also I 'd like to do the indirect time line business . Um but regardless , I mean , w that 's something that you , me , and Jane can talk about later . Um , but I 've installed XML tools of various sorts in various languages and so if people are interested in doing  extracting any information from any of these files , either uh information on users because the user database is that way  I 'm converting the Key files to XML so that you can extract m uh various inf uh sorted information on individual meetings\nCool .\nYeah .\nand then also the transcripts . And so l just let me know there  it 's mostly Java and Perl but we can get other languages too if  if that 's desirable .\nOh , quick question on that . Is  do we have the   the seat information ? In  in the Key files now ?\nMm - hmm .\nThe seat information is on the Key files for the ones which\nAh .\nOh in  For the new one\nit 's been recorded ,\nOK .\nyeah .\nSeat ?\nGreat . Sea - yeah .\nWhere  where you 're sitting .\nOh ! Not  not the quality or anything . No .\nn\nRight .\nOK . I see .\n\" It 's pretty soft and squishy . \"\nYeah . Yeah .\nAlright .\nOK .\nOK .\nOh , but that might just be me . Um .\nAlright .\nThat 's more seat information than we wanted .\nNever mind .\nHmm .\nI 'm just trying to figure out , you know , when Morgan 's voice appears on someone 's microphone are they next to him or are they across from him ?\nYeah .\nMaybe we should bleep that out .\nMmm , yeah .\nWait a minute ,\nYeah .\nhow  how w eh where is it in the Key file ?\nRight . The square bracket .\nCuz I mean I haven't been putting it in and  in by\nYou haven't been putting it in .\nRight .\nWell bu\nI have not .\nOh , OK .\nIsn't it always on the digits ?\nSome of these are missing .\nAnd\nAren't they ?\nIsn't it always on the digits forms ?\nSome fall out of\nWell it\nYeah so we can go back and fill them in for the ones we have .\nOoo .\nI mean they 're on th right , these , but I just hadn't ever been putting it in the Key files .\nYeah I  I never\nAnd I don't think Chuck was either\nI never knew we were supposed to put it in the Key file .\ncuz\nI had told you guys about it\nOh really ?\nOh , so we 're both sorry .\nbut\nSo\nI mean this is why I wanna use a g a tool to do it rather than the plain text\nOK .\nOK .\nbecause with the plain text it 's very easy to skip those things .\nOK .\nSo . Um if you use the Edit - key , or Key - edit\nEdit - key .\nI think it 's Edit - key ,  command  Did I show you guys that ?\nYep .\nYou mentioned it ,\nI did show it to you ,\nyeah . Yeah .\nbut I think you both said \" no , you 'll just use text file \" .\nText .\nUm it has it in there , a place to fill it in .\nOK .\nOK .\nYeah , and so if you don't fill it in , you 're not gonna get it in the meetings .\nSo if  Right . Well I  I just realized I hadn't been doing it\nSo .\nand probably  So\nYep .\nu\nYeah and then the other thing also that Thilo noticed is , on the microphone , on channel zero it says hand - held mike or Crown mike ,\nYeah . Right .\nyou actually have to say which one .\nI know  Yeah , I usually delete the\nSo .\nOh ! OK . I didn't do that either .\nI don't ,\nYeah .\nmaybe I forgot to d\nTakes me no time at all to edit these .\nBut it 's almost  Yeah .\nYeah that 's cuz you kn\nI 'm not doing anything .\nI  I know why .\nAnd I was  I was looking at Chuck 's , like , \" oh what did Chuck do , OK I 'll do that \" . So .\nAnd then uh also in a couple of places instead of filling the participants under \" participants \" they were filled in under \" description \" .\nAh , OK .\nUh\nAnd so that 's also a problem . So anyway .\nWe will do better .\nThat 's it . Oh uh also I 'm working on another version of this tool , the  the one that shows up here ,  that will flash yellow if the mike isn't connected . And it 's not quite ready to go yet because um it 's hard to tell whether the mike 's connected or not because the best quality ones , the Crown ones ,  are about the same level if they 're off and no one 's o off or if they 're on and no one 's talking .\nHuh .\nUm these  these ones , they are much easier , there 's a bigger difference . So I 'm working on that and it  it sorta works and so eventually we will change to that and then you 'll be able to see graphically if your mike is dropping in or out .\nWill that also include like batteries dying ? Just a any time the mike 's putting out zeros basically .\nYep . Yep . Yep .\nBut with the screensaver kicking in , it\nBut\nNow\ny yeah .\nYeah .\nYeah .\nWell I 'll turn off the screensaver too .\nOops . Speaking of which .\nUm the other thing is as I 've said before , it is actually on the thing . There 's a little level meter but of course no one ever pays attention to it . So I think having it on the screen is more easy to notice .\nIt would be nice if  if these had little light indicators , little L E Ds for\nUh buzzer .\nYeah , a buzzer .\n\" Bamp , bamp ! \"\nSmall shocks\nYeah . Actually\nadministered to the  OK . Oh", "topic_id": 2, "keywords": "xml, transcription, transcriber, formats, transcripts", "dialogue_id": 16}, {"text": "OK , disk backup , et cetera ? Um I spoke with Dave Johnson about putting all the Meeting Recorder stuff on non - backed - up disk to save the overhead of backup and he pretty much said \" yeah , you could do that if you want \" but he thought it was a bad idea . In fact what he said is doing the manual one ,  doing uh NW archive to copy it  is a good idea and we should do that and have it backed up . He w he 's a firm believer in  in lots of different modalities of backup . I mean , his point was well taken . This data cannot be recovered .\nYeah .\nAnd so if a mistake is made and we lose the backup we should have the archive and if then a mistake is made and we lose the archive we should have the backup .\nWell I guess it is true that even with something that 's backed up it 's not gonna  if it 's stationary it 's not going to go through the increment it 's not gonna burden things in the incremental backups .\nJust  just the monthly full .\nHmm .\nYeah , so the monthly full will be a bear but\nYeah . But he said that  that we sh shouldn't worry too much about that , that we 're getting a new backup system and we 're far enough away from saturation on full backups that it 's w probably OK .\nReally ?\nAnd uh , so the only issue here is the timing between getting more disks and uh recording meetings .\nSo I guess the idea is that we would be reserving the non - backed - up space for things that took less than twenty - four hours to recreate or something like that , right ?\nThings that are recreatable easily and also  Yeah , basically things that are recreatable .\nYeah . Yeah .\nThe expanded files and things like that .\nOK .\nThey take up a lot more room anyway .\nYeah .\nUh but we do need more disk .\nSo we can get more disk . Yeah . So .\nYeah . And I  I think I agree with him . I mean his point was well taken that if we lose one of these we cannot get it back .\nOK .\nI don't think there was any other et cetera there .\nWell I was allowing someone else to come up with something related that they had uh\nI thought you guys were gonna burn C Ds ?\nUm unfortunately  we could burn C Ds but first of all it 's a pain .\nYeah .\nBecause you have to copy it down to the PC and then burn it and that 's a multi - step procedure . And second of all the  the write - once burners as opposed to a professional press don't last .\nYeah .\nSo I think burning them for distribution is fine but burning them for backup is not a good idea .\nI see . OK .\nCuz th they  they fail after a couple years .\nAlright .\nI do have uh uh  It 's a different topic . Can I add one top topic ? We have time ? I wanted to ask , I know that uh that Thilo you were , um , bringing the Channeltrans interface onto the Windows machine ? And I wanted to know is th\nYeah it 's  it  Basically it 's done ,\nIt 's all done ? That 's g wonderful . Great .\nyeah . Yeah .\nYes , since Tcl - TK runs on it , basically things 'll just work .\nYeah it  Yeah , it was just a problem with the Snack version and the Transcriber version but it 's solved .\nDoes  and that  does that mean , I\nSo .\nmaybe I should know this but I don't . Does this mean that the  that this could be por uh ported to a Think - Pad note or some other type of uh\nYeah , basically uh I did install it on my laptop and yeah\nWonderful .\nit worked .\nWonderful .\nHmm ! Good . CrossPads ? CrossPads ?\nUh got an email from uh James Landay who basically said \" if you 're not using them , could you return them ? \" So he said he doesn't need them , he just periodically w at the end of each term sends out email to everyone who was recorded as having them and asks them if they 're still using them .\nSo we 've never used them .\nWe used them once .\nOnce ?\nWe  we used them a couple times ,\nMm - hmm . Couple times .\nThem ? There 's more than one ?\nbut\nYeah .\ni\nYeah , we have two . Um .\nBut\nMy opinion on it is , first , I never take notes anyway so I 'm not gonna use it , um and second , it 's another level of infrastructure that we have to deal with .\nAnd I have  uh so my  my feeling on it is that I think in principle it 's a really nice idea , and you have the time tags which makes it better tha than just taking ra raw notes . On the other hand , I  the down side for me was that I think the pen is really noisy . So you have ka kaplunk , kaplunk , kaplunk . And I  and I don't know if it 's audible on the  but I  I sort of thought that was a disadvantage . I do take notes , I mean , I could be taking notes on these things and I guess the plus with the CrossPads would be the time markings but  I don't know .\nUh , what is a CrossPad ?\nSo it 's  it 's um  it 's a regular pad , just a regular pad of paper but there 's this pen which indicates position .\nThank you .\nAnd so you have time and position stuff stored\nOK .\nso that you can  you have a record of whatever it is you 've written .\nOK .\nAnd then you can download it and they have OCR and searching and all sorts of things .\nOK . OK .\nSo i if you take notes it 's a great little device .\nCould  Mm - hmm .\nBut I don't take notes ,\nAnd one of the reasons that it was brought up originally was because uh we were interested in  in higher - level things ,\nso .\nnot just the , you know , microphone stuff but also summarization and so forth and the question is if you were going to go to some gold standard of what wa what was it that happened in the meeting you know , where would it come from ? And um I think that was one of the things ,\nYeah .\nYeah .\nYep .\nright ? And so the  it seemed like a neat idea . We 'll have a  you know , have a scribe , have somebody uh take good notes and then that 's part of the record of the meeting . And then we did it once or twice and we sort of\nYep , and then just sort of died out .\nprobably chose the wrong scribe but it was   It 's uh\nI mean\nYeah that 's right .\nWell I did it one time\nYep .\nbut um\nYeah .\nu but I guess the  the other thing I 'm thinking is if we wanted that kind of thing I wonder if we 'd lose that much by having someone be a scribe by listening to the tape , to the recording afterwards and taking notes in some other interface .\nI mean we 're transcribing it anyways , why do we need notes ?\nOh it 's la it 's useful ,\nBecause that 's summary .\nhave a summary and high points .\nSummary .\nI think  there 's also  there 's this use that\nSummarize it from the transcription .\nthe  Well , what if you 're sitting there and you just wanna make an X and you don't wanna take notes and you 're  you just wanna\nDoodle .\nget the summary of the transcript from this time location like  you know , and  and then while you 're bored you don't do anything and once in a while , maybe there 's a joke and you put a X and   But  in  in other words you can use that just to highlight times in a very simple way . Also with  I was thinking and I know Morgan disagrees with me on this but suppose you have a group in here and you wanna let them note whenever they think there might be something later that they might not wanna distribute in terms of content , they could just sort of make an X near that point or a question mark that sort of alerts them that when they get the transcript back they c could get some red flags in that transcript region and they can then look at it . So . I know we haven't been using it but I w I can imagine it being useful just for sort of marking time periods\nRight .\nwhich you then get back in a transcript\nWell .\nI guess  so , you know , what  what makes one think i is maybe we should actually schedule some periods where people go over something later\nso .\nand  and  and put some kind of summary or something uh you know , some  there 'd be some scribe who would actually listen , w who 'd agreed to actually listen to the whole thing , not transcribe it , but just sort of write down things that struck them as important . But  then you don't  you don't have the time reference uh that you 'd have if you had it live .\nRight . And you don't have a lot of other cues that might be useful ,\nYeah .\nHow do you synchronize the time in the CrossPad and the time of the recording ?\nso .\nI mean that was one of the issues we talked about originally and that that 's w part of the difficulty is that we need an infrastructure for using the time  the CrossPads and so that means synchronizing the time\nMm - hmm .\nYou know you want it pretty close and there 's a fair amount of skew because it 's a hand - held unit with a battery\nWell when  when I d\nand so you\nOK .\nso you have to synchronize at the beginning of each meeting all the pads that are being used , so that it 's synchronized with the time on that and then you have to download to an application , and then you have to figure out what the data formats are and convert it over if you wanna do anything with this information .\nw Mm - hmm .\nWhy\nAnd so there 's a lot of infrastructure which\nThere is an alternative .\nunless someone\nThere is an alternative , I mean , it 's still , there 's uh  you know , your point stands about there be  needing to be an infrastructure , but it doesn't have to be synchronized with the little clock 's timer on it . You c I mean , I  when I  when I did it I synchronized it by voice , by whispering \" one , two , three , four \" onto the microphone\nHmm .\nand uh , you know .\nWell , but then there 's the infrastructure at the other end\nRight .\nwhich someone has to listen to that and find that point ,\nYeah , it 's transcribed . It 's in the transcript .\nand then mark it .\nYeah .\nSo .\nWell it 's in the transcript .\nWell , could we keep one of these things for another year ? Would h I mean is there a big cau\nWe can keep all  both of them for the whole whole year .\njust  just in case we\nI mean , it 's just\neven maybe some of the transcribers who might be wanting to annotate uh f just there 's a bunch of things that might be neat to do but I  it might not be the case that we can actually synchronize them and then do all the infrastructure but we could at least try it out .\nWell  one thing that we might try um is on some set of meetings , some collection of meetings , maybe EDU is the right one or maybe something else , we  we get somebody to buy into the idea of doing this as part of the task . I mean ,\nRight .\nuh part of the reason  I think part of the reason that Adam was so interested in uh the SpeechCorder sort of f idea from the beginning is he said from the beginning he hated taking notes and\nYep .\nand so forth so and  and Jane is more into it but eh uh you know I don't know if you wanna really do  do this all the time so I think the thing is to  to get someone to actually buy into it and have at least some series of meetings where we do it . Um  and if so , it 's probably worth having one . The p the  the problem with the  the more extended view , all these other you know with uh quibbling about particular applications of it is that it looks like it 's hard to get people to um uh routinely use it , I mean it just hasn't happened anyway . But maybe if we can get a person to\nYeah I don't think it has to be part of a what everybody does in a meeting but it might be a useful , neat part of the project that we can , you know , show off as a mechanism for synchronizing events in time that happen that you just wanna make a note of , like what Jane was talking about with some later browsing , just  just as a convenience , even if it 's not a full - blown note taking substitute .\nWell if you wanted to do that maybe the right architecture for it is to get a PDA with a wireless card . And  and that way you can synchronize very easily with the  the  the meeting because you 'll be synchroni you can synchronize with the  the Linux server and uh\nSo what kind of input would you be  ?\nso  so , I mean , if you 're not worried about\nButtons .\nYou 'd just be pressing like a  a\nWell  well you have a PDA and may and you could have the same sort of X interface or whatever , I mean , you 'd have to do a little eh a little bit of coding to do it .\nMm - hmm .\nBut you could imagine ,\nYeah , that be good .\nI mean , if  if all you really wanted was  you didn't want this secondary note - taking channel but just sort of being able to use m markers of some sort , a PDA with a l a wireless card would be the  probably the right way to go . I mean even buttons you could do , sort of , I mean , as you said .\nI mean for what  what you 've been describing buttons would be even more convenient than anything else ,\nM right .\nRight .\nThat would be fine too .\nright ? You have the\nI mean , I don't have , you know , grandiose ideas in mind but I 'm just sort of thinking well we 've  we 're getting into the next year now and we have a lot of these things worked out at  in terms of the speech maybe somebody will be interested in this and\nI like this PDA idea . Yeah .\nYeah , I do like the idea of having a couple buttons\nYeah .\nWell I 'm sure there would\nYeah .\nwhere like one  one button was \" uh - oh \" and then another button was \" that 's great \" and another button \" that 's f \"\nOr like this is my \" I 'm supposed to do this \" kind of button ,\nYeah .\nlike \" I better remember to  \"\nAction item .\nYeah something like that or\nAnd then\nI mean I think the CrossPad idea is a good one .\nUh - huh .\nIt 's just a question of getting people to use it and getting the infrastructure set up in such a way that it 's not a lot of extra work . I mean that 's part of the reason why it hasn't happened is that it 's been a lot of extra work for me\nYeah .\nRight .\nWell , and not just for you .\nand\nBut it 's also , it has this problem of having to go from an analog to a d a digital record too ,\nW\ndoesn't it ? I mean\nWell it 's digital but it 's in a format that is not particularly standard .\nBut I mean , say , if i if  if you 're writing  if you 're writing notes in it does  it  it can't do handwriting recognition , right ?\nNo , no , but it 's just  it 's just storing the pixel informa position information ,\nOK .\nit 's all digital .\nI  I guess what I 'm thinking is that the PDA solution you h you have it already without needing to go from the pixelization to a  to a  I mean\nRight . You don't have to\nThe transfer function is less errorful ,\nOh , nicely put .\nYeah .\nyes .\nYeah , yeah .\nYeah . Yeah .\nWell it also  it 's maybe realistic cuz people are supposed to be bringing their P D As to the meeting eventually , right ? That 's why we have this little  I don't know what  I don't wanna cause more work for anyone but I can imagine some interesting things that you could do with it and so if we don't have to return it and we can keep it for a year  I don't know .\nWell  w we don't  we certainly don't have to return it , as I said . All  all he said is that if you 're not using it could you return it , if you are using it feel free to keep it . The point is that we haven't used it at all and are we going to ?\nSo we have no but  uh by I  I would suggest you return one . Because we  we you know , we  we haven't used it at all .\nYeah .\nOK .\nWe c\nWe have some aspirations of using them\nOne would probably be fine .\nand\nMaybe we could do like a student project , you know , maybe someone who wants to do this as their main like s project for something would be cool .\nYeah .\nYep . I mean if we had them out and sitting on the table people might use them a little more\nMaybe Jeremy could sit in some meetings and press a button when there  when  when somebody laughed .\nalthough there is a little\nWell , I 'm  yeah , that 's not a bad\nYeah , yeah . Yeah .\nJeremy 's gonna be an  he 's a new student starting on modeling brea breath and laughter , actually , which sounds funny but I think it should be cool ,\nYeah .\nso .\nSounds breathy to me .\nOK . \" Ha - ha - ha . \"\nBreath and lau \" ha - ha - ha - ha \" . \" Ha - ha - ha - ha . \"\nWell dear .\nUm .\nHmm .\nThat reminded me of something . Oh well , too late . It slipped out .\nOK .\nYou 're  you 're gonna tease me ?\nOh , equipment .\nOK .\nOrdered  Uh , well I 'm always gonna do that . W uh   We ordered uh more wireless , and so they should be coming in at some point .\nGreat .\nAnd then at the same time I 'll probably rewire the room as per Jane 's suggestion so that uh the first N channels are wireless , eh are the m the close - talking and the next N are far - field .\nYou know what he means but isn't that funny sounding ? \" We ordered more wireless . \" It 's like wires are the things so you 're wiring  you 're  you 're  you  we 're  we ordered more absence of the thing .\nThat 's a very philosophical statement from Morgan .\nwired less , wired more .\nI just  it 's sort of a anachronism , I mean it 's like  It 's great .\nAnyway .\nShould we do digits ? Do we have anything else ?\nYeah .\nOK .\nI mean there 's  there 's all this stuff going on uh between uh Andreas and  and  and Dave and Chuck and others with various kinds of runs uh um  recognition runs , trying to figure things out about the features but it 's  it 's all sort of in process , so there 's not much to say right now . Uh why don't we start with our  our esteemed guest .\nOK . Alright .\nSo just the transcript number and then the  then the\nThis is  Yes , this is number two for me today .\nSee all you have to do is go away to move way up in the\nOh .\nWe could do simultaneous . Initiate him .\nWe  we could .\nShould we do simultaneous ?\nWell , I 'm just thinking , are you gonna try to save the data before this next group comes in ?\nYeah .\nYeah , absolutely .\nYeah , so we might wanna do it simultaneous .\nI mean you hav sorta have to .\nWell OK , so let 's do one of those simultaneous ones .\nRight , so  so we might n we might need to do that actually .\nThat sounds good .\nOK .", "topic_id": 3, "keywords": "backups, backup, archive, storing, backed", "dialogue_id": 16}, {"text": "OK .\nEverybody ready ?\nYeah .\nA one .\nYou have to plug your ears , by the way uh Eric ,\nWell I have to ,\nYou don't have to .\nOK , alright .\nor  or you start laughing .\nI don't know about other people .\nOK , a one and a two and a three . OK , babble , take five .", "topic_id": 4, "keywords": "laughing, ears, plug, babble, everybody", "dialogue_id": 16}, {"text": "We 're going ? OK . Sh - Close your door on  door on the way out ?\nOK . Thanks .\nThanks .\nOh .\nYeah . Probably wanna get this other door , too . OK . So . Um .   What are we talking about today ?\nUh , well , first there are perhaps these uh Meeting Recorder digits that we tested .\nOh , yeah . That was kind of uh interesting .\nSo .\nThe  both the uh   the SRI System and the oth\nUm .\nAnd for one thing that  that sure shows the  difference between having a lot of uh training data  or not ,\nOf data ? Yeah .\nuh , the uh   The best kind of number we have on the English uh  on near microphone only is  is uh three or four percent .\nMm - hmm .\nAnd uh it 's significantly better than that , using fairly simple front - ends  on   on the uh   uh , with the SRI system .\nMm - hmm .\nSo I th I think that the uh  But that 's  that 's using uh a  a pretty huge amount of data , mostly not digits , of course , but  but then again  Well , yeah . In fact , mostly not digits for the actual training the H M Ms whereas uh in this case we 're just using digits for training the H M\nYeah . Right .\nDid anybody mention about whether the  the SRI system is a   is  is doing the digits um the wor as a word model or as uh a sub s sub - phone states ?\nI guess it 's  it 's uh allophone models ,\nYeah . Probably .\nso , well\nHuh ?\nYeah . I think so , because it 's their very d huge , their huge system .\nYeah .\nAnd . But . So . There is one difference  Well , the SRI system  the result for the SRI system that are represented here are with adaptation . So there is  It 's their complete system and  including on - line uh unsupervised adaptation .\nThat 's true .\nAnd if you don't use adaptation , the error rate is around fifty percent worse , I think , if I remember .\nOK .\nYeah .\nIt 's tha it 's that much , huh ?\nNnn . It 's  Yeah . It 's quite significant .\nOh . OK .\nYeah .\nStill .\nMm - hmm .\nBut  but uh what  what I think I 'd be interested to do given that , is that we  we should uh  take  I guess that somebody 's gonna do this , right ?  is to take some of these tandem things and feed it into the SRI system , right ?\nYeah .\nYeah .\nWe can do something like that .\nYeah . Because\nYeah . But  But I guess the main point is the data because uh  I am not sure . Our back - end is  is fairly simple but until now , well , the attempts to improve it or  have fail Ah , well , I mean uh what Chuck tried to  to  to do\nYeah , but he 's doing it with the same data , right ? I mean so to   So there 's  there 's  there 's two things being affected .\nYeah . So it 's  Yeah .\nI mean . One is that  that , you know , there 's something simple that 's wrong with the back - end . We 've been playing a number of states\nMm - hmm .\nuh I  I don't know if he got to the point of playing with the uh number of Gaussians yet\nMm - hmm .\nbut  but uh , uh , you know . But , yeah , so far he hadn't gotten any big improvement ,\nMm - hmm .\nbut that 's all with the same amount of data which is pretty small .\nYeah .\nAnd um .\nMmm . So , yeah , we could retrain some of these tandem on  on huge\nWell , you could do that , but I 'm saying even with it not  with that part not retrained , just  just using  having the H M Ms  much better H M\nAh , yeah . Just  f for the HMM models .\nYeah .\nYeah . Mm - hmm . Mm - hmm .\nUm .  But just train those H M Ms using different features , the features coming from our Aurora stuff .\nYeah .\nSo .\nYeah . But  what would be interesting to see also is what  what  perhaps it 's not related , the amount of data but the um recording conditions . I don't know . Because  it 's probably not a problem of noise , because our features are supposed to be robust to noise .\nWell , yeah .\nIt 's not a problem of channel , because there is um   normalization with respect to the channel . So\nI  I  I 'm sorry . What  what is the problem that you 're trying to explain ?\nThe  the fact that  the result with the tandem and Aurora system are  uh so much worse .\nThat the  Oh . So much worse ? Oh .\nYeah .\nI uh but I 'm  I 'm almost certain that it  it   I mean , that it has to do with the um amount of training data .\nIt\nIt  it 's  it 's orders of magnitude off .\nYeah but  Yeah . Yeah but we train only on digits and it 's  it 's a digit task , so . Well .\nBut  but having a huge  If   if you look at what commercial places do , they use a huge amount of data .\nIt  Mm - hmm .\nThis is a modest amount of data .\nAlright . Yeah .\nSo .  I mean , ordinarily you would say \" well , given that you have enough occurrences of the digits , you can just train with digits rather than with , you know \"\nMm - hmm . Mm - hmm .\nBut the thing is , if you have a huge  in other words , do word models  But if you have a huge amount of data then you 're going to have many occurrences of similar uh allophones .\nRight . Mmm .\nAnd that 's just a huge amount of training for it .\nYeah .\nSo it 's  um   I  I think it has to be that , because , as you say , this is , you know , this is near - microphone ,\nMm - hmm .\nit 's really pretty clean data .\nMm - hmm .\nUm . Now , some of it could be the fact that uh  let 's see , in the  in these multi - train things did we include noisy data in the training ?\nYeah .\nI mean , that could be hurting us actually , for the clean case .\nYeah . Well , actually we see that the clean train for the Aurora proposals are  are better than the multi - train ,\nIt is if  Yeah .\nyeah .\nYeah . Cuz this is clean data , and so that 's not too surprising .\nMm - hmm .\nBut um . Uh . So .\nWell , o I guess what I meant is that well , let 's say if we  if we add enough data to train on the um on the Meeting Recorder digits , I guess we could have better results than this .\nUh - huh . Mm - hmm .\nAnd . What I meant is that perhaps we can learn something uh from this , what 's  what 's wrong uh what  what is different between TI - digits and these digits and\nWhat kind of numbers are we getting on TI - digits ?\nIt 's point eight percent , so .\nOh . I see .\nFour - Fourier .\nSo in the actual TI - digits database we 're getting point eight percent ,\nYeah . Yeah .\nand here we 're getting three or four  three , let 's see , three for this ?\nMm - hmm .\nYeah . Sure , but I mean , um point eight percent is something like double uh or triple what people have gotten who 've worked very hard at doing that .\nMm - hmm .\nAnd  and also , as you point out , there 's adaptation in these numbers also . So if you , you know , put the ad adap take the adaptation off , then it  for the English - Near you get something like two percent .\nMmm .\nAnd here you had , you know , something like three point four . And I could easily see that difference coming from this huge amount of data that it was trained on .\nMm - hmm .\nSo it 's\nMm - hmm .\nYou know , I don't think there 's anything magical here .\nYeah .\nIt 's , you know , we used a simple HTK system with a modest amount of data . And this is a  a , you know , modern  uh system uh has  has a lot of nice points to it .\nYeah . Mm - hmm .\nUm . So . I mean , the HTK is an older HTK , even . So . Yeah it  it 's not that surprising .\nMm - hmm .\nBut to me it just  it just meant a practical  point that um if we want to  publish results on digits that  that people pay  attention to we probably should uh  Cuz we 've had the problem before that you get  show some  nice improvement on something that 's  that 's uh , uh  it seems like too large a number , and uh  uh people don't necessarily take it so seriously .\nMm - hmm .\nUm . Yeah . Yeah . So the three point four percent for this uh is  is uh  So why is it  It 's an interesting question though , still . Why is  why is it three point four percent for the d the digits recorded in this environment as opposed to  the uh point eight percent for  for  for the original TI - digits database ? Um .\nYeah . th that 's  th that 's my point\nGiven  given the same  Yeah . So ignore  ignoring the  the  the SRI system for a moment ,\nI  I  I don't I  Mm - hmm .\njust looking at  the TI - di the uh tandem system , if we 're getting point eight percent , which , yes , it 's high . It 's , you know , it  it 's not awfully high ,\nMm - hmm .\nbut it 's , you know  it 's  it 's high . Um .  Why is it  uh four times as high , or more ?\nYeah , I guess .\nRight ? I mean , there 's   even though it 's close - miked there 's still  there really is background noise .\nMm - hmm .\nUm . And  uh I suspect when the TI - digits were recorded if somebody fumbled or said something wrong or something that they probably made them take it over .\nMm - hmm .\nIt was not  I mean there was no attempt to have it be realistic in any  in any sense at all .\nWell . Yeah . And acoustically , it 's q it 's  I listened . It 's quite different . TI - digit is  it 's very , very clean and it 's like studio recording\nMm - hmm .\nwhereas these Meeting Recorder digits sometimes you have breath noise and Mmm .\nRight . Yeah . So I think they were\nIt 's {nonvocalsound} not controlled at all , I mean .\nBless you .\nThanks .\nI  Yeah . I think it 's  it 's  So . Yes .\nMm - hmm . But\nIt 's  I think it 's  it 's the indication it 's harder .\nYeah .\nUh .  Yeah and again , you know , i that 's true either way . I mean so take a look at the uh   um , the SRI results . I mean , they 're much much better , but still you 're getting something like one point three percent for uh things that are same data as in T  TI - digits the same  same text .\nMm - hmm .\nUh . And uh , I 'm sure the same  same system would  would get , you know , point  point three or point four or something  on the actual TI - digits . So this  I think , on both systems the  these digits are showing up as harder .\nMmm .\nUm .\nMm - hmm .\nWhich I find sort of interesting cause I think this is closer to  uh I mean it 's still read . But I still think it 's much closer to  to what  what people actually face ,  um when they 're  they 're dealing with people saying digits over the telephone . I mean .  I don't think uh  I mean , I 'm sure they wouldn't release the numbers , but I don't think that uh  the uh  the  the companies that  that do telephone  speech get anything like point four percent on their  digits . I 'm  I 'm  I 'm sure they get  Uh , I mean , for one thing people do phone up who don't have uh uh Middle America accents and it 's a we we it 's  it 's  it 's US .\nMm - hmm .", "topic_id": 0, "keywords": "recorder, microphone, recording, acoustically, digits", "dialogue_id": 17}, {"text": "it has  has many people   who sound in many different ways . So . Um . I mean . OK . That was that topic . What else we got ?\nUm .\nDid we end up giving up on  on , any Eurospeech submissions ,\nBut\nor  ? I know Thilo and Dan Ellis are  are submitting something , but uh .\nYeah . I   I guess e the only thing with these  the Meeting Recorder and , well ,  So , I think , yeah  I think we basically gave up .\nUm .  Now , actually for the  for the Aur - uh\nBut\nwe do have stuff for Aurora , right ? Because  because we have ano an extra month or something .\nYeah . Yeah . Yeah . So . Yeah , for sure we will do something for the special session .\nYeah . Well , that 's fine . So th so  so we have a couple  a couple little things on Meeting Recorder\nYeah . Mm - hmm .\nand we have   We don't  we don't have to flood it with papers . We 're not trying to prove anything to anybody . so . That 's fine . Um . Anything else ?\nYeah . Well . So . Perhaps the point is that we 've been working on  is , yeah , we have put the um the good VAD in the system and  it really makes a huge difference . Um . So , yeah . I think , yeah , this is perhaps one of the reason why our system was not   not the best , because with the new VAD , it 's very  the results are similar to the France Telecom results and perhaps even better sometimes .\nHmm .\nHuh .\nUm . So there is this point . Uh . The problem is that it 's very big and   we still have to think how to  where to put it and   um ,\nMm - hmm .\nbecause it  it  well , this VAD uh either some delay and we  if we put it on the server side , it doesn't work , because on the server side features you already have LDA applied  from the f from the terminal side and  so you accumulate the delay so the VAD should be before the LDA which means perhaps on the terminal side and then smaller  and\nSo wha where did this good VAD come from ?\nSo . It 's um from OGI . So it 's the network trained  it 's the network with the huge amounts on hidden  of hidden units , and um nine input frames compared to the VAD that was in the proposal which has a very small amount of hidden units and fewer inputs .\nThis is the one they had originally ?\nYeah .\nOh . Yeah , but they had to  get rid of it because of the space , didn't they ?\nYeah . So . Yeah . But the abso assumption is that we will be able to make a VAD that 's small and that works fine . And . So we can\nWell . So that 's a problem . Yeah .\nYeah but  nnn .\nBut the other thing is uh to use a different VAD entirely . I mean , uh i if  if there 's a  if  if  I  I don't know what the thinking was amongst the  the  the  the ETSI folk but um if everybody agreed sure let 's use this VAD and take that out of there\nMm - hmm . Mm - hmm . They just want , apparently  they don't want to fix the VAD because they think there is some interaction between feature extraction and  and VAD or frame dropping But they still  want to  just to give some um  requirement for this VAD because it 's  it will not be part of  they don't want it to be part of the standard .\nOK .\nSo . So it must be at least uh somewhat fixed but not completely . So there just will be some requirements that are still not  uh not yet uh ready I think .\nDetermined . I see . But I was thinking that  that uh  s \" Sure , there may be some interaction ,\nNnn .\nbut I don't think we need to be stuck on using our or OGI 's  VAD . We could use somebody else 's if it 's smaller or\nYeah .\nYou know , as long as it did the job .\nMm - hmm .\nSo that 's good .\nUh . So there is this thing . There is um  Yeah . Uh I designed a new  a new filter because when I designed other filters with shorter delay from the LDA filters ,  there was one filter with fif sixty millisecond delay and the other with ten milliseconds\nRight .\nand  uh Hynek suggested that both could have sixty - five sixty - s I think it 's sixty - five .\nYeah .\nYeah . Both should have sixty - five because\nYou didn't gain anything , right ?\nYeah . And . So I did that and uh it 's running . So ,  let 's see what will happen . Uh but the filter is of course closer to the reference filter .\nMm - hmm .\nMmm . Um . Yeah . I think\nSo that means logically , in principle , it should be better . So probably it 'll be worse .\nYeah\nOr in the basic perverse nature uh of reality . Yeah . OK .\nYeah . Sure .\nYeah .\nOK .\nYeah , and then we 've started to work with this of um voiced - unvoiced stuff .\nMm - hmm .\nAnd next week I think we will  perhaps try to have um a new system with uh uh MSG stream also see what  what happens . So , something that 's similar to the proposal too , but with MSG stream .\nMm - hmm . Mm - hmm .\nMmm .\nOK .\nNo , I w  I begin to play  with Matlab and to found some parameter robust for voiced - unvoiced decision . But only to play . And we   they  we found that maybe w is a classical parameter , the  sq the variance  between the um FFT of the signal and the small spectrum of time  we  after the um mel filter bank .\nUh - huh .\nAnd , well , is more or less robust . Is good for clean speech . Is quite good  for noisy speech .\nHuh ? Mm - hmm .\nbut um we must to have bigger statistic with TIMIT ,\nMm - hmm .\nand is not ready yet to use on ,\nYeah .\nwell , I don't know .\nYeah .\nYeah . So , basically we wa want to look at something like the ex the ex excitation signal and\nRight .\nMm - hmm .\nwhich are the variance of it and\nI have here . I have here for one signal , for one frame .\nMmm .\nYeah . Uh - huh .\nThe  the mix of the two , noise and unnoise , and the signal is this . Clean , and this noise .\nUh .\nThese are the two  the mixed , the big signal is for clean .\nWell , I 'm s uh  There 's  None of these axes are labeled , so I don't know what this  What 's this axis ?\nUh this is uh  this axis is  nnn , \" frame \" .\nFrame .\nMm - hmm .\nAnd what 's th what this ?\nUh , this is uh energy , log - energy of the spectrum . Of the this is the variance , the difference {nonvocalsound} between the spectrum of the signal and FFT of each frame of the signal and this mouth spectrum of time after the f may fit for the two ,\nFor this one . For the noi\nthis big , to here , they are to signal . This is for clean and this is for noise .\nOh . There 's two things on the same graph .\nYeah . I don't know . I  I think that I have d another graph , but I 'm not sure .\nSo w which is clean and which is noise ?\nYeah . I think the lower one is noise .\nThe lower is noise and the height is clean .\nOK . So it 's harder to distinguish\nIt 's height .\nbut it  but it g\nYeah .\nwith noise of course but  but\nOh . I must to have .\nUh .\nPity , but I don't have two different\nAnd presumably when there 's a  a\nSo this should the  the  the t voiced portions .\nUh - huh .\nYeah , it is the height is voiced portion .\nThe p the peaks should be voiced portion .\nAnd this is the noise portion .\nUh - huh .\nAnd this is more or less like this . But I meant to have see @ @ two  two the picture .\nYeah . Yeah .\nThis is , for example , for one frame .\nYeah\nthe  the spectrum of the signal . And this is the small version of the spectrum after ML mel filter bank .\nYeah . And this is the difference ?\nAnd this is I don't know . This is not the different . This is trying to obtain  with LPC model the spectrum but using Matlab without going factor and s\nNo pre - emphasis ? Yeah .\nNot pre - emphasis . Nothing .\nYeah so it 's  doesn't do too well there .\nAnd the  I think that this is good . This is quite similar . this is   this is another frame . ho how I obtained the  envelope , {nonvocalsound} this envelope , with the mel filter bank .\nRight . So now I wonder  I mean , do you want to  I know you want to get at something orthogonal from what you get with the smooth spectrum Um . But if you were to really try and get a voiced - unvoiced , do you  do you want to totally ignore that ? I mean , do you  do you  I mean , clearly a  a very big  very big cues  for voiced - unvoiced come from uh spectral slope and so on , right ?\nMm - hmm .\nUm .\nYeah . Well , this would be  this would be perhaps an additional parameter ,\nYeah .\nsimply isn't\nI see .\nYeah .\nYeah because when did noise clear {nonvocalsound} in these section is clear\nUh .\nMm - hmm .\nif s @ @ {nonvocalsound} val value is indicative that is a voice frame and it 's low values\nYeah . Yeah . Well , you probably want  I mean ,  certainly if  you want to do good voiced - unvoiced detection , you need a few features . Each  each feature is  by itself not enough . But , you know , people look at  at slope and  uh first auto - correlation coefficient , divided by power .\nMmm .\nOr  or uh um there 's uh  I guess we prob probably don't have enough computation to do a simple pitch detector or something ? I mean with a pitch detector you could have a   have a  an estimate of  of what the\nMmm .\nUh . Or maybe you could you just do it going through the P FFT 's figuring out some um probable  um harmonic structure . Right . And  and uh .\nMmm .\nyou have read up and  you have a paper ,  the paper that you s give me yesterday . they say that yesterday  they are some {nonvocalsound} problem\nOh , yeah . But  Yeah , but it 's not  it 's , yeah , it 's  it 's another problem .\nand the  Is another problem .\nYeah Um . Yeah , there is th this fact actually . If you look at this um spectrum ,\nYeah .\nWhat 's this again ? Is it  the mel - filters ?\nYeah like this . Of kind like this .\nYeah . OK . So the envelope here is the output of the mel - filters\nMm - hmm .\nand what we clearly see is that in some cases , and it clearly appears here , and the  the harmonics are resolved by the f Well , there are still appear after mel - filtering ,\nMm - hmm .\nand it happens  for high pitched voice because the width of the lower frequency mel - filters  is sometimes even smaller than the pitch .\nYeah .\nIt 's around one hundred , one hundred and fifty hertz  Nnn .\nRight .\nAnd so what happens is that this uh , add additional variability to this envelope and   um\nYeah .\nso we were thinking to modify the mel - spectrum to have something that  that 's smoother on low frequencies .\nThat 's as  as a separate thing .\ni\nYeah .\nYeah . This is a separate thing .\nSeparate thing ?\nYeah .\nYeah .\nAnd .\nYeah . Maybe so . Um . Yeah . So , what  Yeah . What I was talking about was just , starting with the FFT you could  you could uh do a very rough thing to estimate  estimate uh pitch .\nYeah . Mm - hmm .\nAnd uh uh , given  you know , given that , uh  you could uh uh come up with some kind of estimate of how much of the low frequency energy was  was explained by   by uh uh those harmonics .\nMm - hmm .\nUh . It 's uh a variant on what you 're s what you 're doing . The  I mean , the  the  the mel does give a smooth thing . But as you say it 's not that smooth here . And  and so if you   if you just you know subtracted off uh your guess of the harmonics then something like this would end up with  quite a bit lower energy in the first fifteen hundred hertz or so and  and our first kilohertz , even .\nMm - hmm .\nAnd um  if was uh noisy , the proportion that it would go down would be if it was  if it was unvoiced or something .\nMm - hmm .\nSo you oughta be able to  pick out voiced segments . At least it should be another  another cue . So .  Anyway .\nMm - hmm .", "topic_id": 1, "keywords": "meeting, recorder, session, talking, sound", "dialogue_id": 17}, {"text": "OK ? That 's what 's going on . Uh . What 's up with you ?\nUm  our t I went to  talk with uh Mike Jordan this  this week\nMm - hmm .\num {nonvocalsound} and uh  shared with him the ideas about um  extending the Larry Saul work and um I asked him some questions about factorial H M so like later down the line when  we 've come up with these  these feature detectors , how do we   how do we uh  you know , uh model the time series that  that happens um   and  and we talked a little bit about  factorial H M Ms and how  um when you 're doing inference  or w when you 're doing recognition , there 's like simple Viterbi stuff that you can do for   for these H M and  the uh   the great advantages that um a lot of times the factorial H M Ms don't  um  don't over - alert the problem there they have a limited number of parameters and they focus directly on   on uh the sub - problems at hand so  you can imagine  um  five or so parallel  um features um transitioning independently and then  at the end you  you uh couple these factorial H M Ms with uh   with uh undirected links um based on   based on some more data .\nHmm .\nSo he  he seemed  he seemed like really interested in   in um  in this and said  said this is  this is something very do - able and can learn a lot and um yeah , I 've just been  continue reading um about certain things .\nMm - hmm .\num thinking of maybe using um  um m modulation spectrum stuff to  um  as features um also in the  in the sub - bands\nMm - hmm .\nbecause  it seems like  the modulation um spectrum tells you a lot about the intelligibility of  of certain um words and stuff So , um . Yeah . Just that 's about it .\nOK .\nOK . And um so I 've been looking at Avendano 's work and um uh I 'll try to write up in my next stat status report a nice description of  what he 's doing , but it 's  it 's an approach to deal with  reverberation or that  the aspect of his work that I 'm interested in the idea is that um    normally an analysis frames are um  too short to encompass reverberation effects um in full . You miss most of the reverberation tail in a ten millisecond window and so   you  you 'd like it to be that  um  the reverberation responses um simply convolved um in , but it 's not really with these ten millisecond frames cuz you j But if you take , say , a two millisecond  um window  I 'm sorry a two second window then in a room like this , most of the reverberation response  is included in the window and the  then it um  then things are l more linear . It is  it is more like the reverberation response is simply c convolved and um   and you can use channel normalization techniques  like uh in his thesis he 's assuming that the reverberation response is fixed . He just does um  mean subtraction , which is like removing the DC component of the modulation spectrum and  that 's supposed to d um deal  uh deal pretty well with the um reverberation and um  the neat thing is you can't take these two second frames and feed them to a speech recognizer um  so he does this  um  method training trading the um  the spectral resolution for time resolution  and um  come ca uh synthesizes a new representation which is with say ten second frames but a lower s um  frequency resolution . So I don't really know the theory . I guess it 's  these are called \" time frequency representations \" and h he 's making the  the time sh um finer grained and the frequency resolution um less fine grained .\nMm - hmm .\ns so I 'm  I guess my first stab actually in continuing  his work is to um  re - implement this  this thing which um  changes the time and frequency resolutions cuz he doesn't have code for me . So that that 'll take some reading about the theory . I don't really know the theory .\nMm - hmm .\nOh , and um ,  another f first step is um , so the  the way I want to extend his work is make it able to deal with a time varying reverberation response um  and um we don't really know  how fast the um  the reverberation response is varying the Meeting Recorder data um so um  we  we have this um block least squares um imp echo canceller implementation and um  I want to try  finding  the  the response , say , between a near mike and the table mike for someone using the echo canceller and looking at the echo canceller taps and then  see how fast that varies  from block to block .\nMm - hmm .\nThat should give an idea of how fast the reverberation response is changing .\nMm - hmm .\nOK . Um . I think we 're  sort of done .\nYeah .\nSo let 's read our digits and go home .\nUm . S so um y you do  I think you read some of the  the zeros as O 's and some as zeros .\nYeah .\nIs there a particular way we 're supposed to read them ?\nThere are only zeros here . Well .\nNo . \" O \"  \" O \"  \" O \" \" O \"  \" O \"  \" O \" and \" zero \" are two ways that we say that digit .\nEee . Yeah .\nSo it 's\nHa !\nBut\nso it 's  i\nPerhaps in the sheets there should be another sign for the  if we want to  the  the guy to say \" O \" or\nNo . I mean . I think people will do what they say .\nIt 's\nIt 's OK .\nYeah .\nI mean in digit recognition we 've done before , you have  you have two pronunciations for that value , \" O \" and \" zero \" .\nAlright .\nOK .\nOK .\nBut it 's perhaps more difficult for the people to prepare the database then , if  because here you only have zeros\nNo , they just write\nand  and people pronounce \" O \" or zero\nthey  they write down OH . or they write down ZERO a and they  and they each have their own pronunciation .\nYeah but if the sh the sheet was prepared with a different sign for the \" O \" .\nBut people wouldn't know what that wa I mean  there is no convention for it .\nOK . Yeah .\nSee . I mean , you 'd have to tell them  \" OK when we write this , say it tha \" ,\nOK .\nyou know , and you just  They just want people to read the digits as you ordinarily would\nMm - hmm . Yeah .\nand  and people say it different ways .\nYep .\nOK . Is this a change from the last batch of  of um forms ? Because in the last batch it was spelled out which one you should read .\nYeah , it was orthographic , so .\nYes . That 's right . It was  it was spelled out , and they decided they wanted to get at more the way people would really say things .\nOh . OK .\nThat 's also why they 're  they 're bunched together in these different groups . So  so it 's\nOK .\nYeah . So it 's  it 's  Everything 's fine .\nOK .\nOK . Actually , let me just s since  since you brought it up , I was just  it was hard not to be self - conscious about that when it  after we  since we just discussed it . But I realized that  that um  when I 'm talking on the phone , certainly , and  and saying these numbers ,  I almost always say zero . And uh  cuz  because uh i it 's two syllables . It 's  it 's more likely they 'll understand what I said . So that  that  that 's the habit I 'm in , but some people say \" O \" and\nYeah I normally say \" O \" cuz it 's easier to say .\nYeah it 's shorter . Yeah . So it 's  So .  So uh .\n\" O \"\nNow , don't think about it .\nOh , no !\nOK . We 're done .", "topic_id": 2, "keywords": "features, feature, recognition, techniques, recognizer", "dialogue_id": 17}, {"text": "Starts  No . No .\nNo . That 's a different thing .\nThere 's another  I don't know . It starts with a P or something . I forget the word for it , but it 's  it 's um\nOh .\nTypically when you  you 're ab r starting around forty for most people , it starts to harden and then it 's just harder for the lens to shift things\nOh .\nand th the  the symptom is typically that you   you have to hold stuff uh uh further away to  to see it .\nUh - huh . Yeah .\nIn fact , uh m my brother 's a  gerontological psychologist and he  he uh  came up with an  an uh  a uh body age test which uh gets down to sort of only three measurements that are good enough st statistical predictors of all the rest of it . And one of them is  is the distance  that you have to hold it at .\nGive someone a piece of paper and then they  Oh .\nYeah .\nYeah .\nWe 're  we 're live by the way , so we 've got a good intro here\nOh . Yeah . About how old I am .\nYep .\nOK .\nWe can edit that out if you want .\nOh , that 's optional .\nNo , that 's OK .\nOK . So . This time the form discussion should be very short ,\nYou know .\nMm - hmm .\nright ?\nIt also should be  later .\nOK .\nBecause Jane uh is not here yet .\nGood point .\nAnd uh she 'll be most interested in that . Uh , she 's probably least involved in the signal - processing stuff so maybe we can just  just uh , I don't think we should go though an elaborate thing , but um uh Jose and I were just talking about  the uh {nonvocalsound} uh , speech e energy thing ,\nThe @ @\nand I uh\nYeah .\nWe didn't talk about the derivatives . But I think , you know , the  the  i if I can  if you don't mind my  my speaking for you for a bit , um  Uh . Right now , that he 's not really showing any kind of uh distinction , but uh  but we discussed a couple of the possible things that uh he can look at . Um . And uh one is that uh this is all in log energy and log energy is basically compressing the distances  uh  between things . Um  Another is that he needs to play with the  the different uh  uh temporal sizes . He was  he  he was taking everything over two hundred milliseconds uh , and uh he 's going to vary that number and also look at moving windows , as we discussed before . Um And uh  and the other thing is that the  yeah doing the   subtracting off the mean and the variance in the   uh and dividing it by the  standard deviation in the log domain ,  may not be  the right thing to do .\nHi Jane !\nHi .\nWe just started .\nYeah .\nCould you take that mike there ?\nAre these the long term means ? Like , over the whole  I mean , the means of  what ?\nThanks .\nUh B Between  between\nAll the frames in the conversation ?\nNo .\nOr of things that\nBetween  Neither . It 's uh between the pauses  uh for some segment .", "topic_id": 0, "keywords": "gerontological, symptom, psychologist, test, statistical", "dialogue_id": 18}, {"text": "No .\nOh .\nAnd so i i his  his  He 's making the constraint it has to be at least two hundred milliseconds .\nOh .\nAnd so you take that . And then he 's  he 's uh measuring at the frame level  still at the frame level , of what\nRight .\nand then  and then just uh normalizing with that larger amount . um and  But one thing he was pointing out is when he  he looked at a bunch of examples in log domain , it is actually pretty hard to see  the change . And you can sort of  see that , because of j of just putting it on the board that  if you sort of have log - X plus log - X , that 's the log of X plus the log of two\nYep .\nYeah , maybe it 's not log distributed .\nMmm . Yeah .\nand it 's just ,  you know , it  it diminishes the  effect of having two of them .\nUm .\nBut you could do like a C D F there instead ? I mean , we don't know that the distribution here is normally .\nYes , right . So  So what I was suggesting to him is that\nSo just some kind of a simple\nActually , a PDF . But , you know , uh But , either way .\nPDF\nYeah . Yeah , eith eith uh  B\nYeah .\nYeah .\nSomething like that where it 's sort of data driven .\nYeah , but I think  also u I think a good first indicator is when the  the  the researcher looks at  examples of the data and can not see a change  in how big the  the signal is ,  when the two speaker\nYeah . Yeah .\nThen , that 's a problem right there . So . I think you should at least be able ,\nOh yeah .\ndoing casual looking and can get the sense , \" Hey , there 's something there . \" and then you can play around with the measures . And when he 's looking in the log domain he 's not really seeing it .\nOh yeah .\nYeah .\nSo . And when he 's looking in straight energy he is , so that 's a good place to start .\nYeah .\nUm . So that was  that was the discussion we just had . Um .  The other thing Actually we ca had a question for Adam in this . Uh , when you did the  sampling ? uh  over the  speech segments or s or sampling over the  the individual channels in order to do the e uh the  amplitude equalization ,  did you do it over just the entire  everything in the mike channels ?\nHow\nYou didn't try to find speech ?\nNo , I just took over the entire s uh entire channel um  sampled ten minutes randomly .\nRight , OK . So then that means that someone who didn't speak  very much  would be largely represented by silence .\nYep .\nAnd someone who would  who would be  So the normalization factor probably is  i i i  is  is\nYeah , this was quite quick and dirty , and it was just for  listening .\nYeah .\nYeah .\nAnd for listening it seems to work really well .\nOK .\nYeah .\nYeah .\nYeah .\nSo .\nYeah . But that 's\nBut , it 's not  Not a good measure .\nRight . So th\nYeah .\nOK . So yeah there  there  there  There 's a good chance then given that different people do talk different amounts  that there is  there  there is still a lot more to be gained from gain norm normalization with some sort\nYeah . Yeah . Mmm .\nYes , absolutely .\nif  if we can figure out a way to do it .\nYeah .\nUh . But we were agreed that in addition to that  uh there should be  s stuff related to pitch and harmonics and so forth .\nYeah .\nSo we didn't talk at all about uh the other derivatives , but uh again just  just looking at  Uh , I think uh Liz has a very good point , that in fact it would be much more graphic just to show  Well , actually , you do have some distributions here , uh for these cases .\nYeah . Yeah .\nYou have some histograms , um  and  uh , they don't look very separate .\nYeah .\nuh   separated .\nThis is the  the first derivate of log of frame energy uh without any kind of normalization .\nWhat\nYeah . Yeah . Yeah .\nLog energy . Sorry .\nThese the These are the  the first experiments uh with comment uh\nFrame energy .\nExcept that  it 's hard to judge this because the  they 're not normalized . It 's just number of frames .\nYeah .\nYeah .\nYeah .\nYeah .\nBut yeah , even so .\nW  I mean , what I meant is , even if you use linear ,  you know , raw  measures , like  raw energy or whatever ,\n\" Number \"\nmaybe we shouldn't make any assumptions about the distribution 's shape , and just use  you know , use the distribution to model the    the mean , or what y you know , rather than the mean take some\nYeah . But  And so in  in these he 's got that .\nYeah .\nHe 's got some pictures . But he doesn't  he doesn't in the  he i\nYeah .\njust in derivatives , but not in the\nYeah . Oh .\nbut he d but he doesn't  doesn't\nRight . So , we don't  know what they look like  on the ,  tsk   For the raw .\nBut he didn't h have it for the energy . He had it for the derivatives . Yeah .\nYeah . So . I mean , there might be something there . I don't know .\nYeah .\nHuh .\nInteresting\nHere I  I\nOh that  yeah that 's a good q\nin  No I  I  I haven't the result\ndid  did you have this sort of thing , for just the  just the l r uh the  the unnormalized log energy ? OK . Yeah . So she  she 's right .\nbut it 's the  it 's the  the  the following .\nThat 's a\nWell it might be just good to know what it looks like .\nYeah . That 's  That 's uh  cuz I 'd mentioned scatter plots before but she 's right ,\nCuz\nHuh ?\nI mean , even before you get the scatter plots , just looking at a single feature  uh , looking at the distribution , is a good thing to do .\nYeah . Catal - uh  Combining the different possibilities of uh the parameters . I  I  I  I mean the  the  the scatter plot  combining eh different  n two combination .\nYeah , but  but what she 's saying  is , which is right , is  le\ncombination of two ,  of energy and derivate\nI mean , let 's start with the  Before we get complicated , let 's start with the most basic wh thing , which is  we 're arguing that if you take energy  uh if you look at the energy , that , when two people are speaking at the same time , usually   there 'll be more energy than when one is right ?\nYeah .\nThat 's  that sort of hypothesis .\nThat 's right .\nAnd the first way you 'd look at that , uh s she 's , you know , absolutely right , is that you would just take a look at the distribution of those two things , much as you 've plotted them here ,\nYeah .\nYou know , but just  but just   just uh do it\nYeah .\nWell in this case you have three . You have the silence , and that  that 's fine .\nYeah .\nSo , uh with three colors or three shades or whatever , just  just look at those distributions .\nYeah .\nAnd then , given that as a base , you can see if that gets improved , you know , or  or   or worsened  by the  looking at regular energy , looking at log energy , we were just proposing that maybe it 's  you know , it 's harder to  see with the log energy , um and uh also these different normalizations , does a particular choice of normalization make it better ?\nYeah .\nBut I had maybe made it too complicated by suggesting early on , that you look at scatter plots because that 's looking at a distribution in two dimensions . Let 's start off just in one , uh , with this feature .\nYeah . Yeah .\nI think that 's probably the most basic thing , before anything very complicated .\nYeah .\nUm And then we w I think we 're agreed that pitch - related things are  are  are going to be a  a really likely candidate to help .\nYeah .\nYeah . I agree , yeah . Uh - huh .\nUm  But  since   uh your intuition from looking at some of the data , is that when you looked at the regular energy , that it did in fact usually go up ,  when two people were talking ,  that 's  eh you know , you should be able to come up with a measure which will  match your intuition .\nOK . Yeah . Yeah . Yeah , yeah , yeah .\nAnd she 's right , that a  that having a  having   having this table , with a whole bunch of things ,  with the standard deviation , the variance and so forth , it 's  it 's  it 's harder to interpret than just looking at the  the same kind of picture you have here .\nBut  Uh - huh . Yeah . But  It  it 's curious but uh I f I found it in the  in the mixed file , in one channel  that eh in several  oh e eh several times eh you have an speaker talking alone with a high level of energy\nMm - hmm . Mm - hmm .\neh in the middle eh a zone of overlapping with mmm less energy\nMm - hmm .\nand eh come with another speaker with high energy\nMm - hmm .\nand the overlapping zone has eh less energy .\nYeah . So there 'll be some cases for which\nBecause there reach very many\nBut , the qu So  So they 'll be\nRight .\nThis is   I w want to point  to visual things , But I mean they  there 'll be time  There 'll be overlap between the distributions , but the question is , \" If it 's a reasonable feature at all , there 's some separation . \"\nYeah . Yeah .\nEspecially locally .\nMm - hmm .\nSo . Locally .\njust locally , yeah .\nAnd  I was just going to say that  that  right now we 're just exploring .\nAnd the other thing is I Sorry . I\nWhat you would imagine eventually , is that you 'll feed all of these features into some  discriminative system .\nYeah .\nYeah .\nAnd so even if  if one of the features does a good job at one type of overlap , another feature might do a good job at another type of overlap .\nYeah . Yeah . Yeah .\nRight . I mean the  the reason I had suggested the scatter f p features is I used to do this a lot , when we had thirteen or fifteen or twenty features  to look at .\nYeah , this is the\num Because something is a good feature uh by itself , you don't really know how it 'll behave in combination and so it 's nice to have as many  as many together at the same time as possible in uh in some reasonable visual form . There 's cool graphic things people have had sometimes to put together three or four in some funny  funny way . But it 's true that you shouldn't do any of that unless you know that the individual ones , at least , have  have some uh  some hope\nYeah .\nWell , especially for normalizing .\nMm - hmm .\nI mean , it 's really important to  pick a normalization that matches the distribution for that feature .\nMm - hmm .\nAnd it may not be the same for all the types of overlaps or the windows may not be the same . e Actually , I was wondering ,  right now you 're taking a  all of the  speech , from the whole meeting , and you 're trying to find points of overlap , but we don't really know which speaker is overlapping with which speaker ,\nRight .\nright ? So I mean another way would just be to take the speech from just , say , Morgan , And just Jane and then just their overlaps ,\nYeah .\nlike  but by hand , by cheating , and looking at you know , if you can detect something that way , because if we can't do it that way , there 's no good way that we 're going to be able to do it .\nNo prayer .\nThat  You know , there might be something helpful and cleaner about looking at just  individuals and then that combination alone .\nYeah .\nPlus , I think it has more elegant  e\nMm - hmm .\nThe m the right model will be  easier to see that way . So if  I don't know , if you go through and you find Adam , cuz he has a lot of overlaps and some other speaker who also has e enough speech\nYeah .\nand just sort of look at those three cases of Adam and the other person and the overlaps ,\nYeah .\nmaybe  and just look at the distributions , maybe there is a clear pattern\nYeah .\nbut we just can't see it because there 's too many combinations of  of people that can overlap .\nUh - huh . Yeah .\nI had the same intuition last  last  last week .\nSo . Just seems sort of complex .\nYeah .\nI think it 's  to start with it 's s your  your idea of simplifying , starting with something that  you can see  eh you know without the  extra  layers of\nRight . Cuz if energy doesn't matter there , like  I don't think this is true , but what if\nTo study individual ?\nSorry , what ?\nHmm ?\nTo study individual ?\nWell , you  you  you don't have to study everybody individually\nWell , to study the simplest case to get rid of extra\nThe  the  the  But  Consider\nbut  just simple case and the one that has the lot of data associated with it .\nRight . Cuz what if it 's the case and I don't think this is true\nThat was a great overlap by the way .\nWhat if it 's the case that when two people overlap they equate their  you know , there 's a  conservation of energy and everybody  both people talk more softly ? I don't think this happens at all .\nOr  or what if what if the equipment  what if the equipment adjusts somehow ,\nOr they get louder .\nthere 's some equalizing in there ?\nYeah or\nUh , no we don't have that .\nI mean .\nWell , but  But I think that 's what I was saying about different types of overlap .\nOK .\nBut .\nSaturation .\nThere are  there are different types , and within those types , like as Jose was saying , that  sounded like a backchannel overlap , meaning the kind that 's  a friendly encouragement , like \" Mm - hmm . \" , \" Great ! \" , \" Yeah ! \"\nYeah .\nAnd it doesn't take  you don't take the floor . Um , but , some of those , as you showed , I think can be discriminated by the duration of the overlap .\nYeah .\nSo . It  Actually the s new student , Don , who um Adam has met , and he was at one of our meetings  He 's  getting his feet wet and then he 'll be starting again  in mid - January . He 's interested in trying to distinguish the types of overlap . I don't know if he 's talked with you yet . But in sort of honing in on these different types\nYeah . I don't consi Now I don't consider that possibility .\nand  So maybe\nThis is a s a general studio of the overlapping we 're studying the  i\nYeah . Well  I  I  I  I would s actually still recommend that he do the overall thing\nSo it might be something that we can  help by categorizing some of them and then , you know , look at that .\nbecause  it would be the quickest thing for him to do . He could  You see , he already has all his stuff in place ,\nYeah .\nhe has the histogram mechanism , he has the stuff that subtracts out  and all he has to do is change it uh uh from  from log to plain energy and plot the histogram and look at it . And then he should go on and do the other stuff bec but  But this will\nYeah . Yeah , no . I didn't mean that  that  for you to do that , but I was thinking if  if Don and I are trying to get  categories\nMm - hmm . Mm - hmm .\nand we label some data for you , and we say this is what we think is going  So you don't have to worry about it . And here 's the three types of overlaps .\nYeah .\nAnd we 'll  we 'll do the labelling for you .\nYeah .\nHm - hmm .\nUm .\nConsider different class of overlap ?\nYeah , that we would be working on anyway .\nIf there 's time .\nThen maybe  you can try some different things for those three cases , and see if that helps , or\nYeah . Yeah . This is the thing I  I comment with you before , that uh we have a great variation of th situation of overlapping .\nMm - hmm .\nAnd the behavior for energy is , uh log energy ,  is not uh the same all the time .\nMm - hmm .\nAnd\nBut I guess I was just saying that  that right now uh from the means that you gave , I don't have any sense of whether even , you know , there are any significant number of cases for which there is distinct  and I would imagine there should be some  you know , there should be  The distributions should be somewhat separated .\nYeah . Yeah .\nUh and I  I would still guess that if they are not separated at all , that there 's some  there 's  there 's most likely something wrong in the way that we 're measuring it .\nYeah . Yeah .\nUm , but  um For instance , I mean I wouldn't expect that it was very common overall , that when two people were talking at the same time , that it would  that it really was lower ,\nYeah .\nalthough sometimes , as you say , it would .\nYeah .\nSo . So .\nYeah , no , that was  That was a jok\nYeah .\nYeah .\nor a sort of , a case where  where you would never know that unless you actually go and look at two individuals .\nI mean . No . It could  it probably does happen sometimes .\nYeah .\nRight .\nYeah . Yeah .\nMind if I turned that light off ?\nYeah .\nSo .\nThe flickering is annoying me .\nOK .\nIt might the case , though , that the significant energy , just as Jose was saying , comes in the non - backchannel cases . Because in back Most people when they 're talking don't change their own  energy when they get a backchannel , cuz they 're not really predicting the backchannel .\nMm - hmm .\nAnd sometimes it 's a nod and sometimes it 's an \" mm - hmm \" .\nYeah .\nAnd the \" mm - hmm \" is really usually very low energy .\nYeah .\nSo maybe those don't actually have much difference in energy . But  all the other cases might .\ne  e and  and again what they  what difference there was would kind of be lost in taking the log ,\nand the backchannels are sort of easy to spot s in terms of their words or  I mean , just listen to it .\nYeah .\nSo .\nso , as well .\nWell , it would be lost  no matter what you do .\nBut  Yeah .\nIt just\nMmm , no , if it 's  if i if it 's\nTone\nWell , it won't be as big .\nI mean , even if you take the log , you can  your model just has a more sensitive  measures .\nYeah .\nSure , but tone might be very\nSo .\nYeah , you 're \" mm - hmm \" tone is going to be very different .\nYeah . Right . Right .\nYou could imagine doing specialized ones for different types of backchannels , if you could  if you had a good model for it . Your \" mm - hmm \" detector .\nIf  if you 're  a I guess my point is , if you 're doing essentially a linear separation , taking the log first does in fact make it harder to separate .\nRight .\nSo it 's  So , uh if you i i So i if there  if there close to things it does\nYeah .\nYeah .\nit 's a nonlinear operation that does in fact change the distinction . If you 're doing a non if you 're doing some fancy thing then  then yeah . And right now we 're essentially doing this linear thing by looking across here and  and saying we 're going to cut it here . Um and that  that 's the indicator that we 're getting . But anyway , yeah , we 're not  disagreeing on any of this , we should look at it more uh  more finely , but uh uh I think that  This often happens , you do fairly complicated things , and then you stand back from them and you realize that you haven't done something simple . So uh , if you generated something like that just for the energy and see , and then , a a a as  as Liz says , when they g have uh uh smaller um , more coherent groups to look at , that would be another interesting thing later .\nUh - huh .\nAnd then that should give us some indication  between those , should give us some indication of whether there 's anything to be achieved f from energy at all .\nUh - huh .\nAnd then you can move on to the uh  uh more {nonvocalsound} pitch related stuff .\nMm - hmm . I  I  I think this is a good idea .\nOK .\nMm - hmm .\nNot consider the log energy .\nYeah . But then the  Have you started looking at the pitch related  stuff at all , or  ? Pitch  related ?\nThe  ?\nHarmonicity and so on ?\nI  I 'm preparing the  the program but I don't  I don't begin because eh  I saw your email\nPreparing to  Yeah .\nand  I agree with you it 's better to  I suppose it 's better to  to consider the  the energy this kind of parameter  bef\nYeah . Oh , that 's not what I meant . No , no . I  I  I  I  Well , we certainly should see this but I  I  I  I think that the harm I certainly wasn't saying this was better than the harmonicity and pitch related things I was just saying\nI  I go on with the  with the pitch ,\nYeah .\naha !  OK .\nYeah , I was just saying\nI  I  I  I understood uh that eh  I  I had to finish  by the moment with the  and  and concentrate my  my energy in that problem .\nOK . OK .  OK . But I think , like , all these derivatives and second derivatives and all these other very fancy things , I think I would just sort of look at the energy  and then get into the harmonicity as  as a suggestion .\nOK . I go on with the pitch .\nUh OK . So maybe uh since w we 're trying to uh compress the meeting , um , I know Adam had some form stuff he wanted to talk about and did you have some ?", "topic_id": 1, "keywords": "constraint, frames, log, frame, normalizations", "dialogue_id": 18}, {"text": "I wanted to ask just s something on the end of this top topic . So , when I presented my results about the uh distribution of overlaps and the speakers and the profiles of the speakers , at the bottom of that I did have a proposal ,\nUh - huh .\nand I had plan to go through with it , of  of co coding the types of overlaps that people were involved in s just with reference to speaker style so , you know , with reference\nOh .\nand you know I said that on my  in my summary ,\nThat 'd be great .\nthat  you know so it 's like people may have different amounts of being overlapped with or overlapping\nYeah , I remem Right .\nbut that in itself is not informative without knowing what types of overlaps they 're involved in so I was planning to do a taxonomy of types overlaps with reference to that .\nThat would be great .\nSo , but it you know it 's like it sounds like you also have uh something in that direction .\nThat would be really great .\nYeah .\nHmm .\nIs  is it\nWe have nothing  You know , basically , we got  his environment set up . He 's  he 's a double - E  you know . So . It 's mostly that ,  if we had to  label it ourselves , we  we would or we 'd have to , to get started , but if   It  it would be much better if you can do it . You 'd be much better  at doing it also because  you know , I  I 'm not  I don't have a good feel for how they should be sorted out ,\nInteresting .\nand I really didn't wanna go into that if I didn't have to . So if  If you 're w willing to do that or  or\nIt would be interesting , though , to talk , maybe not at the meeting , but at some other time about what are the classes .\nWell maybe we can OK .\nYeah .\nMm - hmm .\nYeah .\nMm - hmm .\nI think that 's a research  effort in and of itself ,\nYeah .\nYeah , it would be interesting .\nbecause you can read the literature , but I don't know how it 'll  turn out\nYeah .\nand , You know , it 's always an interesting question .\nIt seems like we also s with reference to a purpose , too , that we we 'd want to have them coded .\nI would think it 's interesting , yeah . Yeah .\nThat 'd be great .\nYep .\nYeah .\nOK .\nThat 'd be really great .\nI can do that .\nAnd we 'd still have some  funding for this project ,\nuh uh\nlike probably , if we had to hire some  like an undergrad , because uh Don is being covered half time on something else\nMm - hmm .\nI mean , he  we 're not paying him  the full RA - ship for  all the time . So .  um If we got it to where we wanted  we needed someone to do that  I don't think there 's really enough data where  where\nMm - hmm . Yeah , I see this as a prototype , to use the only the  the already transcribed meeting as just a prototype .\nYeah .\nYeah .\nI  I think a a another parameter we c we  we can consider is eh the  duration .\nBut\nMm - hmm .\nAnother e e m besides eh the  the class of overlap , the duration . Because is possible  eh some s s um eh some classes eh has eh  a type of a duration , eh ,  a duration very short uh when we have   we have overlapping with speech .\nMm - hmm .\nYeah , definitely .\nYeah , maybe  It may be correlated . Mm - hmm .\nIs possible to have . And it 's interesting ,  I think ,  to consider the  the window of normalization , normalization window . Eh  because eh if we have a type of ,  a kind of eh overlap , eh backchannel overlap , with a short duration , is possible  eh to normali i i that if we normalize eh with eh  eh consider only the  the eh window eh by the left eh ri eh  side on the right side overlapping with a  a very  eh oh a small window eh the  if the fit of normalization is eh mmm bigger eh in that overlapping zone eh very short\nMm - hmm .\nYeah , that 's true . The window shouldn't be larger than the backchannel .\nI  I me I  I understand . I mean that you have eh you have a backchannel , eh , eh  you have a overlapping zone very short\nYeah .\nand you consider eh n eh all the channel to normalize this very short eh\nMm - hmm . Mm - hmm .\nfor example \" mmm mm - hmm hmm \" eh And the energy is not eh height eh I think if you consider all the channel to normalize and the channel is  mmm bigger  eh eh eh compared with the  with the overlapping eh duration ,\nMm - hmm .\neh the effect is mmm stronger eh  that I  I mean the  the e effect of the normalization eh with the mean and the  and the variance eh is different that if you consider  only a  window compared eh with the n the duration of overlapping .\nMm - hmm . You  you want it around the overlapping part .\nNot  Yeah .\nYou want it to include something that 's not in overlapping\nYeah .\nMm - hmm .\nbut  but uh\nYeah . I  I don't know .\nYeah .\nIs  s If\nWell it 's a sliding window , right ? So if you take the  the measure in the center of the overlapped  piece , you know , there 'd better be some something .\nMm - hmm .\nYeah . Yeah .\nBut if your window is really huge then yeah you 're right you won't even\nYeah , This is the  This is the  the idea ,  to consider only the  the small window near  near  near the  the overlapping zone .\nThe portion of the   of the backchannel won't  won't effect anything . But you  Yeah . So . You know , you shouldn't be more than like   You should definitely not be three times as big as your  as your  backchannel .\nYeah .\nMm - hmm .\nThen you 're gonna w have a wash . And hopefully it 's more like on the order of\nI 'm not sure that 's  necessarily true .\nYeah ?\nIt is an empirical question , it seems like .\nBecause  because it  because um again if you 're just compensating for the gain ,\nYea\nYeah .\nYeah .\nyou know , the fact that this  this gain thing was crude , and the gain wh if someone is speaking relatively at consistent level , just to  to give a  an extreme example , all you 're doing is compensating for that . And then you still s And then if you look at the frame with respect to that , it still should  should uh change\nYeah , it depends how different your normalization is , as you slide your window across .\nMm - hmm .\nI mean . That 's something we don't know .\nIt 's possible to try it both ways ,\nWell , I mean we 're also talking about a couple of different things .\nisn't it ? in this small\nI mean , one is your analysis window and then the other is any sort of normalization that you 're doing .\nYeah I was talking about the n normalization window .\nAnd the  And they could be quite different .\nRight .\nYeah .\nYeah .\nThis was sort of where  where we were last week .\nYep .\nYeah . That 's true . Yeah .\nBut , anyway We  we 'll have to look at some core things .\nOK .\nUm . But that 'd be great if  if you 're marking those\nOK .\nGreat .\nand  um .\nOK .\nBut it is definitely true that we need to have the time marks ,\nYeah .\nMm - hmm .\nand I was assuming that will be inherited because , if you have the words and they 're roughly aligned in time via forced alignment or whatever we end up using , then you know , this  student and I would be looking at the time marks\nYep , I agree . Mm - hmm . Coming off of the other\nand classifying all the frames inside those as whatever labels Jane gave\nYeah .\nGood . So , it wouldn't be  I wasn't planning to label the time marks .\nI can give you my transcription file ,\nI was thinking that that would come from the engineering side ,\nI don't think you need to .\nno ?\nyeah .\nYeah . That should be linked to the words which are linked to time somehow ,\nThere you go .\nWell we 're not any time soon going to get a forced alignment .\nright ? Not now .\nSo .\nYeah .\nUm If it 's not hand - marked then we 're not going to get the times .\nWell , it 's something that w Well , we  we wouldn't be able to do any work without a forced alignment anyway ,\nYes\nso somehow if  once he gets going we 're gonna hafta come up with one\nYes .\nand Yeah .\nI mean w I guess we could do a very bad one with Broadcast News .\nGood . Good .\nSo whatever you would label would be attached to the words , I think .\nGreat ! Good , good . Mm - hmm .\nYeah .\nWell again for the close  mike stuff , we could come up  take a s take the Switchboard system or something ,\nThat might be good enough . Yeah .\nand  Um\nIt 'd be worth a try . It would be interesting to see what we get .\nJust , you know , low - pass filter the speech and\nCuz there 's  there 's a lot of work you can't do without that , I mean , how  how would you\nYeah .\nYou 'd have to go in and measure every start and stop point next to a word\nYep .\nIt would be very inefficient .\nis y if you 're interested in anything to do with words .\nYeah .\nMm - hmm .\nSo . Anyway  So that 'd be great .\nGood . OK .\nYeah .\nThere 's something we should talk about later but maybe not just now . But , uh , should talk about our options as far as the uh uh  transcription\nYep , if IBM doesn't\nBut . Well , w But we 'll do that later .\nOK . Good .\nDo we hafta  turn\nYeah . Let 's do that later .\nAre we supposed to keep recording here ?\nYeah  Right .\nYeah .\nWe 'll talk about it later .\nYeah .\nSo  uh Uh \" forms \" .\nForms Next iteration of forms .\nYou had something on forms .\nOops .", "topic_id": 2, "keywords": "overlaps, overlap, overlapping, overlapped, speaker", "dialogue_id": 18}, {"text": "Oh ! Oh good , OK .\nUm . Oh .\nHow  So it 's two pages per person ?\nNope . One 's a digit form , one 's a speaker form .\nOh !\nSo one is a one time only  speaker form and the other is the digits .\nOh , I see .\nOh it 's the same . Oh no no . Is  is new Is OK .\nSo don't fill these out .\nAlright .\nThis is just the suggestion for uh what the new forms would look like . So , they incorporate the changes  that we talked about .\nDate and time . Uh why did you switch the order of the Date and Time fields ? This is rather a low - level , but\nOn which one ?\nOn  on the new one , Time comes first and then Date , but I thought\nOh you mean on the digit form ?\nThis is  this is rather a low level question , but  but it used  used to be Date came first .\nUh , because the user fills out the first three fields and I fill out the rest .\nOh I see .\nSo it was intentional .\nWell , how would the  How would the user know the time if they didn't know the date ?\nIt 's an interesting observation , but it was intentional . Because the date is when you actually read the digits and the time and , excuse me , the time is when you actually read the digits , but I 'm filling out the date beforehand . If you look at the form in front of you ? that you 're going to fill out when you read the digits ? you 'll see I 've already filled in the date but not the time .\nYeah . I always assumed  So the time is supposed to be pretty exact , because I 've just been taking beginning time  time of the meeting .\nYeah , me too .\nYeah , I 've noticed that in the forms .\nYeah , I  yeah .\nThe  the reason I put the time in , is so that the person who 's extracting the digits , meaning me , will know where to look in the meeting , to try to find the digits .\nMe too . Oh !\nOh dear . We 've been  we 've been messing up your forms .\nBut  I am put  I am putting the beginning of the meeting .\nI know .\nSo you should call it , like , \" digits start time \" . Or .\nAnd I haven't said anything . Yep .\nin  on there .\nWhy  What  what were you putting in ?\nOh , well , I was saying if we started the meeting at two thirty ,\nYeah .\nI 'd put two thirty , and I guess d e everyone was putting two thirty ,\nOh .\nYeah .\nNo , it 's about fifty fifty .\nand I didn't realize there was \" uh oh I 'm about to read this and I should \"\nActually it 's about one third each . About one third of them are blank , about one third of them are when the digits are read , and about one third of them are when the  meeting starts . So .\nOh .\nThis would be a radical suggestion but\nI could put instructions ? Nah .\nEi - either that or maybe you could maybe write down when people  start reading digits on that particular session .\nYeah .\nBut if I 'm not at the meeting , I can't do that .\nI know , OK . That 's a good point .\nYeah , he 's been setting stuff up and going away . So .\nI see . Good point good point .\nFor some reason he doesn't want to sit through every meeting that 's\nYep , but that is the reason Name , Email and Time are where they are .\nOh , OK . Alright .\nYeah .\nI rest my\nAnd then the others are later on .\nUh - huh .\nOK . w\nAnd the Seat is this number ?\nMm - hmm .\nSeat and Session .\n\" For official use only \" That 's   Well , he 's very professional .\n\" use only \"\nActually you could  Well that does raise another question , which is why is the \" Professional use only \" line not higher ? Why doesn't it come in at the point of Date and Seat ? Oh . Because we 're filling in other things .\nWhat ?\nWhat ?\nWell , because  If y your  your professional use , you 're gonna already have the date , and the s\nWhat  which form are you talking about ?\nWell I 'm comparing the new one with the old one . This is the digit form .\nOh .\nOh you 're talking about the digit form .\nDigit . Digit form .\nYeah .\nThe digit form doesn't  The digit\nOh ! I wasn't supposed to\nYeah .\nNo , that 's alright .\nSorry . Sorry .\nThe digit form doesn't have a \" for official use only \" line . It just has a line ,  which is what you 're supposed to read .\nThat  uh OK .\nSo on the digits form , everything above the line is a fill - in form\nSorry about that . Yeah .\nand everything below the line is digits that the user reads .\nYeah . OK . Alright s but I didn't mean to derail our discussion here , so you really wanted to start with this other form .\nNo , either way is fine I just  You just started talking about something , and I didn't know which form you were referring to .\nAlright yeah , I was comparing  so th this is  So I was looking at the change first . So it 's like we started with this and now we 've got a new version of it wi  with reference to this . So the digit form , we had one already . Now the f the fields are slightly different .\nSo the main thing that the person fills out um  is the name and email and time ?\nYeah .\nRight .\nYou do the rest ?\nAh !\nYep . Just as uh  as I have for all the others .\nWhat  And there 's an addition of the native language , which is a bit redundant .\nRight .\nThis one has Native Language and this one does too .\nThat 's because the one , the digit form that has native language is the old form not the new form .\nOh ! Thank you .  Thank you , thank you . There we go .\nYeah .\nOh , yeah . I 'll catch up here . OK , I see .\n\" South Midland , North Midland \"\nThat 's the old and that 's the new .\nYeah this was the problem with these categories , I  I picked those categories from TIMIT . I don't know what those are .\nActually , the only way I know is from working with the database and having to figure it out .\nWhat\nWith TIMIT , yeah ?\nuh - huh .\nSo , I was gonna ask\nWhat i\nSo is South Midland like Kansas ?\nwh w I mean .\nand North Midland like  like uh Illinois , or  ?\nWell yeah . Nor - um\nYeah .\nSo  so what accent are we speaking ? Western ?\nBy definition ?\nAnd for simple for  for me ?\nWell ,\nProbably Western , yeah .\nIs mean my native language Spanish  Spanish ? eh The original is the center of Spain and the  beca\nYeah , I mean you could call it whatever you want . For the foreign language we couldn't classify every single one . So I just left it blank and you can put whatever you want .\nBecause is different , the Span - uh  the Spanish language from the  the north of Spain , of the south , of the west and the\nSure .\nBut .\nSo I 'm not sure what to do about the Region field for English variety . You know , when I wrote  I was writing those down , I was thinking , \" You know , these are great  if you 're a linguist \" .\nYeah .\nBut I don't know how to  I don't know how to  I don't know how to categorize them .\nYeah .\nActually even if you   t\nYeah .\nIf you 're  if e  if y\nThis wasn't developed by  th these regions weren't\nif you 're a TI or MIT  from  nineteen eighty - five .\nYeah So I guess my only question was if  if you were a South Midland speaking region , person ? Would you know it ?\nYeah .\nMm - hmm .\nIs that what you would call yourself ?\nI don't know .\nYeah .\nYou know , I think if you 're talking  if you 're thinking in terms of places ,  as opposed to  names different peop names people have given to  different ways of talking ,  I would think North Midwest , and South Midwest would be more common than saying Midland , right , I mean , I  I went to s\nYeah . Now  the usage  Maybe we can give them a li  like a little map ? with the regions and they just  No , I 'm serious .\nNo , that 's not bad . Yeah .\nBecause it takes less time , and it 's sort of cute\ni at this   in that side  in that side of the  the paper .\nthere 's no figure .\nWell .\nWell just a little  You know , it doesn't have all the detail , but you sort of\nBut what if you moved five times and  and uh\nWell , I was thinking you could have ma multiple ones and then the amount of time\nNo , but you 're categorized . That 's the same\nso , roughly . So . You could say ,  you know \" ten years  on the east coast , five years on the west coast \" or something or other .\nWell , We  I think we don't want to get that level of detail at this form . I think that 's alright if we want to follow up . But .\nI guess we don't really know .\nI mean I  As I said , I don't think there 's a huge  benefit to this region thing . It  it gets  The problem is that for some things it 's really clear and usually listening to  it you can tell right away if it 's a New York or Boston accent , but New York and Boston are two  well , I guess they have the NYC , but New England has a bunch of very different dialects and\nMm - hmm .\nand  so does um S So do other places .\nYeah , so I picked these regions cuz we had talked about TIMIT , and those are right from TIMIT .\nRight . And so these would be  satisfying like a speech  research  community if we released the database ,\nSo .\nbut as to whether subjects know where they 're from , I 'm not sure because um I know that they had to fill this out for Switchboard . This is i almost exactly the same as Switchboard regions\nOh . OK .\nor very close . Yeah . Um And I don't know how they filled that out . But th if Midland  Yeah , Midland is the one that 's difficult I guess .\nI think a lot of people  Yeah .\nAlso Northwest you 've got Oreg - Washington and Oregon now which uh y people don't know if it 's western or northern .\nYeah , I certainly don't . I mean , I was saying I don't even know what I speak .\nIt 's like Northwest\nAm I speaking  Am I speaking Western ?\nOh , what is Northern ? Well and what  and what 's Northern ?\nI think originally it was North  Northwest\nNorthwest ?\nBut\nYeah .\nYeah , so this is a real problem . I don't know what to do about it .\nYeah .\nI wouldn't know how to characterize mine either . And  and so I would think  I would say , I 've  I 've got a mix of California and Ohio .\nI c I think at the first level , for example , we speak the same .\nI don't know .\nour  our dialects Or  whatever you  region are the same .\nUh - huh .\nBut I don't know what it is . So .\nWell , you have a like techno - speak accent I think .\na techno - speak accent ?\nYeah , you know ?\nA techno\nA  a geek region ?\nWell it 's  I mean I  you can sort of identify\nGeek region .\nit f It 's  it 's  not  not that that 's\nIs different . Is different .\nbut  but maybe that  maybe we could leave this and see what people  See what people choose and then um let them just fill in if they don't  I mean I don't know what else we can do , cuz   That 's North Midland .\nI 'm wondering about a question like , \" Where are you from mostly ? \"\nYeah .\nBut I  I 'm s I 'm  now that you mentioned it though , I am  really am confused by \" Northern \" .\nYeah .\nI agree . I agree .\nI really am .\nI agree .\nI mean , if  if you 're  in New England , that 's North .\nYeah .\nIf you 're  i if you 're\nScandinavian , the Minnesota area 's north .\nUh yeah . That 's  But that 's also North Midland ,\nYeah .\nOh , @ @ .  OK .\nright ?\nAnd  and  and Oregon and  and Oregon and Washington are  are Western , but they 're also Northern .\nYeah . Of course , that 's very different from , like , Michigan , or\nMmm .\nMm - hmm .\nuh , Idaho ?\nWell there are hardly any subjects from Idaho .\nMontana ?\nNo problem .\nJust rule them out .\nThere 's only a few people in Idaho .\nThere are hardly any subjects from \" beep \"\nYeah .\nSorry .\nMaybe  Maybe we  Maybe we should put a little map and say \" put an X on where you 're from \" ,\nNo , that 's\nAnd  is  in those\nYeah really .\nWe could ask where they 're from .\nAnd if you put\nIt 'd be pretty simple , yeah .\nYeah . But - We went back to that .\nYeah . If you put eh the state ?\nWell well we sort of\nWhere are you from mostly ?\nWe  we went  we went around this and then  a lot of people ended up saying that it\nUh - huh . Mm - hmm .\nYou know .\nWell , I like the idea of asking \" what variety of English do you speak \" as opposed to where you 're from Because th if we start asking where we 're from , again you have to start saying , \" well , is that the language you speak or is that just where you 're from ? \"\nYeah .\nHmm ?\nRight . Right .\nYeah .\nLet 's  Mm - hmm .\nI mean it gives us good information on where they 're from , but that doesn't  tell us anything\nAnd\nWe could always ask them if they 're from\nwell , enough about their\nI mean . So  so I would say Germany\nlike\nYou know am I speaking with German accent\nOh .\nI don't think so .\nWell , see , I 'm thinking \" Where are you from mostly \"\nRight .\nOh , OK yeah .\nbecause , you know , then you have some  some kind of subjective amount of time factored into it .\nYeah . Yeah .\nYep . Yeah , I guess I could try to put  squeeze in a little map .\nYeah .\nI mean there 's not a lot of r of room\nI 'd say , uh , \" Boston , New York City , the South and Regular \" .\nWell\nOh , I don't know .\nI think of those , Northern is the only one that I don't even know what they 're meaning .\nYeah . Yeah .\nAnd  And   Um  And usually here  people here know what is their kind of mmm lang English language ?\nThat 's a joke . That 's\nSo let 's make it up . S I mean , who cares . Right ? We can make up our own  So we can say \" Northwest \" , \" Rest of West \" or something . You know . \" West \" and I mean .\nYe I don't think the Northwest people speak any differently than I do .\nIt doesn't even  Yeah , exactly . That 's not really a region .\nI\n\" Do you come from the Louisiana Purchase ? \"\nSo we could take out \" North \"  \" Northern \" .\nThat  that 's exactly what we 're arguing about .\neh here Is easy for people to know ?\nThat 's  Yeah , w It 's  In  It 's  it 's harder in America anywhere else , basically .\nWe don't know .\nbecause you have\nI mean some of them are very obvious . If you  if you talk to someone speaking with Southern drawl , you know .\nN m Yeah .\nYeah , or Boston .\nOr Boston , yeah .\nI can't do it , but\nOr Boston ?\nYeah .\nAnd those people , if you ask them to self - identify their accent they know .\nYeah .\nYeah , they do .\nThey know very well .\nYeah I agree I agree . I agree .\nThey know they don't speak the same as the\nBut is Boston New England ?\nAnd they 're proud of it .\nday o\nYeah .\nYeah , exactly .\nIt 's identity thing .\nAnd they 're glad to tell you .\nstyle .\nWell . Depends who you ask , I suppose .\nW  I guess that 's the problem with these categories .\nBut that 's why they have New York City but\nWell , we ca Well , why can't we just say characterize  something like char characterize your accent\nWell , Boston 's @ @ , too .\nOr  \" Characterize your accent  if you can . \"\nand  and so I would say , \" I don't know \" .\nYeah . Right , which probably means you have a very\nBut someone from Boston with a really strong coloration would know . And so would an R - less Maine  or something ,\nAnd that 's actually good .\nYeah .\nyeah .\nI was  I was thinking of something along that line\nHow\nGood .\nbecause  if you don't know , then , you know , ruling out the fact that you 're totally  inept or something ,\nHmm .\nif somebody doesn't know , it probably means their accent isn't very strong compared to the sort of midwest standard .\nWell ,  I mean , it wasn't that long ago that we had somebody here who was from Texas who was absolutely sure that he didn't have any accent left .\nHmm ?\nAnd  and had  he had a pretty  noticeable drawl .\nOK , so . I propose ,  take out Northern add , don't know .\nOh .  Yeah . I  I would say more  more sweepingly , \" how would you characterize your accent ? \"\nYeah .\nSo you want to change the instructions also not just say region ?\nW\nWell , I think this discussion has made me think that 's s something to consider .\nI don't know if I  if I read this form , I think they 're going to ask  it  they 're going to answer the same way if you say , \" What 's variety of English do you speak ? Region . \" as if you say \" what variety of region  region  do you speak ? Please characterize your accent ? \" They 're going to answer the same way .\nI guess  Well , I was not sure that  I\nMmm .\nSo . I was suggesting not having the options , just having them\nOh , I see .\nHuh .\nWell what we talked about with that is  is so that they would understand the granularity .\nYes , but if , as Liz is suggesting , people who have strong accents know that they do\nI mean that 's what I had before , and you told me to list the regions to list them .\nand are  Well , I know .\nRight .\nEach  each one has pros and cons\nSo .\nRight .\nThat 's true .\nRight .\nI mean we  we\nYeah last week  last week I was sort of r arguing for having it wide open , but then everybody said \" Oh , no , but then it will be hard to interpret because some people will say Cincinnati and some will say Ohio \" .\nI mean I had it wide open last week and  and you said TIMIT .\nAnd .\nYeah .\nYeah .\nWhat if we put in both ?\nThat 's what the \" Other \" is for .\nAnd  Would people  No , I mean what if we put in both ways of asking them ? So . One is  Region and the another one is \" if you had to characterize yourself  your accent , what would you say ? \"\nWon't they answer the same thing ?\nWell they might only answer only one of the questions but if\nYeah that 's fine .\nYou know .\nThey might say \" Other \" for Region because they don't know what category to use\nActually\nbut they might have something\nRight .\nbecause it is easier to have it open ended .\nIt just  And we  we might learn from what they say , as to which one 's a better  way to ask it .\nW This is just a small thing\nBut  I  Cuz I really don't know .\nbut um It says \" Variety \" and then it gives things that e have American as one of the choices . But then it says \" Region \" , but Region actually just applies to uh , US ,\nRight .\nright ?\nI mean that 's why I put the \" Other \" in .\nWell , we thought about it .\nAh , OK .\nYeah , OK . We just  We sort of thought , \" yes ,  \" y y I mean\nS\nAt the last meeting , my recollection was that  we felt people would have uh less  that  that there are so many types and varieties of  these other languages and we are not going to have that many subjects from these different language groups\nYep .\nand that it 's a huge waste of  of space .\nOK .\nSo I mean , I  I mean the way I had it last time  was Region was blank ,\nThat 's what I thought .\nit just said Region colon .\nYeah .\nAnd  and I think that that 's the best way to do it ,\nYeah .\nbecause  because of the problems we 're talking about but what we said last week , was no , put in a list , so I put in a list . So should we go back to\nMaybe we can make the list a little smaller .\nWell , certainly dropping \" Northern \" I think is right , because none of us know what that is .\nCuz , I mean  And keeping \" Other \" , and then  maybe this North Midland , we call it \" North Midwest \" . South  Midwest , or just\nYes I  I  I think so . Yeah .\nSouth Midwest . Does that make sense ?\nSouth Midwest ?\nThat would help me\nU unless you 're from Midland , Kansas .\nYeah . Cuz  Midland\nBut . Yeah .\nI don't know where Midland is\nThere 's a  Or Midland  Midland\nIs \" Midwest \" one word ?\nIs it Midland  Midland  Midland , Texas or Midland , Kansas ? I forget .\nY yeah , one w\nBut there 's a town . in  in there .\nOh .\nI forget what it is @ @ .\nI don't think that 's what they mean .\nBut ,\nYeah .\nyeah . So . Kansas would be  South Midland . Right ?\nY yeah .\nAnd  and wouldn't  Yeah .\nAnd Colorado , right across the border , would be  North Midland .\nSo , th I 'm from Kansas , actually .\nSouthern Midland .\nYeah .\nAnd uh\nColora Oh , right . And then , the  the  dropping North , so it would be Western . It 's just one big shebang , where , of course , you have huge variation in dialects ,\nBut that 's true of New England too .\nBut you do in the others , too . So .\nbut   but so do you\nSo . I mean only one\nYeah .\nYeah .\nYeah . Yeah .\nWell , I shouldn't say that . I have no clue . I was going to say the only one that doesn't have a huge variety is New York City . But I have no idea whether it does or not .\nIt does seem  I mean . I  I would think that these categories would be more  w would be easier for an an analyst to put in rather than the subject himself .\nU\nI think that  that was what happened with TIMIT , was that it was an analyst .\nOK .\nWait a minute . Where does  Where does   d w Where  Where 's  where does uh  New  New York west of  west of uh New York City and  Pennsylvania  uh and uh\nYeah , I don't know how it came from .\nOK .\nNew England\nSo . That 's New England I think .\nN No , it 's not .\nYeah .\nOh , no .\nI sort of thought they were part of the  one of the Midlands .\nOh no . No , no .  No . Pennsylvania is not\n\" Other \" , it goes under \" Other \" , definitely under \" Other \" .\nWell , you know , Pennsylvania has a pretty strong dialect and it 's totally different than\nPennsylvania  Yeah . Pennsylvania is not New England . and uh New Jersey is not New England and Maryland is not New England and none of those are the South .\nOK . So . Another suggestion . Rather than have circle fill in forms , say \" Region , open paren , E G Southern comma Western comma close paren colon . \"\nYeah . OK .\nOK !\nFine by me , fine by me .\nThat 's good . I like that .\nSure !\nYeah .\nYeah .\nWe 're all  sufficiently  tired of this that we 're agreeing with you .\nLet 's just  And we 'll see what we get .\nYeah .\nBe easier on the subjects . I think that 's fine . No . I think\nSo .\nI like that . I like that .\nYou like it ?\nYeah , I do .\nOK .\nActually , maybe we do one non - English one as well .\nGood .\nSouthern , Cockney ?\nYeah , and\nYeah .\nIs that a  real accent ?\nSure , yeah !\nHow do you spell it ?\nYeah .\nI think that 's fine .\nCockney ?\nN E\nCO  Yeah .\nYou could say Liverpool .\nLiverpuddlian .\nYeah . Alright .\nActually , Liverpool doesn't l Yeah . It 's   I 'm s I ha\nWell . Well . I mean , pure\nOK , we 'll do it that way . Actually , I like that a lot . Because that get 's at both of the things we were trying to do ,\nOK .\nthe granularity , and the person can just self - assess and we don't have to argue about what these regions are .\nThat 's right . And it 's easy on the subjects .\nOK .\nYeah .\nYep .\nNow I have one suggestion on the next section .\nMm - hmm .\nMm - hmm .\nSo you have native language , you have region , and then you have time spent in English speaking country . Now , I wonder if it might be useful to have another open field saying \" which one parenthesis S  paren closed parenthesis \" . Cuz if they spent  time in  in Britain and America\nYes .\nIt doesn't have to be ex all  at all exact , just in the same open field format that you have .\nYep , just which one . I think that 's fine .\nMm - hmm . with a  with an S\nMm - hmm .\n\" which one sss ,  optional S .\nOK .\nYeah .\nWe uh  We done ?\nYep .\nYeah , that 's good .\nOK . um s e Any  any other uh open mike topics or should we go  right to the digits ?", "topic_id": 3, "keywords": "date, forms, form, digits, format", "dialogue_id": 18}, {"text": "Um , did you guys get my email on the multitrans ? That  OK .\nIsn't that wonderful ! Yeah .\nYeah . So . So . I  I have a version also which actually displays all the channels .\nExcellent ! Thank you !\nIt 's really great .\nBut it 's hideously slow .\nSo you  this is n Dan 's patches , Dan Ellis 's patches .\nThe  what  the ones I applied , that you can actually do are Dan 's , because it doesn't slow it down .\nM\nFantastic !\nJust uses a lot of memory .\nSo when you say \" slow \" , does that mean to\nNo , the  the one that 's installed is fine . It 's not slow at all . I wrote another version . Which , instead of having the one pane with the one view , It has multiple panes  with the views .\nYeah .\nMm - hmm .\nBut the problem with it is the drawing of those waveforms is so slow that every time you do anything it just crawls .\nMm - hmm .\nIt 's really bad .\nIt 's  So , it  it 's the redrawing of the w\nThat 's a consideration .\nMm - hmm .\noh uh - huh , w as you move .\nAs you play , as you move , as you scroll . Just about anything , and it  it was so slow it was not usable . So that 's why I didn't install it and didn't pursue it .\nAnd this 'll be a  hav having the multiwave will be a big help cuz  in terms of like disentangling overlaps and things , that 'll be a big help .\nOh yeah .\nSo . I think that the one Dan has is usable enough .\nYeah .\nIt doesn't display the others . It displays just the mixed signal .\nMm - hmm .\nBut you can listen to any of them .\nThat 's excellent . He also has version control which is another nice\nYeah .\ne so you  e the patches that you\nNo , he suggested that , but he didn't   It 's not installed .\nOh , I thought it was in one of those patches .\nNo . No .\nOh OK . Well . Alright .\nSo is there any hope for actually displaying the wave form ?\nUm , not if we 're going to use Tcl - TK At least not if we 're going to use Snack .\nOK .\nI mean you would have to do something ourselves .\nWell , or use the one that crawls .\nOK . Well , I 'm  I probably would be trying to use the   whatever 's there . And it 's useful to have the\nWhy don't we  we see how Dan 's works and if it  If we really need the display\nYeah . I mean . I wonder  I 'm just wondering if we can display things other than the wave form . So . Suppose we have a feature  a feature stream . And it 's just , you know , a  a uni - dimensional feature , varying in time .\nYeah .\nAnd we want to plot that , instead of the whole wave form .\nI mean .\nThat might be faster .\nYeah .\nRight ?\nWe  we could do that but that would mean changing the code .\nSo .\nYeah .\nI mean this isn't a program we wrote .\nYeah .\nThis is a program that we got from someone else , and we 've done patches on .\nOK .\nMm - hmm .\nOK . Well , I 'll talk to you about it and we can see\nSo .\nCou - i e I mean , y\nYeah .\nYeah .\nbut it 's definitely  great to have the other one .\nIf there was some  Is there some way to  have someone write patches in something faster and  and  link it in , or something ?\nThat 's\nNot easily .\nOr is that\nI mean y yes we could do that . You could  you can write widgets in C . And try to do it that way but I just don't think  it\nYeah .\nLet 's try it with Dan 's and if that isn't enough , we can do it otherwise .\nRight .\nI think it is , cuz when I was playing with it , the mixed signal has it all in there . And so it 's really  It 's not too bad to find places in the  in the stream where things are happening .\nOK .\nSo I  I don't think it 'll be bad .\nAnd it 's also  also the case that  that uh this multi - wave thing  is proposed to the\nHmm ?\nSo . Dan proposed it to the Transcriber central people , and it 's likely that uh  So . And  and they responded favorably looks as though it will be incorporated in the future version .\nOh .\nThey said that the only reason they hadn't had the multi the parallel uh stream one before was simply that  they hadn't had time to do it . And uh  so it 's likely that this  this may be entered into the ch this central @ @ .\nYeah .\nAnd if  if\nThey may well have not had much demand for it .\nWell that 's  that 's  that 's true , too .\nYeah .\nThis is a   a useful thing for us .\nSo . You mean they could  they could do it and it would be  fast enough if they do it ?\nYeah .\nDepends on how much work they did .\nOh . No . I just mean  I just mean that it 's  that  that his\nOr  ?\nOh .\nSo .  This one that we now have does have the status of  potentially being incorporated l likely being incorporated into the central code .\nMm - hmm . OK .\nNow , tha Now , if we develop further then , y uh , I don't\nI think if  if  if one of us sat down and coded it , so that it could be displayed fast enough I 'm sure they would be quite willing to incorporate it .\nI mean it 's  I think it 's a nice feature to have it  set that way . Mm - hmm .\nBut it 's not a trivial task .\nMm - hmm . Yeah .\nOK .\nI just like the idea of it being something that 's , you know , tied back into the original , so that other people can benefit from it .\nYeah .\nYeah . However . I also understand that you can have  widgets that are very useful for their purpose and that you don't need to always go that w route . Yeah .\nOK .\nanyway , shall we do digits ?\nYeah .\nYeah . Let 's do digits , uh , and then we 'll turn off the mikes , and then I have one other thing to discuss .\nOK .\nOK .\nI actually have to leave . So . Um . I mean  I had to leave at three thirty ,\nUh - oh .\nOK .\nOh .\nso I can   Well , I can wait  for the digits but I can't stay for the discussion\nWell , you want to go first ? Or .\nI c  I have to make a call .\nOK .\nSo .\nWell , should we  e should we switch off the g\nWell , we 'll talk to you about it   Uh\nDo you wanna go do digits or do you wanna just skip digits ?\nUm . No , I can do digits if  if  But I don't wanna butt in , or something .\nThen  Alright . You go ahead .\nBut if there 's something on the rest of the  I 'm  I 'll be around just have to make call before quarter of . So .", "topic_id": 4, "keywords": "multiwave, slow, waveforms, channels, view", "dialogue_id": 18}, {"text": "Mm - hmm .\nSo I  Or we can talk about it .\nKe\nWhy don't you read the digits ?\nYeah , why don't you read the digits and then you can  go .\nOK .  Alright . Oh , this is the new one .\nYeah , don't  Don't read the old one .\nYeah .\nAlright . The  And the time is . OK .\nOK\nTurn it off .\nOK .\nBut wait till he  OK .\nAnd", "topic_id": 5, "keywords": "digits, read, old, time, new", "dialogue_id": 18}, {"text": "Eh , we should be going .\nSo ne next week we 'll have , uh , both Birger  and , uh , Mike  Michael  Michael Kleinschmidt and Birger Kollmeier will join us .\nUh - huh .\nUm , and you 're   you 're probably gonna go up in a couple  three weeks or so ? When d when are you thinking of going up to , uh , OGI ?\nYeah , like , uh , not next week but maybe the week after .\nOK . Good . So at least we 'll have one meeting with  yo with you still around , and  and\nUh - huh .\nThat 's good .\nUm , Yeah . Well ,  maybe we can start with this . Mmm .\nAll today , huh ?\nYeah .\nOh .\nUm . Yeah . So there was this conference call this morning , um , and the only topic on the agenda was just to discuss a and to come at  uh , to get a decision about this latency problem .\nNo , this  I 'm sorry , this is a conference call between different Aurora people or just  ?\nUh , yeah . It 's the conference call between the Aurora ,  uh , group .\nIt 's the main conference call . OK .\nUh , yeah . There were like two hours of  discussions , and then suddenly ,  uh , people were tired , I guess , and they decided on {nonvocalsound} a number , two hundred and twenty , um , included e including everything . Uh , it means that it 's like eighty milliseconds  less than before .\nAnd what are we sitting at currently ?\nUm .\nYeah .\nSo , currently d uh , we have system that has two hundred and thirty . So , that 's fine .\nTwo thirty .\nYeah . So that 's the system that 's described on the second point of  this  document .\nSo it 's  we have to reduce it by ten milliseconds somehow .\nYeah . But that 's  Yeah . That 's not a problem , I  I guess .\nOK . W It 's  it 's p d primary  primarily determined by the VAD at this point ,\nUm .\nright ?\nYeah .\nS so we can make the VAD a little shorter .\nYeah . At this point , yeah .\nThat 's\nYeah , uh - huh .\nYeah . We probably should do that pretty soon so that we don't get used to it being a certain way .\nUh - huh .\nYeah .\nUm .\nWas Hari on the  on the phone ?\nYeah , sure .\nOK .\nWell , it was mainly a discussion  between Hari and  David ,\nHmm .\nwho was like\nYeah .\nUh ,\nOK .\nmmm  Uh , yeah . So , the second thing is the system that we have currently . Oh , yes . We have , like , a system that gives sixty - two percent improvement , but  if you want to stick to the   this latency  Well , it has a latency of two thirty , but  if you want also to stick to the number  of features that  limit it to sixty ,  then we go a little bit down but it 's still sixty - one percent . Uh , and if we drop the tandem network , then we have fifty - seven percent .\nUh , but th the two th two thirty includes the tandem network ?\nYeah .\nOK . And i is the tandem network , uh , small enough that it will fit on the terminal size in terms of  ?\nUh , no , I don't think so .\nNo .\nNo .\nOK .\nIt 's still  in terms of computation , if we use , like , their way of computing the  the maps  the  the MIPs ,  I think it fits ,\nMm - hmm . Mm - hmm .\nbut it 's , uh , m mainly a problem of memory .\nRight .\nUm , and I don't know how much  this can be discussed or not , because it 's  it could be in ROM , so it 's maybe not that expensive . But\nHo - how much memory d ? H how many  ?\nI d I d uh , I  I don't kn remember exactly , but   Uh . Yeah , I c I  I have to check that .\nYeah . I 'd like to  see that , cuz maybe I could think a little bit about it , cuz we  maybe we could make it a little smaller or  I mean , it 'd be  it 'd be neat if we could fit it all .\nUh - huh .\nUh , I 'd like to see how far off we are .\nMm - hmm .\nBut I guess it 's still within their rules to have  have it on the , uh , t uh , server side . Right ?\nYeah . Yeah .\nOK .\nMmm .\nAnd this is still  ? Uh , well , y you 're saying here . I c I should just let you go on .\nYeah , there were small tricks to make this tandem network work . Uh ,  mmm , and one of the trick was to ,  um , use  some kind of hierarchical structure where  the silence probability is not computed by  the final tandem network but by the VAD network . Um , so apparently it looks better when ,  uh , we use the silence probability from the VAD network\nHuh .\nand we re - scale the other probabilities by one minus the silence probability . Um . So it 's some kind of hierarchical thing ,  uh , that Sunil also tried , um ,   on SPINE and apparently it helps a little bit also . Mmm . And . Yeah , the reason w why  why we did that with the silence probability was that ,  um\nCould  ? Uh , uh , I 'm  I 'm really sorry . Can you repeat what you were saying about the silence probability ?\nMm - hmm .\nI only  My mind was some\nYeah . So there is the tandem network that e e e estimates the phone probabilities\nYeah . Yeah .\nand the silence probabilities also .\nRight .\nAnd  things get better when , instead of using the silence probability computed by the tandem network , we use the silence probability , uh , given by the VAD network ,\nOh .\num ,\nThe VAD network is  ?\nWhich is smaller , but maybe , um  So we have a network for the VAD which has one hundred hidden units , and the tandem network has five hundred . Um . So it 's smaller but th the silence probability  from this network seems , uh , better .\nOK .\nMmm . Uh . Well , it looks strange , but\nYeah . But\nbut it\nOK .\nMaybe it 's  has something to do to  the fact that  we don't have infinite training data and\nWe don't ?\nWell ! And so  Well , things are not optimal\nYeah .\nand  Mmm\nAre you  you were going to say why  what made you  wh what led you to do that .\nYeah . Uh , there was a p  problem that we observed , um ,   that there was  there were , like , many insertions in the  in the system .\nMm - hmm .\nMmm .\nHmm .\nActually plugging in the tandem network was increasing , I  I  I think , the number of insertions .\nMm - hmm .\nAnd ,  um  So it looked strange and then just using the  the other silence probability helps . Mmm . Um  Yeah . The next thing we will do is train this tandem on more data .\nSo , you know , in a way what it might  i it 's  it 's a little bit like  combining knowledge sources .\nUm\nRight ? Because  the fact that you have these two nets that are different sizes  means they behave a little differently ,\nMm - hmm .\nthey find different  things . And , um , if you have , um  f the distribution that you have from , uh , f speech sounds is w  sort of one source of knowledge .\nMm - hmm .\nAnd this is  and rather than just taking one minus that to get the other , which is essentially what 's happening , you have this other source of knowledge that you 're putting in there . So you make use of both of them  in  in  what you 're ending up with . Maybe it 's better .\nYeah .\nAnyway , you can probably justify anything if what 's use\nYeah .\nYeah .\nAnd  and the features are different also . I mean , the VAD doesn't use the same features there are .\nMm - hmm .\nHmm .\nOh !\nUm\nThat might be the key , actually .\nMm - hmm .\nCuz you were really thinking about speech versus nonspeech for that .\nMm - hmm .\nThat 's a good point .\nMmm . Uh . Well , there are other things that  we should do but ,  um ,  it requires time and   We have ideas , like  so , these things are like hav having a better VAD . Uh , we have some ideas about that . It would   probably implies working a little bit on features that are more  suited to a voice activity detection .\nMm - hmm .\nWorking on the second stream . Of course we have ideas on this also , but   w we need to try different things and  Uh , but their noise estimation , um   uh\nI mean , back on the second stream , I mean , that 's something we 've talked about for a while . I mean , I think {nonvocalsound} that 's certainly a high hope .\nYeah .  Mmm .\nUm , so we have this  this default idea about just using some sort of purely spectral thing ?\nUh , yeah .\nfor a second stream ?\nBut , um , we  we did a first try with this , and it  it  clearly hurts .\nBut , uh , how was the stream combined ?\nUh .  It was c it was just combined , um , by the acoustic model . So there was , no neural network for the moment .\nRight . So , I mean , if you just had a second stream that was just spectral and had another neural net and combined there , that  that , uh ,  might be good .\nMm - hmm . Yeah . Mm - hmm . Mm - hmm . Mmm . Yeah . Um  Yeah , and the other thing , that noise estimation and th um , maybe try to train  uh , the training data for the t tandem network , right now , is like  i is using the noises from the Aurora task and   I think that people might ,  um , try to argue about that because  then in some cases we have the same noises in  for training the network  than the noises that are used for testing ,\nRight .\nand  So we have t n uh , to try to get rid of these   this problem .\nYeah . Maybe you just put in some other noise , something that 's different .\nMm - hmm .  Yeah .\nI mean , it  it 's probably helpful to have  have a little noise there . But it may be something else\nUh - huh .\nth at least you could say it was .\nYeah .\nAnd then  if it doesn't hurt too much , though .\nUh - huh .\nYeah . That 's a good idea .", "topic_id": 0, "keywords": "conference, meeting, aurora, latency, discussions", "dialogue_id": 19}, {"text": "Um . Yeah . The last thing is that I think we are getting close to human performance . Well , that 's something I would like to investigate further , but , um , I did , like , um  I did , uh , listen to the m most noisy utterances of the SpeechDat - Car Italian and tried to transcribe them . And , um\nSo this is a particular human . This is  this i this is Stephane .\nYeah . So that 's  that 's\nSt - Stephane .\nYeah .\nthat 's the  the flaw of the experiment . This is just  i j    it 's just one subject ,\nYeah .\nGetting close .\nbut  but still , uh ,  what happens is  is that ,  uh , the digit error rate on this is around one percent ,\nYeah .\nwhile our system is currently at seven percent . Um , but what happens also is that if I listen to the , um  {nonvocalsound} a re - synthesized version of the speech and  I re - synthesized this using a white noise that 's filtered by a LPC , uh , filter\nYeah .\nUm , well , you can argue , that , uh  that this is not speech ,\nYeah .\nso the ear is not trained to recognize this . But s actually it sound like  whispering , so we are\nWell , I mean , it 's\neh\nThere 's two problems there . I mean  I mean , so  so the first is  that by doing LPC - twelve with synthesized speech w like you 're saying , uh , it 's   i i you 're  you 're adding other degradation .\nUh - huh .\nRight ? So it 's not just the noise but you 're adding in fact some degradation because it 's only an approximation . Um , and the second thing is  which is m maybe more interesting  is that , um ,   if you do it with whispered speech , you get this number . What if you had  done analysis  re - synthesis and taken the pitch as well ? Alright ? So now you put the pitch in .\nUh - huh .\nWhat would the percentage be then ?\nUm\nSee , that 's the question . So , you see , if it 's  if it 's  if it 's , uh  Let 's say it 's  back down to one percent again .\nUh - huh .\nThat would say at least for people , having the pitch is really , really important , which would be interesting in itself . Um ,\nUh , yeah . But\nif i on the other hand , if it stayed up  near five percent ,  then I 'd say \" boy , LPC n twelve is pretty crummy \" . You know ?\nUh - huh .\nSo I I I 'm not sure  I 'm not sure how we can conclude from this anything about  that our system is close to  the human performance .\nYe Yeah . Well , the point is that eh l ey  the point is that , um ,  what I  what I listened to when I re - synthesized the LP - the LPC - twelve  spectrum  is in a way what the system , uh , is hearing , cuz @ @  all the  all the , um , excitation  all the  well , the excitation is  is not taken into account . That 's what we do with our system . And\nWell , you 're not doing the LPC\nin this case\nI mean , so  so what if you did a\nWell , it 's not LPC , sure ,\nWhat if you did LPC - twenty ?\nbut  LPC  ?\nTwenty . Right ? I mean , th the thing is LPC is not a  a really great representation of speech .\nMm - hmm . Mm - hmm .\nSo , all I 'm saying is that you have in addition to the w the , uh , removal of pitch ,  you also are doing , uh , a particular parameterization ,\nMm - hmm .\nwhich , um , uh\nMmm .\nUh , so , let 's see , how would you do  ? So , fo\nBut that 's  that 's what we do with our systems . And\nNo . Actually , we d we  we don't , because we do  we do , uh ,  uh , mel filter bank , for instance . Right ?\nYeah , but is it that  is it that different , I mean ?\nUm ,  I don't know what mel ,  uh , based synthesis would sound like ,\nI\nbut certainly the spectra are quite different .\nMm - hmm .\nCouldn't you t couldn't you , um , test the human performance on just the original  audio ?\nMm - hmm . This is the one percent number .\nYeah , it 's one percent . He 's trying to remove the pitch information\nMm - hmm .\nOh , oh . OK ,\nMm - hmm .\nI see .\nand make it closer to what  to what we 're seeing as the feature vectors .\nOK . So , y uh , your performance was one percent , and then when you re - synthesize with LPC - twelve it went to five .\nUh - huh . Yeah .\nOK .\nI mean  We were  we were j It  it  it 's a little bit still apples and oranges because we are choosing these features in order to be the best for recognition .\nUh - huh .\nAnd , um , i if you listen to them they still might not be very  Even if you made something closer to what we 're gonna  i it might not sound very good .\nYeah .\nUh , and i the degradation from that might  might actually make it even harder ,  uh , to understand than the LPC - twelve . So all I 'm saying is that the LPC - twelve  puts in  synthesis puts in some degradation that 's not what we 're used to hearing ,\nUh - huh .\nand is , um  It 's not  it 's not just a question of how much information is there , as if you will always take maximum  advantage of any information that 's presented to you .\nMm - hmm .\nIn fact , you  hear some things better than others . And so it  it isn't\nBut\nBut ,  I agree that it says that , uh , the kind of information that we 're feeding it is probably ,  um , um , a little bit , um , minimal . There 's definitely some things that we 've thrown away . And that 's why I was saying it might be interesting if you   an interesting test of this would be if you  if you actually put the pitch back in . So , you just extract it from the actual speech and put it back in , and see does that  is that  does that make the difference ? If that  if that takes it down to one percent again ,  then you 'd say \" OK , it 's  it 's in fact having , um ,  not just the spectral envelope but also the  also the  the pitch  that , uh ,  @ @  has the information that people can use , anyway . \"\nUh - huh . Mmm .\nBut from this it 's pretty safe to say that the system is with either  two to seven percent away from  the performance of a human . Right ? So it 's somewhere in that range .\nWell , or it 's  it 's\nTwo  two to six percent .\nYeah , so  It 's  it 's one point four times , uh , to , uh , seven times the error ,\nTo f seven times , yeah .\nfor Stephane .\nUm .\nSo , uh  uh , but i I don't know . I do don't wanna take you away from other things .\nBut   but\nBut that 's   that 's what  that 's the first thing that I would be curious about , is , you know , i i  when you we\nBut the signal itself is like a mix of  um , of a  a periodic sound and ,  @ @  uh , unvoiced sound , and the noise\nMm - hmm .\nwhich is mostly ,  uh , noise . I mean not  periodic . So ,  what  what do you mean exactly by putting back the pitch in ? Because\nIn the LPC synthesis ? I think\nYeah . You did LPC re - synthesis\nI\nL PC re - synthesis .\nUh - huh .\nSo ,  uh  and you did it with a noise source , rather than with  with a s periodic source .\nMm - hmm .\nRight ? So if you actually did real re - synthesis like you do in an LPC synthesizer , where it 's unvoiced you use noise , where it 's voiced you use ,  uh , periodic pulses .\nUm .\nRight ?\nYeah , but it 's neither  purely voiced or purely unvoiced . Esp - especially because there is noise .\nWell , it might be hard to do it\nSo\nbut it but  but the thing is that if you   um , if you detect that there 's periodic  s strong periodic components , then you can use a voiced  voice thing .\nOh . Uh - huh . Yeah .\nYeah . I mean , it 's probably not worth your time . It 's  it 's a side thing and  and  and there 's a lot to do .\nUh - huh , yeah .\nBut I 'm  I 'm just saying , at least as a thought experiment ,  that 's what I would wanna test .\nMm - hmm .\nUh , I wan would wanna drive it with a  a  a two - source system rather than a  than a one - source system .\nMm - hmm . Mm - hmm .\nAnd then that would tell you whether in fact it 's  Cuz we 've talked about , like , this harmonic tunneling or  other things that people have done based on pitch , maybe that 's really a key element . Maybe  maybe , uh ,  uh , without that , it 's  it 's not possible to do a whole lot better than we 're doing . That  that could be .\nYeah . That 's what I was thinking by doing this es experiment ,\nYeah .\nlike  Mmm .  Evi\nBut , I mean , other than that , I don't think it 's  I mean , other than the pitch de information ,  it 's hard to imagine that there 's a whole lot more  in the signal that  that , uh  that we 're throwing away that 's important .\nYeah , but  Yeah .  Mm - hmm . Yeah , right .\nRight ? I mean , we 're using  a fair number of filters in the filter bank and  uh\nMm - hmm . Uh , yeah .\nHmm . Yeah .\nUm .\nYeah . That look\nYeah , that 's it .\nYeah . That 's  that 's  I mean , one  one percent is sort of what I would  I would figure . If somebody was paying really close attention , you might get  I would actually think that if ,  you looked at people on various times of the day and different amounts of attention , you might actually get up to three or four percent error on digits . Uh ,  uh\nMm - hmm . Um .\nSo it 's  you know , we 're not  we 're not incredibly far off . On the other hand , with any of these numbers except maybe the one percent , it 's st it 's not actually usable in a commercial system with a full telephone number or something .\nUh - huh . Yeah . At these noise levels .\nYeah .\nYeah . Mm - hmm .\nRight .\nWell , yeah . These numbers , I mean . Mmm .", "topic_id": 1, "keywords": "utterances, hearing, speechdat, noise, noisy", "dialogue_id": 19}, {"text": "Good . Um , while we 're still on Aurora stuff  maybe you can talk a little about the status with the , uh ,  Wall Street Journal  things for it .\nSo I 've , um , downloaded , uh , a couple of things from Mississippi State . Um , one is their  software  their , uh , LVCSR system . Downloaded the latest version of that . Got it compiled and everything . Um , downloaded the scripts . They wrote some scripts that sort of make it easy to run  the system on the Wall Street Journal , uh , data . Um , so I haven't run the scripts yet . Uh , I 'm waiting  there was one problem with part of it and I wrote a note to Joe asking him about it . So I 'm waiting to hear from him . But , um , I did print something out just to give you an idea about where the system is . Uh ,  they  on their web site they , uh , did this little table of where their system performs relative to other systems that have done this  this task . And , um , the Mississippi State system  using a bigram grammar , uh , is at about eight point two percent . Other comparable systems from , uh   were getting from , uh , like six point nine , six point eight percent . So they 're\nThis is on clean test set ?\nThis is on clean  on clean stuff . Yeah . They  they 've started a table  where they 're showing their results on various different noise conditions but they  they don't have a whole lot of it filled in and   and I didn't notice until after I 'd printed it out that , um ,  they don't say here  what these different testing conditions are .\nYou actually have to click on it on the web site to see them . So I  I don't know what those  numbers really mean .\nWhat kind of numbers are they getting on these  on the test conditions ?\nWell , see , I was a little confused because on this table , I 'm  the they 're showing word error rate . But on this one , I  I don't know if these are word error rates because they 're really big . So ,  under condition one here it 's ten percent . Then under three it goes to sixty - four point six percent .\nYeah , that 's probably Aurora .\nYeah .\nI mean\nSo m I guess maybe they 're error rates but they 're , uh  they 're really high .\nI  I  I don't find that surpri\nSo\nI mean , we  W what 's  what 's some of the lower error rates on  on  on  uh , some of the higher error rates on , uh ,  some of these w uh , uh , highly mismatched difficult conditions ? What 's a  ?\nUh . Yeah , it 's around fifteen to twenty percent .\nCorrect ?\nAnd the baseline , eh\nAccuracy ?\nUh , error rate .\nYeah .\nTwenty percent error rate ,\nYeah . So twenty percent error rate on digits .\nand\nOh , oh , on digits .\nSo if you 're doing  so if you 're doing ,\nand\nYeah .\nOn digits .\nOK .\nyou know ,\nAnd this is so  so  still the baseline .\nsixty - thousand\nRight ?\nYeah .\nYeah , and if you 're saying sixty - thousand word recognition , getting sixty percent error on some of these noise condition not at all surprising .\nYeah .\nThe baseline is sixty percent also on digits ,\nOh , is it ?\non the m more  mismatched conditions .\nOK .\nYeah .\nSo .\nSo , yeah , that 's probably what it is then . Yeah . So they have a lot of different conditions that they 're gonna be filling out .\nIt 's a bad sign when you  looking at the numbers , you can't tell whether it 's accuracy or error rate .\nYeah . Yeah . It 's  it 's gonna be hard . Um , they 're  I I 'm still waiting for them to  release the , um ,  multi - CPU version of their scripts , cuz right now their script only handles processing on a single CPU , which will take a really long time to run . So . But their s\nThis is for the training ?\nUh  I beli Yes , for the training  also . And , um , they 're supposed to be coming out with it any time ,\nOK .\nthe multi - CPU one . So , as soon as they get that , then I 'll  I 'll grab those too\nOK .\nand so w\nYeah . Cuz we have to get started ,\nYeah .\ncuz it 's  cuz , uh ,\nYeah . I 'll go ahead and try to run it though with just the single CPU one ,\nif the\nand  I  they  they ,  um , released like a smaller data set that you can use that only takes like sixteen hours to train and stuff . So I can  I can run it on that just to make sure that the   the thing works and everything .\nOh ! Good . Yeah . Cuz we 'll\nHmm .\nI guess the actual evaluation will be in six weeks or something . So . Is that about right  you think ?\nUh , we don't know yet , I  I think .\nReally , we don't know ?\nUh - huh . Um .\nIt wasn't on the conference call this morning ?\nHmm .\nNo .", "topic_id": 2, "keywords": "mississippi, systems, processing, state, aurora", "dialogue_id": 19}, {"text": "Hmm . Did they say anything on the conference call  about , um , how the  Wall Street Journal part of the test was going to be  run ? Because I  I thought I remembered hearing that some sites  were saying that they didn't have the compute to be able to run the Wall Street Journal stuff at their place ,\nNo . Mmm .\nso there was some talk about having Mississippi State run  the systems for them . And I  Did  did that come up at all ?\nUh , no . Well , this  first , this was not the point at all of this  the meeting today\nOh , OK .\nand ,\nSome\nuh , frankly , I don't know because I d  didn't read also the  most recent mails about  the large - vocabulary task . But ,  uh , did you  do you still , uh , get the mails ? You 're not on the mailing list or what ?\nHmm - mm . The only , um , mail I get is from Mississippi State\nUh - huh .\nso\nOh , yeah . So we should have a look at this .\nabout their system . I  I don't get any  mail about\nI have to say , there 's uh something funny - sounding about saying that one of these big companies doesn't have enough cup compute power do that , so they 're having to have it done by Mississippi State .\nYeah .\nIt just   just sounds funny .\nYeah . It does .\nBut ,\nYeah . I 'm  I 'm wondering about that\nanyway .\nbecause there 's this whole issue about , you know , simple tuning parameters , like word insertion penalties .\nMm - hmm .\nAnd  whether or not those are going to be tuned or not , and   So .\nMm - hmm .\nI mean , it makes a big difference . If you change your front - end , you know , the scale is completely  can be completely different , so . It seems reasonable that that at least should be tweaked to match the front - end . But\nYou didn't get any answer from  Joe ?\nI did , but Joe  said , you know , \" what you 're saying makes sense\nUh - huh .\nand  I don't know \" . So he doesn't know what the answer is .\nUh - huh .\nI mean , that 's th We had this back and forth a little bit about ,  you know , are sites gonna  are you gonna run this data for different sites ? And , well , if  if Mississippi State runs it , then maybe they 'll do a little optimization on that  parameter , and , uh  But then he wasn't asked to run it for anybody . So i it 's  it 's just not clear yet what 's gonna happen .\nMm - hmm .\nUh , he 's been putting this stuff out on their web site and  for people to grab but I haven't heard too much about what 's happening .\nSo it could be  I mean , Chuck and I had actually talked about this a couple times , and  and  over some lunches , I think ,  that , um ,  one thing that we might wanna do  The - there 's this question about , you know , what do you wanna scale ? Suppose y you can't adjust  these word insertion penalties and so forth , so you have to do everything at the level of the features . What could you do ? And , uh , one thing I had suggested at an earlier time was maybe some sort of scaling , some sort of root or  or something of the , um ,  uh , features . But the problem with that is that isn't quite the same , it occurred to me later , because what you really want to do is scale the , uh , @ @  the range of the likelihoods rather than\nNnn , the dist Yeah .\nBut ,  what might get at something similar , it just occurred to me , is kind of an intermediate thing  is because we do this strange thing that we do with the tandem system , at least in that system what you could do  is take the , um ,  uh , values that come out of the net , which are something like log probabilities , and scale those . And then , uh , um   then at least those things would have the right values or the right  the right range . And then that goes into the rest of it and then that 's used as observations . So it 's  it 's ,  um , another way to do it .\nMm - hmm . Mm - hmm . But , these values are not directly used as probabilities anyway .\nI know they 're not .\nSo there are  there is\nI know they 're not . But  but , you know  So because what we 're doing is pretty strange and complicated , we don't really know what the effect is  at the other end .\nUh - huh . Mm - hmm .\nSo ,  um ,  my thought was maybe  I mean , they 're not used as probabilities , but the log probabilities  we 're taking advantage of the fact that something like log probabilities has more of a Gaussian shape than Gaus - than  probabilities , and so we can model them better . So ,  in a way we 're taking advantage of the fact that they 're probabilities , because they 're this quantity that looks kind of Gaussian when you take it 's log . So ,   uh , maybe  maybe it would have a  a reasonable effect to do that .\nMm - hmm .\nI d I don't know . But ,  I mean , I guess we still haven't had a   a ruling back on this . And we may end up being in a situation where we just you know really can't change the  word insertion penalty . But the other thing we could do  is  also we could  I mean , this  this may not help us ,  uh , in the evaluation but it might help us in our understanding at least . We might ,  just run it with different insper insertion penalties , and show that , uh , \" well , OK , not changing it ,  playing the rules the way you wanted , we did this . But in fact if we did that , it made a   a big difference . \"\nI wonder if it  it might be possible to , uh , simulate the back - end with some other system . So we  we get our f front - end features , and then , uh , as part of the process of figuring out the scaling of these features ,  you know , if we 're gonna take it to a root or to a power or something ,   we have some back - end that we attach onto our features that sort of simulates what would be happening .\nMm - hmm .\nUm ,\nAnd just adjust it until it 's the best number ?\nand just adjust it until that  our l version of the back - end , uh , decides that  that\nWell , we can probably use the real thing , can't we ? And then jus just , uh ,  use it on a reduced test set or something .\nYeah . Oh , yeah . That 's true .\nYeah .\nAnd then we just use that to determine some scaling factor that we use .\nYeah . So I mean , I I think that that 's a reasonable thing to do and the only question is what 's the actual knob that we use ?\nMm - hmm .\nAnd the knob that we use should  uh , uh , unfortunately , like I say , I don't know the analytic solution to this cuz what we really want to do is change the scale of the likelihoods ,\nMm - hmm .\nnot the cha not the scale of the   the  observations . But  but , uh\nMm - hmm .\nYeah .\nOut of curiosity , what  what kind of recognizer  is the one from Mississippi State ?\nUh , w what do you mean when you say \" what kind \" ?\nIs it  ? Um , is it like a  Gaussian mixture model ?\nYeah . Gaussian mixture model .\nOK .\nIt 's the same system that they use  when they participate in the Hub - five evals . It 's a ,  um  sort of  came out of , uh  uh , looking a lot like HTK . I mean , they started off with  um , when they were building their system they were always comparing to HTK to make sure they were getting similar results . And so ,  it 's a Gaussian mixture system , uh\nDo they have the same sort of mix - down sort of procedure , where they  start off with a small number of some things\nI don't know . Yeah . And then  divide the mixtures in half .\nand  ? Yeah .\nI don't know if they do that . I 'm not really sure .\nYeah .\nHmm .\nD Do you know what kind of tying they use ? Are they  they sort of  some sort of  a bunch of Gaussians that they share across everything ? Or   or if it 's  ?\nYeah , th I have  I  I  I don't have it up here but I have a   the whole system description , that describes exactly what their  system is\nOK .\nand I  I 'm not sure . But , um\nOK .\nIt 's some kind of a mixture of Gaussians and ,  uh , clustering and , uh  They 're  they 're trying to put in sort of all of the standard features that people use nowadays .\nMm - hmm .", "topic_id": 3, "keywords": "mailing, mails, mail, conference, journal", "dialogue_id": 19}, {"text": "So the other , uh , Aurora thing maybe is  I I dunno if any of this is gonna   come in in time to be relevant , but , uh , we had talked about , uh ,  Guenter  playing around , uh , uh , over in Germany\nMm - hmm .\nand  and , @ @  uh ,  possibly coming up with something  that would , uh ,  uh , fit in later . Uh , I saw that other mail where he said that he   uh , it wasn't going to work for him to do CVS .\nYeah . Yeah . So now he has a version of the software .\nSo he just has it all sitting there . Yeah .\nYeah . Um  Mm - hmm .\nSo if he 'll  he might work on improving the noise estimate or on  some histogram things , or\nYeah . Mm - hmm .\nYeah . I just saw the Eurospeech  We  we didn't talk about it at our meeting but I just saw the  just read the paper . Someone , I forget the name ,  and  and Ney , uh , about histogram equalization ? Did you see that one ?\nUm , it was a poster . Or\nYeah . I mean , I just read the paper .\nYeah .\nI didn't see the poster .\nYeah . Um   It was something  similar to n  on - line normalization finally  I mean , in  the idea of  of normalizing\nYeah . But it 's a little more  it  it 's a little finer , right ? So they had like ten quantiles\nYeah .\nand   and they adjust the distribution .\nRight .\nSo you  you have the distributions from the training set ,\nN\nand then , uh  So this is just a  a histogram of  of  the amplitudes , I guess . Right ? And then   Um , people do this in image processing some .\nMm - hmm .\nYou have this kind of   of histogram of  of levels of brightness or whatever . And  and  and then ,  when you get a new  new thing that you  you want to adjust to be  better in some way ,  you adjust it so that the histogram of the new data looks like the old data .\nHmm .\nYou do this kind of  piece - wise linear or ,  uh , some kind of piece - wise approximation . They did a  uh one version that was piece - wise linear and another that had a power law thing between them   between the  points . And , uh , they said they s they sort of see it in a way as s for the speech case   as being kind of a generalization of spectral subtraction in a way , because , you know , in spectral subtraction you 're trying to  get rid of this excess energy . Uh , you know , it 's not supposed to be there . Uh   and , uh , this is sort of   adjusting it for  for a lot of different levels . And then they have s they have some kind of ,  uh ,  a floor or something ,\nHmm .\nso if it gets too low you don't  don't do it .\nHmm .\nAnd they  they claimed very nice results ,\nMm - hmm .\nSo is this a histogram across different frequency bins ?\nand\nOr  ?\nUm , I think this i You know , I don't remember that . Do you remember  ?\nI think they have , yeah , different histograms . I uh  Something like one per  frequency band ,\nOne\nSo , one histogram per frequency bin .\nOne per critical\nor  But I did  Yeah , I guess .\nAnd that 's\nBut I should read the paper . I just went  through the poster quickly ,\nYeah .\nSo th\nAnd I don't remember whether it was  filter bank things\nOh .\nand I didn't\nor whether it was FFT bins\nHuh .\nor\nAnd  and that  that , um ,  histogram represents  the  different energy levels that have been seen at that  frequency ?\nI don't remember that . And how often they  you 've seen them . Yeah .\nUh - huh .\nHmm .\nYeah . And they do  they said that they could do it for the test  So you don't have to change the training . You just do a measurement over the training . And then , uh , for testing , uh , you can do it for one per utterance . Even relatively short utterances . And they claim it  it works pretty well .\nSo they , uh  Is the idea that you  you run a test utterance through some histogram generation thing and then you compare the histograms and that tells you  what to do to the utterance to make it more like  ?\nI guess in pri Yeah . In principle .\nI see .\nI didn't read carefully how they actually implemented it ,\nHmm . Yeah .\nwhether it was some ,  uh , on - line thing , or whether it was a second pass , or what . But  but they   That  that was sort of the idea .\nHmm .\nSo that  that seemed , you know , different . We 're sort of curious about , uh , what are some things that are , u u um ,  @ @   conceptually quite different from what we 've done .\nMm - hmm .\nCuz we  you know , one thing that w that , uh , Stephane and Sunil seemed to find ,  uh , was , you know , they could actually make a unified piece of software that handled a range of different things that people were talking about , and it was really just sort of setting of different  constants . And it would turn , you know , one thing into another . It 'd turn Wiener filtering into spectral subtraction , or whatever . But there 's other things that we 're not doing . So , we 're not making any use of pitch , uh , uh , which again , might  might be important , uh , because the stuff between the harmonics is probably a schmutz . And  and the ,  uh , transcribers will have fun with that . Uh   And , um , the , uh , stuff at the harmonics isn't so much . And  and , uh  And we there 's this overall idea of really sort of matching the  the hi distributions somehow . Uh , not just , um ,  um  not just subtracting off your estimate of the noise . So . So I guess , uh ,  Guenter 's gonna play around with some of these things now over this next  period ,\nUh , I dunno .\nor  ?\nI don't have feedback from him , but\nYeah .\nI guess he 's gonna , maybe\nWell , he 's got it anyway , so he can .\nYeah .\nSo potentially if he came up with something that was useful , like a diff a better noise estimation module or something , he could ship it to you guys u up there\nUh - huh .\nand\nYeah .\nwe could put it in .\nMm - hmm .  Mm - hmm .", "topic_id": 4, "keywords": "aurora, histogram, histograms, software, cvs", "dialogue_id": 19}, {"text": "Yeah . Yeah . So , that 's good . So , why don't we just , uh , um  I think starting   starting a w couple weeks from now , especially if you 're not gonna be around for a while , we 'll  we 'll be shifting more over to some other   other territory . But , uh , uh ,  uh , n not  not so much in this meeting about Aurora , but  but , uh , uh , maybe just , uh , quickly today about  maybe you could just say a little bit about what you 've been talking about with Michael . And  and then Barry can say something about  what   what we 're talking about .\nOK . So Michael Kleinschmidt , who 's a PHD student from Germany ,  showed up this week . He 'll be here for about six months . And he 's done some work using  an auditory model  of , um ,  human hearing , and  using that f uh , to generate speech recognition features . And  he did  work back in Germany  with , um , a toy recognition system  using , um , isolated  digit recognition  as the task . It was actually just a single - layer neural network  that classified words  classified digits ,  in fact . Um , and  he tried that on  I think on some Aurora data and got results that he thought  seemed respectable . And he w he 's coming here to u u use it on a  uh , a real speech recognition system . So I 'll be working with him on that . And , um , maybe I should say a little more about these features , although I don't understand them that well . The  I think it 's a two - stage idea . And , um ,  the first stage of these features correspond to what 's called the peripheral  auditory system . And  I guess that is like  a filter bank with a compressive nonlinearity . And  I 'm - I 'm not sure what we have @ @ in there that isn't already modeled in something like ,  um ,  PLP . I should learn more about that . And then  the second stage  is , um ,  the most different thing , I think , from what we usually do . It 's , um    it computes features which are ,  um ,  based on  sort of like based on diffe different w um , wavelet basis functions  used to analyze  the input . So th he uses analysis functions called  Gabor functions , um ,  which have a certain  extent , um ,  in time and in frequency . And  the idea is these are used to sample ,  um , the signal in a represented as a time - frequency representation . So you 're  sampling some piece of this time - frequency plane . And , um ,  that ,  um , is  is interesting , cuz ,  @ @ for  for one thing , you could use it ,  um , in a  a multi - scale way . You could have these  instead of having everything  like we use a twenty - five millisecond or so analysis window ,  typically , um , and that 's our time scale for features , but you could   using this , um , basis function idea , you could have some basis functions which have a lot longer time scale and , um , some which have a lot shorter , and  so it would be like  a set of multi - scale features . So he 's interested in , um  Th - this is  because it 's , um  there are these different parameters for the shape of these  basis functions ,  um   there are a lot of different possible basis functions . And so he   he actually does  an optimization procedure to choose an   an optimal set of basis functions out of all the possible ones .\nHmm . H What does he do to choose those ?\nThe method he uses is kind of funny  is ,   um ,  he starts with  he has a set of M of them . Um , he  and then  he uses that to classify  I mean , he t he tries , um ,  using  just M minus one of them . So there are M possible subsets of this  length - M vector . He tries classifying , using each of the M  possible sub - vectors .\nHmm .\nWhichever sub - vector ,  um , works the  the best , I guess , he says   the  the fe feature that didn't use was the most useless feature ,\nY yeah . Gets thrown out . Yeah .\nso we 'll throw it out and we 're gonna randomly select another feature  from the set of possible basis functions .\nHmm !\nYeah .\nSo it 's a\nSo i so it 's actuall\nit 's a little bit like a genetic algorithm or something in a way .\nWell , it 's  it 's much simpler .\nIt 's like a greedy\nBut it 's  but it 's  uh , it 's  there 's a lot  number of things I like about it , let me just say .\nGreedy .\nSo , first thing , well , you 're absolutely right . I mean ,  i i {nonvocalsound} in truth ,  both pieces of this are  have their analogies in stuff we already do . But it 's a different take  at how to approach it and potentially one that 's m maybe a bit more systematic than what we 've done , uh , and a b a bit more inspiration from  from auditory things . So it 's  so I think it 's a neat thing to try . The primary features ,  um , are in fact  Yeah , essentially , it 's  it 's , uh , you know , PLP or  or mel cepstrum , or something like that . You 've  you 've got some ,  uh , compression . We always have some compression . We always have some  you know , the  the  the kind of filter bank with a kind of   quasi - log scaling . Um ,  if you put in  if you also include the RASTA in it  i RASTA  the filtering being done in the log domain  has an AGC - like , uh , characteristic , which , you know , people typi typically put in these kind of ,  uh ,  um ,  uh , auditory front - ends . So it 's very , very similar , uh , but it 's not exactly the same . Um , I would agree that the second one is  is somewhat more different but ,  um , it 's mainly different in that the things that we have been doing like that have been   um , had a different kind of motivation and have ended up with different kinds of constraints . So , for instance , if you look at the LDA RASTA stuff ,  you know , basically what they do is they  they look at the different eigenvectors out of the LDA and they form filters out of it . Right ? And those  filters have different , uh , kinds of temporal extents and temporal characteristics . And so in fact they 're multi - scale . But , they 're not sort of systematically multi - scale , like \" let 's start here and go to there , and go to there , and go to there \" , and so forth . It 's more like ,  you run it on this , you do discriminant analysis , and you find out what 's helpful .\nI it 's multi - scale because you use several of these in parallel ,\nYeah . They use several of them .\nis that right ? Of\nYeah .\nOK .\nUh , I mean , you don't have to but  but  but , uh , Hynek has . Um , but it 's also , uh  Hyn - when Hynek 's had people do this kind of LDA analysis , they 've done it on frequency direction and they 've done it on the time direction . I think he may have had people sometimes doing it on both simultaneously  some two - D  and that would be the closest to these Gabor function kind of things . Uh , but I don't think they 've done that much of that . And , uh , the other thing that 's interesting  the  the , uh  the feature selection thing , it 's a simple method , but I kinda like it . Um ,  there 's a   a old , old method for feature selection . I mean ,  eh , uh , I remember people referring to it as old when I was playing with it twenty years ago , so I know it 's pretty old , uh , called Stepwise Linear Discriminant Analysis in which you  which  I think it 's used in social sciences a lot . So , you  you  you  you pick the best feature . And then  you take  y you find the next feature that 's the best in combination with it . And then so on and so on . And what  what Michael 's describing seems to me much , much better , because the problem with the stepwise discriminant analysis is that you don't know that  you know , if you 've  picked the right set of features . Just because something 's a good feature doesn't mean that you should be adding it . So ,  um ,  uh , here at least you 're starting off with all of them , and you 're  throwing out useless features . I think that 's  that seems , uh   that seems like a lot better idea . Uh , you 're always looking at things in combination with other features . Um , so the only thing is , of course , there 's this  this artificial question of  of , uh ,  exactly how you  how you a how you assess it and if  if your order had been different in throwing them out . I mean , it still isn't necessarily really optimal , but it seems like a pretty good heuristic . So I th I think it 's  it 's  I think it 's kinda neat stuff .\nHmm .\nAnd  and  and , uh , the thing that I wanted to  to add to it also was to have us use this in a multi - stream way .\nHmm .\nUm , so  so that , um ,  when you come up with these different things ,  and these different functions ,  you don't necessarily just put them all into one huge vector , but perhaps  you  have some of them in one stream and some of them in another stream , and so forth . And , um , um ,  um  And we 've also talked a little bit about , uh ,  uh , Shihab Shamma 's stuff , in which  you  the way you look at it is that there 's these different mappings and some of them emphasize , uh , upward moving ,  uh , energy and fre and frequency . And some are emphasizing downward and  fast things and slow things and  and  so forth . So . So there 's a bunch of stuff to look at . But , uh , I think we 're sorta gonna start off with what  he , uh , came here with and branch out   branch out from there . And his advisor is here , too ,  at the same time . So , he 'll be another  interesting source of  wisdom .\nHmm .\nSo .\nAs  as we were talking about this I was thinking ,  um ,  whether there 's a relationship between   um ,   between Michael 's approach to , uh , some  some sort of optimal brain damage or optimal brain surgeon on the neural nets .\nYeah .\nHmm .\nSo , like , if we have , um  we have our  we have our RASTA features and  and presumably the neural nets are  are learning some sort of a nonlinear mapping ,  uh , from the  the  the features  to  to this  this probability posterior space .\nMm - hmm .\nRight ? And , um    and each of the hidden units is learning some sort of  some sort of  some sort of pattern . Right ? And it could be , like   like these , um  these auditory patterns that Michael  is looking at . And then when you 're looking at the   the , uh ,  um ,  the best features ,  you know , you can take out  you can do the  do this , uh , brain surgery by taking out ,  um , hidden units that don't really help at all .\nMm - hmm . Or the  or features .\nAnd this is k sorta like\nRight ?\nYeah .\nI mean , y actually , you make me think a  a very important point here is that , um ,  if we a again try to look at how is this different from what we 're already doing ,  uh , there 's a  a , uh   a nasty argument that could be made th that it 's  it 's not different at  at all , because , uh  if you ignore the  the selection part because we are going into a  a very powerful ,  uh , nonlinearity that , uh , in fact is combining over time and frequency , and is coming up with its own  you know , better than Gabor functions its , you know , neural net functions ,\nMm - hmm .\nits    whatever it finds to be best .\nUm , so you could argue that in fact it  But I  I don't actually believe that argument because I know that , um ,  you can , uh  computing features is useful , even though  in principle you haven't   added anything  in fact , you subtracted something , from the original waveform  You know , uh , if you 've  you 've processed it in some way you 've typically lost something  some information . And so ,  you 've lost information and yet it does better with   with features than it does with the waveform . So , uh , I  I know that i sometimes it 's useful to   to constrain things . So that 's  why it really seems like the constraint  in  in all this stuff it 's the constraints that are actually what matters . Because if it wasn't  the constraints that mattered , then we would 've completely solved this problem long ago , because long ago we already knew how to put waveforms into powerful statistical mechanisms . So .\nYeah . Well , if we had infinite processing power and  data ,  I guess , using the waveform could\nRight .\nYeah Uh , then it would work . Yeah , I agree . Yeah . There 's the problem .\nSo , that 's\nYeah . Then it would work . But  but , I mean , i it 's   With finite  of those things  I mean , uh , we  we have done experiments where we literally have put waveforms in and  and  and , uh ,\nMm - hmm .\nwe kept the number of parameters the same and so forth , and it used a lot of training data . And it  and it  it , uh  not infinite but a lot , and then compared to the number parameters  and it  it , uh  it just doesn't do nearly as well . So , anyway the point is that you want to suppress\nMm - hmm .\nit 's not just having the maximum information , you want to suppress ,  uh , the aspects of the input signal that are not helpful for  for the discrimination you 're trying to make . So . So maybe just briefly , uh\nWell , that sort of segues into  what  what I 'm doing .\nYeah .\nUm ,  so , uh , the big picture is k um ,  come up with a set of ,  uh , intermediate categories , then build intermediate category classifiers , then do recognition , and , um , improve speech recognition in that way . Um , so right now I 'm in  in the phase where  I 'm looking at  at , um , deciding on a initial set of intermediate categories . And  I 'm looking  for data data - driven  methods that can help me find ,  um , a set of intermediate categories  of speech that , uh , will help me to discriminate  later down the line . And one of the ideas ,  um , that was to take a  take a neural net  train  train an ordinary neural net  to   uh , to learn the posterior probabilities of phones . And so , um , at the end of the day you have this neural net and it has hidden   hidden units . And each of these hidden units is   um , is learning some sort of pattern . And so , um , what  what are these patterns ?\nHmm .\nI don't know . Um , and I 'm gonna to try to   to look at those patterns  to  to see ,  um ,  from those patterns  uh , presumably those are important patterns for discriminating between phone classes . And maybe   maybe some , uh , intermediate categories can come from  just looking at the patterns of   um , that the neural net learns .\nBe - before you get on the next part l let me just point out that s there 's  there 's a  a pretty nice   relationship between what you 're talking about doing and what you 're talking about doing there . Right ?\nYeah .\nSo ,  it seems to me that , you know , if you take away the  the   the difference of this  primary features ,  and , say , you use  as we had talked about maybe doing  you use P - RASTA - PLP or something for the  the primary features ,  um , then this feature discovery ,  uh , uh , thing  is just what he 's talking about doing , too , except that he 's talking about doing them in order to discover  intermediate categories that correspond  to these  uh , uh , what these sub - features are  are  are  are showing you . And , um ,  the other difference is that , um ,  he 's doing this in a  in a multi - band setting , which means that he 's constraining himself  to look across time in some f relatively limited , uh , uh , spectral extent . Right ? And whereas in  in this case you 're saying \" let 's just do it unconstrained \" . So they 're  they 're really pretty related and maybe they 'll be  at some point where we 'll see the  the connections a little better and  connect them .\nHmm .\nMm - hmm . Um . Yeah , so  so that 's the  that 's the first part  uh , one  one of the ideas to get at some   some patterns of intermediate categories . Um ,  the other one  was ,  um , to ,  uh , come up with a  a  a model   um , a graphical model ,  that treats  the intermediate categories  as hidden  hidden variables , latent variables , that we don't know anything about , but that through ,  um , s statistical training and the EM algorithm ,  um , at the end of the day ,  we have , um  we have learned something about these  these latent , um  latent variables which happen to correspond to  intermediate categories . Um .  {nonvocalsound} Yeah , and so those are the  the two directions that I 'm  I 'm looking into right now . And , uh ,  um    Yeah . I guess that 's  that 's it .\nOK . Should we do our digits and get ou get our treats ?\nOh , tea time ?\nYeah . It 's kind of like , you know , the little rats with the little thing dropping down to them .\nThat 's ri\nWe do the digits and then we get our treats .\nOops .\nOK .", "topic_id": 5, "keywords": "aurora, neural, auditory, hearing, recognition", "dialogue_id": 19}, {"text": "OK . We 're on .\nHello ?\nOK , so uh  had some interesting mail from uh Dan Ellis . Actually , I think he  he  redirected it to everybody also so uh  the PDA mikes uh have a big bunch of energy at  at uh five hertz uh where this came up was that uh I was showing off these wave forms that we have on the web and  and uh  I just sort of hadn't noticed this , but that  the major , major component in the wave  in the second wave form in that pair of wave forms is actually the air conditioner .\nHuh .\nSo . So . I   I have to be more careful about using that as a  as a   as a good illustration , uh , in fact it 's not , of uh   of the effects of room reverberation . It is isn't a bad illustration of the effects of uh room noise .  on  on uh some mikes uh but So . And then we had this other discussion about um  whether this affects the dynamic range , cuz I know , although we start off with thirty two bits , you end up with uh sixteen bits and  you know , are we getting hurt there ? But uh Dan is pretty confident that we 're not , that  that quantization error is not  is still not a significant  factor there . So . So there was a question of whether we should change things here , whether we should  change a capacitor on the input box for that or whether we should\nYeah , he suggested a smaller capacitor , right ?\nRight . But then I had some other uh thing discussions with him\nFor the P D\nand the feeling was  once we start monk monkeying with that , uh , many other problems could ha happen . And additionally we  we already have a lot of data that 's been collected with that , so .\nYeah .\nA simple thing to do is he  he  he has a  I forget if it  this was in that mail or in the following mail , but he has a  a simple filter , a digital filter that he suggested . We just run over the data before we deal with it .\nMm - hmm .\num The other thing that I don't know the answer to , but when people are using Feacalc here , uh whether they 're using it with the high - pass filter option or not . And I don't know if anybody knows .\nUm .  I could go check .\nBut . Yeah . So when we 're doing all these things using our software there is  um if it 's  if it 's based on the RASTA - PLP program ,  which does both PLP and RASTA - PLP  um then  uh there is an option there which then comes up through to Feacalc which  um allows you to do high - pass filtering and in general we like to do that , because of things like this and  it 's  it 's pretty  it 's not a very severe filter . Doesn't affect speech frequencies , even pretty low speech frequencies , at all , but it 's\nWhat 's the  cut - off frequency it used ?\nOh . I don't know I wrote this a while ago\nIs it like twenty ?\nSomething like that .\nYeah .\nYeah . I mean I think there 's some effect above twenty but it 's  it 's  it 's  it 's mild . So , I mean it probably  there 's probably some effect up to a hundred hertz or something but it 's  it 's pretty mild . I don't know in the  in the STRUT implementation of the stuff is there a high - pass filter or a pre pre - emphasis or something in the\nUh . I think we use a pre - emphasis . Yeah . Yeah .\nSo . We  we  we want to go and check that in i for anything that we 're going to use the P D A mike for .  uh He says that there 's a pretty good roll off in the PZM mikes so  we don't need  need to worry about them one way or the other but if we do make use of the cheap mikes ,  uh we want to be sure to do that  that filtering before we  process it . And then again if it 's uh depending on the option that the  our  our software is being run with , it 's  it 's quite possible that 's already being taken care of . uh But I also have to pick a different picture to show the effects of reverberation . uh\nDid somebody notice it during your talk ?\nuh No .\nHuh .\nWell . uh Well . If they made output they were  they were , you know  they were nice .\nDidn't say anything ?\nBut .  I mean the thing is it was since I was talking about reverberation and showing this thing that was noise , it wasn't a good match , but it certainly was still uh an indication of the fact that you get noise with distant mikes . uh It 's just not a great example because not only isn't it reverberation but it 's a noise that we definitely know what to do .\nMm - hmm .\nSo , I mean , it doesn't take deep   a new  bold new methods to get rid of uh five hertz noise , so .\nYeah .\num  uh But . So it was  it was a bad example in that way , but it 's  it still is  it 's the real thing that we did get out of the microphone at distance , so it wasn't  it w it w wasn't wrong it was inappropriate . So .  So uh , but uh , Yeah , someone noticed it later pointed it out to me , and I went \" oh , man . Why didn't I notice that ? \"\nHmm .\num . So .  um So I think we 'll change our  our picture on the web , when we 're @ @ . One of the things I was  I mean , I was trying to think about what  what 's the best  way to show the difference an and I had a couple of thoughts one was ,  that spectrogram that we show  is O K , but the thing is  the eyes uh and the  the brain behind them are so good at picking out patterns  from  from noise  that in first glance you look at them it doesn't seem like it 's that bad uh because there 's many features that are still preserved . So one thing to do might be to just take a piece of the spec uh of the spectrogram where you can see  that something looks different , an and blow it up , and have that be the part that 's  just to show as well . You know .\nMm - hmm . Mm - hmm .\ni i Some things are going to be hurt . um  Another , I was thinking of was um  taking some spectral slices , like uh  like we look at with the recognizer , and look at the spectrum or cepstrum that you get out of there , and the  the uh , um ,  the reverberation uh does make it  does change that . And so maybe  maybe that would be more obvious .\nHmm .\nSpectral slices ?\nYeah .\nW w what d what do you mean ?\nWell , I mean um all the recognizers look at frames . So they  they look at\nSo like one instant in time .\nYeah , look at a\nOK .\nSo it 's , yeah , at one point in time or uh twenty  over twenty milliseconds or something ,  you have a spectrum or a cepstrum .\nOK .\nThat 's what I meant by a slice .\nI see .\nYeah . And  if you look at\nYou could just  you could just throw up , you know , uh  the uh  some MFCC feature vectors . You know , one from one , one from the other , and then , you know , you can look and see how different the numbers are .\nRight . Well , that 's why I saying either   Well , either spectrum or cepstrum\nI 'm just kidding .\nbut   but I think the thing is you wanna\nI don't mean a graph . I mean the actual numbers .\nOh . I see . Oh . That would be lovely , yeah .\nYeah . \" See how different these  sequences of numbers are ? \"\nYeah . Or I could just add them up and get a different total .\nYeah . It 's not the square .\nOK . Uh . What else  wh what 's  what else is going on ?", "topic_id": 0, "keywords": "reverberation, wave, quantization, noise, mikes", "dialogue_id": 20}, {"text": "Uh , yeah . Yeah , at first I had a remark why  I am wondering why the PDA is always so far . I mean we are always meeting at the  beginning of the table and  the PDA 's there .\nUh . I guess cuz we haven't wanted to move it . We  we could   we could move us ,\nYeah ?\nand .\nOK .\nThat 's right .\nWell , anyway . Um . Yeah , so . Uh . Since the last meeting we 've  we 've tried to put together um  the clean low - pass um downsampling , upsampling , I mean , Uh the new filter that 's replacing the LDA filters , and also  the um delay issue so that  We considered th the  the delay issue on the  for the on - line normalization . Mmm . So we 've put together all this and then we have results that are not um   very impressive . Well , there is no  real improvement .\nBut it 's not wer worse and it 's better  better latency ,\nIt 's not\nright ?\nYeah . Yeah . Well . Actually it 's better . It seems better when we look at the mismatched case but  I think we are like  like cheated here by the  th this problem that  uh in some cases when you modify slight  slightly modify the initial condition you end up  completely somewhere air somewhere else in the  in the space ,  the parameters .\nYeah .\nSo . Well . The other system are for instance . For Italian is at seventy - eight  percent recognition rate on the mismatch , and this new system has eighty - nine . But I don't think it indicates something , really . I don't  I don't think it means that the new system is more robust\nUh - huh .\nor  It 's simply the fact that  Well .\nWell , the test would be if you then tried it on one of the other test sets , if  if it was\nY\nRight . So this was Italian , right ?\nYeah . Yeah .\nSo then if you take your changes\nIt 's similar for other test sets\nand then\nbut I mean  from this se seventy - eight um percent recognition rate system ,  I could change the transition probabilities for the  the first HMM and  it will end up to eighty - nine also .\nUh - huh .\nBy using point five instead of point six , point four  as in the  the HTK script .\nUh - huh . Yeah .\nSo . Well . That 's\nYeah . Yeah I looked at um   looked at the results when Stephane did that\nWell . Eh uh\nand it 's  it 's really wo really happens .\nThis really happens .\nI mean th the only difference is you change the self - loop transition probability by a tenth of a percent\nYeah .\nYeah .\nand it causes ten percent difference in the word error rate .\nA tenth of a per cent .\nYeah . From point\nEven tenth of a percent ?\nI  I 'm sorry\nWell , we tried  we tried point one ,\nf for point  from  You change at point one\nyeah .\nOh !\nand n not tenth of a percent , one tenth ,\nHmm .\nYeah .\nalright ? Um so from point five  so from point six to point five and you get ten percent better .\nMm - hmm .\nAnd it 's   I think it 's what you basically hypothesized in the last meeting  about uh it just being very\nMm - hmm .\nand I think you mentioned this in your email too  it 's just very um\nMmm , yeah .\nyou know get stuck in some local minimum and this thing throws you out of it I guess .\nMm - hmm .\nWell , what 's  what are  according to the rules what  what are we supposed to do about the transition probabilities ? Are they supposed to be point five or point six ?\nI think you 're not allowed to  Yeah . That 's supposed to be point six , for the self - loop .\nYeah .\nPoint  It 's supposed to be point six .\nYeah . But changing it to point five I think is  which gives you much better results , but that 's  not allowed .\nBut not allowed ? Yeah . OK .\nYeah .\nYeah , but even if you use point five , I 'm not sure it will always give you the better results\nYeah .\non other test set or it\nRight . We only tested it on the  the medium mismatch ,\non the other training set , I mean .\nright ? You said on the other cases you didn't notice\nYeah . But . I think , yeah . I think the reason is , yeah , I not I  it was in my mail I think also ,  is the fact that the mismatch is trained only on the far microphone . Well , in  for the mismatched case everything is um using the far microphone training and testing , whereas for the highly mismatched , training is done on the close microphone so  it 's  it 's clean speech basically so you don't have this problem of local minima probably and for the well - match , it 's a mix of close microphone and distant microphone and  Well .\nI did notice uh something\nSo th I think the mismatch is the more difficult for the training part .\nSomebody , I think it was Morgan , suggested at the last meeting that I actually count to see  how many parameters and how many frames .\nMm - hmm .\nMm - hmm .\nAnd there are uh almost one point eight million frames of training data and less than forty thousand parameters in the baseline system .\nHmm .\nYeah .\nSo it 's very , very few parameters compared to how much training data .\nWell . Yes .\nMm - hmm .\nSo . And that  that says that we could have lots more parameters actually .\nYeah . Yeah .\nMm - hmm .\nI did one quick experiment just to make sure I had everything worked out and I just   uh f for most of the um  For  for all of the digit models , they end up at three mixtures per state . And so I just did a quick experiment , where I changed it so it went to four and um  it it  it didn't have a r any significant effect at the uh medium mismatch and high mismatch cases and it had   it was just barely significant for the well - matched better . Uh so I 'm r gonna run that again but  um with many more uh mixtures per state .\nYeah . Cuz at forty thou I mean you could you could have uh  Yeah , easily four times as many  parameters .\nMm - hmm . And I think also  just seeing what we saw  uh in terms of the expected duration of the silence model ? when we did this tweaking of the self - loop ? The silence model expected duration was really different .\nYeah .\nAnd so in the case where  um  it had a better score , the silence model expected duration was much longer .\nYeah .\nSo it was like   it was a better match . I think  you know if we make a better silence model I think that will help a lot too um for a lot of these cases so but one one thing I  I wanted to check out before I increased the um  number of mixtures per state was  uh  in their  default training script they do an initial set of three re - estimations and then they built the silence model and then they do seven iterations then the add mixtures and they do another seven then they add mixtures then they do a final set of seven and they quit . Seven seems like a lot to me and it also makes the experiments go take a really long time I mean to do one turn - around of the well matched case takes like a day .\nMm - hmm . Mm - hmm .\nAnd so  you know in trying to run these experiments I notice , you know , it 's difficult to find machines , you know , compute the run on . And so one of the things I did was I compiled HTK for the Linux  machines\nMm - hmm .\ncuz we have this one from IBM that 's got like five processors in it ?\nRight .\nand so now I 'm  you can run stuff on that and that really helps a lot because now we 've got  you know , extra machines that we can use for compute . And if  I 'm do running an experiment right now where I 'm changing the number of iterations ?  from seven to three ?\nMm - hmm .\nYeah .\njust to see how it affects the baseline system . And so if we can get away with just doing three , we can do  many more experiments more quickly . And if it 's not a  a huge difference from running with seven iterations ,  um , you know , we should be able to get a lot more experiments done .\nHmm .\nAnd so . I 'll let you know what  what happens with that . But if we can  you know , run all of these back - ends f with many fewer iterations and  on Linux boxes we should be able to get a lot more experimenting done .\nMm - hmm .\nSo . So I wanted to experiment with cutting down the number of iterations before I  increased the number of Gaussians .\nRight . Sorry . So um , how 's it going on the\nUm .\nSo . You  you did some things . They didn't improve things in a way that convinced you you 'd substantially improved anything .\nYeah .\nBut they 're not making things worse and we have reduced latency , right ?\nYeah . But actually  um actually it seems to do a little bit worse for the well - matched case and we just noticed that  Yeah , actually the way the final score is computed is quite funny . It 's not a mean of word error rate . It 's not a weighted mean of word error rate , it 's a weighted mean of improvements .\nUh - huh .\nSo . Which means that  actually the weight on the well - matched is  Well I well what what  What happened is that if you have a small improvement or a small if on the well - matched case  it will have uh huge influence on the improvement compared to the reference because the reference system is  is  is quite good for  for the well - ma well - matched case also .\nSo it  it weights the improvement on the well - matched case really heavily compared to the improvement on the other cases ?\nNo , but it 's the weighting of the  of the improvement not of the error rate .\nYeah . Yeah , and it 's hard to improve on the  on the best case , cuz it 's already so good , right ?\nYeah but  what I mean is that you can have a huge improvement on the H  HMK 's , uh like five percent uh absolute , and this will not affect the final score almost  Uh this will almost not affect the final score because  this improvement  because the improvement  uh relative to the  the baseline is small\nSo they do improvement in terms of uh accuracy ? rather than word error rate ?\nUh . Uh improvement ?\nSo\nNo , it 's compared to the word er it 's improvement on the word error rate ,\nOK .\nyeah . Sorry .\nSo if you have uh ten percent error and you get five percent absolute uh  improvement then that 's fifty percent .\nMm - hmm .\nOK . So what you 're saying then is that if it 's something that has a small word error rate ,  then uh a  even a relatively small improvement on it , in absolute terms ,  will show up as quite  quite large in this .\nMm - hmm .\nIs that what you 're saying ?\nYeah .\nYes .\nYeah .\nOK . But yeah that 's  that 's  it 's the notion of relative improvement . Word error rate .\nYeah . Sure , but when we think about the weighting , which is point five , point three , point two ,  it 's on absolute on  on relative figures ,\nYeah .\nnot\nYeah .\nSo when we look at this error rate\nNo . That 's why I 've been saying we should be looking at word error rate uh and  and not  not at  at accuracies .\nuh  Mmm , yeah . Mmm , yeah .\nIt 's\nMm - hmm .\nI mean uh we probably should have standardized on that all the way through . It 's just\nWell .\nMm - hmm .\nI mean , it 's not  it 's not that different , right ? I mean , just subtract the accuracy .\nYeah but you 're  but when you look at the numbers , your sense of the relative size of things is quite different .\nI mean  Oh . Oh , I see . Yeah .\nIf you had ninety percent uh correct  and five percent , five over ninety doesn't look like it 's a big difference , but  five over ten is  is big .\nMm - hmm .\nMm - hmm .\nSo just when we were looking at a lot of numbers and  getting sense of what was important .\nI see . I see . Yeah . That makes sense .\nUm .\nMmm .\nUm .\nWell anyway uh . So . Yeah . So it hurts a little bit on the well - match and yeah .\nWhat 's a little bit ? Like\nLike , it 's difficult to say because again um   I 'm not sure I have the um\nHey Morgan ? Do you remember that Signif program that we used to use for testing signi ? Is that still valid ? I  I 've been using that .\nYeah . Yeah , it was actually updated .\nOK .\nUh .  Jeff updated it some years ago\nOh , it was . Oh , I shoul\nand  and uh cleaned it up made some things better in it . So .\nOK . I should find that new one . I just use my old one from  ninety - two or whatever\nYeah , I 'm sure it 's not that different but  but he   he uh  he was a little more rigorous , as I recall .\nOK .\nRight . So it 's around , like , point five . No , point six  uh percent absolute on Italian\nWorse .\nWorse , yep .\nOut of what ? I mean . s\nUh well we start from ninety - four point sixty - four , and we go to ninety - four point O four .\nUh - huh . So that 's six  six point th\nUh .\nNinety - three point six four , right ? is the baseline .\nOh , no , I 've ninety - four . Oh , the baseline , you mean .\nYeah .\nWell I don't  I 'm not talking about the baseline here .\nOh . Oh . I 'm sorry .\nI uh  My baseline is the submitted system .\nAh ! OK . Ah , ah .\nHmm .\nYeah .\nSorry .\nOh yeah . For Finnish , we start to ninety - three point eight - four and we go to ninety - three point seventy - four . And for Spanish we are  we were at ninety - five point O five and we go to ninety - three - s point sixty one .\nOK , so we are getting hurt somewhat .\nSo .\nAnd is that wh what  do you know what piece  you 've done several changes here . Uh , do you know what pie\nYeah . I guess  I guess it 's  it 's the filter . Because nnn , well uh we don't have complete result , but the filter  So the filter with the shorter delay hurts on Italian well - matched , which  And , yeah . And the other things , like um  downsampling , upsampling , don't seem to hurt and  the new on - line normalization , neither .\nI 'm\nSo .\nI 'm really confused about something . If we saw that making a small change like , you know , a tenth , to the self - loop had a huge effect ,  can we really make any conclusions about differences in this stuff ?\nMm - hmm . Yeah that 's th Yeah .\nI mean , especially when they 're this small . I mean .\nI think we can be completely fooled by this thing , but  I don't know .\nWell , yeah .\nSo . There is first this thing , and then the  yeah , I computed the um   like , the confidence level on the different test sets . And for the well - matched they are around um  point six uh percent . For the mismatched they are around like let 's say one point five percent . And for the well - m uh HM they are also around one point five .\nBut  OK , so you  these  these degradations you were talking about were on the well - matched case\nSo .\nUh . Do the  does the new filter make things uh better or worse for the other cases ?\nYeah . But . Uh . About the same . It doesn't hurt . Yeah .\nDoesn't hurt , but doesn't get a little better , or something .\nNo .\nNo . OK , so  um I guess the argument one might make is that , \" Yeah , if you looked at one of these cases  and you jiggle something and it changes  then uh you 're not quite sure what to make of it . But when you look across a bunch of these and there 's some  some pattern , um  I mean , so eh h here 's all the  if  if in all these different cases  it never gets better , and there 's significant number of cases where it gets worse ,  then you 're probably  hurting things ,  I would say . So um  I mean at the very least that would be a reasonably prediction of what would happen with  with a different test set , that you 're not jiggling things with . So I guess the question is if you can do better than this . If you can  if we can approximate  the old numbers while still keeping the latency down .\nMmm . Yeah .\nUh , so . Um . What I was asking , though , is uh  are  what 's  what 's the level of communication with uh  the O G I gang now , about this and\nWell , we are exchanging mail as soon as we   we have significant results .\nYeah .\nUm . Yeah . For the moment , they are working on integrating  the um  spectral subtraction apparently from Ericsson .\nMm - hmm .\nUm . Yeah . And so . Yeah . We are working on our side on other things like  uh also trying a sup spectral subtraction but of  of our own , I mean , another  spectral substraction .\nMm - hmm .\nUm . Yeah . So I think it 's  it 's OK . It 's going\nIs there any further discussion about this  this idea of  of having some sort of source code control ?\nYeah . Well . For the moment they 're  uh everybody 's quite um  There is this Eurospeech deadline , so .\nI see .\nUm . And . Yeah . But yeah . As soon as we have something that 's significant and that 's better than  than what was submitted , we will fix  fix the system and  But we 've not discussed it  it  it  this yet , yeah .\nYeah . Sounds like a great idea but  but I think that  that um  he 's saying people are sort of scrambling for a Eurospeech deadline .\nMmm .\nBut that 'll be uh , uh done in a week . So , maybe after  this next one .\nYeah .\nWow ! Already a week ! Man !\nYeah .\nYou 're right . That 's amazing .", "topic_id": 1, "keywords": "pda, lda, latency, improvements, downsampling", "dialogue_id": 20}, {"text": "Yeah . Anybo - anybody in the  in this group do doing anything for Eurospeech ?\nS\nOr , is that what  is that\nYeah we are   We are trying to  to do something with the Meeting Recorder digits ,\nRight .\nand  But yeah . Yeah . And the good thing is that  there is this first deadline ,\nYeah .\nand , well , some people from OGI are working on a paper for this , but there is also the um  special session about th Aurora which is   uh which has an extended deadline . So . The deadline is in May .\nFor uh   Oh , for Eurospeech ?\nFor th Yeah .\nOh !\nSo f only for the experiments on Aurora . So it  it 's good ,\nOh , a special dispensation .\nyeah .\nThat 's great .\nMm - hmm . Where is Eurospeech this year ?\nIt 's in Denmark .\nAalborg  Aalborg uh\nOh .\nSo the deadline  When 's the deadline ? When 's the deadline ?\nHmm ? I think it 's the thirteenth of May .\nThat 's great ! It 's great . So we should definitely get something in for that .\nYeah .\nBut on meeting digits , maybe there 's  Maybe .\nYeah .\nMaybe .\nSo it would be for the first deadline .\nYeah .\nNnn .\nYeah . So , I mean , I  I think that you could certainly start looking at  at the issue uh but  but uh  I think it 's probably , on s from what Stephane is saying , it 's  it 's unlikely to get sort of active participation from the two sides until after they 've\nWell I could at least  Well , I 'm going to be out next week but I could  try to look into like this uh CVS over the web . That seems to be a very popular  way of  people distributing changes and  over , you know , multiple sites and things\nMm - hmm .\nso maybe  if I can figure out how do that easily and then pass the information on to everybody so that it 's  you know , as easy to do as possible and  and people don't  it won't interfere with  their regular work , then maybe that would be good . And I think we could use it for other things around here too . So .\nGood .\nThat 's cool . And if you 're interested in using CVS , I 've set it up here ,\nOh great .\nso .\nOK .\num j\nI used it a long time ago but it 's been a while so maybe I can ask you some questions .\nOh . So . I 'll be away tomorrow and Monday but I 'll be back on Tuesday or Wednesday .\nOK .\nYeah . Dave , the other thing , actually , is  is this business about this wave form . Maybe you and I can talk a little bit at some point about  coming up with a better  uh demonstration of the effects of reverberation for our web page , cuz uh   the uh  um I mean , actually the  the uh It made a good  good audio demonstration because when we could play that clip the  the  the really  obvious difference is that you can hear two voices and    in the second one and only hear\nMaybe we could just  like , talk into a cup .\nYeah .\nSome good reverb .\nNo , I mean , it sound  it sounds pretty reverberant , but I mean you can't  when you play it back in a room with a  you know a big room ,  nobody can hear that difference really .\nYeah .\nThey hear that it 's lower amplitude and they hear there 's a second voice ,\nUh - huh .\num  but uh that  actually that makes for a perfectly good demo because that 's a real obvious thing , that you hear two voices .\nBut not of reverberation .\nYeah .\nA boom .\nWell that  that  that 's OK . But for the  the visual , just , you know , I 'd like to have uh  uh , you know , the spectrogram again ,\nYeah .\nbecause you 're  you 're  you 're visual  uh abilities as a human being are so good  you can pick out  you know , you  you look at the good one , you look at the cru the screwed up one , and  and you can see the features in it without trying to @ @\nI noticed that in the pictures .\nyeah .\nI thought \" hey , you know th \" I  My initial thought was \" this is not too bad ! \"\nRight . But you have to  you know , if you look at it closely , you see \" well , here 's a place where this one has a big formant  uh uh formant  maj major formants here are   are moving quite a bit . \" And then you look in the other one and they look practically flat .\nMm - hmm .\nSo I mean you could  that 's why I was thinking , in a section like that , you could take a look  look at just that part of the spectrogram and you could say \" Oh yeah . This  this really distorted it quite a bit . \"\nYeah . The main thing that struck me in looking at those two spectrograms was the difference in the high frequencies . It looked like  for the one that was farther away , you know , it really  everything was attenuated\nRight .\nand  I mean that was the main visual thing that I noticed .\nRight . But it 's  it 's uh  So . Yeah . So there are  clearly are spectral effects . Since you 're getting all this indirect energy , then a lot of it does have  have uh  reduced high frequencies . But um the other thing is the temporal courses of things really are changed , and   and uh we want to show that , in some obvious way . The reason I put the wave forms in there was because  uh they  they do look quite different . Uh . And so I thought \" Oh , this is good . \" but I   I just uh  After  after uh they were put in there I didn't really look at them anymore , cuz I just  they were different . So  I want something that has a  is a more interesting explanation for why they 're different . Um .\nOh . So maybe we can just substitute one of these wave forms and um  then do some kind of zoom in on the spectrogram on an interesting area .\nSomething like that . Yeah .\nUh - huh .\nThe other thing that we had in there that I didn't like was that um  the most obvious characteristic of the difference uh when you listen to it is that there 's a second voice , and the  the  the  the  the uh  cuts that we have there actually don't correspond to the full wave form . It 's just the first  I think there was something where he was having some trouble getting so much in , or . I  I forget the reason behind it . But  it  it 's um   it 's the first six seconds or something  of it and it 's in  the seventh or eighth second or something where @ @ the second voice comes in . So we  we would like to actually see  the voice coming in , too , I think , since that 's the most obvious thing  when you listen to it .\nMm - hmm .\nSo . Um .\nUh , yeah . Yeah . I brought some  I don't know if   some  figures here . Well . I start  we started to work on spectral subtraction . And  um  the preliminary results were very bad .\nUh - huh .\nSo the thing that we did is just to add spectral subtraction before this , the Wall uh process , which contains LDA on - line normalization . And it hurts uh a lot .\nUh - huh .\nAnd so we started to look at  at um things like this , which is , well , it 's  Yeah . So you have the C - zero parameters for one uh Italian utterance .\nYou can @ @ .\nAnd I plotted this for two channels . Channel zero is the close mic microphone , and channel one is the distant microphone . And it 's perfectly synchronized , so . And the sentence contain only one word , which is \" Due \" And it can't clearly be seen . Where  where is it ?\nUh - huh .\nWhere is the word ?\nThis is  this is ,\nHmm .\noh , a plot of C - zero ,\nSo .\nthe energy .\nThis is a plot of C - zero , uh when we don't use spectral substraction , and when there is no on - line normalization .\nMm - hmm .\nSo . There is just some filtering with the LDA and  and some downsampling , upsampling .\nC - zero is the close talking ?\nSo .\nuh the close channel ?\nYeah . Yeah .\nand s channel one is the\nYeah . So C - zero is very clean , actually .\nYeah .\nUh then when we apply mean normalization it looks like the second figure , though it is not . Which is good . Well , the noise part is around zero\nMm - hmm .\nand    And then the third figure is what happens when we apply mean normalization and variance normalization . So . What we can clearly see is that on the speech portion  the two channel come  becomes very close , but also what happens on the noisy portion is that the variance of the noise is\nMm - hmm .\nThis is still being a plot of C - zero ? OK .\nYeah . This is still C - zero .\nCan I ask um what does variance normalization do ? w What is the effect of that ?\nNormalizes the variance .\nSo it  it  Yeah .\nI mean\nIt normalized th the standard deviation .\ny Yeah .\nSo it\nNo , I understand that ,\nYou  you get an estimate of the standard deviation .\nbut I mean\nThat 's\nNo .\num\nNo , I understand what it is , but I mean , what does it  what 's  what is\nYeah but .\nuh\nWhat 's the rationale ?\nWe Yeah . Yeah . Why  why do it ?\nUh .\nWell , I mean , because  everything uh  If you have a system based on Gaussians , everything is based on means and variances .\nYeah .\nSo if there 's an overall  reason  You know , it 's like uh if you were doing uh image processing and in some of the pictures you were looking at , uh there was a lot of light uh and  and in some , there was low light ,\nMm - hmm .\nyou know , you would want to adjust for that in order to compare things .\nMm - hmm .\nAnd the variance is just sort of like the next moment , you know ? So uh  what if um one set of pictures was taken uh so that throughout the course it was  went through daylight and night uh  um um ten times , another time it went thr I mean i is , you know , how  how much   how much vari\nOh , OK .\nOr no . I guess a better example would be  how much of the light was coming in from outside rather than artificial light . So if it was a lot   if more was coming from outside , then there 'd be the bigger effect of the  of the  of the change in the  So every mean  every  all  all of the  the parameters that you have , especially the variances , are going to be affected by the overall variance .\nOh , OK . Uh - huh .\nAnd so , in principle , you  if you remove that source , then , you know , you can\nI see . OK . So would  the major effect is  that you 're gonna get is by normalizing the means ,\nThat 's the first order but  thing ,\nbut it may help  First - order effects .\nbut then the second order is  is the variances\nAnd it may help to do the variance . OK .\nbecause , again , if you  if you 're trying to distinguish between E and B\nOK .\nif it just so happens that the E 's  were a more  you know , were recorded when  when the energy was  was  was larger or something ,\nMm - hmm . Mm - hmm . Mm - hmm .\nor the variation in it was larger ,  uh than with the B 's , then this will be  give you some  some bias .\nSo the   it 's removing these sources of variability in the data  that have nothing to do with the linguistic component .\nOK .\nMmm .\nGotcha . OK . Sorry to interrupt .\nBut the  the uh  but let me as ask  ask you something .\nYep . And it  and this\ni is  if  If you have a good voice activity detector , isn't  isn't it gonna pull that out ?\nYeah . Sure . If they are good . Yeah . Well what it  it shows is that , yeah , perhaps a good voice activity detector is  is good before on - line normalization and that 's what uh  we 've already observed . But uh , yeah , voice activity detection is not   an easy thing neither .\nBut after you do this , after you do the variance normalization  I mean .\nMm - hmm .\nI don't know , it seems like this would be a lot easier than this signal to work with .\nYeah . So . What I notice is that , while I prefer to look at the second figure than at the third one , well , because you clearly see where speech is .\nYeah .\nYeah .\nBut the problem is that on the speech portion , channel zero and channel one are more different than when you use variance normalization where channel zero and channel one become closer .\nRight .\nBut for the purposes of finding the speech\nAnd  Yeah , but here\nYou 're more interested in the difference between the speech and the nonspeech ,\nYeah .\nright ?\nYeah . So I think , yeah . For I th I think that it  perhaps it shows that  uh the parameters that the voice activity detector should use  uh have to use should be different than the parameter that have to be used for speech recognition .\nYeah . So basically you want to reduce this effect .\nWell , y\nSo you can do that by doing the voi voice activity detection . You also could do it by spect uh spectral subtraction before the  variance normalization , right ?\nYeah , but it 's not clear , yeah .\nSo uh\nWe So . Well . It 's just to\nYeah .\nthe  the number that at that are here are recognition experiments on Italian HM and MM  with these two kinds of parameters . And ,  well , it 's better with variance normalization .\nYeah . Yeah . So it does get better even though it looks ugly .\nUh\nOK . but does this have the voice activity detection in it ?\nYeah .\nOK .\nUm .\nSo .\nOK .\nWhere 's th\nBut the fact is that the voice activity detector doesn't work on channel one . So . Yeah .\nUh - huh .\nWhere  at what stage is the voice activity detector applied ? Is it applied here or a after the variance normalization ?\nHmm ?\nSpectral subtraction , I guess .\nor\nIt 's applied before variance normalization . So it 's a good thing ,\nOh .\nbecause I guess voice activity detection on this should  could be worse .\nYeah . Is it applied all the way back here ?\nIt 's applied the um on , yeah , something like this ,\nMaybe that 's why it doesn't work for channel one .\nyeah . Perhaps , yeah .\nCan I\nSo we could perhaps do just mean normalization before VAD .\nMm - hmm .\nMm - hmm . Can I ask a , I mean  a sort of top - level question , which is  um \" if  if most of what the OGI folk are working with is trying to  integrate this other  other uh spectral subtraction ,  why are we worrying about it ? \"\nMm - hmm . About ? Spectral subtraction ?\nYeah .\nIt 's just uh  Well it 's another  They are trying to u to use the um   the Ericsson and we 're trying to use something  something else . And . Yeah , and also to understand what happens because\nOK .\nuh fff Well . When we do spectral subtraction , actually , I think  that this is the  the two last figures .\nYeah .\nUm . It seems that after spectral subtraction , speech is more emerging now uh  than  than before .\nMm - hmm .\nSpeech is more what ?\nWell , the difference between the energy of the speech and the energy of the n spectral subtrac subtracted noise portion is  is larger .\nMm - hmm .\nWell , if you compare the first figure to this one  Actually the scale is not the same , but if you look at the  the numbers um  you clearly see that the difference between the C - zero of the speech and C - zero of the noise portion is larger . Uh but what happens is that after spectral subtraction ,  you also increase the variance of this  of C - zero .\nMm - hmm .\nAnd so if you apply variance normalization on this , it completely sc screw everything . Well .\nMm - hmm .\nUm . Uh . Yeah . So yeah . And what they did at OGI is just  uh they don't use on - line normalization , for the moment , on spectral subtraction and I think  Yeah . I think as soon as they will try on - line normalization  there will be a problem . So yeah , we 're working on the same thing but  I think uh with different  different system and\nRight . I mean , i the Intellectually it 's interesting to work on things th uh one way or the other\nMm - hmm .", "topic_id": 2, "keywords": "eurospeech, deadline, ogi, meeting, aurora", "dialogue_id": 20}, {"text": "but I 'm  I 'm just wondering if um   on the list of things that there are to do , if there are things that we won't do because  we 've got two groups doing the same thing .\nMm - hmm .\nUm . That 's\nMm - hmm .\nUm . Just  just asking . Uh . I mean , it 's\nYeah , well ,\nThere also could be  I mean . I can maybe see a reason f for both working on it too\nuh .\nif  um you know , if  if  if you work on something else and  and you 're waiting for them to give you  spectral subtraction  I mean it 's hard to know whether  the effects that you get from the other experiments you do will  carry over once you then bring in their spectral subtraction module . So it 's  it 's almost like everything 's held up waiting for this  one thing . I don't know if that 's true or not , but I could see how\nMmm .\nI don't know .\nMaybe that 's what you were thinking .\nI don't know .  I mean , we still evidently have a latency reduction plan which  which isn't quite what you 'd like it to be . That  that seems like one prominent thing . And then uh weren't issues of  of having a  a second stream or something ? That was  Was it  There was this business that , you know , we  we could use up the full forty - eight hundred bits , and\nYeah . But I think they ' I think we want to work on this . They also want to work on this , so . Uh .  yeah . We  we will try MSG , but um , yeah . And they are t I think they want to work on the second stream also , but more with  some kind of multi - band or , well , what they call TRAP or generalized TRAP .\nMm - hmm .\nUm . So .\nOK . Do you remember when the next meeting is supposed to be ? the next uh\nIt 's uh in June .\nIn June . OK .\nYeah .\nYeah . Um . Yeah , the other thing is that you saw that  that mail about uh the VAD  V A Ds performing quite differently ? That that uh So um . This  there was this experiment of uh \" what if we just take the baseline ? \"\nMmm .\nset uh of features , just mel cepstra , and you inc incorporate the different V A And it looks like the  the French VAD is actually uh better  significantly better .\nImproves the baseline ?\nYeah . Yeah .\nYeah but I don't know which VAD they use . Uh . If the use the small VAD I th I think it 's on  I think it 's easy to do better because it doesn't work at all . So . I  I don't know which  which one . It 's Pratibha that  that did this experiment .\nYeah .\nUm . We should ask which VAD she used .\nI don't @ @ . He  Actually , I think that he say with the good VAD of  from OGI and with the Alcatel VAD . And the experiment was sometime better , sometime worse .\nYeah but I  it 's uh  I think you were talking about the other mail that used VAD on the reference features .\nYes .\nYeah .\nAnd on that one , uh the French one is  was better .\nI don't remember .\nIt was just better .\nMm - hmm .\nI mean it was enough better that  that it would  uh account for a fair amount of the difference between our performance , actually .\nMm - hmm .\nMm - hmm .\nSo .  Uh . So if they have a better one , we should use it . I mean . You know ? it 's  you can't work on everything .\nYeah .\nUh .  Uh . Yeah .\nYeah , so we should find out if it 's really better . I mean if it  the  compared to the small or the big network .\nMm - hmm .\nYeah .\nAnd perhaps we can easily improve if  if we put like mean normalization before the  before the VAD . Because   as  as you 've  mentioned .\nYeah .\nMmm .\nH Hynek will be back in town uh the week after next , back  back in the country . So . And start  start organizing uh  more visits and connections and so forth ,\nMm - hmm .\nand  uh working towards June .\nYeah .\nAlso is Stephane was thinking that  maybe it was useful to f to think about uh  voiced - unvoiced\nMm - hmm .\nto work uh here in voiced - unvoiced detection .\nYeah . Yeah .\nAnd we are looking   in the uh signal .\nYeah , my feeling is that um actually  when we look at all the proposals , ev everybody is still using some kind of spectral envelope\nRight .\nand um it 's\nNo use of pitch uh basically . Yeah .\nYeah , well , not pitch , but to look at the um fine  at the  at the high re high resolution spectrum .\nYeah . Well , it\nSo . We don't necessarily want to find the  the pitch of the  of the sound but uh  Cuz I have a feeling that  when we look  when we look at the  just at the envelope there is no way you can tell if it 's voiced and unvoiced , if there is some  It 's  it 's easy in clean speech because voiced sound are more low frequency and . So there would be more ,\nYeah .\nuh  there is the first formant , which is the larger and then voiced sound are more high frequencies cuz it 's frication and\nRight .\nBut , yeah . When you have noise there is no um   if  if you have a low frequency noise it could be taken for  for voiced speech and .\nYeah , you can make these mistakes ,\nSo .\nbut  but\nIsn't there some other\nS\nuh d\nSo I think that it  it would be good  Yeah , yeah , well , go  go on .\nUh , I was just gonna say isn't there   aren't  aren't there lots of ideas for doing voice activity , or speech - nonspeech rather ,  um by looking at  um , you know , uh  I guess harmonics or looking across time\nWell , I think he was talking about the voiced - unvoiced , though ,\nMmm .\nright ? So , not the speech - nonspeech .\nYeah . Well even with e\nYeah .\nuh w ah you know , uh even with the voiced - non  voiced - unvoiced\nMmm .\num  I thought that you or  somebody was talking about\nWell . Uh yeah . B We should let him finish what he w he was gonna say ,\nSo .\nOK .\nand\nSo go ahead .\nUm yeah , so yeah , I think if we try to develop a second stream well , there would be one stream that is the envelope and the second , it could be interesting to have that 's  something that 's more related to the fine structure of the spectrum . And . Yeah , so I don't know . We were thinking about like using ideas from  from Larry Saul , have a good voice detector , have a good , well , voiced - speech detector , that 's working on  on the FFT and  uh\nU\nLarry Saul could be an idea . We were are thinking about just  kind of uh taking the spectrum and computing the variance of  of the high resolution spectrum  and things like this .\nSo u s u OK . So  So many  tell you something about that . Uh we had a guy here some years ago who did some work on  um  making use of voicing information uh to  help in reducing the noise .\nYeah ?\nSo what he was doing is basically y you   you do estimate the pitch .\nMm - hmm .\nAnd um you  from that you  you estimate  or you estimate fine harmonic structure , whichev ei either way , it 's more or less the same . But  uh the thing is that um you then  can get rid of things that are not  i if there is strong harmonic structure ,  you can throw away stuff that 's  that 's non - harmonic .\nMm - hmm . Mm - hmm .\nAnd that  that is another way of getting rid of part of the noise\nYeah .\nSo um that 's something  that is sort of finer ,\nYeah .\nbrings in a little more information than just spectral subtraction . Um .\nMm - hmm .\nAnd he had some  I mean , he did that sort of in combination with RASTA . It was kind of like RASTA was taking care of convolutional stuff\nMmm .\nand he was\nMm - hmm .\nand  and got some  some decent results doing that . So that  that 's another  another way . But yeah , there 's  there 's\nYeah . Mmm .\nRight . There 's all these cues . We 've actually back when Chuck was here we did some voiced - unvoiced uh  classification using a bunch of these ,\nBut\nand  and uh works OK . Obviously it 's not perfect but um\nMm - hmm .\nBut the thing is that you can't  given the constraints of this task , we can't ,  in a very nice way , feed  forward to the recognizer the information  the probabilistic information that you might get about whether it 's voiced or unvoiced , where w we can't you know affect the   the uh distributions or anything .\nMm - hmm .\nBut we  what we uh  I guess we could Yeah .\nDidn't the head dude send around that message ? Yeah , I think you sent us all a copy of the message , where he was saying that  I I 'm not sure , exactly , what the gist of what he was saying , but something having to do with the voice  activity detector and that it will   that people shouldn't put their own in or something . It was gonna be a\nThat  But  OK . So that 's voice activity detector as opposed to voicing detector .\nThey didn't .\nSo we 're talking about something a little different .\nMmm .\nOh , I 'm sorry .\nRight ?\nI  I missed that .\nMmm .\nI guess what you could do , maybe this would be w useful , if  if you have  if you view the second stream , yeah , before you  before you do KLT 's and so forth , if you do view it as probabilities , and if it 's an independent  So , if it 's  if it 's uh not so much  envelope - based by fine - structure - based , uh looking at harmonicity or something like that , um if you get a probability from that information and then multiply it by  you know , multiply by all the voiced  outputs and all the unvoiced outputs , you know , then  use that as the\nMm - hmm .\nuh  take the log of that or  uh pre pre uh  pre - nonlinearity ,\nYeah . i if\nuh and do the KLT on the  on  on that ,\nYeah .\nthen that would  that would I guess be uh a reasonable use of independent information . So maybe that 's what you meant . And then that would be\nYeah , well , I was not thinking this  yeah , this could be an yeah So you mean have some kind of probability for the v the voicing\nR Right . So you have a second neural net .\nand then use a tandem system\nIt could be pretty small . Yeah . If you have a tandem system and then you have some kind of  it can be pretty small  net\nMm - hmm .\nwe used  we d did some of this stuff . Uh I  I did , some years ago ,\nYeah .\nand the  and  and you use   the thing is to use information primarily that 's different as you say , it 's more fine - structure - based than  than envelope - based\nMm - hmm .\nuh so then it you  you  you can pretty much guarantee it 's stuff that you 're not looking at very well with the other one , and uh then you only use for this one distinction .\nAlright .\nAnd  and so now you 've got a probability of the cases , and you 've got uh the probability of the finer uh categories on the other side . You multiply them where appropriate and uh  um\nI see , yeah . Mm - hmm .\nif they really are from independent  information sources then  they should have different kinds of errors\nMm - hmm .\nand roughly independent errors , and  it 's a good choice for\nMm - hmm . Mm - hmm . Yeah .\nUh . Yeah , that 's a good idea .\nYeah . Because , yeah , well , spectral subtraction is good and we could u we could use the fine structure to  to have a better estimate of the noise but  still there is this issue with spectral subtraction that it seems to increase the variance of  of  of\nYeah .\num Well it 's this musical noise which is annoying if you d you do some kind of on - line normalization after .\nRight .\nSo . Um . Yeah . Well . Spectral subtraction and on - line normalization don't seem to  to go together very well . I\nOr if you do a spectral subtraction  do some spectral subtraction first and then do some on - line normalization then do some more spectral subtraction  I mean , maybe  maybe you can do it layers or something so it doesn't  doesn't hurt too much or something .\nAh , yeah .\nBut it  but uh , anyway I think I was sort of arguing against myself there by giving that example\nYeah .\nuh I mean cuz I was already sort of  suggesting that we should be careful about not spending too much time on exactly what they 're doing In fact if you get  if you go into uh  a uh harmonics - related thing  it 's definitely going to be different than what they 're doing and uh uh\nMm - hmm .\nshould have some interesting properties in noise . Um .  I know that when have people have done  um sort of the obvious thing of taking  uh your feature vector and adding  in some variables which are  pitch related or uh that  it hasn't  my impression it hasn't particularly helped . Uh . Has not .\nIt  it i has not ,\nYeah .\nyeah .\nBut I think uh  that 's  that 's a question for this uh you know extending the feature vector versus having different streams .\nOh . Was it nois noisy condition ? the example that you  you just\nAnd  and it may not have been noisy conditions .\nYeah .\nYeah . I  I don't remember the example but it was   it was on some DARPA data and some years ago and so it probably wasn't , actually\nMm - hmm . Mm - hmm . Yeah . But we were thinking , we discussed with Barry about this , and  perhaps  thinking  we were thinking about some kind of sheet cheating experiment where we would use TIMIT\nUh - huh .\nand see if giving the d uh , this voicing bit would help in  in terms of uh frame classification .\nWhy don't you  why don't you just do it with Aurora ?\nMmm .\nJust any i in  in each  in each frame\nYeah , but  but  B but we cannot do the cheating , this cheating thing .\nWe 're\nuh\nWe need labels .\nWhy not ?\nWell . Cuz we don't have  Well , for Italian perhaps we have , but we don't have this labeling for Aurora . We just have a labeling with word models\nI see .\nbut not for phonemes .\nNot for foreigners .\nwe don't have frame  frame level transcriptions .\nUm .\nRight .\nUm .  Yeah .\nBut you could  I mean you can  you can align so that  It 's not perfect , but if you  if you know what was said and\nBut the problem is that their models are all word level models . So there 's no phone models  that you get alignments for .\nMm - hmm .\nOh .\nYou  So you could find out where the word boundaries are but that 's about it .\nYeah . I see .\nS But we could use uh the  the noisy version that TIMIT , which  you know , is similar to the  the noises found in the TI - digits  um portion of Aurora .\nYeah . noise , yeah . Yeah , that 's right , yep . Mmm .\nYeah .\nWell , I guess  I guess we can  we can say that it will help , but I don't know . If this voicing bit doesn't help , uh , I think we don't have to  to work more about this because\nUh .\nUh . It 's just to know if it  how much i it will help\nYeah .\nand to have an idea of how much we can gain .\nRight . I mean in experiments that we did a long time ago\nMmm .\nand different ta it was probably Resource Management or something , um , I think you were getting  something like still eight or nine percent error on the voicing , as I recall . And um , so um\nAnother person 's voice .\nwhat that said is that , sort of , left to its own devices , like without the  a strong language model and so forth , that you would   you would make significant number of errors  just with your uh probabilistic machinery in deciding\nIt also\none oh\nYeah , the  though I think uh there was one problem with that in that , you know , we used canonical mapping so  our truth may not have really been  true to the acoustics .\nUh - huh .\nHmm .\nSo .\nMmm .", "topic_id": 3, "keywords": "latency, spectrum, spectral, experiments, performance", "dialogue_id": 20}, {"text": "Yeah . Well back twenty years ago when I did this voiced - unvoiced stuff , we were getting more like  ninety - seven or ninety - eight percent correct in voicing . But that was  speaker - dependent  actually . We were doing training  on a particular announcer\nMm - hmm .\nand  and getting a  very good handle on the features .\nMm - hmm .\nAnd we did this complex feature selection thing where we looked at all the different possible features one could have for voicing and   and  and uh  and exhaustively searched  all size subsets and  and uh  for  for that particular speaker and you 'd find you know the five or six features which really did well on them .\nWow !\nMm - hmm .\nAnd then doing  doing all of that we could get down to two or three percent error . But that , again , was speaker - dependent with  lots of feature selection\nMm - hmm .\nand a very complex sort of thing .\nMmm .\nSo I would  I would believe  that uh it was quite likely that um looking at envelope only , that we 'd be  significantly worse than that .\nMm - hmm .\nUh .\nAnd the  all the  the SpeechCorders ? what 's the idea behind ? Cuz they  they have to  Oh , they don't even have to detect voiced spe speech ?\nThe modern ones don't do a   a simple switch .\nThey just work on the code book\nThey work on the code book excitation .\nand find out the best excitation .\nYeah they do  analysis - by - synthesis . They try  they  they try every  every possible excitation they have in their code book and find the one that matches best .\nYeah . Mmm . Alright . Yeah . So it would not help .\nYeah .\nHmm .\nUh . O K .\nCan I just mention one other interesting thing ?\nYeah .\nUm . One of the ideas that we  had come up with last week for things to try to  improve the system  Um . Actually I  I s we didn't  I guess I wrote this in after the meeting b but  the thought I had was um looking at the language model that 's used in the HTK recognizer , which is basically just a big  loop ,\nMm - hmm .\nright ? So you  it goes \" digit \"\nMm - hmm .\nand then that can be  either go to silence or go to another digit , which  That model would allow for the production of  infinitely long sequences of digits , right ?\nRight .\nSo . I thought \" well I 'm gonna just look at the  what actual digit strings do occur in the training data . \"\nRight .\nAnd the interesting thing was it turns out that there are no sequences of two - long or three - long digit strings  in any of the Aurora training data . So it 's either one , four , five , six , uh up to eleven , and then it skips and then there 's some at sixteen .\nBut what about the testing data ?\nUm . I don't know . I didn't look at the test data yet .\nYeah . I mean if there 's some testing data that has  has   has two or three\nSo . Yeah . But I just thought that was a little odd , that there were no two or three long  Sorry . So I  I  just for the heck of it , I made a little grammar which um , you know , had it 's separate path  for each length digit string you could get . So there was a one - long path and there was a four - long and a five - long\nMm - hmm .\nand I tried that and it got way worse . There were lots of deletions .\nMm - hmm .\nSo it was   you know , I  I didn't have any weights of these paths or  I didn't have anything like that .\nMm - hmm .\nAnd I played with tweaking the  word transition penalties a bunch , but I couldn't go anywhere .\nHmm .\nBut um . I thought \" well if I only allow  \" Yeah , I guess I should have looked at  to see how often there was a mistake where a two - long or a three - long path was actually put out as a hypothesis . Um . But .\nHmm .\nSo to do that right you 'd probably want to have   allow for them all but then have weightings and things . So . I just thought that was a interesting  thing about the data .\nOK . So we 're gonna read some more digit strings I guess ?\nYeah . You want to go ahead , Morgan ?\nSure .", "topic_id": 4, "keywords": "speechcorders, voiced, voicing, speaker, features", "dialogue_id": 20}, {"text": "st\nSo we 're on .\nYeah . That 's better .\nAnd ,  somewhere is my agenda . I think the most important thing is Morgan wanted to talk about , uh , the ARPA  demo .\nWell , so , here 's the thing . Um , why don't we s again start off with  with , uh , Yeah , I 'll get it . I 'll get the door . Um , I think we want to start off with the agenda . And then , given that , uh , Liz and Andreas are gonna be  ten , fifteen minutes late , we can try to figure out what we can do most effectively without them here . So   So  so , one thing is , yeah , talk about demo ,\nOK . So , uh  uh , IBM transcription status ,\nIBM transcription . Uh , what else ?\nWhat 's SmartKom ? SmartKom ?\nUh , we wanna talk about if w if we wanna add the data to the mar Meeting Recorder corpus .\nThe data . The data which we are collecting here .\nWhat  what  what are we collecting here ?\nData ?\nSo why don't we have that on the agenda and we 'll  we 'll get to it and talk about it ?\nThe SmartKom data ?\nYeah , right .\nYeah .\nUh , right . Uh .\nUh , reorganization status .\nReorganization status .\nOh . Files and directories ?\nFiles and directories .\nYep . Uh - huh . Absinthe , which is the multiprocessor UNIX  Linux . I think it was  Andreas wanted to talk about segmentation and recognition , and update on SRI recognition experiments .\nUm\nAnd then if ti if there 's time I wanted to talk about digits , but it looked like we were pretty full , so I can wait till next week .\nRight . OK . Well , let 's see . I think the a certainly the segmentation and recognition we wanna maybe focus on when An - Andreas is here since that was particularly his thing .\nAnd also the SmartKom thing should b\nSmartKom also , Andreas . Absinthe , I think also he has sort of been involved in a lot of those things .\nAt least ,\nYeah .\nyeah , he 'll t he 'll probably be interested .\nYeah .\nBut .\nUm So , I mean , I think they 'll be inter I 'll be interested in all this , but  but , uh , probably , if we had to pick something  that we would talk on for ten minutes or so while they 're coming here . Or I guess it would be , you think , reorganization status , or  ?\nYeah . I mean , I think , Chuck was the one who added out the agenda item . I don't really have anything to say other than that we still haven't done it .\nWell , I mean , I uh   just basically that\nSo .\nmaybe I said  maybe we said this before  just that we met and we talked about it and we sort of have a plan for getting things organized and\nAnd I  and I think a crucial part of that is the idea of  of not wanting to do it until right before the next level zero back - up so that there won't be huge number of  of added ,\nRight .\nuh\nRight .\nThat  that was basically it . Not  not much @ @\nAlthough Dave basically said that if we wanna do it , just tell him and he 'll do a d level zero then .\nYeah . Uh - huh . Oh , excellent .\nSo .\nOh , good .\nOh , so maybe we should just go ahead and get everything ready , and\nYep . So , I think we do need to talk a little bit about  Well , we don't need to do it during this meeting .\nYeah .\nWe have a little more to discuss . But , uh , we 're  we 're basically ready to do it . And , uh , I have some web pages on ts  more of the background . So , naming conventions and things like that , that I 've been trying to keep actually up to date . So . And I 've been sharing them with U - d UW folks also .\nI 'm sorry , you 've been what ? Showing them ?\nOK .\nSharing them .\nSharing them with the UW folks .\nOK . OK .\nOK . Well , maybe uh , since that  that was a pretty short one , maybe we should talk about the IBM transcription status . Someone can  fill in Liz and Andreas later . Uh\nOK . So , we , uh  we did another version of the beeps , where we separated each beeps with a spoken digit . Chuck came up here and recorded some di himself speaking some digits , and so it just goes \" beep one beep \" and then the phrase , and then \" beep two beep \" and then the phrase . And that seems pretty good . Um , I think they 'll have a b easier time keeping track of where they are in the file .\nAnd we have done that on the  automatic segmentations .\nAnd we did it with the automatic segmentation , and I don't think  We ne we didn't look at it in detail . We just sent it to IBM . We  we sorta spot - checked it .\nI listened to  probably , uh , five or ten minutes of it from the beginning .\nYeah .\nOh , really ?\nYeah .\nOK .\nAnd\nI sorta spot - checked here and there and it sounded pretty good . So . I think it 'll work .\nOK .\nAnd , uh , we 'll just hafta see what we get back from them . Uh\nAnd the main thing will be if we can align what they give us with what we sent them . I mean , that 's the crucial part .\nRight .\nAnd I think we 'll be able to do that at  with this new beep format .\nYep . Well , I think it 's also they are much less likely to d have errors .\nMm - hmm .\nI mean , so the problem wi last time is that there were errors in the transcripts where they put beeps where there weren't any , or  and they put in extraneous beeps .\nRight . Yeah .\nAnd with the numbers there , it 's much less likely .\nYeah , one interesting note is  uh , or problem  I dunno if this was just because of how I play it back , I say , uh , SND - play and then the file , every once in a while , @ @  uh , like a beep sounds like it 's cut into two beeps .\nYeah . Into two pieces .\nYeah , and I  I dunno if that 's an , uh , artifact of playback\nYeah . Yep .\nbu uh , I don't think it 's probably in the original file . Um , but , uh\nI recognize that , too . Yeah .\nHa . That 's interesting . I didn't hear that .\nYeah . But with this new format , um , that hopefully they 're not hearing that , and if they are , it shouldn't throw them .\nYep .\nSo .\nWell , maybe we better listen to it again , make sure , but , I mean , certainly the software shouldn't do that ,\nYeah . That 's what I thought .\nso .\nMm - hmm .\nI it 's probably just , you know , mmm , somehow the audio  device gets hung for a second ,\nYeah . Some latency or something .\nHiccups .\nYeah ?\nAs long as they have one number , and they know that there 's only one beep maximum  that goes with that number .\nor\nYeah .\nYeah . Right .\nYeah . The only  the only part that might be confusing is when Chuck is reading digits .\nRight .\nYep .\nWell , you know , actually , are we having them\nSo  th\n\" Seven four eight beep seven beep  eight three two \" .\nYeah , but are we having them do digits ?\nYes . Because , uh , we don't  we didn't  In order to cut them out we 'd have to listen to it .\nWe  we didn't cut those out .\nYeah . They are not transcribed yet . So . Yeah .\nOK .\nYeah .\nAnd we wanted to avoid doing that ,\nOK .\nso we  they are transcribing the digits .\nOK .\nWe can  we can ignore it when we get it back ,\nAlthough we could tell them    we could tell them , if you hear someone reading a digits string just say \" bracket digit bracket \"\nhuh .\nand don't bother actually computing the di writing down the digits .\nYeah .\nThat 'd be great . That 'd be what I 'm having the transcribers here do , cuz it can be extracted later .\nYep . And then I wanted to talk about  but as I said I  we may not have time  what we should do about digits . We have a whole pile of digits that haven't been transcribed .\nLe - let 's talk about it , because that 's  that 's something that I  I know Andreas is less interested in than Liz is ,\nOK .\nso , you know . It 's good\nDo we have anything else to say about transcription ? About IBM stuff ?\nUh , Brian  I  I  sent bresset    sent Brian a message about   the meeting and I haven't heard back yet . So . I g hope he got it and hopefully he 's\nOK .\nHmm .\nmaybe he 's gone , I dunno . He didn't even reply to my message . So . I should probably ping him just to make sure that he got it .\nAlright . So , we have a whole bunch of digits , if we wanna move on to digits .\nActually , maybe I  One  one relate more related thing in transcription . So that 's the IBM stuff . We 've got that sorted out . Um , how 're we doing on the  on the rest of it ?\nWe 're doing well . I  I hire  I 've hired two extra people already , expect to hire two more .\nHmm .\nAnd , um ,  I 've prepared , um , uh , a set of five which I 'm  which I 'm calling set two , which are now being edited by my head transcriber ,  in terms of spelling errors and all that . She 's also checking through and mar and   and monitoring , um , the transcription of another transcriber . You know , I mean , she 's going through and doing these kinds of checks .\nUh - huh .\nAnd , I 've moved on now to what I 'm calling set three . I sort of thought if I do it in sets  groups of five , then I can have , like , sort of a  a parallel processing through  through the  the current .\nUh - huh .\nAnd  and you indicated to me that we have a g a goal now ,  for the  for the , um , {nonvocalsound}  the , uh , DARPA demo , of twenty hours . So , I 'm gonna go up to twenty hours , be sure that everything gets processed , and released , and    and that 's  that 's what my goal is . Package of twenty hours right now ,  and then once that 's done , move on to the next .\nYeah , uh , so twenty hours . But I guess the other thing is that , um , that  that 's kinda twenty hours ASAP because the longer before the demo we actually have the twenty hours , the more time it 'll be for people to actually do cool things with it .\nMm - hmm . Good . I 'm  I 'm hiring people who ,  uh , really are\nSo . OK .\nThey would like to do it full - time , several of these people . And  and I don't think it 's  possible , really , to do this full - time , but , that  what it shows is motivation to do as many hours as possible .\nMm - hmm .\nIt 'll keep your accuracy up . Yep .\nYeah .\nAnd they 're really excellent .\nYeah . Well , that 's good .\nYeah . Got a good core group now .\nYeah , I mean , I guess the  So the difference if  if , um , if the IBM stuff works out , the difference in the job would be that they p primarily would be checking through things that were already done by someone else ?\nAgain . Mm - hmm .\nIs that most of what it  ?\nAnd correcting .\nI mean  Correcting .\nCorrecting . We 'll  we 'll expect that they 'll have to move some time bins and do some corrections .\nAnd I  you know , I 've also d uh , discovered  So with the new transcriber I 'm  um  So  Uh , lemme say that my , uh  So , um  At present , um , the people have been doing these transcriptions a channel at a time . And , that sort of , um ,  is useful , and t you know , and then once in a while they 'll have to refer to the other channels to clear something up . OK . Well ,  I realize that , um , w i we we 're using the pre - segmented version , and , um , the pre - segmented version is extremely useful , and wouldn't it be , useful also to have the visual representation of those segments ? And so I 've   uh ,  I , uh , uh , I 've  trained the new one  uh , the new the newest one ,  to , um ,  use the visual from the channel that is gonna be transcribed at any given time . And that 's just amazingly helpful . Because what happens then , is you scan across the signal and once in a while you 'll find a blip that didn't show up in the pre - segmentation .\nOh , right .\nAnd that 'll be something like   I it 's ver  it 's interesting .\nI see what you mean . A backchannel , or\nOnce in a while it 's a backchannel .\nYep .\nSometimes it seems to be , um , similar to the ones that are being picked up .\nMm - hmm .\nAnd they 're rare events , but you can really go through a meeting very quickly . You just  you just , you know , yo you s you scroll from screen to screen , looking for blips . And , I think that we 're gonna end up with , uh  better coverage of the backchannels ,\nYeah .\nbut at the same time we 're benefitting tremendously from the pre - segmentation because  there are huge places where there is just absolutely no activity at all . And , uh , the audio quality is so good\nMm - hmm .\nSo they can  they can , um , scroll through that pretty quick ?\nYeah . Mm - hmm .\nThat 's great .\nYeah . So I think that that 's gonna , also  eh ,  you know , speed the efficiency of this part of the process .\nHmm . OK . Uh , yeah . So , uh  Yeah . So let 's talk about the digits , since they 're not here yet .\nUh , so , we have a whole bunch of digits that we 've read and we have the forms and so on , um , but only a small number of that ha well , not a small number  only a subset of that has been transcribed . And so we need to decide what we wanna do . And , uh , Liz and Andreas  actually they 're not here , but , they did say at one point that they thought they could do a pretty good job of just doing a forced alignment . And , again , I don't think we 'll be able to do with that alone , because , um , sometimes people correct themselves and things like that . But  so , I was just wondering what people thought about how automated can we make the process of finding where the people read the digits , doing a forced alignment , and doing the timing .\nWell , forced alignment would be one thing . What about just actually doing recognition ?\nWell , we  we know what they read , because we have the forms .\nNo , they make mistakes .\nRight . But , the point is that we wanna get a set of clean digits .\nYou 're talking about as a pre - processing step .\nRight .\nRight , Morgan ?\nUm\nIs that what you 're  ?\nYeah , I 'm  I 'm not quite sure what I 'm talking about . I mean  I  I mean , uh , we 're talking about digits now . And  and so , um , there 's a bunch of stuff that hasn't been marked yet . Uh . And , um ,  there 's the issue that  that they  we know what  what was said , but do we ?\nI mean , so one option i\nBecause people make mistakes and stuff . I was just asking , just out of curiosity , if  if with , uh  uh , the SRI recognizer getting one percent word error , uh , would we  would we do  better  ? So , if you do a forced alignment but the force but the  but the transcription you have is wrong because they actually made mistakes , uh , or  false starts , it 's  it 's much less c  it 's  much less common than one percent ?\nBut that 's pretty uncommon . Um , if we could really get one percent on\nWe should be able to .\nWell , I guess  yeah , I guess if we segmented it , we could get one percent on digits .\nRight ?\nYeah .\nYeah . So that 's just my question . I 'm not saying it should be one way or the other , but it 's  If\nBut , Well , there  there 're a couple different of doing it . We could use the tools I 've already developed and transcribe it . Hire some people , or use the transcribers to do it . We could let IBM transcribe it . You know , they 're doing it anyway , and unless we tell them different , they 're gonna transcribe it . Um , or we could try some automated methods .\nWell\nAnd my  my tendency right now is , well , if IBM comes back with this meeting and the transcript is good , just let them do it .\nYeah , it 's  Y you raised a point , kind of , uh , euphemistically  but , I mean , m maybe it is a serious problem . Ho - what will they do when they go  hear \" beep  seven  beep  seven three five two \"  I mean ,  you think they 'll  we 'll get  ?\nIt 's pretty distinct .\nYeah ?\nThe beeps are  pre - recorded .\nIt 'll  only be a problem for m for mine .\nYeah .\nWell it  it  well , it 'd be preceded by \" I 'm reading transcript so - and - so \" ?\nYeah .\nYes .\nSo , I think if they 're processing it at\nI mean , it 'll be  it will be in the midst of a digit string .\nYeah .\nSo  I mean it  sure , there  there might be a place where it 's \" beep seven  beep eight  beep  eight  beep \" . But , you know , they  they 're  they 're gonna macros for inserting the beep marks . And so , I  I don't think it 'll be a problem . We 'll have to see , but I don't think it 's gonna be a problem .\nOK . Well , I  I  I dunno , I  I think that that 's  if they are in fact going to transcribe these things , uh , certainly any process that we 'd have to correct them , or whatever is  needs to be much less elaborate for digits than for other stuff .\nRight .\nSo , why not ? Sure . That was it ?\nThat was it . Just , what do we do with digits ?\nOK .\nWe have so many of them ,  and it 'd be nice to  actually do something with them .\nWell , we  we  we wanna have them . Yeah , I\nYou mean there 're more than ten ?\nAnything else ? Your mike is a little low there .\nI in Berkeley , yeah . So ,  uh  You  you have to go a little early , right ? At twenty\nWell , I can stay till about , uh , three forty .\nAlright . So le let 's make sure we do the ones that  that , uh , saved you .\nYeah . Mm - hmm .\nSo there was some  Uh   In  in  Adam 's agenda list , he had something from you about segmentation this last recognition ?", "topic_id": 0, "keywords": "agenda, meeting, processing, data, computing", "dialogue_id": 21}, {"text": "Well , yeah . So this is just partly to inform everybody , um , and  and of course to get , um , input .\nOops .\nUm , so , {nonvocalsound} uh , we had a discussion  Don and Liz and I had discussion last week about how to proceed with , uh , you know , with Don 's work ,\nCh\nand   and  and , uh , one of the obvious things that occur to us was that we 're  since we now have Thilo 's segmenter and it works , you know , amazingly well ,  um , we should actually basically re - evaluate the recognition , um , results using  you know , without cheating on the segmentations .\nSo\nAnd , that should be fairly\nAnd how do we find the transcripts for those so that  ? Yeah . The references for  for  those segments ?\nOh , OK . So , there 's actually\nIt 's not that\nWhy do you ask ?\nI could\nNo , actually , um , NIST has , um m a fairly sophisticated scoring program  that you can give a , um   a time ,\nHand ones .\nWell\nOK .\nuh  You know , you basically just give two  time - marked sequences of words , and it computes the um  the ,  uh   you know , the  the  th\nIt does all the work for you .\nit does all the work for you .\nYeah .\nOK .\nSo , it  we just  and we use that actually in Hub - five to do the scoring . Um . So what we 've been using so far was sort of a  simplified version of the scoring . And we can  we can handle the  the  the type of problem we have here .\nSo , basically you give some time constraints for  for the references and for  for the hypothesis ,\nSo , we ha Yeah . Right .\nand  Yeah , OK .\nYeah .\nRight .\nMaybe the  start of your speech and the end of it ,\nSo do\nOK .\nor stuff like that .\nRight . It does time - constrained word - alignment .\nOK .\nSo . So that should be possible . I mean that shouldn't be a problem . Uh , so that was the one thing , and the other was that , um  What was the other problem ? Oh ! That Thilo wanted to use  the recognizer alignments to train up his , um , speech detector .\nYeah .\nUm , so that we could use , uh  you know there wouldn't be so much hand  labelling needed to , uh  to generate training data for  for the speech detector .\nYeah . I 'm just in progress of  of doing that . So .\nAnd I think you 're in the process of doing that .\nYeah .\nSo , you can   you can\nIt 'll give you a lot more data , too . Won't it ?\nYeah . So , it 's basically  s I think , eight meetings or something which  which I 'm using , and ,  it 's   before it was twenty minutes of one meeting .\nMm - hmm .\nSo  should  be a little bit better .\nRight .\nGreat .\nThat won't be perfect  the alignments aren't perfect ,\nYeah . But\nbut , um , it 's probably still better to have all this extra data , than\nYeah .\nYeah . Yep .\nYeah .\nWe 'll see that .\nYeah .\nOK .\nActually , I had a question about that . If you find that you can  lower the false alarms that you get where there 's no speech , that would be useful  for us to know . So , um\nThere were the false alarms .\nYeah . So ,  r right now you get f fal you know , false  false , uh , speech regions when it 's just like , um ,  breath or something like that ,\nOK . Yeah . Yep .\nand I 'd be interested to know the  wha if you retrain um ,\nYeah .\ndo those actually go down or not ? Because  of\nYeah . I 'll  can make  an can , like , make a c comparison of  of the old system to the  to the new one , and  then\nYeah , just to see if by doing nothing in the modeling of  just having that training data wh what happens .\nYeah . Yeah . Yep .\nUm another one that we had on Adam 's agenda  that definitely involved you was s something about SmartKom ?\nRight . So , Rob Porzel  eh , Porzel ? and the , uh  Porzel  and the , uh , SmartKom group are collecting some dialogues .\nPorzel . Porzel .\nBasically they have one person sitting in here , looking at a picture , and a wizard sitting in another room somewhere . And , uh , they 're doing a travel task . And , uh , it involves starting  I believe starting with a  It 's  it 's always the wizard , but it starts where the wizard is pretending to be a computer and it goes through a , uh ,  speech generation system .\nYeah . Actually , it 's changed to a synthesis for  for the first part now .\nSynthesis system .\nYeah .\nUm , and then , it goes to a real wizard and they 're evaluating that . And they wanted to use this equipment , and so the w question came up , is  well , here 's some more data . Should this be part of the corpus or not ? And my attitude was yes , because there might be people who are using this corpus for  acoustics , as opposed to just for language . Um , or also for dialogue of various sorts . Um , so it 's not a meeting . Right ? Because it 's two people and they 're not face to face .\nWait a minute . So , I just wanted to understand it , cuz I  I 'm  uh , hadn't quite followed this process .\nYeah .\nUm . So , it 's wizard in the sen usual sense that the person who is asking the questions doesn't know that it 's , uh , a machi not a machine ?\nRight .\nAt the beginning .\nActually  actually , w w the  the  We do this  I dunno who came up with it , but I think it 's a really clever idea . We simulate a computer breakdown halfway through the session , and so then after that , the person 's told that they 're now talking to a , uh  to a human .\nYeah .\nIt 's a human operator .\nYeah .\nYeah .\nBut of course they don't know that it 's the same person both times .\nSo , we  we collect  we collect both human - computer and human - human data , essentially , in the same session .\nYou might wanna try collecting it the other way around sometime , saying that th the computer isn't up yet\nHmm .\nand then  so then you can separate it out whether it 's the beginning or end kind of effects .\nThat 's an idea .\nBut , yeah .\nYep .\nYeah .\nThat 's a good idea .\n\" I have to go now . You can talk to the computer . \"\nIt 's a lot more believable , too ,\n\" No ! \"\nif you tell them that they 're  the computer part is running on a Windows machine . And the whole breakdown thing kinda makes sense .\nO Just  just reboot it .\nAbort  abort , retry , fail ?\nSo did they actually save the far - field  data ?\nYes .\nWell , this was  this was the question .\nCuz at first they weren't  they weren't sa\nYeah .\nSo  so they were saying they were not going to ,\nYeah .\nOK .\nand I said , \" well that 's silly , if  if we 're gonna try to do it for a corpus , there might be people who are interested in acoustics . \"\nYeah .\nWow .\nNo .\nOr\nprojector  We were not saying we are not  doing it .\nYeah .\nS\nWe wer we just wanted to do\nNo , the  the question is do we save one or two far - field channels or all of them ?\nRight .\nYeah . Yeah .\nI  I see no reason not to do all of them .\nUm\nThat  that if we have someone who is doing acoustic studies , uh , it 's nice to have the same for every recording .\nNnn . Yeah .\nHmm .\nSo , what is the purpose of this recording ?\nMm - hmm .\nThis is to get acoustic and language model training data for SmartKom. OK .\nIt 's to be traini to b training data and development data for the SmartKom  system .\nThe English system ? Yeah .\nYeah . Right . Right .\nWhere does this  ?\nMaybe we can have him vary the microphones , too ,\nWell ,\nB\nor they 're different s speakers .\nRight . So  so  so for their usage , they don't need anything .\nso why not  ?\nYeah .\nRight ?\nBut  but I 'm not sure about the legal aspect of  of that . Is  is there some contract with SmartKom or something about the data ?\nYeah .\nWhat they  or , is  is that our data which we are collecting here ,\nWe 've never signed anything that said that we couldn't use anything that we did .\nor  ? OK . OK .\nWe weren't supposed to collect any data .\nSo . OK .\nYeah .\nSo . Yeah , th th that was the question .\nThis was all\nIf  if  ? Yeah .\nYeah .\nNo that 's not a problem .\nBasically .\nI  L look , it seems to me that if we 're doing it anyway and we 're doing it for these  these purposes that we have ,  and we have these distant mikes , we definitely should re should save it all as long as we 've got disk space ,\nMm - hmm .\nand disk is pretty cheap .\nOK .\nSo should we save it ?\nAnd then\nNow th Yeah . So we save it because it 's  it  it 's potentially useful . And now , what do we do with it is  is a s separate question .\nRight .\nI mean , anybody who 's training something up could  choose to put it  eh , to u include this or not .\nRight .\nI  I would not say it was part of the meetings corpus . It isn't . But it 's some other data we have , and if somebody doing experiment wants to train up including that then they can . Right ?\nMm - hmm .\nSo it 's  It  it  I guess it  the  begs the question of what is the meeting corpus . So if , at UW they start recording two - person hallway conversations is that part of the meeting corpus ?\nI think it 's  I  I think  I th think the idea of two or more people conversing with one another is key .\nWell , this has two or more people conversing with each other .\nNnn , well\nYeah .\nWell this\nThey 're just not face to face .\nWhat if we just give it a  a name like we give these meetings a name ?\nNo , it doesn't . Right ? It has\nI mean , that was my intention .\nAnd then later on some people will consider it a meeting and some people won't ,\nWell this\nYeah .\nThat was my intention . So  so  s  so part of the reason that I wanted to bring this up is ,  do we wanna handle it as a special case or do we wanna fold it in ,\nand  Just give it a  title .\nOh .\nI think it is a s\nwe give everyone who 's involved as their own user ID , give it session I Ds ,  let all the tools that handle Meeting Recorder handle it , or do we wanna special case it ? And if we were gonna special case it , who 's gonna do that ?\nSo .\nWell , it  it makes sense to handle it with the same infrastructure , since we don't want to duplicate things unnecessarily .\nIt  it  it\nI think\nBut as far as distributing it , we shouldn't label it as part of this meeting corpus .\nYeah .\nWe should let it be its own corp\nWell it 's  it  well , because\nI don't see why not . It 's just a different topic .\nI ha I have an extra point , which is the naturalness issue . Because we have , like , meetings that have a reason . That 's one of the reasons that we were talking about this . And  and those  and this sounds like it 's more of an experimental setup .\nYeah .\nIt 's got a different purpose .\nIt 's scenario - based , it 's  it 's human - computer interface   it 's really pretty different .\nYeah .\nBut I I  I have no problem with somebody folding it in for some experiment they 're gonna do , but I don't think i it  it doesn't match anything that we 've described about meetings .\nMm - hmm .\nWhereas everything that we talked about them doing at  at UW and so forth really does . They 're actually talking\nOK . So w so what does that mean for how we are gonna organize things ?\nHmm .\nYeah .\nYou can  you can  Again , as  as I think Andreas was saying ,  if you wanna use the same tools and the same conventions , there 's no problem with that . It 's just that it 's , you know , different directory , it 's called something different , it 's  you know . It is different . You can't just fold it in as if it 's  I mean , digits are different , too . Right ?\nYeah , but those are folded in ,\nIt might also be potentially confusing .\nand it 's just  you just mark the transcripts differently . So  so one option is you fold it in ,\nRight .\nand just simply in the file you mark somewhere that this is this type of interaction , rather than another type of interaction .\nYeah , I th\nWell , I don I wouldn't call reading digits \" meetings \" . Right ? I mean , we  we  we were doing\nWell , but  but ,  I put it under the same directory tree .\nWell\nYou know , it 's in \" user doctor speech data MR \" .\nCan we just have a directory called , like , \" other stuff \" ?\nOther .\nAnd  Well  or , I dunno .\nI mean , I don't care what directory tree you have it under .\nAnd   and just , um , store it there .\nRight ? I mean that 's just a\nOK . My preference is to have a single procedure so that I don't have to think too much about things .\nYes .\nI mean\nYeah .\nAnd , just have a marking .\nO - You  you can use whatever procedure you want that 's p convenient for you .\nIf we do it any other way that means that we need a separate procedure , and someone has to do that .\nAll I 'm saying is that there 's no way that we 're gonna tell people that reading digits is meetings . And similarly we 're not gonna tell them that someone talking to a computer to get travel information is meetings .\nRight .\nThose aren't meetings . But if it makes it easier for you to pu fold them in the same procedures and have them under the same directory tree , knock yourself out .\nThere 's a couple other questions that I have too ,\nYou know ?\nand  and  one of them is , what about , uh , consent issues ? And the other one is , what about transcription ? Are  ?\nTranscription is done in Munich .\nOK . So we don't have to worry about transcribing it ?\nAlright .\nYeah .\nSo , w we will hafta worry about format .\nThat 's a  that 's another argument to keep it separate , because it 's gonna follow the SmartKom transcription conventions and not the ICSI meeting transcription conventions .\nYeah .\nOh , OK .\nAh . Good point .\nOK . Well , I didn't realize that . That 's  that 's a\nGood point . But I 'm sure no one would have a problem with our folding it in for some acoustic modeling or  or some things . Um . Do we h do we have , uh , um , American - born folk , uh , reading German  German , uh , pla uh , place names and so forth ? Is that  ?\nYeah .\nExactly .\nYeah , great .\nYeah .\nYep .", "topic_id": 1, "keywords": "transcripts, corpus, transcription, segmentations, segmenter", "dialogue_id": 21}, {"text": "Yeah .\nThey  they even have a reading list .\nI bet that sounds good , huh ?\nYeah .\nIt 's pretty funny .\nYeah .\nYou can do that if you want .\nOK .\nYeah .\nI dunno if you want that .\nRight .\nYeah .\nHmm .\nHeidelberg\nSo\nExactly\nDisk might eventually be an issue so we might  we  we might need to , uh ,  get some more disk pretty soon .\nDo you wanna be a subject ?\nYeah , I be pretty good .\nWe  Yeah .\nWe 're about  we 're about half  halfway through our disk right now .\nYeah .\nThat was one of our concerns .\nAre we only half ? I thought we were more than that .\nWe 're probably a little more than that because we 're using up some space that we shouldn't be on . So , once everything gets converted over to the disks we 're supposed to be using we 'll be probably , uh , seventy - five percent .\nWell , when I was looking for space for Thilo , I found one disk that had , uh , I think it was nine gigs and another one had seventeen .\nYep .\nAnd everything else was sorta committed . Uh\nWere those backed - up or non - backed - up ?\nThose were non - backed - up .\nNon - back - up .\nRight . So that 's different .\nS oh , you 're talking about backed - up .\nI 'm much more concerned about the backed - up . The non - backed - up ,\nI haven't looked to see how much of that we have .\nyeah , i is cheap . I mean , if we need to we can buy a disk , hang it off a s uh , workstation . If it 's not backed - up the sysadmins don't care too much .\nYeah . So , I mean , pretty much anytime we need a disk , we can get it at the rate that we 're\nYou can  I shouldn't be saying this , but , you can just  you know , since the back - ups are every night , you can recycle the backed - up diskspace .\nYeah . But that 's  that 's   that 's risky .\nYeah . You really shouldn't be saying\nMmm . Mmm .\nI didn't say that .\nYeah , that 's right .\nI didn't say that .\nBeep that out .\nDa - we had allowed Dave to listen to these   these ,  uh , recordings .\nRight .\nUm   Yeah , I me and there 's been this conversation going on about getting another file server , and  and  we can do that .\nMm - hmm .\nWe 'll take the opportunity and get another big raft of   of disk , I guess .\nYeah . It 's really the back - up issue rather than the file server issue .\nWell , I think   I think there 's an argument for having  you know , you could use our old file server for  for disks that have data that  is very rarely accessed , and then have a fast new file server for data that is , um , heavily accessed .\nYeah . My understanding is , the issue isn't really the file server .\nYeah .\nWe could always put more disks on .\nYeah . It 's the back it 's the back - up capaci\nIt 's the back - up system .\nYeah .\nSo  which is near saturation , apparently . So .\nI think  I think the file server could become an issue as we get a whole bunch more new compute machines .\nSoon .\nAnd we 've got , you know , fifty machines trying to access data off of Abbott at once .\nWell , we 're alright for now because the network 's so slow .\nI mean , I think  I think we 've raised this before and someone said this is not a reliable way to do it , but the  What about putting the stuff on , like , C - CD - ROM or DVD or something ?\nYeah . That was me . I was the one who said it was not reliable . The - they  they wear out .\nOK . Oh , OK .\nYeah . The  the  th\nBut they wear out just from sitting on the shelf ?\nYep . Absolutely .\nOr from being  read and read ?\nNo . Read and write don't hurt them too much unless you scratch them .\nOh , OK .\nBut the r the write once , and the read - writes , don't last . So you don't wa you don't wanna put ir un reproduceable data  on them .\nUh - huh .\nWear out after what amount of time ?\nYear or two .\nWould it be  ?\nYear or two ?\nYep .\nWow .\nHmm .\nBut if that  then you would think you 'd  hear much more clamoring about data loss\nYeah .\nand\nI mean , yeah , all the L\nI  I don't know many people who do it on CD . I mean , they 're  the most  fo\nLDC - all the LDC distributions are on CD - ROM .\nYeah .\nThey 're on CD , but they 're not  tha that 's not the only source .\nLike\nThey have them on disk . And they burn new ones every once in a while . But if you go   if you go k\nBut , you know , we have\nBut we have like thirty  you know , from  ten years ago ?\nWe have all sorts of CD - ROMs from a long time ago .\nNo .\nYeah .\nYeah !\nWell , th th OK .\nTen years ago .\nRight .\nNinety - one , and they 're still all fine .\nYeah .\nWere they burned or were they pressed ?\nUh , both . I 've burned them and they 're still OK .\nYeah .\nThe  the pressed ones last for\nI mean , usually they 're\nwell , not forever , they 've been finding even those degrade .\nOh , I see .\nBut , uh , the burned ones  I mean , when I say two or three years what I 'm saying is that I have had disks which are gone in a year .\nThat 's what I\nOn the average , it 'll probably be three or four years . But , uh  I  I  you don't want to per p have your only copy on a media that fails .\nMmm .\nAnd they do . Um , if you have them professionally pressed , y you know , they 're good for decades .\nSo how about  ? So  so how about putting them on that plus , like on a  on  on DAT or some other medium that isn't risky ?\nI think th um , we can already put them on tape . And the tape is hi is very reliable .\nOK . Mm - hmm .\nSo the  the only issue is then  if we need access to them . So that 's fine f if we don't need access to them .\nRight . Well , if  if  if you  if they last  Say , they actually last , like , five years , huh , in  in the typical case , and  and occasionally you might need to recreate one , and then you get your tape out , but otherwise you don't . Can't you just  you just put them on  ?\nSo you just archive it on the tape , and then put it on CD as well ?\nYeah . Right .\nOh . So you 're just saying put them on C Ds for normal access .\nYeah .\nRight .\nWhat you\nYeah . I mean , you can do that but that 's pretty annoying , because the C Ds are so slow .\nSee  Yeah .\nYeah .\nMmm .\nWhat 'd be nice is a system that re - burned the C Ds every  year .\nH everytime it was a \" gonna \"  \" gonna die \" .\nWell\nWell , I mean , the C Ds are  are an op\nYeah .\nIt 's like  like dynamic ra DRAM .\nJust before .\nYeah .\nJust before they be before it goes bad , it burns them in .\nThe  the CD is an alternative to tape .\nYeah .\nICSI already has a perfectly good tape system and it 's more reliable .\nYou know  I would think\nSo for archiving , we 'll just use tape .\nOne  one thing I don't understand is , if you have the data  if  if you if the meeting data is put on disk exactly once , then it 's backed - up once and the back - up system should never have to bother with it , uh , more than once .\nWell , regardless  Well , first of all there was , um , a problem with the archive in that I was every once in a while doing a chmod on all the directories an or recursive chmod and chown , because  they weren't getting set correctly every once in a while ,\nMm - hmm .\nand I was just ,  doing a minus R star ,  not realizing that that caused  it to be re - backed - up .\nMm - hmm .\nAh .\nBut normally you 're correct . But even without that , the back - up system is becoming saturated .\nBut  but this back - up system is smart enough to figure out that something hasn't changed and doesn't need to be  backed - up again .\nThe b I think th the  at least the once tha that you put it on , it would   it would   kill that .\nSure , but we still have enough changed that the nightly back - ups are starting to take too long .\nOK . So  so then , if  So  so then , let 's\nSo .\nIt has nothing to do with the meeting . It 's just the general ICSI back - up system is becoming saturated .\nRight . OK . Right . So , what if we buy , uh  uh , what  what do they call these , um  high density  ?\nWell , why don't you have this  have a  this conversation with Dave Johnson tha rather than with me ?\nNo , no . Because this is  maybe something that we can do without involving Dave , and  and , putting more burden on him . How about we buy , uh  uh  uh , one of these high density tape drives ? And we put the data actually on non - backed - up disks . And we do our own back - up once and for all  all , and then  and we don't have to bother this @ @ up ?\nActually , you know , we could do that just with the tape  with the current tape .\nI dunno what the these tapes  uh , at some point these  I dunno . What kind of tape drive is it ?\nI dunno but it 's an automatic robot so it 's very convenient .\nIs it  is  ?\nWh The o the one that we have ?\nYou just run a program to restore them .\nRight .\nThe  I mean\nYeah .\nBut it might interfere with their back - up schedule ,\nBut\nNo , we have s we  Don't we have our own ?\neh .\nSomething wi th that doesn't  that isn't used by the back - up gang ? Don't we have something downstairs ?\nWell they\nWhat kinda tape drive ?\nJust in  ? Yeah .\nWell  but  no , but Andreas 's point is a good one . And we don't have to do anything ourselves to do that . They 're already right now on tape .\nRight .\nRight . So your  your point is , and I think it 's a good one , that we could just get more disk and put it there .\nMmm . On an XH  uh , X  X whatever partition .\nYeah . That 's not a bad idea .\nYeah .\nYeah , that 's basically what I was gonna say , is that a disk is  is so cheap it 's es essentially , you know , close to free . And the only thing that costs is the back - up  issue ,  eh , to first order .\nSo once it 's on tape\nRight . Right .\nAnd we can take care of that by putting it on non - back  up drives and just backing it up once onto this tape .\nMm - hmm .\nI think that 's a good idea .\nRight .\nOh . Yeah .\nOK .\nGood . It 's good .\nSo , who 's gonna do these back - ups ? The people that collect it ?\nUh Well , I 'll talk to Dave , and  and see what th how  {nonvocalsound} what the best way of doing that is .\nIt 's probably gonna n\nThere 's a little utility that will manually burn a tape for you , and that 's probably the right way to do it .\nYeah , and we should probably make that part of the procedure for recording the meetings .\nWell , s\nYep .\nYeah . That 's what I 'm wondering , if\nWell  we 're g we 're gonna automate that .\nOK .\nMy intention is to  do a script that 'll do everything .\nI mean , you don't have to physically put a tape in the drive ?\nNo . It 's all tape robot ,\nOr s ? s ?  Oh , OK .\nso you just sit down at your computer and you type a command .\nSo it 's just  Oh , OK .\nYeah , but then you 're effectively using the resources of the back - up system . Or is that a different tape robot ?\nYeah .\nBut not at the same time .\nBut y but you would be anyway .\nNo , no , no .\nRight ?\nHe 's saying get a whole different drive .\nBecause\nNo , no . See\nBut there 's no reason to do that .\nYeah , just give a dedi\nIt  we already have it there and it  it 's\nWell , I 'm saying is @ @ i if you go to Dave , and  and  and ask him \" can I use your tape robot ? \" , he will say , \" well  that 's gonna screw up our back - up operation . \"\nNo , we won't . He 'll say \" if  if that means  that it 's not gonna be backed - up standardly , great . \"\nHe - I  Dave has  has promoted this in the past . So I don't think he 's actually against it .\nYeah . It 's  it 's definitely no problem .\nOh , OK . Alright .\nYeah .\nAlright .\nOK .\nGood .\nWhat about if the times overlap with the normal back - up time ?\nUm , it 's  it 's just  it 's just a utility which queues up . It just queues it up and  and when it 's available , it will copy it .\nOK .\nYeah .\nAnd then you can tell it to then remove it from the disk or you can , you know , do it a a few days later or whatever you wanna do , after you confirm that it 's really backed - up .\nOK .\nNW  ?\nYou saying NW archive ?\nNW archive .\nYep   And if you did that during the day it would never make it to the nightly back - ups .\nThat 's what it is .\nOK .\nRight .\nAnd then there wouldn't be this extra load .\nWell , it  if he  you have to put the data on a  on a non - backed - up disk to begin with .\nWell , but you can have it NW archive to  you can have ,  uh , a non - backed - up disk NW archived ,\nRight .\nSo that  so that  otherwise you don't  you\nand it 'll never show up on the nightly back - ups .\nRight . And then it never\nRight . Right .\nRight . Which I 'm sure would make ever the sysadmins very happy .\nRight .\nYeah .\nSo , I think that 's a good idea .\nOK .\nThat 's what we should do .\nOK .\nSo , that means we 'll probably wanna convert all  all those files  filesystems to non - backed - up media .\nThat sounds good .\nYeah .", "topic_id": 2, "keywords": "disk, filesystems, diskspace, disks, drives", "dialogue_id": 21}, {"text": "Yep .\nUm , another , thing on the agenda said SRI recognition experiments ? What 's that ?\nSRI recognition ? Oh .\nThat wasn't me .\nUh .\nUm . well ,\nWho 's that ?\nwe have lots of them . Uh , I dunno . Chuck , do you have any  any updates ?\nN I 'm successfully , uh , increasing the error rate . Uh\nThat 's good .\nMmm .\nOh .\nLift the Herve approach .\nYeah . So , I mean I 'm just playing with , um , the number of Gaussians that we use in the  the recognizer , and\nWell , you have to sa you have to  tell people that you 're  you 're doing  you 're trying the tandem features .\nYes , I 'm using tandem features .\nOh you are ?\nAnd\nCool .\nA and I 'm still tinkering with the PLP features .\nYeah , I got confused by the results . It sai because  uh , the  meeting before ,  you said \" OK , we got it down to where they 're  they 're within a tenth of a percent \" .\nThat was on males .\nRight . That was  that was before I tried it on the females .\nOh .\nSee , women are nothi are , trouble .\nIt 's the women are the problem . OK .\nRight ? As we all know . So .\nWell , let 's just say that men are simple .\nSo   so , when  So I  I had  I ha\nThat was a quick response .\nSo , we had reached the point where\nI 'm well rehearsed .\nYeah .\nwe had reached the point where ,  um , on the male portion of the  development set , the , um  or one of the development sets , I should say   the , um  the male error rate with , uh , ICSI PLP features was pretty much identical with , uh , SRI features . which are  MFCC . So , um , then I thought , \" Oh , great . I 'll j I 'll  just let 's make sure everything works on the females . \" And the error rate  you know , there was a three percent difference .\nOh . Uh - huh .\nSo ,\nIs there less training data ?\nuh\nI mean , we don\nNo , actually there 's more training data .\nThis is on just digits ?\nNo .\nNo , no .\nNo .\nHub - five .\nIt 's , uh , Swi\nOh , sorry . OK . This is on\nThis is Hub - five .\nOh , OK .\nHub - five . Yeah .\nYeah . Um , and the test data is CallHome and Switchboard . So , uh  so then  um  Oh , and plus the  the vocal tract  length normalization didn't  actually made things worse . So something 's really seriously wrong . So  Um\nAha ! OK .\nSo  So\nSo  but you see , now , between  between the males and the females , there 's certainly a much bigger difference in the scaling range , than there is , say , just within the males . And what you were using before was scaling factors that were just from the  the m the  SRI front - end . And that worked  that worked fine .\nThat 's true . Yeah .\nUh , but now you 're looking over a larger range and it may not be so fine .\nWell , um  So  I just  d so the one thing that I then tried was to put in the low - pass filter , which we have in the  So , most  most Hub - five systems actually band - limit the  uh , at about , uh , thirty - seven hundred , um , hertz .\nUh - huh .\nAlthough , you know , normally , I mean , the channel goes to four  four thousand . Right ? So , um  And that actually helped , uh  uh , a little bit .\nUh - huh .\nUm  and it didn't hurt on the males either . So , um  And I 'm now , uh , trying the  Oh , and suddenly , also the v the vocal tract length normalization only in the test se on the test data . So , you can do vocal tract length normalization on the test data only or on both the training and the test .\nYeah .\nAnd you expect it to help a little bit if you do it only on the test , and s more if you do it on both training and test .\nYeah .\nAnd so the  It now helps , if you do it only on the test , and I 'm currently retraining another set of models where it 's both in the training and the test , and then we 'll  we 'll have , hopefully , even better results . So  But there 's  It looks like there will still be some difference , maybe between one and two percent , um , for the females .\nHuh .\nAnd so , um , you know , I 'm open to suggestions .\nMm - hmm .\nAnd it is true that the , uh  that the   you know , we are using the  But  it can't be just the VTL ,\nUh - huh .\nbecause if you don't do VTL in both systems , uh , you know , the  the females are considerably worse in the  with the PLP features .\nNo  no . I  I remember that .\nIt 's much worse . Yeah .\nSo there must be some  something else going on .\nWell , what 's the standard  ? Yeah , so I thought the performance was actually a little better on females than males .\nThat 's what I thought , too .\nUm ,  that  ye  overall , yes , but on this particular development test set , they 're actually a little worse . But that 's beside the point . We 're looking at the discrepancy between the SRI system and the SRI system when trained with ICSI features .\nRight . I 'm just wondering if that  if  if you have any indication of your standard features ,\nWhat 's  Are the freq ?\nyou know , if that 's also different  or in the same direction or not .\nYou 're  This is  lemme ask a q more basic que\nCuz\nI mean , is this , uh  uh , iterative , Baum - Welch training ?\nMm - hmm .\nOr is it Viterbi training ? Or  ?\nIt 's Baum - Welch training .\nBaum - Welch training . And how do you determine when to  to stop iterating ?\nUm  Well , actually , we  we just basically do a s a fixed number of iterations .\nHmm .\nUh , in this case four . Um , which  Eh , we used to do only three , and then we found out we can squeeze  And it was basically , we 're s we 're keeping it on the safe side . But you 're d Right . It might be that one more iteration  would  would help , but it 's sort of\nOr maybe  or maybe you 're doing one too many .\nyou know .\nI mean it 's  it 's\nNo , but with Baum - Welch , there shouldn't be an over - fitting issue , really .\nUh .  Well , there can be . Sure .\nWell , you can try each one on a cross - validation set ,\nUm .\nIt d if you  if you remember some years ago Bill Byrne did a thing where he was  he was looking at that ,\ncan't you ?\nand he showed that you could get it .\nYeah .\nSo . But   but   but , um\nWell , yeah . We can  Well , that 's  that 's the easy one to check ,\nYeah .\nbecause we save all the intermediate models\nDo you  ?\nand we can\nAnd in each case , ho\nWhat  ?\num , I 'm sorry  in each case how do you determine , you know , the  the usual  fudge factors ? The , uh   the , uh , language , uh , scaling , acoustic scaling , uh , uh\nUm  I uh   I 'm actually re - optimizing them . Although that hasn't shown to make  a big difference .\nOK . And the pru the question he was asking at one point about pruning , uh  Remember that one ?\nPruning  ?\nWell , he was  he 's  it looked like the probabil at one point he was looking at the probabilities he was getting out  at the likelihoods he was getting out of PLP versus mel cepstrum , and they looked pretty different ,\nPruning in the  ?\nYeah , the likelihoods were  lower for the PLP .\nas I recall .\nOh .\nAnd so , uh , there 's the question\nI you mean  did you see this in the SRI system ?\nMm - hmm . Was just looking through the log files ,\nUm . Well , the likelihoods are\nand\nYou can't directly compare them , because , for every set of models you compute a new normalization . And so these log probabilities , they aren't directly comparable\nOh .\nbecause you have a different normalization constants for each model you train .\nHmm .\nBut , still it 's a question\nSo\nif you have some threshold somewhere in terms of beam search or something ,\nWell , yeah . That 's what I was wondering .\nor  ?\nW yeah . I mean  Uh\nI mean , if you have one threshold that works well because the range of your likelihoods is in this area\nWe prune very conservatively . I mean , as we saw with the meeting data , um  we could probably tighten the pruning without really  So we we basically we have a very open beam .\nBut , you 're only talking about a percent or two .\nYeah .\nRight ? Here we 're - we 're saying that we there  gee , there 's this b eh , there 's this difference here . And  it  See cuz , i i  there could be lots of things . Right ? But  but  but  but , um , let 's suppose just for a second that , uh , we 've sort of taken out a lot of the  the major differences , uh , between the two .\nRight . Course . Mm - hmm . Right .\nI mean , we 're already sort of using the mel scale and we 're using the same style filter integration , and  and , well , we 're making sure that low and high\nActually , there is  the difference in that . So , for the PLP features we use the triangular filter shapes . And for the  in the SRI front - end we use the trapezoidal one .\nAnd what 's the top frequency of each ?\nWell , now it 's the same . It 's thirty  thirty to seven hundred and sixty hertz .\nYeah . Exp - one 's triangular , one 's trapezoidal . So\nNo , no . But\nBefore we  i i th with straight PLP , it 's trapezoidal also .\nWell  But\nBut then we had a slight difference in the  in the scale . Uh , so .\nSince currently the Feacalc program doesn't allow me to change  the filter shape independently of the scale .\nUh - huh .\nAnd , I did the experiment on the SRI front - end where I tried the  y where the standard used to be to use trapezoidal filters . You can actually continuously vary it between the two . And so I wen I swi I tried the trap eh , triangular ones . And it did slightly worse , but it 's really a small difference .\nHmm .\nCoup - Couple tenths of a percent or something .\nSo\nOK .\nRight .\nSo it 's not just losing some  frequency range .\nYeah , exactly . So , it 's not  I don't think the filter shape by itself will make a huge  difference .\nYeah . Right . So the oth  the other thing that\nYeah .\nSo , f i We 've always viewed it , anyway , as the major difference between the two , is actually in the smoothing , that the  that the , um ,  PLP , and  and the reason PLP has been advantageous in , uh , slightly noisy situations is because ,  PLP does the smoothing at the end by an auto - regressive model ,\nMm - hmm . Mm - hmm .\nand mel cepstrum does it by just computing the lower cepstral coefficients .\nMm - hmm .\nUm . So , um  Mm - hmm .\nOK . So  one thing I haven't done yet is to actually do all of this with a much larger  with our full training set . So right now , we 're using a  I don't know , forty ? I i it 's  it 's  eh  it 's a f training set that 's about , um , you know , by a factor of four smaller than what we use when we train the full system . So , some of these smoothing issues are over - fitting for that matter .\nMm - hmm .\nAnd the Baum - Welch should be much less of a factor , if you go full  whole hog .\nCould be . Yeah .\nAnd so , w so , just um  so the strategy is to first sort of treat things  with fast turn - around on a smaller training set and then ,  when you 've sort of , narrowed it down , you try it on a larger training set .\nYeah .\nAnd so , we haven't done that yet .\nNow the other que related question , though , is  is ,  uh , what 's the boot models for these things ?\nTh - th the boot models are trained from scratch . So we compute , um  So , we start with a , um , alil alignment that we computed with the b sort of the best system we have . And  and then we train from scratch . So we com we do a , you know , w um   We collect the  uh , the observations from those alignments under each of the feature sets that  that we  train . And then , from there we do , um  There 's a lot of , actually   The way it works , you first train a phonetically - tied mixture model . Um . You do a total of  First you do a context - independent PTM model . Then you switch to a context  You do two iterations of that . Then you do two iterations of  of  of context - dependent phonetically - tied mixtures . And then from that you  you do the  you  you go to a state - clustered model ,\nYeah .\nand you do four iterations of that . So there 's a lot of iterations overall between your original boot models and the final models . I don't think that  Hmm . We have never seen big differences . Once I thought \" oh , I can  Now I have these much better models . I 'll re - generate my initial alignments . Then I 'll get much better models at the end . \" Made no difference whatsoever . It 's  I think it 's  eh , i\nRight . Well , mis for making things better .\nthe boot models are recur\nYeah . But , this for making things worse . This it migh Th - the thought is  is  is possible  another possible  partial cause is if the boot models  used a comple used a different feature set , that\nMm - hmm . Mm - hmm . But there are no boot models , in fact . You  you 're not booting from initial models . You 're booting from initial alignments .\nWhich you got from a different feature set .\nThat 's correct .\nSo , those features look at the data differently , actually .\nYeah , but\nI mean , you know , they  they will find boundaries a little differently , though  You know , all th all that sort of thing is actually slightly different . I 'd expect it to be a minor effect ,\nBut  but  but , what I 'm  what I 'm saying is\nbut\nSo , we e w f w For a long time we had used boot alignments that had been trained with a   with the same front - end but with acoustic models that were , like , fifteen percent worse than what we use now .\nMm - hmm .\nAnd with a dict different dictionary  with a considerably different dictionary , which was much less detailed and much less well - suited .\nMm - hmm . Yeah .\nAnd so ,  then we switched to new boot alignments , which  which now had the benefit of all these improvements that we 've made over two years in the system .\nRight .\nAnd , the result in the end was no different .\nRight .\nSo , what I 'm saying is , the exact nature of these boot alignments is probably not  a big factor in the quality of the final models .\nYeah , maybe not . But  it  it  I st still see it as  I mean ,  there 's  there 's a history to this , too ,\nYeah .\nbut I  uh , I don't wanna go into ,\nMm - hmm .\nbut  but I  I  I th I think it could be the things  that it  the data is being viewed in a certain way , uh , that a beginning is here rather than there and so forth ,\nYeah . Right .\nbecause the actual signal - processing you 're doing is slightly different .\nRight .\nBut ,  it 's  it 's  that 's probably not it .\nYeah . Anyway , I  I  I should really reserve , uh , any conclusions until we 've done it on the large training set , um , and until we 've seen the results with the  with the VTL in training .\nYeah . At some point you also might wanna take the same thing and try it on , uh , some Broadcast News data or something else that actually has  has some noisy   noisy components , so we can see if any conclusions we come to holds  across  different data .\nSo . Yeah . Right .\nUh\nAnd , uh , with this , I have to leave .\nOK .\nHmm !\nSo , is there something quick about Absinthe  that you  ?\nWith this said .\nUh . Just what we were talking about before , which is that I ported a Blass library to Absinthe , and then got  got it working with fast - forward , and got   a speedup roughly proportional to the number of processors times the clock cycle .\nOh .\nSo , that 's pretty good .\nOh ! Cool .\nUm , I 'm in the process of doing it for Quicknet , but there 's something going wrong and it 's about half the speed that I was estimating it should be , and I 'm not sure why .\nMm - hmm .\nBut I 'll keep working on it . But the  what it means is that it 's likely that for net training and forward passes , we 'll  Absinthe will be a good machine . Especially if we get a few more processors and upgrade the processors .\nA few more processors ? How many are you shooting for ?\nThere 're five now . It can hold eight .\nOh , OK .\nYeah , we 'll just go buy them , I guess .\nAnd it 's also five - fifty megahertz and you can get a gigahertz .\nYeah .\nSo .\nCan you mix  t uh , processors of different speed ?\nI don't think so . I think we 'd have to do all\nOK .\nProbably just throw away the old ones , and\nYep .\nThank you  for the box ,\nOh , OK .\nand   I 'll just go buy their process .\nHmm !\nMaybe we can stick them in another system . I dunno .\nWe 'd have to get a  almost certainly have to get a , uh , Netfinity server .\nI see .\nThey 're pretty  pretty specialized .\nYeah . OK .\nOK .", "topic_id": 3, "keywords": "recognizer, recognition, tandem, features, feature", "dialogue_id": 21}, {"text": "Is  is Liz coming back , do you know , or  ? I dunno . Yeah . Oh , you don't . OK . Alright . Alright . See you . Um . Alright . So  Uh , they 're having tea out there . So I guess the other thing that we were gonna talk about is  is , uh , demo . And , um , so , these are the demos for the  uh , July , uh , meeting  and , um  DARPA mee\nJuly what ? Early July ? Late July ?\nOh , I think it 's July fifteenth .\nSixteen to eighteen , I think .\nIs that it ?\nRoughly .\nYeah , sixteenth , eighteenth . Yeah . So , we talked about getting something together for that , but maybe , uh  maybe we 'll just put that off for now , given that  But I think maybe we should have a  a sub - meeting , I think , uh , probably , uh , Adam and  and , uh , Chuck and me should talk about  should get together and talk about that sometime soon .\nOver a cappuccino tomorrow ?\nYeah  something like that . Um , uh , you know , maybe  maybe we 'll involve Dan Ellis at some  some level as well .\nMm - hmm .\nUm . OK . The  the tea is  is going , so , uh , I suggest we do , uh  uh , a unison .\nA unison digits ?\nOK .\nYeah . Gets our\nWhich is gonna be a little hard for a couple people because we have different digits forms .\nOops .\nWe have a  I found a couple of old ones .\nOh .\nHmm .\nWell , that 'll be interesting . So , uh\nHave you done digits before ?\nNo .\nI haven't done it .\nOK . So , uh , the idea is just to read each line  with a short pause between lines ,\nAlright .\nnot between  And , uh , since we 're in a hurry , we were just gonna read everyone all at once . So , if you sorta plug your ears and read\nOK .\nSo first read the transcript number , and then start reading the  digits .\nSure .\nOK ? One , two , three .\nOK we 're done .\nAnd", "topic_id": 4, "keywords": "meeting, tea, liz, involve, cappuccino", "dialogue_id": 21}, {"text": "OK .\nOh , I don't\nI think I 'm zero .\nWow ! Unprecedented .\nHello , hello , hello , hello .\nAh\nWh - what causes the crash ?\nDid you fix something ?\nHello .\nFive , five .\nHello , hello .\nOh , maybe it 's the turning  turning off and turning on of the mike , right ?\nUh , you think that 's you ? Oh .\nAaa - aaa - aaa .\nYeah , OK , mine 's working .\nOK . That 's me .\nOK . OK . So , um I guess we are  um  gonna do the digits at the end . Uh\nChannel  channel three , yeah .\nChannel two .\nOK .\nMmm , channel five ? Doesn't work ?\nYeah , that 's the mike number there , uh  Uh , mike number five , and  channel  channel four .\nTwo .\nIs it written on her sheet , I believe .\nNo ? Ah ,\nMike four .\nWatch this .\nera el cuatro .\nYep , that 's me .\nYeah .\nBut , channel\nYeah yeah yeah .\nThis is you .\nOK . I saw that . Ah  yeah , it 's OK .\nYeah . And I 'm channel uh two I think ,\nOoo .\nor channel\nI think I 'm channel two .\nOh , I 'm channel  must be channel one . Channel one ?\nChannel   I decided to talk about that .\nYes , OK . OK . So uh  I also copied uh the results that we all got in the mail I think from uh   from OGI and we 'll go  go through them also . So where are we on   on uh   our runs ?\nUh so .  uh  We  So  As I was already said , we  we mainly focused on uh four kind of features .\nExcuse me .\nThe PLP , the PLP with JRASTA , the MSG , and the MFCC from the baseline Aurora .\nMm - hmm .\nUh , and we focused for the  the test part on the English and the Italian . Um . We 've trained uh several neural networks on  so  on the TI - digits English  and on the Italian data and also on the broad uh  English uh French and uh Spanish databases . Mmm , so there 's our result tables here , for the tandem approach , and um , actually what we  we @ @ observed is that if the network is trained on the task data it works pretty well .\nOK . Our  our uh   There 's a   We 're pausing for a photo\nChicken on the grill . Try that corner .\nHow about over th from the front of the room ?\nYeah , it 's longer .\nWe 're pausing for a photo opportunity here . Uh .  Uh . So .\nOh wait wait wait wait wait . Wait .\nGet out of the  Yeah .\nHold on . Hold on .\nOK .\nLet me give you a black screen .\nHe 's facing this way . What ? OK , this  this would be a  good section for our silence detection .\nOK .\nMm - hmm .\nUm Oh .\nMusical chairs everybody !\nOK . So um ,  you were saying  about the training data  Yeah .\nYeah , so if the network is trained on the task data um  tandem works pretty well . And uh actually we have uh , results are similar Only on ,\nDo you mean if it 's trained only on  On data from just that task ,\nyeah .\nthat language ?\nJust that task . But actually we didn't train network on  uh both types of data I mean  uh  phonetically ba phonetically balanced uh data and task data .\nMmm .\nWe only did either task  task data or  uh broad  data .\nMm - hmm .\nUm  Yeah . So ,\nSo how  I mean  clearly it 's gonna be good then\nSo what 's th\nbut the question is how much  worse is it  if you have broad data ? I mean ,  my assump From what I saw from the earlier results , uh I guess last week ,  was that um ,  if you  trained on one language and tested on another , say , that  the results were  were relatively poor .\nMmm . Yeah .\nBut  but the question is if you train on one language  but you have a broad coverage  and then test in another ,  does that   is that improve things  i c in comparison ?\nIf we use the same language ?\nNo , no , no . Different lang So  um  If you train on TI - digits  and test on Italian digits ,  you do poorly ,  let 's say .\nMm - hmm .\nI don't have the numbers in front of me ,\nBut  Yeah but I did not uh do that .\nso I 'm just imagining . E So , you didn't train on  TIMIT and test on   on Italian digits , say ?\nWe  No , we did four  four kind of  of testing , actually . The first testing is  with task data  So , with nets trained on task data . So for Italian on the Italian speech @ @ . The second test is trained on a single language um with broad database , but the same language as the t task data .\nOK .\nBut for Italian we choose Spanish which  we assume is close to Italian . The third test is by using , um the three language database\nW which in\nand the fourth is\nIt has three languages . That 's including the w the   the\nThis includes\nthe one that it 's\nYeah .\nIn\nBut  not digits . I mean it 's\nThe three languages  is not digits ,\nRight .\nit 's the broad  data . OK .\nYeah And the fourth test is uh  excluding from these three languages the language  that is  the task language .\nOh , OK , yeah , so , that is what I wanted to know .\nYeah .\nI just wasn't saying it very well , I guess .\nUh , yeah . So um  for uh TI - digits for ins example  uh when we go from TI - digits training to  TIMIT training  uh we lose  uh around ten percent , uh . The error rate increase u of  of  of ten percent , relative .\nRelative . Right .\nSo this is not so bad . And then when we jump to the multilingual data it 's uh it become worse and , well Around uh , let 's say ,  twenty perc twenty percent further .\nAb - about how much ?\nSo . Yeah .\nTwenty percent further ?\nTwenty to  to thirty percent further . Yeah .\nAnd so , remind me , the multilingual stuff is just the broad data . Right ? It 's not the digits .\nYeah .\nSo it 's the combination of  two things there . It 's  removing the  task specific  training and  it 's adding other languages .\nYeah . Yeah .\nOK .\nBut the first step is al already removing the task s specific from  from\nAlready , right right right .\nSo .\nSo they were sort of building  here ?\nAnd we lose\nOK ?\nYeah . Uh  So , basically when it 's trained on the  the multilingual broad data  um or number  so , the  the  ratio of our error rates uh with the  baseline error rate is around  uh one point one .\nYes .  And it 's something like one point three of  of the  uh\nSo .\nI i if you compare everything to the first case at the baseline , you get something like one point one for the  for the using the same language but a different task , and something like one point three  for three  three languages  broad stuff .\nNo no no . Uh same language we are at uh  for at English at O point eight . So it improves ,  compared to the baseline . But  So . Le - let me .\nI  I  I 'm sorry .\nTas - task data\nI  I  I meant something different by baseline\nwe are u Yeah .\nSo let me  let me  Um ,  so ,  um\nMmm .\nOK , fine . Let 's  let 's use the conventional meaning of baseline .\nHmm .\nI  I  By baseline here I meant  uh using the task specific data .\nOh yeah , the f Yeah , OK .\nBut uh   uh , because that 's what you were just doing with this ten percent .\nYeah .\nSo I was just  I just trying to understand that .\nYeah . Sure .\nSo if we call  a factor of w just one , just normalized to one , the word error rate  that you have  for using TI - digits as  as  training and TI - digits as test ,\nMmm .\nuh different words , I 'm sure ,\nMm - hmm .\nbut   but uh , uh the same  task and so on .\nMm - hmm .\nIf we call that \" one \" ,  then what you 're saying is  that the word error rate  for the same language but using  uh different training data than you 're testing on , say TIMIT and so forth ,  it 's one point one .\nMm - hmm . Yeah , it 's around one point one .\nRight . And if it 's\nYeah .\nyou  do  go to  three languages including the English ,  it 's something like one point three . That 's what you were just saying , I think .\nYe Uh , more actually .\nOne point four ?\nIf I  Yeah .\nSo , it 's an additional thirty percent .\nWhat would you say ? Around one point four\nOK .\nyeah .\nAnd if you exclude  English ,  from this combination , what 's that ?\nIf we exclude English ,  um  there is  not much difference with the  data with English .\nAha !\nSo . Yeah .\nThat 's interesting .  That 's interesting . Do you see ? Because  Uh ,\nUh .\nso  No , that  that 's important . So what  what it 's saying here is just that \" yes , there is a reduction  in performance ,  when you don't  um  have the s  when you don't have  um\nTask data .\nWait a minute , th th the\nHmm .\nNo , actually  it 's interesting . So it 's  So when you go to a different task , there 's actually not so  different . It 's when you went to these  So what 's the difference between two and three ? Between the one point one case and the one point four case ? I 'm confused .\nIt 's multilingual .\nYeah . The only difference it 's  is that it 's multilingual  Um\nCuz in both  in both  both of those cases , you don't have the same task .\nYeah . Yeah sure .\nSo is  is the training data for the  for this one point four case  does it include the training data for the one point one case ?\nUh yeah .\nYeah , a fraction of it .\nA part of it , yeah .\nHow m how much bigger is it ?\nUm  It 's two times ,\nYeah , um .\nactually ? Yeah . Um . The English data   No , the multilingual databases are two times the  broad English  data . We just wanted to keep this , w well , not too huge . So .\nSo it 's two times , but it includes the  but it includes the broad English data .\nI think so . Do you  Uh , Yeah .\nAnd the broad English data is what you got this one point one  with . So that 's TIMIT basically right ?\nYeah .\nMm - hmm .\nSo it 's band - limited TIMIT . This is all eight kilohertz sampling .\nMm - hmm .\nMm - hmm .\nYeah .\nDowns Right .\nSo you have band - limited TIMIT ,  gave you uh almost as good as a result as using TI - digits  on a TI - digits test . OK ?\nHmm ?\nUm  and  um But ,  when you add in more training data but keep the neural net the same size ,  it  um performs worse on the TI - digits . OK , now all of this is   This is noisy  TI - digits , I assume ? Both training and test ?\nYeah . OK . Um OK . Well .  We  we  we may just need to uh  So I mean it 's interesting that h going to a different  different task didn't seem to hurt us that much , and going to a different language um It doesn't seem to matter  The difference between three and four is not particularly great , so that means that  whether you have the language in or not is not such a big deal .\nMmm .\nIt sounds like um  uh  we may need to have more  of uh things that are similar to a target language or  I mean .  You have the same number of parameters in the neural net , you haven't increased the size of the neural net , and maybe there 's just   just not enough  complexity to it to represent  the variab increased variability in the  in the training set . That  that could be . Um  So , what about  So these are results with  uh th  that you 're describing now , that  they are pretty similar for the different features or   or uh\nUh , let me check . Uh .\nYeah .\nSo . This was for the PLP ,\nYeah .\nUm . The  Yeah . For the PLP with JRASTA the   the  we  This is quite the same  tendency ,  with a slight increase of the error rate ,  uh if we go to  to TIMIT . And then it 's  it gets worse with the multilingual . Um . Yeah . There  there is a difference actually with  b between PLP and JRASTA is that  JRASTA  seems to  perform better with the highly mismatched  condition  but slightly  slightly worse  for the well matched condition . Mmm .\nI have a suggestion , actually , even though it 'll delay us slightly , would  would you mind  running into the other room and making  copies of this ? Cuz we 're all sort of  If we c if we could look at it , while we 're talking , I think it 'd be\nYeah , yeah . OK .\nuh   Uh , I 'll  I 'll sing a song or dance or something while you  do it , too .\nSo um", "topic_id": 0, "keywords": "digits, channel, mike, number, numbers", "dialogue_id": 22}, {"text": "Alright .\nGo ahead . Ah , while you 're gone I 'll ask s some of my questions .\nYeah .\nUm .\nYeah . Uh , this way and just slightly to the left , yeah .\nThe um  What was  Was this number  forty or  It was roughly the same as this one ,  he said ? When you had the two language versus the three language ?\nUm . That 's what he was saying .\nThat 's where he removed English ,\nYeah .\nright ?\nRight .\nIt sometimes , actually , depends on what features you 're using .\nYeah . But  but i it sounds like\nUm , but    He  Mm - hmm .\nI mean . That 's interesting because  it  it seems like what it 's saying is not so much that you got hurt  uh because  you  uh didn't have so much representation of English , because in the other case you don't get hurt any more , at least when  it seemed like uh it  it might simply be a case that you have something that is just much more diverse ,\nMm - hmm .\nbut you have the same number of parameters representing it .\nMm - hmm . I wonder  were um all three of these nets  using the same output ? This multi - language  uh labelling ?\nHe was using uh sixty - four phonemes from  SAMPA .\nOK , OK .\nYeah .\nSo this would   From this you would say , \" well , it doesn't really matter if we put Finnish  into  the training of the neural net ,  if there 's  gonna be ,  you know , Finnish in the test data . \" Right ?\nWell , it 's  it sounds   I mean , we have to be careful , cuz we haven't gotten a good result yet .\nYeah .\nAnd comparing different bad results can be  tricky .\nHmm .\nBut I  I  I   I think it does suggest that it 's not so much uh  uh cross  language as cross type of speech .\nMm - hmm .\nIt 's  it 's um   But we did  Oh yeah , the other thing I was asking him , though , is that I think that in the case  Yeah , you  you do have to be careful because of com compounded results . I think we got some earlier results  in which you trained on one language and tested on another and you didn't have  three , but you just had one  language . So you trained on  one type of digits and tested on another . Didn - Wasn't there something of that ? Where you ,  say , trained on Spanish and tested on  on TI - digits , or the other way around ? Something like that ?\nNo .\nI thought there was something like that ,  that he showed me  last week . We 'll have to wait till we get\nYeah , that would be interesting .\nUm , This may have been what I was asking before , Stephane , but   but , um , wasn't there something that you did ,  where you trained  on one language and tested on another ? I mean no  no mixture but just\nI 'll get it for you .\nUh , no , no .\nWe 've never just trained on one lang\nTraining on a single language , you mean , and testing on the other one ?\nYeah .\nUh , no .\nNot yet .\nSo the only  task that 's similar to this is the training on two languages , and  that\nBut we 've done a bunch of things where we just trained on one language . Right ? I mean , you haven't  you haven't done all your tests on multiple languages .\nUh , No . Either thi this is test with  uh the same language  but from the broad data , or it 's test with  uh different languages also from the broad data , excluding the  So , it 's  it 's three or  three and four .\nThe early experiment that\nDid you do different languages from digits ?\nUh . No . You mean  training digits  on one language and using the net  to recognize on the other ?\nDigits on another language ?\nNo .\nSee , I thought you showed me something like that last week . You had a  you had a little\nUh ,  No , I don't think so .\nUm What\nThese numbers are uh  ratio to baseline ?\nSo , I mean wha what 's the\nSo .\nThis  this chart  this table that we 're looking at  is um , show is all testing for TI - digits , or  ?\nBigger is worse .\nSo you have uh basically two  uh parts .\nThis is error rate , I think .\nRatio .\nNo .  No .\nThe upper part is for TI - digits\nYeah , yeah , yeah .\nand it 's divided in three  rows  of four  four rows each .\nMm - hmm .\nYeah .\nAnd the first four rows is well - matched , then the s the second group of four rows is mismatched , and  finally highly mismatched . And then the lower part is for Italian and it 's the same   the same thing .\nSo , so the upper part is training  TI - digits ?\nSo . It 's  it 's the HTK results , I mean . So it 's  HTK training testings  with different kind of features\nAh .\nand what appears in the  uh left column is  the networks that are used for doing this .\nHmm .\nSo . Uh Yeah .\nWell , What was is that i What was it that you had  done  last week when you showed  Do you remember ? Wh - when you showed me  the  your table last week ?\nIt - It was part of these results . Mmm . Mmm .\nSo where is the baseline  for the TI - digits  located in here ?\nYou mean the HTK Aurora baseline ?\nYeah .\nIt 's uh the one hundred number . It 's , well , all these numbers are the ratio  with respect to the baseline .\nAh ! Ah , OK , OK .\nSo this is word  word error rate , so a high number is bad .\nYeah , this is  a word error rate ratio .\nYeah .\nOK , I see .\nYeah . So , seventy point two means that  we reduced the error rate uh by thirty  thirty percent .\nOK , OK , gotcha .\nSo .\nOK ,  so if we take\nHmm .\nuh um let 's see PLP  uh with on - line  normalization and  delta - del so that 's this thing you have circled here  in the second column ,\nYeah .\num  and \" multi - English \" refers to what ?\nTo TIMIT . Mmm . Then you have  uh MF ,  MS and ME which are for French , Spanish and English . And , yeah . Actually I   I uh forgot to say that  the multilingual net are trained  on  uh  features without the s derivatives uh but with  increased frame numbers . Mmm . And we can  we can see on the first line of the table that it  it   it 's slightly  slightly worse when we don't use delta but it 's not   not that much .\nRight . So w w So , I 'm sorry . I missed that . What 's MF , MS and ME ?\nMulti - French , Multi - Spanish\nSo . Multi - French , Multi - Spanish , and Multi - English .\nUh OK . So , it 's  uh  broader vocabulary . Then  And\nYeah .\nOK so I think what I 'm  what I saw in your smaller chart that I was thinking of was  was  there were some numbers I saw , I think , that included these multiple languages and it  and I was seeing  that it got worse . I  I think that was all it was . You had some very limited results that  at that point\nYeah .\nwhich showed  having in these  these other languages . In fact it might have been just this last category ,  having two languages broad that were  where  where English was removed . So that was cross language and the  and the result was quite poor . What I   we hadn't seen yet was that if you added in the English , it 's still poor .\nYeah .\nUh   Um now , what 's the noise condition  um  of the training data\nStill poor .\nWell , I think this is what you were explaining . The noise condition is the same  It 's the same uh Aurora noises uh , in all these cases  for the training .\nYeah . Yeah .\nSo there 's not a  statistical  sta a strong st  statistically different  noise characteristic between  uh the training and test\nNo these are the s s s same noises ,\nand yet we 're seeing some kind of effect\nyeah . At least  at least for the first   for the well - matched ,\nWell matched condition .\nRight .\nyeah .\nSo there 's some kind of a  a  an effect from having these  uh this broader coverage um Now I guess what we should try doing with this is try  testing these on u this same sort of thing on  you probably must have this  lined up to do . To try the same t  with the exact same training , do testing on  the other languages .\nMmm .\nOn  on um  So . Um , oh I well , wait a minute . You have this here , for the Italian . That 's right . OK , so ,  So .\nYeah . Yeah , so for the Italian the results are  uh  stranger um  Mmm . So what appears is that perhaps Spanish is  not very close to Italian because uh , well ,  when using the  the network trained only on Spanish it 's   the error rate is  almost uh twice  the baseline error rate .\nMm - hmm .\nMmm .  Uh .\nWell , I mean , let 's see . Is there any difference in  So it 's in  the uh  So you 're saying that  when you train on English  and  uh  and  and test on\nYeah .", "topic_id": 1, "keywords": "language, multilingual, languages, lang, english", "dialogue_id": 22}, {"text": "No , you don't have training on English testing\nThere  there is  another difference , is that the noise  the noises are different .\nIn  in what ?\nWell , For  for the Italian part I mean the  uh  the um  networks are trained with noise from  Aurora  TI - digits ,\nAurora - two .\nmmm .\nAnd the noise is different in th\nYeah . And perhaps the noise are  quite different from the noises  in the speech that Italian .\nDo we have any um  test sets  uh in  any other language that um have the same noise as in  the Aurora ?\nAnd\nMmm , no .\nNo .\nCan I ask something real quick ? In  in the upper part   in the English  stuff ,  it looks like the very best number is sixty point nine ? and that 's in the uh   the third  section in the upper part under PLP JRASTA , sort of the middle column ?\nYeah .\nI is that  a noisy condition ?\nYeah .\nSo that 's matched training ? Is that what that is ?\nIt 's  no , the third part , so it 's uh  highly mismatched . So . Training and  test noise are different .\nSo  why do you get your best number in  Wouldn't you get your best number in the clean case ?\nWell , it 's relative to the um  baseline mismatching\nYeah .\nAh ,\nYeah . Yeah .\nOK so these are not  OK , alright , I see .\nYeah .\nOK . And then  so , in the  in the um   in the  non - mismatched clean case ,  your best one was under MFCC ? That sixty - one point four ?\nYeah .  But it 's not a clean case . It 's  a noisy case but  uh training and test noises are the same .\nOh ! So this upper third ?\nSo  Yeah .\nUh that 's still noisy ?\nYeah .\nAh , OK .\nSo it 's always noisy basically ,\nMm - hmm .\nand ,  well , the\nI see .\nMmm .\nOK ? Um  So uh , I think this will take some  looking at , thinking about . But ,  what is uh  what is currently running , that 's  uh , i that  just filling in the holes here or  or  ?   pretty much ?\nUh , no we don't plan to fill the holes\nOK .\nbut  actually there is something important , is that  um we made a lot of assumption concerning the on - line normalization and we just noticed  uh recently that  uh the  approach that we were using  was not  uh  leading to very good results  when we  used the straight features to HTK . Um   Mmm . So basically d  if you look at the  at the left of the table ,  the first uh row ,  with eighty - six , one hundred , and forty - three and seventy - five , these are the results we obtained for Italian  uh with  straight  mmm , PLP features  using on - line normalization .\nMm - hmm .\nMmm . And the , mmm  what 's  in the table , just  at the left of the PLP twelve  on - line normalization column , so , the numbers seventy - nine , fifty - four and  uh forty - two  are the results obtained by uh Pratibha with  uh his on - line normalization  uh her on - line normalization approach .\nWhere is that ? seventy - nine , fifty\nUh , it 's just sort of sitting right on the uh  the column line .\nSo .\nFifty - one ? This\nOh I see , OK .\nUh .  Yeah .\nJust  uh Yeah . So these are the results of  OGI with  on - line normalization and straight features to HTK . And the previous result , eighty - six and so on ,  are with our  features straight to HTK .\nYes . Yes .\nSo  what we see that  is  there is that um  uh the way we were doing this was not correct , but  still  the networks  are very good . When we use the networks  our number are better that  uh Pratibha results .\nWe improve .\nSo , do you know what was wrong with the on - line normalization , or  ?\nYeah . There were diff there were different things and  basically ,  the first thing is the mmm ,  alpha uh  value . So , the recursion  uh  part . um ,  I used point five percent ,  which was the default value in the   in the programs here . And Pratibha used five percent .\nUh\nSo it adapts more  quickly\nYes . Yeah .\nUm , but , yeah . I assume that this was not important because  uh previous results from  from Dan and  show that basically  the  both  both values g give the same  same  uh results . It was true on uh  TI - digits but it 's not true on Italian .\nMm - hmm .\nUh , second thing is the initialization of the  stuff . Actually ,  uh what we were doing is to start the recursion from the beginning of the  utterance . And using initial values that are the global mean and variances  measured across the whole database .\nRight . Right .\nAnd Pratibha did something different is that he  uh she initialed the um values of the mean and variance  by computing  this on the  twenty - five first frames of each utterance . Mmm . There were other minor differences , the fact that  she used fifteen dissities instead s instead of thirteen , and that she used C - zero instead of log energy . Uh , but the main differences concerns the recursion . So .  Uh , I changed the code uh and now we have a baseline that 's similar to the OGI baseline .\nOK .\nWe  It  it 's slightly  uh different because  I don't exactly initialize the same way she does . Actually I start ,  mmm , I don't wait to a fifteen  twenty - five  twenty - five frames  before computing a mean and the variance  to e to  to start the recursion .\nMm - hmm .\nYeah .\nI  I use the on - line scheme and only start the re recursion after the twenty - five   twenty - fifth frame . But , well it 's similar . So  uh I retrained  the networks with  these  well , the  the  the networks are retaining with these new  features .\nMm - hmm .\nAnd , yeah .\nOK .\nSo basically what I expect is that  these numbers will a little bit go down but  perhaps not  not so much\nRight .\nbecause  I think the neural networks learn perhaps  to\nRight .\neven if the features are not  normalized . It  it will learn how to normalize and\nOK , but I think that  given the pressure of time we probably want to draw  because of that  especially , we wanna draw some conclusions from this , do some reductions  in what we 're looking at ,\nYeah .\nand make some strong decisions for what we 're gonna do testing on before next week . So do you  are you  w did you have something going on , on the side , with uh multi - band  or  on  on this ,\nYeah  I\nor  ?\nNo , I  we plan to start this uh so , act actually we have discussed uh  @ @ um , these  what we could do  more as a  as a research and   and  we were thinking perhaps that  uh  the way we use the tandem is not  Uh , well , there is basically perhaps a flaw in the  in the  the stuff because  we  trained the networks  If we trained the networks on the  on  a language and a t or a specific  task ,\nMm - hmm .\num , what we ask is  to the network  is to put the bound the decision boundaries somewhere in the space .\nMmm .\nAnd uh  mmm and ask the network to put one ,  at one side of the  for  for a particular phoneme at one side of the boundary  decision boundary and one for another phoneme at the other side . And  so there is kind of reduction of the information there that 's not correct because if we change task  and if the phonemes are not in the same context in the new task ,  obviously the  decision boundaries are not   should not be at the same  place .\nI di\nBut the way the feature gives  The  the way the network gives the features is that it reduce completely the   it removes completely the information   a lot of information from the  the features  by uh  uh  placing the decision boundaries at  optimal places for  one kind of  data but  this is not the case for another kind of data .\nIt 's a trade - off ,\nSo\nright ? Any - anyway go ahead .\nYeah . So uh what we were thinking about is perhaps  um one way  to solve this problem is increase the number of  outputs of the neural networks . Doing something like , um  um phonemes within context and , well , basically context dependent phonemes .\nMaybe . I mean , I  I think  you could make  the same argument , it 'd be just as legitimate ,  for hybrid systems  as well . Right .\nYeah but , we know that\nAnd in fact ,  th things get better with context dependent  versions . Right ?\nYe - yeah but here it 's something different . We want to have features\nYeah .\nuh well ,  um .\nYeah , but it 's still true  that what you 're doing  is you 're ignoring  you 're  you 're coming up with something to represent ,  whether it 's a distribution ,  probability distribution or features , you 're coming up with a set of variables  that are representing  uh ,  things that vary w over context .\nMm - hmm .\nUh , and you 're  putting it all together , ignoring the differences in context . That  that 's true  for the hybrid system , it 's true for a tandem system . So , for that reason , when you  in  in  in a hybrid system ,  when you incorporate context one way or another ,  you do get better scores .\nYeah .\nOK ? But I  it 's  it 's a big deal  to get that . I  I 'm  I 'm sort of  And once you  the other thing is that once you represent  start representing more and more context  it is  uh  much more  um specific  to a particular task in language . So um Uh , the   the acoustics associated with  uh a particular context , for instance you may have some kinds of contexts that will never occur  in one language and will occur frequently in the other , so the qu the issue of getting enough training  for a particular kind of context becomes harder . We already actually don't have a huge amount of training data um\nYeah , but  mmm , I mean ,  the  the way we  we do it now is that we have a neural network and  basically  the net network is trained almost to give binary decisions .\nRight .\nAnd  uh  binary decisions about phonemes . Nnn  Uh It 's\nAlmost . But I mean it  it  it does give a distribution .\nYeah .\nIt 's  and  and  it is true that if there 's two phones that are very similar ,  that  uh  the   i it may prefer one but it will  give a reasonably high value to the other , too .\nYeah . Yeah , sure but uh  So basically it 's almost binary decisions and  um the idea of using more  classes is  to  get something that 's  less binary decisions .\nOh no , but it would still be even more of a binary decision . It  it 'd be even more of one . Because then you would say  that in  that this phone in this context is a one ,  but the same phone in a slightly different context is a zero .\nBut  yeah , but\nThat would be even  even more distinct of a binary decision . I actually would have thought you 'd wanna go the other way and have fewer classes .\nYeah , but if\nUh , I mean for instance , the  the thing I was arguing for before , but again which I don't think we have time to try ,  is something in which you would modify the code so you could train to have several outputs on and use articulatory features\nMmm . Mm - hmm .\ncuz then that would  that would go   that would be much broader and cover many different situations . But if you go to very very fine categories , it 's very  binary .\nMmm . Yeah , but I think  Yeah , perhaps you 're right , but you have more classes so  you  you have more information in your features . So ,  Um  You have more information in the  uh\nMm - hmm . True .\nposteriors vector um which means that  But still the information is relevant\nMm - hmm .\nbecause it 's  it 's information that helps to discriminate ,\nMm - hmm .\nif it 's possible to be able to discriminate  among the phonemes in context .\nWell it 's  it 's   it 's an interesting thought .\nBut the\nI mean we  we could disagree about it at length\nMmm .\nbut the  the real thing is if you 're interested in it you 'll probably try it\nMmm .\nand   and  we 'll see . But  but what I 'm more concerned with now , as an operational level , is  uh , you know ,\nMmm .\nwhat do we do in four or five days ? Uh , and   so we have  to be concerned  with Are we gonna look at any combinations of things , you know once the nets get retrained so you have this problem out of it .\nMmm .\nUm , are we going to look at  multi - band ? Are we gonna look at combinations of things ? Uh , what questions are we gonna ask , uh now that , I mean ,  we should probably turn shortly to this O G I note . Um , how are we going to  combine  with what they 've been focusing on ? Uh ,  Uh we haven't been doing any of the L D A RASTA sort of thing .\nMm - hmm .\nAnd they , although they don't talk about it in this note , um ,  there 's um ,  the issue of the  um Mu law  business  uh  versus the logarithm , um ,  so .\nMm - hmm .\nSo what i what is going on right now ? What 's right  you 've got  nets retraining , Are there  is there  are there any H T K  trainings  testings going on ?\nN\nI  I  I 'm trying the HTK with eh ,  PLP twelve on - line delta - delta and MSG filter  together .\nThe combination , I see .\nThe combination , yeah . But I haven't result  at this moment .\nMSG and  and PLP .\nYeah .\nAnd is this with the revised  on - line normalization ?\nYe - Uh , with the old  older ,\nYeah .\nOld one . So it 's using all the nets for that\nyeah .\nbut again we have the hope that it   We have the hope that it   maybe it 's not making too much difference ,\nYeah . But  We can know soon .\nbut  but\nMaybe .\nyeah .\nI don't know .\nYeah .\nUh , OK .\nUh so there is this combination , yeah . Working on combination obviously .\nMm - hmm .\nUm , I will start work on multi - band . And  we  plan to work also on the idea of using both  features  and net outputs .", "topic_id": 2, "keywords": "testing, testings, italian, test, noisy", "dialogue_id": 22}, {"text": "Um . And  we think that  with this approach perhaps  we could reduce the number of outputs of the neural network . Um , So , get simpler networks , because we still have the features . So we have um  come up with um  different kind of  broad phonetic categories . And we have  Basically we have three  types of broad phonetic classes . Well , something using place of articulation which  which leads to  nine , I think ,  broad classes . Uh , another which is based on manner , which is  is also something like nine classes . And then ,  something that combine both , and we have  twenty f  twenty - five ?\nTwenty - seven .\nTwenty - seven broad classes . So like , uh , oh , I don't know , like back vowels , front vowels .\nSo what you do  um I just wanna understand\nUm For the moments we do not  don't have nets ,\nso  You have two net or three nets ? Was this ? How many  how many nets do you have ? No nets .\nI mean ,  It 's just  Were we just changing  the labels to retrain nets  with fewer out outputs .\nBegin to work in this . We are @ @ .\nRight . But  but I didn't understand\nAnd then  Mm - hmm .\nUh .  the software currently just has  uh a  allows for I think , the one  one hot output . So you 're having multiple nets and combining them , or  ? Uh , how are you  how are you coming up with  If you say  uh  If you have a place  characteristic and a manner characteristic , how do you\nIt - It 's the single net ,\nI think they have one output .\nyeah .\nOh , it 's just one net .\nIt 's one net with  um  twenty - seven outputs\nYeah .\nmm - hmm\nif we have twenty - seven classes ,\nI see . I see , OK .\nyeah . So it 's  Well , it 's basically a standard net with fewer  classes .\nSo you 're sort of going the other way of what you were saying a bit ago instead of  yeah .\nYeah , but I think  Yeah . B b including the features , yeah .\nBut including the features .\nYeah .\nI don't think this  will work  alone . I think it will get worse because Well , I believe the effect that  of  of too reducing too much the information is  basically  basically what happens\nUh - huh .\nand\nBut you think if you include that  plus the other features ,\nbut  Yeah , because  there is perhaps one important thing that the net  brings , and OGI show showed that , is  the distinction between  sp speech and silence Because these nets are trained on well - controlled condition . I mean the labels are obtained on clean speech , and we add noise after . So this is one thing And But perhaps , something intermediary using also  some broad classes could  could bring so much more information . Uh .\nSo  so again then we have these broad classes and  well , somewhat broad . I mean , it 's twenty - seven instead of sixty - four ,  basically . And you have the original features .\nYeah .\nWhich are PLP , or something .\nYeah .\nAnd then uh , just to remind me , all of that goes  into  uh , that all of that is transformed by uh , uh , K - KL or something , or  ?\nMm - hmm . There will probably be ,\nMu .\nyeah , one single KL to transform everything\nRight .\nor   uh ,\nNo transform the PLP\nper\nand only transform the other I 'm not sure .\nWell no ,\nThis is  still something  that\nI think  I see .\nyeah , we  don't know\nSo there 's a question of whether you would\nTwo e @ @ it 's one .\nYeah .\nRight . Whether you would transform together or just one . Yeah . Might wanna try it both ways . But that 's interesting . So that 's something that you 're  you haven't trained yet but are preparing to train , and\nYeah .\nYeah . Um   Yeah , so I think Hynek will be here Monday .\nMmm .\nMonday or Tuesday . So\nUh , yeah .\nSo I think , you know , we need to  choose the  choose the experiments carefully , so we can get uh key   key questions answered  uh before then\nMm - hmm .\nand  leave other ones aside even if it  leaves incomplete  tables   someplace , uh  uh , it 's  it 's really time to   time to choose .\nMm - hmm .\nUm , let me pass this out ,  by the way . Um These are  Did  did   did I interrupt you ?\nYeah , I have one .\nWere there other things that you wanted to\nUh , no . I don't think so .\nYeah , I have one .\nOh , thanks .\nAh !  OK .  OK , we have  lots of them .\nWe have one .\nOK , so  um , Something I asked  So they 're  they 're doing  the  the VAD I guess they mean voice activity detection So again , it 's the silence  So they 've just trained up a net  which has two outputs , I believe . Um  I asked uh  Hynek whether  I haven't talked to Sunil  I asked Hynek whether  they compared that to  just taking the nets we already had  and summing up the probabilities .\nMm - hmm .\nUh .  To get the speech  voice activity detection , or else just using the silence ,  if there 's only one  silence output . Um  And , he didn't think they had , um . But on the other hand , maybe they can get by with a smaller net and  maybe  sometimes you don't run the other , maybe there 's a computational advantage to having a separate net , anyway .\nMm - hmm .\nSo um Their uh   the results look pretty good . Um ,  I mean , not uniformly .\nYeah .\nI mean , there 's a  an example or two  that you can find , where it made it slightly worse , but  uh in  in all but a couple  examples .\nMmm .\nUh .\nBut they have a question of the result . Um how are trained the  the LDA filter ? How obtained the LDA filter ?\nMmm .\nI I 'm sorry . I don't understand your question .\nYes , um the LDA filter  needs some  training set  to obtain the filter . Maybe I don't know exactly how  they are obtained .\nIt 's on  training .\nTraining , with the training test of each  You understand me ?\nNo .\nYeah , uh for example ,  LDA filter  need a set of   a set of training  to obtain the filter .\nYes .\nAnd maybe  for the Italian , for the TD  TE on for Finnish , these filter are  are obtained with their own training set .\nYes , I don't know . That 's  that 's  so that 's a  that 's a very good question , then  now that it   I understand it . It 's \" yeah , where does the LDA come from ? \" In the  In  earlier experiments , they had taken LDA  from a completely different database , right ?\nYeah . Yeah , because maybe it the same situation that the neural network training with their own\nMmm .\nset .\nSo that 's a good question . Where does it come from ? Yeah , I don't know . Um ,  but uh to tell you the  truth , I wasn't actually looking at the LDA so much when I  I was looking at it I was  mostly thinking about the   the VAD . And um , it ap  it ap Oh what does  what does ASP ? Oh that 's\nThe features , yeah . Yeah .\nI don't understand also\nIt says \" baseline ASP \" .\nwhat is   what is the difference between ASP and uh baseline over ?\nASP .\nYeah , I don't know .\nThis is\nAnybody know  any\nOh . There it is .\nUm Cuz there 's \" baseline Aurora \"  above it .\nMm - hmm .\nAnd it 's  This is mostly better than baseline , although in some cases it 's a little worse , in a couple cases .\nWell , it says baseline ASP is twenty - three mill  minus thirteen .\nYeah .\nYeah , it says what it is . But I don't how that 's different  from\nFrom the baseline .  OK .\nI think this was   I think this is the same point we were at when  when we were up in Oregon .\nYeah .\nI think   I think it 's the C - zero  using C - zero instead of log energy .\nAh , OK , mm - hmm .\nYeah , it 's this .\nOh . OK .\nyeah .\nIt should be that , yeah .\nThey s they say in here that the VAD is not used as an additional feature .\nShouldn't it be\nBecause\nDoes  does anybody know how they 're using it ?\nYeah . So  so what they 're doing here is ,  i\nYeah .\nif you look down at the block diagram ,  um ,  they estimate  they get a   they get an estimate  of whether it 's speech or silence ,\nBut that\nand then they have a median filter of it .\nMm - hmm .\nAnd so um ,  basically they 're trying to find stretches . The median filter is enforcing a  i it having some continuity .\nMm - hmm .\nYou find stretches where the  combination of the  frame wise VAD and the   the median filter say that there 's a stretch of silence . And then it 's going through and just throwing the data away .\nHmm .\nRight ? So um\nSo it 's  it 's  I don't understand . You mean it 's throwing out frames ? Before\nIt 's throwing out chunks of frames , yeah . There 's  the  the median filter is enforcing that it 's not gonna be single cases of frames , or isolated frames .\nYeah .\nSo it 's throwing out frames and the thing is  um ,  what I don't understand is how they 're doing this with H T\nYeah , that 's what I was just gonna ask .\nThis is\nHow can you just throw out frames ?\nYeah . Well , you  you can ,\ni\nright ? I mean y you  you\nYeah .\nit stretches again . For single frames I think it would be pretty hard .\nYeah .\nBut if you say speech starts here , speech ends there .\nMm - hmm .\nRight ?\nHuh .\nYeah . Yeah , you can basically remove the  the frames from the feature  feature files .\nYeah . Yeah , so I mean in the  i i in the  in the decoding , you 're saying that we 're gonna decode from here to here .\nI t\nMm - hmm .\nI think they 're  they 're  they 're treating it ,  you know , like uh  well , it 's not isolated word , but  but connected , you know , the  the\nIn the text they say that this  this is a tentative block diagram of a possible configuration we could think of . So that sort of sounds like they 're not doing that yet .\nWell .  No they  they have numbers though , right ? So I think they 're  they 're doing something like that . I think that they 're  they 're  I think what I mean by tha that is they 're trying to come up with a block diagram that 's plausible for the standard . In other words , it 's  uh  I mean from the point of view of  of uh reducing the number of bits you have to transmit it 's not a bad idea to detect silence anyway .\nYeah . Yeah . I 'm just wondering what exactly did they do up in this table if it wasn't this .\nUm . But it 's  the thing is it 's that  that  that 's  that 's I  I  Certainly it would be tricky about it intrans in transmitting voice ,  uh uh for listening to , is that these kinds of things  uh cut  speech off a lot .\nMm - hmm .\nRight ? And so  um\nPlus it 's gonna introduce delays .\nIt does introduce delays but they 're claiming that it 's  it 's within the   the boundaries of it .\nMmm .\nAnd the LDA introduces delays , and b  what he 's suggesting this here is a parallel path so that it doesn't introduce  uh , any more delay . I it introduces two hundred milliseconds of delay but at the same  time the LDA  down here  I don't know  Wh what 's the difference between TLDA and SLDA ?\nTemporal and spectral .\nAh , thank you .\nTemporal LDA .\nYeah , you would know that .\nYeah\nSo um . The temporal LDA does in fact include the same  so that  I think he  well , by  by saying this is a b a tentative block di diagram I think means  if you construct it this way , this  this delay would work in that way\nAh .\nand then it 'd be OK . They  they clearly did actually remove  silent sections in order  because they  got these  word error rate  results . So um I think that it 's  it 's nice to do that in this because in fact , it 's gonna give a better word error result and therefore will help within an evaluation . Whereas to whether this would actually be in a final standard , I don't know . Um . Uh , as you know , part of the problem with evaluation right now is that the  word models are pretty bad and nobody wants   has  has approached improving them . So  it 's possible that a lot of the problems  with so many insertions and so forth would go away if they were better word models  to begin with . So  this might just be a temporary thing . But  But , on the other hand , and maybe  maybe it 's a decent idea . So um The question we 're gonna wanna go  through next week when Hynek shows up I guess is given that we 've been  if you look at what we 've been trying , we 're uh looking at  uh , by then I guess , combinations of features and multi - band Uh , and we 've been looking at  cross - language , cross  task  issues . And they 've been not so much looking at  the cross task uh multiple language issues . But they 've been looking at uh   at these issues . At the on - line normalization and the uh  voice activity detection . And I guess when he comes here we 're gonna have to start deciding about  um what do we choose  from what we 've looked at  to um blend with  some group of things in what they 've looked at And once we choose that ,  how do we split up the  effort ? Uh , because we still have  even once we choose ,  we 've still got  uh another  month or so , I mean there 's holidays in the way , but  but uh  I think the evaluation data comes January thirty - first so there 's still a fair amount of time  to do things together it 's just that they probably should be somewhat more coherent between the two sites  in that  that amount of time .\nWhen they removed the silence frames , did they insert some kind of a marker so that the recognizer knows it 's   knows when it 's time to back trace or something ?\nWell , see they , I  I think they 're Um . I don't know the   the specifics of how they 're doing it . They 're   they 're getting around the way the recognizer works because they 're not allowed to  um , change the scripts  for the recognizer ,  I believe .\nOh , right . Maybe they 're just inserting some nummy frames or something ?\nSo . Uh . Uh , you know that 's what I had thought . But I don't  I don't think they are .\nHmm .\nI mean that 's  sort of what  the way I had imagined would happen is that on the other side , yeah you p put some low level noise or something . Probably don't want all zeros .\nHmm .\nMost recognizers don't like zeros but  but  you know ,  put some epsilon in or some rand\nYeah .\nsorry epsilon random variable  in or something .\nSome constant vector . I mean i w Or something\nMaybe not a constant but it doesn't , uh  don't like to divide by the variance of that , but I mean it 's\nThat 's right . But something that  what I mean is something that is  very distinguishable from  speech .\nMm - hmm .\nSo that the  the silence model in HTK will always pick it up .\nYeah . So I  I  that 's what I thought they would do . or else , uh  uh maybe there is some indicator to tell it to start and stop , I don't know .\nHmm .\nBut whatever they did , I mean they have to play within the rules of this specific evaluation .\nYeah .\nWe c we can find out .\nCuz you gotta do something . Otherwise , if it 's just a bunch of speech , stuck together\nNo they 're\nYeah .\nIt would do badly\nYeah , right .\nand it didn't so badly , right ? So they did something .\nYeah , yeah .\nYeah . Uh . So , OK , So I think  this brings me up to date a bit . It hopefully brings other  people up to date a bit . And um Um  I think  Uh , I wanna look at these numbers off - line a little bit and think about it and   and talk with everybody uh ,  outside of this meeting . Um , but uh No I mean it sounds like  I mean  there  there  there are the usual number of  of  little  little problems and bugs and so forth but it sounds like they 're getting ironed out . And now we 're  seem to be kind of in a position to actually  uh ,  look at stuff and  and  and compare things . So I think that 's  that 's pretty good . Um  I don't know what the  One of the things I wonder about ,  coming back to the first results you talked about , is  is  how much ,  uh  things could be helped  by more parameters . And uh   And uh how many more parameters we can afford to have ,   in terms of the uh computational limits . Because anyway when we go to  twice as much data  and have the same number of parameters , particularly when it 's twice as much data and it 's quite diverse , um , I wonder if having twice as many parameters would help .\nMm - hmm .\nUh , just have a bigger hidden layer . Uh But  I doubt it would  help by forty per cent . But   but uh\nYeah .\nJust curious . How are we doing on the  resources ? Disk , and\nI think we 're alright ,\nOK .\num ,  not much problems with that .\nComputation ?\nIt 's OK .\nWe\nWell this table took uh  more than five days to get back .\nYeah . Yeah , well .\nBut  Yeah .\nAre  were you folks using Gin ? That 's a  that just died , you know ?\nMmm , no . You were using Gin  perhaps , yeah ? No .\nNo .\nNo ? Oh , that 's good .\nIt just died .\nOK . Yeah ,  we 're gonna get a replacement  server that 'll be a faster server ,  actually .\nYes .\nThat 'll be  It 's a  seven hundred fifty megahertz uh SUN\nHmm .  Mm - hmm .\nuh  But it won't be installed for  a little while .\nTonic .\nU Go ahead .\nDo we  Do we have that big new IBM machine the , I think in th\nWe have the  little tiny IBM machine   that might someday grow up to be a big  IBM machine . It 's got s slots for eight , uh IBM was donating five , I think we only got two so far , processors . We had originally hoped we were getting eight hundred megahertz processors . They ended up being five fifty . So instead of having eight processors that were eight hundred megahertz , we ended up with two  that are five hundred and fifty megahertz . And more are supposed to come soon and there 's only a moderate amount of dat of memory . So I don't think  anybody has been sufficiently excited by it to  spend much time  uh  with it , but uh  Hopefully ,  they 'll get us some more  parts , soon and  Uh , yeah , I think that 'll be  once we get it populated ,  that 'll be a nice machine . I mean we will ultimately get eight processors in there . And uh  and uh a nice amount of memory . Uh so it 'll be a pr pretty fast Linux machine .\nAnd if we can do things on Linux ,  some of the machines we have going already , like Swede ?\nMm - hmm .\nUm It seems pretty fast .\nMm - hmm .\nBut  I think Fudge is pretty fast too .\nYeah , I mean you can check with uh  Dave Johnson . I mean , it  it 's   I think the machine is just sitting there . And it does have two processors , you know and   Somebody could do   you know , uh , check out  uh the multi - threading  libraries . And  I mean i it 's possible that the  I mean , I guess the prudent thing to do would be for somebody to do the work on   on getting our code running  on that machine with two processors  even though there aren't five or eight . There 's  there 's  there 's gonna be debugging hassles and then we 'd be set for when we did have five or eight , to have it really be useful . But .  Notice how I said somebody and  turned my head your direction . That 's one thing you don't get in these recordings . You don't get the   don't get the visuals but\nI is it um  mostly um the neural network trainings that are  um slowing us down or the HTK runs that are slowing us down ?\nUh , I think yes . Uh ,  Isn't that right ? I mean I think you 're  you 're sort of held up by both , right ? If the  if the neural net trainings were a hundred times faster  you still wouldn't  be anything  running through these a hundred times faster because you 'd  be stuck by the HTK trainings ,\nMmm .\nright ?\nYeah .\nBut if the HTK  I mean I think they 're both  It sounded like they were roughly equal ? Is that about right ?\nYeah .\nYeah .\nBecause , um  I think that 'll be running Linux , and Sw - Swede and Fudge are already running Linux so ,  um I could try to get  um the train the neural network trainings or the HTK stuff running under Linux , and to start with I 'm  wondering which one I should pick first .\nUh , probably the neural net cuz it 's probably  it  it 's   it 's um  Well , I  I don't know . They both  HTK we use for  um  this Aurora stuff Um  Um , I think  It 's not clear yet what we 're gonna use  for trainings uh  Well ,  there 's the trainings uh  is it the training that takes the time , or the decoding ? Uh , is it about equal  between the two ? For  for Aurora ?\nFor HTK ?\nFor  Yeah . For the Aurora ?\nUh Training is longer .\nOK .\nYeah .\nOK . Well , I don't know how we can  I don't know how to  Do we have HTK source ? Is that  Yeah .\nMmm .\nYou would think that would fairly trivially  the training would , anyway , th the testing  uh I don't  I don't  think would  parallelize all that well . But I think  that  you could  certainly do d um ,  distributed , sort of   Ah , no , it 's the   each individual  sentence is pretty tricky to parallelize . But you could split up the sentences in a test set .\nThey have a  they have a thing for doing that and th they have for awhile , in H T And you can parallelize the training .\nYeah ?\nAnd run it on several machines\nAha !\nand it just basically keeps counts . And there 's something   a final  thing that you run and it accumulates all the counts together .\nI see .\nMmm .\nI don't what their scripts are  set up to do for the Aurora stuff , but\nYeah .\nSomething that we haven't really settled on yet is other than  this Aurora stuff ,  uh what do we do , large vocabulary  training slash testing  for uh tandem systems . Cuz we hadn't really done much with tandem systems for larger stuff . Cuz we had this one collaboration with CMU and we used SPHINX . Uh , we 're also gonna be collaborating with SRI and we have their  have theirs . Um  So  I don't know Um . So I  I think the  the advantage of going with the neural net thing is that we 're gonna use the neural net trainings , no matter what , for a lot of the things we 're doing ,\nOK .\nwhereas , w exactly which HMM  Gaussian - mixture - based HMM thing we use is gonna depend uh So with that , maybe we should uh  go to our {nonvocalsound} digit recitation task . And , it 's about eleven fifty . Canned . Uh , I can  I can start over here . Great , uh , could you give Adam a call . Tell him to He 's at two nine seven seven .\nOh .\nOK . I think we can  @ @ You know Herve 's coming tomorrow , right ? Herve will be giving a talk , yeah , talk at eleven . Did uh , did everybody sign these consent Er everybody Has everyone signed a consent form before , on previous meetings ? You don't have to do it again each time Yes . microphones off", "topic_id": 3, "keywords": "phonetic, vowels, neural, net, networks", "dialogue_id": 22}, {"text": "And we 're on .\nOK . Might wanna  close the door so that  Uh , Stephane will\nI 'll get it .\nYeah\nHey Dave ? Could you go ahead and turn on , uh , Stephane 's\nMm - hmm .\nSo that 's the virtual Stephane over there .\nOK .\nDo you use a PC for recording ? Or\nUh , yeah , a Linux box . Yeah . It 's got , uh , like sixteen channels going into it .\nUh - huh . Uh - huh . The quality is quite good ? Or  ?\nMm - hmm . Yeah , so far , it 's been pretty good .\nMm - hmm .\nYeah . So , uh , yeah  the suggestion was to have these guys start to\nOK . Why don't you go ahead , Dave ?\nOK . Um , so , yeah , the  this past week I 've been main mainly occupied with , um , getting some results , u from the SRI system trained on this short Hub - five training set for the mean subtraction method . And , um , I ran some tests last night . But , um , c the results are suspicious . Um , it 's , um ,  cuz they 're  the baseline results are worse than , um , Andreas  than results Andreas got previously . And  it could have something to do with , um\nThat 's on digits ?\nThat 's on digits . It c it  it could h it could have something to do with , um , downsampling .\nHmm .\nThat 's  that 's worth looking into . Um , d and , um , ap ap apart from that , I guess the  the main thing I have t ta I have to talk is , um , where I 'm planning to go over the next week . Um . So I 've been working on integrating this mean subtraction approach into the SmartKom system . And there 's this question of , well , so , um , in my tests before with HTK I found it worked  it worked the best with about twelve seconds of data used to estimate the mean , but , we 'll often have less  in the SmartKom system . Um . So I think we 'll use as much data as we have  at a particular time , and we 'll   we 'll concatenate utterances together , um , to get as much data as we possibly can from the user . But ,  um ,  there 's a question of how to set up the models . So um , we could train the models . If we think twelve seconds is ideal we could train the models using twelve seconds to calculate the mean , to mean subtract the training data . Or we could , um , use some other amount . So  like I did an experiment where I , um , was using six seconds in test , um , but , for  I tried twelve seconds in train . And I tried , um , um , the same in train  I 'm a I tried six seconds in train . And six seconds in train  was about point three percent better . Um , and   um , it 's not clear to me yet whether that 's  something significant . So I wanna do some tests and , um ,  actually make some plots of , um  for a particular amount of data and test what happens if you vary the amount of data in train .\nMm - hmm .\nUh , Guenter , I don't know if you t  followed this stuff but this is , uh ,  a uh , uh , long - term  long - term window F F Yeah . Yeah , he  you talked about it .\nYeah , we  we spoke about it already ,\nOh , OK . So you know what he 's doing .\nyeah .\nAlright .\ny s so I was  I actually ran the experiments mostly and I  I was  I was hoping to have the plots with me today . I just didn't get to it . But , um  yeah , I wou I would be curious about people 's feedback on this cuz I 'm   @ @  I p I think there are some I think it 's  it 's kind of like a  a bit of a tricky engineering problem . I 'm trying to figure out what 's the optimal way to set this up . So , um ,  I 'll try to make the plots and then put some postscript up on my  on my web page . And I 'll mention it in my status report if people wanna take a look .\nYou could clarify something for me . You 're saying point three percent , you take a point three percent hit ,  when the training and testing links are  don't match or something ?\nHello .\nIs that what it is ?\nw Well , it c\nOr  ?\nI  I don't think it  it 's  just for any mismatch  you take a hit .\nYeah .\ni In some cases it might be u better to have a mismatch . Like I think I saw something like  like if you only have two seconds in test , or , um , maybe it was something like four seconds , you actually do a little better if you , um ,  train on six seconds than if you train on four seconds .\nYeah . Right .\nUm , but the case , uh  with the point three percent hit was  using six seconds in test , um , comparing train on twelve seconds  versus train on six seconds .\nAnd which was worse ?\nThe train on twelve seconds .\nOK . But point three percent , uh , w from what to what ? That 's point three percent\nOn  The  the  the accuracies  w went from  it was something vaguely like ninety - five point six accuracy , um , improved to ninety - five point nine wh when I\nSo four point four to four point one .\nOK .\nSo  yeah . So about a  about an eight percent , uh , seven or eight percent relative ?\nOK .\nUh , Yeah . Well , I think in a p You know , if  if you were going for an evaluation system you 'd care . But if you were doing a live system that people were actually using nobody would notice . It 's  uh , I think the thing is to get something that 's practical , that  that you could really use .\nHuh . That 's  that 's interesting . Alright , the e uh , I see your point . I guess I was thinking of it as , um ,  an interesting research problem . The  how to g I was thinking that for the ASRU paper we could have a section saying ,  \" For SmartKom , we  we d in  we tried this approach in , uh ,  interactive system \" , which I don't think has been done before .\nYeah . Mm - hmm .\nAnd  and then there was two research questions from that .\nMm - hmm .\nAnd one is the k does it still work if you just use the past history ?\nMm - hmm .\nAlright , and the other was this question of , um what I was just talking about now . So I guess that 's why I thought it was interesting .\nI mean , a short - time FFT  short - time cepstrum calculation , uh , mean  u mean calculation work that people have in commercial systems , they do this all the time . They  the  they calculate it from previous utterances and then use it , you know .\nYeah , um .\nBut  but , uh , as you say , there hasn't been that much with this long  long - time , uh , spectra work .\nOh , o Oh , OK .\nUh ,\nSo that 's  that 's  that 's standard . Um\nYeah . Pretty common .\nOK .\nYeah . Um , but , u uh , yes . No , it is interesting . And the other thing is , I mean , there 's two sides to these really small , uh , gradations in performance . Um , I mean , on the one hand in a practical system if something is , uh , four point four percent error , four point one percent error , people won't really tell  be able to tell the difference . On the other hand , when you 're doing , uh , research , you may , eh  you might find that the way that you build up a change from a ninety - five percent accurate system to a ninety - eight percent accurate system is through ten or twelve little things that you do that each are point three percent . So  so the  they  they  it 's  I don't mean to say that they 're  they 're irrelevant . Uh , they are relevant . But , um ,  i for a demo , you won't see it .\nMm - hmm . Right . OK .\nYeah .\nAnd , um , Let 's  l let 's see . Um , OK . And then there 's um , another thing I wanna start looking at , um ,  wi is , um , the choice of the analysis window length . So I 've just been using two seconds just because that 's what Carlos did before . Uh , I wrote to him asking about he chose the two seconds . And it seemed like he chose it a bit informally . So , um , with the  with the HTK set - up I should be able to do some experiments , on just varying that length , say between one and three seconds , in a few different reverberation conditions , um , say this room and also a few of the artificial impulse responses we have for reverberation , just , um , making some plots and seeing how they look . And , um , so , with the  the sampling rate I was using , one second or two seconds or four seconds is at a power of two um , number of samples and , um , I 'll  I 'll jus f for the ones in between I guess I 'll just zero - pad .\nMm - hmm . I guess one thing that might also be an issue , uh , cuz part of what you 're doing is you 're getting a  a spectrum over a bunch of different kinds of speech sounds . Um , and so it might matter how fast someone was talking for instance .\nOh .\nYou know , if you  if  if  if there 's a lot of phones in one second maybe you 'll get a  a really good sampling of all these different things , and   and , uh , on the other hand if someone 's talking slowly maybe you 'd need more . So\nHuh .\nI don't know if you have some samples of faster or slower speech but it might make a difference . I don't know .\nUh , yeah , I don't  I don't think the TI - digits data that I have , um ,  i is  would be appropriate for that .\nYeah , probably not . Yeah .\nBut what do you  What about if I w I fed it through some kind of , um , speech processing algorithm that changed the speech rate ?\nYeah , but then you 'll have the degradation of  of , uh , whatever you do uh , added onto that . But maybe . Yeah , maybe if you get something that sounds  that  that 's  does a pretty job at that .\nYeah . Well , uh , just if you think it 's worth looking into .\nYou could imagine that .\nI mean , it  it is getting a little away from reverberation .\nUm , yeah . It 's just that you 're making a choice  uh , I was thinking more from the system aspect , if you 're making a choice for SmartKom , that  that  that it might be that it 's  it c the optimal number could be different , depending on\nYeah . Right .\nCould be . I don't know .\nAnd  and th the third thing , um , uh , is , um , Barry explained LDA filtering to me yesterday . And so , um , Mike Shire in his thesis um ,  did a  a series of experiments , um , training LDA filters in d on different conditions . And you were interested in having me repeat this for  for this mean subtraction approach ? Is  is that right ? Or for these long analysis windows , I guess , is the right way to put it .\nI guess , the  the  the issue I was  the general issue I was bringing up was that if you 're  have a moving   moving window , uh , a wa a  a set of weights times things that , uh , move along , shift along in time , that you have in fact a linear time invariant filter . And you just happened to have picked a particular one by setting all the weights to be equal . And so the issue is what are some other filters that you could use , uh , in that sense of \" filter \" ?\nMm - hmm .\nAnd , um , as I was saying , I think the simplest thing to do is not to train anything , but just to do some sort of , uh , uh , hamming or Hanning , uh , kind of window , kind of thing ,\nRight . Mm - hmm .\njust sort of to de - emphasize the jarring . So I think that would sort of be the first thing to do . But then , yeah , the LDA i uh , is interesting because it would sort of say well , suppose you actually trained this up to do the best you could by some criterion , what would the filter look like then ?\nUh - huh .\nUh , and , um , that 's sort of what we 're doing in this Aur - Aurora stuff . And , uh , it 's still not clear to me in the long run whether the best thing to do would be to do that or to have some stylized version of the filter that looks like these things you 've trained up , because you always have the problem that it 's trained up for one condition and it isn't quite right for another . So . uh  that 's  that 's why  that 's why RASTA filter has actually ended up lasting a long time , people still using it quite a bit , because y you don't change it . So doesn't get any worse . Uh ,\nHuh .\nAnyway .\no OK . So , um , a actually I was just thinking about what I was asking about earlier , wi which is about having  less than say twelve seconds in the SmartKom system to do the mean subtraction . You said in  systems where you use cepstral mean subtraction , they concatenate utterances and ,  do you know how they address this issue of , um , testing versus training ? Can\nGo ahead .\nI think what they do is they do it always on - line , I mean , that you just take what you have from the past , that you calculate the mean of this and subtract the mean .\nOK . Um\nAnd then you can  yeah , you  you can increase your window whi while you get  while you are getting more samples .\nOK , um , and , um , so  so in tha in that case , wh what do they do when they 're t um , performing the cepstral mean subtraction on the training data ? So  because you 'd have hours and hours of training data . So do they cut it off and start over ? At intervals ? Or  ?\nSo do you have  uh , you  you mean you have files which are hours of hours long ? Or  ?\nOh , well , no . I guess not . But\nYeah . I mean , usually you have in the training set you have similar conditions , I mean , file lengths are , I guess the same order or in the same size as for test data , or aren't they ?\nOK . But it 's  OK . So if someone 's interacting with the system , though , uh , Morgan  uh , Morgan said that you would  tend to , um ,  chain utterances together um , r\nWell , I think what I was s I thought what I was saying was that , um , at any given point you are gonna start off with what you had from before .\nOh .\nFrom  and so if you 're splitting things up into utterances  So , for instance , in a dialogue system ,  where you 're gonna be asking , uh , you know , th for some information , there 's some initial th something . And , you know , the first time out you  you might have some general average . But you  you d you don't have very much information yet . But at  after they 've given one utterance you 've got something . You can compute your mean cepstra from that ,\nMm - hmm .\nand then can use it for the next thing that they say , uh , so that , you know , the performance should be better that second time . Um , and I think the heuristics of exactly how people handle that and how they handle their training I 'm sure vary from place to place . But I think the  ideally , it seems to me anyway , that you  you would wanna do the same thing in training as you do in test . But that 's  that 's just , uh , a prejudice . And I think anybody working on this with some particular task would experiment .\nRight . I g I guess the question I had was , um , amount of data e u was the amount of data that you 'd give it to , um  update this estimate . Because say you  if you have say five thousand utterances in your training set ,  um , and you  you keep the mean from the last utterance , by the time it gets to the five thousandth utterance\nNo , but those are all different people with different  I mean , i in y So for instance , in  in the  in a telephone task , these are different phone calls . So you don't wanna @ @  chain it together from a  from a different phone call .\nOK , so  so  so they would  g s\nSo it 's within speaker , within phone call ,\nYeah .\nif it 's a dialogue system , it 's within whatever this characteristic you 're trying to get rid of is expected to be consistent over ,\nHmm .\nr and it\nright ?\nright . OK , so you 'd  you  and so in training you would start over at  at every new phone call or at every  new speaker . Yeah ,\nYeah .\nOK .\nYeah . Now ,  you know , maybe you 'd use something from the others just because at the beginning of a call you don't know anything , and so you might have some kind of general thing that 's your best guess to start with . But  So , s I  I  you know , a lot of these things are proprietary so we 're doing a little bit of guesswork here . I mean , what do comp what do people do who really face these problems in the field ? Well , they have companies and they don't tell other people exactly what they do .\nR right .\nBut  but I mean , when you  the  the hints that you get from what they  when they talk about it are that they do  they all do something like this .\nRight , OK . I see . Bec - because I  so this SmartKom task first off , it 's this TV and movie information system .\nYeah , but you might have somebody who 's using it\nAnd  Yeah .\nand then later you might have somebody else who 's using it .\nYeah . Right . Right . I  I see .\nAnd so you 'd wanna set some\nI was  I was about to say . So if  if you ask it \" What  what movies are on TV tonight ? \" ,\nYeah . Yeah .\nif I look at my wristwatch when I say that it 's about two seconds . The way I currently have the mean subtraction , um , set up , the  the analysis window is two seconds .\nYeah .\nSo what you just said , about what do you start with , raises a question of  what do I start with then ?\nMm - hmm .\nI guess it  because\nWell , w OK , so in that situation , though , th maybe what 's a little different there , is I think you 're talking about  there 's only one  it  it  it also depends  we 're getting a little off track here .\nOh , right .\nr But  but  but  Uh , there 's been some discussion about whether the work we 're doing in that project is gonna be for the kiosk or for the mobile or for both . And I think for this kind of discussion it matters . If it 's in the kiosk , then the physical situation is the same . It 's gonna  you know , the exact interaction of the microphone 's gonna differ depending on the person and so forth . But at least the basic acoustics are gonna be the same . So f if it 's really in one kiosk , then I think that you could just chain together and  and you know , as much  as much speech as possible to  because what you 're really trying to get at is the  is the reverberation characteristic .\nYeah .\nBut in  in the case of the mobile , uh ,  presumably the acoustic 's changing all over the place .\nRight .\nAnd in that case you probably don't wanna have it be endless because you wanna have some sort of  it 's  it 's not a question of how long do you think it 's  you can get an approximation to a stationary something , given that it 's not really stationary .\nRight . Right .\nSo .\nHmm .\nAnd I  I g I guess I s just started thinking of another question , which is ,  for  for the very first frame , w what  what do I do if I 'm  if I take  if I use that frame to calculate the mean , then I 'm just gonna get n nothing .\nMm - hmm .\nUm ,\nRight .\nso I should probably have some kind of default  mean for the first f couple of frames ?\nYeah . Yeah .\nOK .\nYeah . Or subtract nothing . I mean , it 's\nOr subtract nothing . And  and that 's  that 's  I guess that 's something that 's p people have figured out how to deal with in cepstral mean subtraction as well ?\nYeah , yeah . Yeah , people do something . They  they , uh , they have some , um , uh , in  in cepstral mean subtraction , for short - term window  analysis windows , as is usually done , you 're trying to get rid of some very general characteristic . And so , uh , if you have any other information about what a general kind of characteristic would be , then you  you can do it there .\nYou can also  you can also reflect the data . So you take , uh  you know , I 'm not sure how many frames you need .\nUh - huh .\nBut you take that many from the front and flip it around to  a as the negative value .\nYeah , that 's  Yeah .\nSo you can always\nThe other thing is that  and  and  I  I remember B B N doing this , is that if you have a multi - pass system , um , if the first pass ta it takes most of the computation , the second and the third pass could be very , very quick ,\nMmm .\njust looking at a relatively small n small , uh , space of hypotheses .\nUh - huh .\nThen you can do your first pass  without any subtraction at all .\nOh .\nAnd then your second pass , uh , uh , eliminates those  most of those hypotheses by , uh  by having an improved  improved version o of the analysis .\nOK . OK .\nSo .\nOK . So that was all I had , for now .\nYeah .", "topic_id": 0, "keywords": "testing, tests, recording, stephane, feedback", "dialogue_id": 23}, {"text": "Do you wanna go , Barry ?\nYeah , OK . Um , so for the past ,  uh , week an or two , I 've been just writing my , uh , formal thesis proposal . Um , so I 'm taking  this qualifier exam that 's coming up in two weeks . And I  I finish writing a proposal and submit it to the committee . Um . And uh , should I  should I explain , uh , more about what  what I 'm proposing to do , and s and stuff ?\nYes , briefly .\nYeah briefly .\nOK . Um , so briefly ,  I 'm proposing to do a n a new p approach to speech recognition using um , a combination of , uh , multi - band ideas and ideas , um ,    about the uh , acoustic phonec phonetic approach to speech recognition . Um , so I will be using  these graphical models that  um , that implement the multi - band approach  to recognize a set of intermediate categories that might involve , uh , things like phonetic features  or other  other f feature things that are more closely related to the acoustic signal itself . Um , and the hope in all of this is that by going multi - band and by going into these ,  um intermediate classifications ,  that we can get a system that 's more robust to  to unseen noises , and situations like that . Um , and so , some of the research issues involved in this are ,  um ,   one , what kind of intermediate categories do we need to classify ? Um , another one is  um , what  what other types of structures in these multi - band graphical models should we consider in order to um , combine evidence from  the sub - bands ? And , uh , the third one is how do we  how do we merge all the , uh , information from the individual uh , multi - band classifiers to come up with word  word recognition or  or phone recognition things . Um , so basically that 's  that 's what I 've been doing . And ,\nSo you 've got two weeks , huh ?\nI got two weeks to brush up on d um , presentation stuff and , um ,\nOh , I thought you were finishing your thesis in two weeks .\nBut . Oh , that too .\nYeah .\nYeah .\nAre you gonna do any dry runs for your thing ,\nYes .\nor are you just gonna\nYes . I , um  I 'm  I 'm gonna do some . Would you be interested ? To help out ?\nSure .\nOK .\nSure .\nThanks . Yeah .\nIs that it ?\nThat 's it .\nHhh . OK . Uh . Hhh . Let 's see . So we 've got forty minutes left , and it seems like there 's a lot of material . An - any suggestions about where we  where we should go next ?\nMmm , @ @ .\nUh . Do you wanna go , Sunil ? Maybe we 'll just start with you .\nYeah . But I actually stuck most of this in our m last meeting with Guenter . Um , but I 'll just  Um , so the last week , uh , I showed some results with only SpeechDat - Car which was like some fifty - six percent . And , uh , I didn't h I mean , I  I found that the results  I mean , I wasn't getting that r results on the TI - digit . So I was like looking into \" why , what is wrong with the TI - digits ? \" . Why  why I was not getting it . And I found that , the noise estimation is a reason for the TI - digits to perform worse than the baseline . So , uh , I actually , picked th I mean , the first thing I did was I just scaled the noise estimate by a factor which is less than one to see if that  because I found there are a lot of zeros in the spectrogram for the TI - digits when I used this approach . So the first thing I did was I just scaled the noise estimate . And I found  So the  the results that I 've shown here are the complete results using the new  Well , the n the new technique is nothing but the noise estimate scaled by a factor of point five . So it 's just an ad - hoc  I mean , some intermediate result , because it 's not optimized for anything . So the results  The trend  the only trend I could see from those results was like the  the p the current noise estimation or the , uh , noise composition scheme is working good for like the car noise type of thing . Because I 've  the only  only  p very good result in the TI - digits is the noise  car noise condition for their test - A , which is like the best I could see that uh , for any non - stationary noise like \" Babble \" or \" Subway \" or any  \" Street \" , some \" Restaurant \" noise , it 's like  it 's not performing w very well . So , the   So that  that 's the first thing I c uh , I could make out from this stuff . And\nYeah , I think what is important to see is that there is a big difference between the training modes .\nYeah .\nUh - huh . If you have clean training , you get also a fifty percent improvement .\nYeah .\nBut if you have muddy condition training you get only twenty percent .\nYeah . Yeah .\nMm - hmm .\nUh , and in that twenty percent @ @ it 's very inconsistent across different noise conditions .\nMm - hmm . Mmm .\nSo I have like a forty - five  percent for \" Car noise \" and then there 's a minus five percent for the \" Babble \" ,\nMmm .\nand there 's this thirty - three for the \" Station \" . And so  it 's  it 's not  it 's not actually very consistent across . So . The only correlation between the SpeechDat - Car and this performance is the c stationarity of the noise that is there in these conditions and the SpeechDat - Car .\nMm - hmm .\nAnd , uh  so  so the overall result is like in the last page , which is like forty - seven , which is still very imbalanced because there are like fifty - six percent on the SpeechDat - Car and thirty - five percent on the TI - digits . And  uh , ps the fifty - six percent is like comparable to what the French Telecom gets , but the thirty - five percent is way off .\nI 'm sort of confused but  this  I 'm looking on the second page ,\nOh , yep .\nand it says \" fifty percent \"  looking in the lower right - hand corner , \" fifty percent relative performance \" .\nFor the clean training .\nIs that\nu And if you  if you look\nis that fifty percent improvement ?\nYeah . For  that 's for the clean training and the noisy testing for the TI - digits .\nYeah .\nSo it 's improvement over the baseline mel cepstrum ?\nYeah . Yeah .\nBut the baseline mel cepstrum under those training doesn't do as well I  I 'm  I 'm trying to understand why it 's  it 's eighty percent  That 's an accuracy number , I guess ,\nYeah , yeah , yeah .\nright ? So that 's not as good as the one up above .\nNo .\nBut the fifty is better than the one up above ,\nYeah .\nso I 'm confused .\nUh , actually the noise compensation whatever , uh , we are put in it works very well for the high mismatch condition . I mean , it 's consistent in the SpeechDat - Car and in the clean training also it gives it  But this fifty percent is  is that the  the high mismatch performance  equivalent to the high mismatch performance in the speech .\nSo n s So since the high mismatch performance is much worse to begin with , it 's easier to get a better relative improvement .\nYeah . Yeah . I do . Yeah , yeah . So by putting this noise\nYeah . Yeah , if we look at the figures on the right , we see that the reference system is very bad .\nOh .\nYeah . The reference drops like a very fast\nOh , oh , oh , oh , oh , oh .\nLike for clean  clean training condition .\nI see .\nYeah .\nI see .\nNnn .\nThis is  this is TI digits  we 're looking at ?\nYeah . Yeah . Oh\nThis whole page is TI - digits\nOh . Yeah .\nor this is  ?\nIt 's not written anywhere . Yeah , it 's TI - digits . The first r spreadsheet is TI - digits .\nMmm . How does clean training do for the , uh , \" Car \"\nHmm .\nThe \" Car \" ?\nstuff ?\nOh . Still  it still , uh  that  that 's still consistent . I mean , I get the best performance in the case of \" Car \" , which is the third column in the A condition .\nNo . I mean , this is added noise . I mean , this is TI - digits . I 'm sorry . I meant  in  in the  in the , uh , multi - language , uh , uh , Finnish and\nUh\nThis is next  next page .\nThat 's the next  next spreadsheet , is\nHmm .\nSo that is the performance for Italian , Finnish and Spanish .\n\" Training condition \"  Oh , right . So \" clean \" corresponds to \" high mismatch \" .\nYeah .\nAnd \" increase \" , That 's increase e\nImprovement .\nImprovement . That 's  \" Percentage increase \" is the percentage improvement over the baseline .\nYeah . It 's  it 's a\nSo that 's\nWhich means decrease in word error rate ?\nYeah .\nOK , so \" percentage increase \" means decrease ?\nYeah , yeah .\nOK .\nYeah . The  the w there was a very long discussion about this on  on the  on the , uh , Amsterdam meeting .\nYeah .\nHow to  how to calculate it then .\nYeah . There 's  there 's a\nI  I  I guess you are using finally this  the scheme which they\nWhich is there in the spreadsheet .\nOK .\nI 'm not changing anything in there .\nMmm .\nAlright .\nSo . Uh , yeah . So all the hi H M numbers are w very good , in the sense , they are better than what the French Telecom gets . So . But the  the only number that 's still  I mean , which Stephane also got in his result was that medium mismatch of the Finnish , which is very   which is a very strange situation where we used the  we changed the proto for initializing the HMM  I mean , this  this is basically because it gets stuck in some local minimum in the training . That seventy - five point seven nine in the Finnish mismatch which is that  the eleven point nine six what we see .\nUh - huh .\nMmm .\nYeah .\nSo we have to jiggle it somehow ?\nYeah  so we start with that different proto and it becomes eighty - eight , which is like some fifty percent improvement .\nS Wait a minute . Start with a different what ?\nDifferent prototype , which is like a different initialization for the , uh , s transition probabilities . It 's just that right now , the initialization is to stay more in the current state , which is point four point six , right ? Yeah .\nYeah .\nAnd if it changes to point five point five , which is equal @ @ for transition and self loop where it becomes eighty - eight percent .\nWell , but that involves mucking with the back - end ,\nYeah . We can't do it .\nwhich is not allowed .\nYeah .\nMmm .\nYeah .\nSo .\nI mean , it uh , like , i i i It is well known , this  this medium match condition of the Finnish data has some strange effects .\nVery s\nYeah .\nIt has a very few at  uh , actually , c uh , tran I mean , words also .\nI mean , that is  Yeah ,\nIt 's a very , very small set , actually .\nthat too . Yeah . Uh - huh .\nSo there is\nThere is a l a  There is a lot of  Uh , there are a lot of utterances with music in  with music in the background .\nYeah . Yeah , yeah , yeah . Yeah .\nMmm .\nUh - huh .\nYeah . It has some music also . I mean , very horrible music like like I know .\nSo maybe for that one you need a much smarter VAD ? Mmm ,\nUh\nif it 's music .\nSo , that  that 's the  that 's about the results . And , uh , the summary is like  OK . So there are  the other thing what I tried was , which I explained in the last meeting , is using the channel zero for , uh , for both dropping and estimating the noise . And that 's like just to f n get a feel of how good it is . I guess the fifty - six percent improvement in the SpeechDat - Car becomes like sixty - seven percent . Like ten percent better . But that 's  that 's not a  that 's a cheating experiment . So . That 's just  So , m w\nBut the  but the , uh , forty - seven point nine percent which you have now , that 's already a remarkable improvement in comparison to the first proposal .\nYeah . So we had forty - four percent in the first proposal .\nOK .\nYeah .\nMm - hmm .\nWe have f a big im So  the major improvement that we got was in all the high mismatch cases , because all those numbers were in sixties and seventies because we never had any noise compensations .\nMmm .\nSo that 's where the biggest improvement came up . Not much in the well match and the medium match and TI - digits also right now . So this is still at three or four percent improvement over the first proposal .\nMmm . Mmm .\nYeah , so that 's good .\nYeah . So .\nThen if we can improve the noise estimation , then it should get better .\nYeah , I  I started thinking about also  I mean yeah , uh ,  I discovered the same problem when I started working on  uh , on this Aurora task  almost two years ago , that you have the problem with this mulit a at the beginning we had only this multi condition training of the TI - digits .\nYeah .\nAnd , uh , I  I found the same problem . Just taking um , what we were used to u  use , I mean , uh , some type of spectral subtraction ,  y  you get even worse results than  the basis\nYeah . Yeah ,\nand uh\nyeah .\nI  I tried to find an explanation for it ,\nMmm .\nso\nSo . Yes . Stephane also has the same experience of using the spectral subtraction right ?\nMmm .\nMm - hmm .\nYeah . So here  here I mean , I found that it 's  if I changed the noise estimate I could get an improvement .\nYeah .\nSo that 's  so it 's something which I can actually pursue , is the noise estimate .\nMm - hmm .\nAnd\nYeah , I think what you do is in  when  when you have the  the  this multi - condition training mode , um then you have  then you can train models for the speech , for the words , as well as for the pauses where you really have all information about the noise available .\nYeah .\nAnd it was surprising  At the beginning it was not surprising to me that you get really the best results on doing it this way , I mean , in comparison to any type of training on clean data and any type of processing . But it was  So , u u it  it seems to be the best what  wh wh what  what we can do in this moment is multi - condition training . And every when we now start introducing some  some noise reduction technique we  we introduce also somehow artificial distortions .\nYeah .\nAnd these artificial distortions  uh , I have the feeling that they are the reason why  why we have the problems in this multi - condition training . That means the H M Ms we trained , they are  they are based on Gaussians ,\nYeah .\nand on modeling Gaussians . And if you  Can I move a little bit with this ? Yeah . And if we introduce now this  this u spectral subtraction , or Wiener filtering stuff  So , usually what you have is maybe , um  I 'm  I 'm showing now an envelope um maybe you 'll  f for this time . So usually you have  maybe in clean condition you have something which looks like this . And if it is noisy it is somewhere here . And then you try to subtract it or Wiener filter or whatever . And what you get is you have always these problems , that you have this  these  these  these zeros in there .\nYeah .\nAnd you have to do something if you get these negative values . I mean , this is your noise estimate and you somehow subtract it or do whatever . Uh , and then you have  And then I think what you do is you introduce some  some artificial distribution in this uh in  in the models . I mean , i you  you train it also this way but , i somehow there is  u u there is no longer a  a Gaussian distribution . It is somehow a strange distribution which we introduce with these  artificial distortions . And  and I was thinking that  that might be the reason why you get these problems in the  especially in the multi - condition training mode .\nYeah , yeah .\nMm - hmm .", "topic_id": 1, "keywords": "phonetic, proposal, utterances, speechdat, classify", "dialogue_id": 23}, {"text": "Th - That 's true . Yeah  the c the models are not complex enough to absorb that additional variability that you 're introducing .\ns\nThanks Adam .\nYeah . Yes .\nWell , that 's  Yeah . So\nI also have the feeling that um , the reason ye why it doesn't work is  yeah , that the models are much  are t um , not complex enough . Because I  actually I als always had a good experience with spectral subtraction , just a straight spectral subtraction algorithm when I was using neural networks , big neural networks , which maybe are more able to model strange distributions and\nMm - hmm .\nBut  Yeah . Then I tried the same  exactly the same spectral subtraction algorithm on these Aurora tasks and it simply doesn't work . It 's even  it , uh , hurts even .\nHmm .\nSo .\nWe probably should at some point here try the tandem  the  the  the system - two kind of stuff with this , with the spectral subtraction for that reason .\nHmm .\nCuz  again , it should do a transformation to a domain where it maybe  looks more Gaussian .\nMm - hmm .\nMm - hmm .\nHmm . Yeah , y I  I was  whe w w just yesterday when I was thinking about it  um w what  what we could try to do , or do about it  I mean , if you  if you get at this  in this situation that you get this  this negative values and you simply set it to zero or to a constant or whatever  if we  if we would use there a somehow , um  a random generator which  which has a certain distribution , u not a certain   yeah , a special distribution we should see  we  we have to think about it .\nIt 's\nAnd that we , so , introduce again some natural behavior in this trajectory .\nMm - hmm .\nMm - hmm . Very different from speech . Still , I mean , it shouldn't confuse the\nYeah , I mean , similar to what  what you see really u in  in the real um noisy situation .\nOK . Mm - hmm .\nOr i in the clean situation . But  but somehow a  a natural distribution .\nBut isn't that s again sort of the idea of the additive thing , if it  as  as we had in the J stuff ? I mean , basically if   if you have random data , um , in  in the time domain , then when you look at the s spectrum it 's gonna be pretty flat . And  and ,\nMm - hmm .\nuh , so just add something everywhere rather than just in those places . It 's just a constant , right ?\nMm - hmm .\nYeah . I think  e yeah . It 's  it 's just especially in these segments , I mean , you introduce , um , very artificial behavior .\nYeah . Yeah .\nAnd\nWell , see if you add something everywhere , it has almost no effect up  up  up on  on top . And it  and it  and it has significant effect down there .\nMm - hmm .\nThat was , sort of the idea .\nMm - hmm .\nHmm . Yeah the  that 's true . That  those  those regions are the cause for this @ @  those negative values or whatever you get .\nI Mm - hmm . Mm - hmm .\nYeah . So .\nI mean , we  we could trit uh , we  we could think how w what  what we could try .\nYeah . Yeah , yeah .\nI mean ,  it  it was just an idea .\nMm - hmm .\nI mean , we\nI think when it 's noisy people should just speak up .\nto  Mmm .\nSo\nIf we look at the France Telecom proposal , they use some kind of noise addition . They have a random number generator , right ? And they add noise on the trajectory of , uh , the log energy only , right ?\nOh , they do !\nYep .\nOh .\nC - z C - zero and log energy also , yeah .\nYeah . Um , But I don't know how much effect it  this have , but they do that .\nNow ?\nYeah .\nOh .\nUh - huh .\nHmm .\nSo it  it  it  it  it is l somehow similar to what\nI think because they have th log energy , yeah , and then just generate random number . They have some kind of mean and variance , and they add this number to  to the log energy simply . Um\nYeah  the  the log energy , the  after the clean  cleaning up .\nTo the l\nSo they add a random  random noise to it .\nMm - hmm .\nTo the  just the energy , or to the mel  uh , to the mel filter ?\nNo . On - only to the log energy .\nOnly  Yeah .\nOh .\nUh - huh .\nSo it  Cuz I mean , I think this is most interesting for the mel filters . Right ?\nUh - huh .\nOr  or F F one or the other .\nBut  but they do not apply filtering of the log energy or what\nLike , uh  I mean\nlike  like a spectral subtraction or\nNo  their filter is not M domain . S so they did filter their time signal\nYeah . I kn\nand then what @ @  u\nAnd then they calculate from this , the log energy\nYeah  then after that it is s almost the same as the baseline prop system .\nor  ? Mm - hmm .\nAnd then the final log energy that they  that they get , that  to the  to that they add some random noise .\nYeah , but again , that 's just log energy as opposed to  filter bank energy .\nYeah . So it 's not the mel .\nMmm .\nYou know , it 's not the mel filter bank output .\nYeah .\nThese are log energy computed from the time s domain signal ,\nMm - hmm .\nMm - hmm .\nnot from the mel filter banks . So  did\nHmm .\nMaybe it 's just a way to decrease the importance of this particular parameter in the  in the world feature vector cu if you add noise to one of the parameters , you widen the distributions\nHmm .\nBecomes flat . The variance , yeah , reduces ,\nand\nso . Hmm , yeah .\nEee - sss - uh .\nSo it could reduce the dependence on the amplitude and so on . Yeah .\nYeah .\nYeah . Although\nMaybe .\nMm - hmm .\nSo is , uh  Is that about it ?\nUh , so the\nOr  ?\nOK . So the other thing is the  I 'm just looking at a little bit on the delay issue where the delay of the system is like a hundred and eighty millisecond . So  I just  just tried another sk system  I mean , another filter which I 've like shown at the end . Which is very similar to the existing uh , filter . Only  Uh , only thing is that the phase is  is like a totally nonlinear phase because it 's a  it 's not a symmetric filter anymore .\nThis is for the LDA ?\nYeah  so  so this  this is like  So this makes the delay like zero for LDA because it 's completely causal .\nOh .\nSo  So I got actually just the results for the Italian for that and that 's like  So the fifty - one point O nine has become forty - eight point O six , which is like three percent relative degradation . So I have like the fifty - one point O nine\nMm - hmm .\nand  So . I don't know it f fares for the other conditions . So it 's just like  it 's like a three percent relative degradation , with the\nBut  but is there  is there a problem with the one hundred eighty milliseconds ? Or  ?\nu Uh , may\nTh - Well , this is\nYeah , I mean , I talked to  to  uh , I ta Uh , I talked , uh , about it with  with Hynek . I mean , there is\nThis is  So  So , basically our  our position is  that , um , we shouldn't be unduly constraining the latency at this point because we 're all still experimenting with trying to make the performance better in the presence of noise . Uh , there is a minority in that group who is a arguing  who are arguing for  um , uh , having a further constraining of the latency . So we 're s just continuing to keep aware of what the trade - offs are and , you know , what  what do we gain from having longer or shorter latencies ?\nMmm .\nBut since we always seem to at least get something out of longer latencies not being so constrained , we 're tending to go with that if we 're not told we can't do it .\nWhat  where was the , um  the smallest latency of all the systems last time ?\nMm - hmm .\nThe French Telecom .\nWell , France Telecom was  was  was very short latency\nIt 's\nand they had a very good result .\nWhat  what was it ?\nIt was thirty - five .\nIt was in the order of thirty milliseconds\nYeah .\nor\nThirteen ?\nth th\nThirty .\nThirty .\nThirty - four .\nYeah .\nYeah .\nYeah , so it 's possible to get very short latency .\nBut , again , we 're  the  the approaches that we 're using are ones that  take advantage of\nYeah . I was just curious about where we are compared to , you know , the shortest that people have done .\nBut  but I think this thirty milliseconds  they  they did  it did not include the  the delta calculation .\nYeah . Yeah . Yeah .\nAnd this is included now ,\nYeah . Yeah .\nyou know ?\nSo if they include the delta , it will be an additional forty millisecond .\nMm - hmm .\nYeah .\nYeah . I  I don't remember the  i th They were not using the HTK delta ?\nNo , they 're using a nine - point window , which is like a four on either side ,\nNine - point .\nwhich is like\nOK .\nf so\nMmm .\nthey didn't include that .\nYeah .\nMm - hmm .\nSo\nWhere does the comprish compression in decoding delay comes from ?\nOK .\nThat 's the way the  the  the frames are packed , like you have to wait for one more frame to pack . Because it 's  the CRC is computed for two frames always .\nWell , that  the they would need that forty milliseconds also .\nMm - hmm .\nNo . They actually changed the compression scheme altogether .\nRight ?\nMm - hmm .\nSo they have their own compression and decoding scheme and they  I don't know what they have .\nOh .\nBut they have coded zero delay for that . Because they ch I know they changed it , their compression . They have their own CRC , their  their own  error correction mechanism .\nOh .\nSo they don't have to wait more than one more frame to know whether the current frame is in error .\nOh , OK .\nSo they changed the whole thing so that there 's no delay for that compression and  part also .\nHmm .\nMm - hmm .\nEven you have reported actually zero delay for the  compression . I thought maybe you also have some different\nMmm . Mmm . No , I think I  I used this scheme as it was before .\nOK . Ah . Mm - hmm .\nOK , we 've got twenty minutes so we should  probably try to move along . Uh , did you wanna go next , Stephane ?", "topic_id": 2, "keywords": "aurora, spectrum, spectral, decoding, gaussian", "dialogue_id": 23}, {"text": "I can go next . Yeah . Mmm .\nOh . Wait a minute . It 's\nIt 's  Yeah , we have to take\nWait a minute . I think  I 'm confused .\nWell  OK .\nAlright .\nSo you have w w one sheet ? This one is  you don't need it , alright .\nUh\nSo you have to take the whole  the five . There should be five sheets .\nOK ,\nI have four now because I left one with Dave because I thought I was dropping one off and passing the others on . So , no , we 're not . OK .\nThanks .\nPlease give me one .\nAh , we need one more over here .\nOK , maybe there 's not enough for everybody .\nI can share with Barry .\nYeah .\nOh , OK .\nBut  Can we look at this ?\nOK .\nYeah .\nSo , yeah , there are two figures showing actually the , mmm , um , performance of the current VAD . So it 's a n neural network based on PLP parameters , uh , which estimate silence probabilities , and then I just put a median filtering on this to smooth the probabilities , right ? Um  I didn't use the  the scheme that 's currently in the proposal because  I don't want to  In the proposal  Well , in  in the system we want to add like speech frame before every word and a little bit of  of , uh , s a couple of frames after also . Uh , but to estimate the performance of the VAD , we don't want to do that , because it would artificially increase the um  the false alarm rate of speech detection . Right ? Um , so , there is u normally a figure for the Finnish and one for Italian . And maybe someone has two for the Italian because I 'm missing one figure here .\nNo .\nWell  Well , whatever . Uh  Yeah , so one surprising thing that we can notice first is that apparently the speech miss rate is uh , higher than the false alarm rate . So . It means\nSo  so what is the lower curve and the upper curve ?\nMm - hmm . Yeah , there are two curves . One curve 's for the close - talking microphone , which is the lower curve .\nYeah .\nAnd the other one is for the distant microphone\nAh , OK .\nwhich has more noise so , it 's logical that  it performs worse . So as I was saying , the miss rate is quite important uh , which means that we tend to label speech as  as a silence . And , uh , I didn't analyze further yet , but  I think it 's  it may be due to the fricative sounds which may be  in noisy condition maybe label  labelled as silence . And it may also be due to the alignment because  well , the reference alignment . Because right now I just use an alignment obtained from  from a system trained on channel zero . And I checked it a little bit but there might be alignment errors . Um , yeah , e like the fact that   the  the models tend to align their first state on silence and their last state o on silence also . So the reference  reference alignment would label as speech some silence frame before speech and after speech . This is something that we already noticed before when  mmm , So this cus this could also explain , uh , the high miss rate maybe . Uh\nAnd  and this  this curves are the average over the whole database , so .\nYeah . Right .\nMmm .\nUm  Yeah , and the different points of the curves are for five uh , thresholds on the probability  uh from point three to point seven .\nSo that threshold\nMm - hmm . Yeah .\nOK . S OK  so d the detection threshold is very\nSo the v\nYeah , yeah .\nThe VAD ? Yeah . There first , a threshold on the probability  @ @  That puts all the values to zero or one .\nMmm .\nAnd then the median filtering .\nYeah , so the median filtering is fixed . You just change the threshold ?\nYeah . It 's fixed ,\nYeah .\nyeah . Mm - hmm . So , going from channel zero to channel one , uh , almost double the error rate . Um , Yeah . Well , so it 's a reference performance that we can  you know , if we want to  to work on the VAD ,  we can work on this basis\nMm - hmm .\nand\nOK .\nIs this  is this VAD a MLP ?\nYeah .\nOK . How  how big is it ?\nIt 's a very big one . I don't remember .\nSo three  three hundred and fifty inputs ,\nm\nuh , six thousand hidden nodes and two outputs . t t\nOK .\nYeah .\nMm - hmm .\nMiddle - sized one .\nYeah .\nMm - hmm .\nYeah . Uh , ppp . I don't know , you have questions about that , or suggestions ?\nMmm . S so\nIt seems  the performance seems worse in Finnish , which\nWell , it 's not trained on Finnish .\nuh\nIt 's worse .\nIt 's not trained on Finnish , yeah .\nWhat 's it trained on ?\nI mean , the MLP 's not trained on Finnish .\nRight , what 's it trained on ?\nOh  oh . Sorry . Uh , it 's Italian TI - digits .\nYeah . Oh , it 's trained on Italian ?\nYeah .\nYeah , OK .\nMm - hmm . And\nThat 's right .\nOK .\nAnd also there are like funny noises on Finnish more than on Italian . I mean , like music\nMm - hmm .\nYeah . Yeah , the  Yeah , it 's true .\nand  um  So , yeah , we were looking at this . But for most of the noises , noises are  um , I don't know if we want to talk about that . But , well , the  the \" Car \" noises are below like five hundred hertz . And we were looking at the \" Music \" utterances and in this case the noise is more about two thousand hertz .\nYeah .\nWell , the music energy 's very low apparently . Uh , uh , from zero to two  two thousand hertz . So maybe just looking at this frequency range for  from five hundred to two thousand would improve somewhat the VAD\nMmm .\nand\nYeah .\nMmm\nSo there are like some  some s some parameters you wanted to use or something ?\nYeah , but  Yes .\nOr  Yeah .\nMm - hmm . Uh , the next , um  Oh , it 's there .\nSo is the  is the  is the training  is the training based on these labels files which you take as reference here ?\nYeah .\nWh - when you train the neural net y y you\nNo . It 's not . It 's  it was trained on some alignment obtained um , uh  For the Italian data , I think we trained the neural network on  with embedded training . So re - estimation of the alignment using the neural network , I guess . That 's right ?\nYeah . We actually trained , uh , the  on the Italian training part .\nYeah .\nWe  we had another  system with u\nSo it was a f f a phonetic classification system for the Italian Aurora data .\nYeah . It must be somewhere . Yeah .\nFor the Aurora data that it was trained on , it was different . Like , for TI - digits you used a  a previous system that you had , I guess .\nWhat  No it  Yeah , yeah . That 's true .\nSo the alignments from the different database that are used for training came from different system .\nSyste Yeah .\nThen we put them tog together . Well , you put them together and trained the VAD on them .\nYeah .\nMmm .\nYeah .\nHmm .\nUh , But did you use channel  did you align channel one also ? Or\nI just took their entire Italian training part .\nYeah .\nSo it was both channel zero plus channel one .\nSo di Yeah . So the alignments might be wrong then on channel one , right ?\nOn one . Possible .\nSo we might ,\nWe can do a realignment .\nyeah ,\nThat 's true .\nat least want to retrain on these alignments , which should be better because they come from close - talking microphone .\nYeah , the  that was my idea . I mean , if  if it ha if it is not the same labeling which is taking the spaces .\nYeah .\nOK .\nYeah , possible .\nYeah .\nMmm .\nI mean , it  so the system\nYeah .\nso the VAD was trained on maybe different set of labels for channel zero and channel one\nMm - hmm .\nand\nMm - hmm .\nwas the alignments were w were different for  s certainly different because they were independently trained .\nMm - hmm .\nWe didn't copy the channel zero alignments to channel one .\nMm - hmm .\nMm - hmm .\nYeah .\nYeah .\nBut for the new alignments what you generated , you just copied the channel zero to channel one , right ? Yeah .\nRight . Yeah . Um . And eh , hhh actually when we look at  at the VAD ,  for some utterances it 's almost perfect , I mean , it just dropped one frame , the first frame of speech or  So there are some utterances where it 's almost one hundred percent VAD performance .\nHmm .\nUh , but  Yeah . Mmm  Yep . So the next thing is um , I have the spreadsheet for three different system . But for this you only have to look right now on the SpeechDat - Car performance uh , because I didn't test  so  I didn't test the spectral subtraction on TI - digits yet . Uh , so you have three she sheets . One is the um proposal - one system . Actually , it 's not exe exactly proposal - one . It 's the system that Sunil just described . Um , but with uh , Wiener filtering from um , France Telecom included . Um , so this gives like fifty - seven point seven percent , uh , s uh , error rate reduction on the SpeechDat - Car data . Mmm , and then I have two sheets where it 's for a system where  uh , so it 's again the same system . But in this case we have spectral subtraction with a maximum overestimation factor of two point five . Uh , there is smoothing of the gain trajectory with some kind of uh , low - pass filter , which has forty milliseconds latency . And then , after subtraction um , I add a constant to the energies and I have two cases d where  The first case is where the constant is twenty - five DB below the mean speech energy and the other is thirty DB below . Um , and for these s two system we have like fifty - five point , uh , five - percent improvement , and fifty - eight point one . So again , it 's around fifty - six , fifty - seven . Uh\nCuz I notice the TI - digits number is exactly the same for these last two ?\nYeah , because I didn't  For the France Telecom uh , spectral subtraction included in the  our system , the TI - digits number are the right one , but not for the other system because I didn't test it yet  this system , including  with spectral subtraction on the TI - digits data . I just tested it on SpeechDat - Car .\nAh ! So  so that means the only thing\nMm - hmm . So  so  so these numbers are simply\nThis , we have to  Yeah .\nBut this number .\nYeah .\nYeah .\nSo you  so you just should look at that fifty - eight perc point O nine percent and so on .\nYes .\nOK .\nRight . Right .\nOK . Good .\nMm - hmm . Um , Yeah .\nSo this  So by  uh , by  by reducing the noise a  a decent threshold like minus thirty DB , it 's like  Uh , you are like r r reducing the floor of the noisy regions , right ?\ns\nYeah . Yeah . The floor is lower . Um ,\nUh - huh .\nmm - hmm .\nI 'm sorry . So when you say minus twenty - five or minus thirty DB , with respect to what ?\nTo the average um , speech energy which is estimated on the world database .\nOK , so basically you 're creating a signal - to - noise ratio of twenty - five or thirty DB ?\nYeah .\nuh r\nBut it 's not\nI  I  I think what you do is this .\nit  it 's\ni When  when you have this ,  after you subtracted it , I mean , then you get something w w with this , uh , where you set the values to zero and then you simply add an additive constant again .\nYeah .\nSo you shift it somehow . This  this whole curve is shifted again .\nBut did you do that before the thresholding to zero ,\nRight . It 's\nor  ?\nBut , it 's after the thresholding .\nOh ,\nSo ,\nso you 'd really want to do it before ,\nmaybe\nright ?\nmaybe we might do it before ,\nYeah , because then the  then you would have less of that phenomenon .\nyeah . Yeah .\nI think .\nUh\nE Hhh .\nYeah .\nc\nBut still , when you do this and you take the log after that , it  it reduce the  the variance .\nYeah , it  it  Right .\nBut  Mmm ,\nYeah , that will reduce the variance . That 'll help . But maybe if you does  do it before you get less of these funny - looking things he 's drawing .\nMm - hmm .\nUm ,\nSo before it 's like adding this , col to the  to the  o exi original\nBut  but\nWe would\nRight at the point where you 've done the subtraction .\nOK .\nUm , essentially you 're adding a constant into everything .\nMm - hmm .\nBut the way Stephane did it , it is exactly the way I have implemented in the phone , so .\nOh , yeah , better do it different , then . Yeah .\nUm .\nJust you  you just ta you just set it for a particular signal - to - noise ratio that you want ?\nYeah .\nYeah I  I made s similar investigations like Stephane did here , just uh , adding this constant and  and looking how dependent is it on the value of the constant\nYeah . Yeah .\nMm - hmm .\nand then , must choose them somehow  to give on average the best results for a certain range of the signal - to - noise ratios .\nUh - huh .\nYeah . Mm - hmm .\nSo\nOh , it 's clear . I should have gi given other results . Also it 's clear when you don't add noise , it 's much worse . Like , around five percent worse I guess .", "topic_id": 3, "keywords": "vad, smoothing, sheet, thresholding, silence", "dialogue_id": 23}, {"text": "Uh - huh .\nAnd if you add too much noise it get worse also . And it seems that  right now this  this is c a constant that does not depend on   on anything that you can learn from the utterance . It 's just a constant noise addition . Um . And I  I think w w\nI  I 'm sorry . Then  then I 'm confused .\nI think\nI thought  you 're saying it doesn't depend on the utterance but I thought you were adding an amount that was twenty - five DB down from the signal energy .\nYeah , so the way I did that ,  i I just measured the average speech energy of the  all the Italian data .\nOh !\nAnd then  I  I have  I used this as mean speech energy . Mm - hmm .\nOh , it 's just a constant amount over all .\nYeah . And\nOK .\nwha what I observed is that for Italian and Spanish ,  when you go to thirty and twenty - five DB ,  uh it  it 's good .\nOh .\nIt stays  In this range , it 's , uh , the p u well , the performance of the  this algorithm is quite good . But for Finnish ,  you have a degradation already when you go from thirty - five to thirty and then from thirty to twenty - five . And  I have the feeling that maybe it 's because just Finnish has a mean energy that 's lower than  than the other databases . And due to this the thresholds should be\nYeah .\nthe  the a the noise addition should be lower\nBut in  I mean , in the real thing you 're not gonna be able to measure what people are doing over half an hour or an hour , or anything , right ?\nand\nSo you have to come up with this number from something else .\nYeah . So\nUh , but you are not doing it now language dependent ? Or  ?\nIt 's not . It 's just something that 's fixed .\nNo . It 's overall .\nYeah .\nOK .\nMm - hmm . Um\nBut what he is doing language dependent is measuring what that number i reference is that he comes down twenty - five down from .\nYeah , so I g No . It  No .\nNo ?\nBecause I did it  I started working on Italian . I obtained this average energy\nYeah .\nand then I used this one .\nFor all the languages . OK .\nYeah .\nSo it 's sort of arbitrary .\nYeah .\nI mean , so if y if  Yeah .\nYep .\nYeah .\nUm , yeah , so the next thing is to use this as  as maybe initialization\nUh - huh .\nand then use something on - line .\nSomething more adaptive ,\nBut   And I expect improvement at least in Finnish because eh  the way\nyeah . OK .\nWell , um , for Italian and Spanish it 's  th this value works good but not necessarily for Finnish . Mmm . But unfortunately there is , like , this forty millisecond latency and , um  Yeah , so I would try to somewhat reduce this @ @ . I already know that if I completely remove this latency , so .  um ,  it  um there is a three percent hit on Italian .\nMm - hmm .\nd Does latency\ni\nSorry . Go ahead .\nYeah . Your  your smoothing was @ @  uh , over this s so to say , the  the factor of the Wiener . And then it 's , uh  What was it ? This\nMm - hmm .\nthis smoothing , it was over the subtraction factor , so to say .\nIt 's a smoothing over the  the gain of the subtraction algorithm .\nWas this done  Mm - hmm . And  and you are looking into the future , into the past .\nRight .\nAnd smoothing .\nSo , to smooth this  thing .\nMm - hmm .\nYeah . Um\nAnd did  did you try simply to smooth um to smooth the  the  t to  to smooth stronger the  the envelope ?\nUm , no , I did not .\nMmm .\nMmm .\nBecause I mean , it should have a similar effect if you\nYeah .\nI mean , you  you have now several stages of smoothing , so to say . You start up . As far as I remember you  you smooth somehow the envelope , you smooth somehow the noise estimate ,\nMm - hmm . Mmm\nand   and later on you smooth also this subtraction factor .\nUh , no , it 's  it 's just the gain that 's smoothed actually\nUh , actually I d I do all the smoothing .\nbut it 's smoothed\nAh . Oh , it w it was you .\nYeah , yeah .\nUh  Yeah .\nYeah .\nYeah . No , in this case it 's just the gain .\nYeah .\nAnd\nUh - huh .\nBut the way it 's done is that um , for low gain , there is this non nonlinear smoothing actually . For low gains um , I use the smoothed sm uh , smoothed version but  for high gain @ @  it 's  I don't smooth .\nUh . Mm - hmm . I just , uh  it  Experience shows you , if  if you do the  The best is to do the smoo smoothing as early as possible .\nUh - huh .\nSo w when you start up . I mean , you start up with the  with the  somehow with the noisy envelope .\nMm - hmm .\nAnd , best is to smooth this somehow .\nMm - hmm . Uh , yeah , I could try this . Um .\nAnd\nSo , before estimating the SNR , @ @ smooth the envelope .\nYeah . Yeah . Uh - huh .\nMm - hmm . But  Yeah . Then I  I would need to find a way to like smooth less also when there is high energy . Cuz I noticed that it  it helps a little bit to s like smooth more during low energy portions and less during speech ,\nYes , y\nbecause if you smooth then y you kind of distort the speech .\nYeah . Yeah .\nUm .\nRight .\nMm - hmm .\nYeah , I think when w you  you could do it in this way that you say , if you  if I 'm  you have somehow a noise estimate ,\nMm - hmm .\nand , if you say I 'm  I 'm  with my envelope I 'm close to this noise estimate ,\nYeah .\nthen you have a bad signal - to - noise ratio and then you  you would like to have a stronger smoothing .\nMm - hmm .\nSo you could  you could base it on your estimation of the signal - to - noise ratio on your actual\nMm - hmm . Mm - hmm . Mmm .\nYeah , or some silence probability from the VAD if you have\nUm , yeah , but I don't trust  the current VAD . So .\nYeah , uh , so not  not right now maybe .\nWell , maybe .\nThe VAD later will be much better .\nMaybe .\nYeah . So . I see .\nSo is  that it ?\nUh , fff  I think that 's it . Yeah . Uh .\ns So to summarize the performance of these , SpeechDat - Car results is similar than  than yours so to say .\nYeah , so the fifty - eight is like the be some fifty - six point\nYeah .\nY you have  you have fifty - six point four\nYeah , that 's true .\nand  and   and dependent on this additive constant , it is s better or  or worse .\nYeah .\nSlightly better .\nMm - hmm .\nYeah .\nMm - hmm .\nYeah .\nAnd ,  yeah , i i i the condition where it 's better than your approach , it 's  it  just because maybe it 's better on well matched and that the weight on well matched is  is bigger ,\nYeah . Yeah , you  you caught up .\nbecause\nYep , that 's true .\nif you don't weigh differently the different condition , you can see that your  well , the win the two - stage Wiener filtering is maybe better or\nYeah .\nIt 's better for high mismatch , right ?\nYeah , it 's better for high mismatch .\nMm - hmm . But a little bit worse for well matched .\nSo over all it gets , yeah , worse for the well matched condition , so y\nUh - huh .\nSo we need to combine these two .\nUh , that 's  that 's the best thing , is like the French Telecom system is optimized for the well matched condition . They c\nMm - hmm .\nYeah . So they know that the weighting is good for the well matched , and so there 's  everywhere the well matched 's s s performance is very good for the French Telecom .\nYeah .\nMm - hmm .\nMm - hmm .\nT we are  we may also have to do something similar @ @ .\nMm - hmm .\nWell , our tradition here has always been to focus on the mismatched .\nUm the\nCuz it 's more interesting .\nMu - my  mine was it too , I mean .\nYeah .\nBefore I started working on this Aurora .\nYeah .\nso .\nYeah . Yeah . OK .\nCarmen ? Do you , uh\nWell , I only say that the  this is , a summary of the  of all the VTS experiments and say that the result in the last  um , for Italian  the last experiment for Italian ,  are bad . I make a mistake when I write . Up at D I copy  one of the bad result .\nSo you\nAnd  There .  You know , this . Um , well . If we put everything , we improve a lot u the spectral use of the VTS but the final result  are not still mmm , good  like the Wiener filter for example . I don't know . Maybe it 's  @ @  it 's possible to  to have the same result .\nThat 's somewhere\nI don't know exactly . Mmm . Because I have ,  mmm ,  worse result in medium mismatch and high mismatch .\nYou s you have a better r Yeah . You have some results that are good for the high mismatch .\nAnd  Yeah . I someti are more or less similar but  but are worse . And still I don't have the result for TI - digits . The program is training . Maybe for this weekend I will have result TI - digits and I can complete that s like this . Well .\nUh . Right .\nOne thing that I  note are not here in this result  but are speak  are spoken before with Sunil I  I improve my result using clean LDA filter .\nMm - hmm .\nMm - hmm .\nIf I use ,  eh , the LDA filter that are training with the noisy speech ,  that hurts the res my results .\nSo what are these numbers here ? Are these with the clean or with the noisy ?\nThis is with the clean .\nOK .\nWith the noise I have worse result , that if I doesn't use it .\nUh - huh .\nBut m that may be because  with this technique  we are using really  really clean speech . The speech  the  representation that go to the HTK is really clean speech because it 's from the dictionary , the code book and maybe from that . I don't know .\nMm - hmm .\nBecause I think that you  did some experiments using the two  the two LDA filter , clean and noi and noise ,\nIt 's\nand it doesn't matter too much .\nUm , yeah , I did that but it doesn't matter on SpeechDat - Car , but , it matters , uh , a lot on TI - digits .\nUsing the clean filter .\nIt 's better to use clean .\nYeah , d uh , it 's much better when you  we used the clean derived LDA filter .\nMm - hmm . Maybe you can do d also this .\nYeah .\nTo use clean speech .\nYeah , I 'll try .\nUh , but , yeah , Sunil in  in your result it 's\nI  I 'll try the cle No , I  I  my result is with the noisy  noisy LDA .\nIt 's with the noisy one . Yeah .\nYeah .\nOh !\nIt 's with the noisy . Yeah . It 's  it 's not the clean LDA .\nSo\nUm\nIt 's  In  in the front sheet , I have like  like the summary . Yeah .\nAnd  and your result  is with the\nIt 's with the clean LDA .\nOh . This is  Your results are all with the clean LDA result ?\nYeah , with the clean LDA .\nOK . @ @ .\nYeah .\nAnd in your case it 's all  all noisy ,\nIs that the reason ?\nAll noisy , yeah .\nyeah . But\nAnd\nUh\nYeah .\nUh\nBut I observe my case it 's in , uh , uh , at least on SpeechDat - Car it doesn't matter but TI - digits it 's like two or three percent absolute , uh ,  better .\nOn TI - digits this matters . Absolute . Uh\nSo you really might wanna try the clean I think .\nSo if\nYeah , I  I  I will have to look at it . Yeah , that 's true .\nYeah . Yeah , that could be sizeable right there .\nAnd this is everything .\nYeah .\nOK .\nMaybe you  you are leaving in  in about two weeks Carmen . No ?\nYeah .\nYeah . So I mean , if  if  if I would put it  put on the head of a project mana manager  I  I  I I would say , uh , um  I mean there is not so much time left now .\nBe my guest .\nI mean , if   um , what  what I would do is I  I  I would pick @ @  the best consolation , which you think , and  c create  create all the results for the whole database that you get to the final number as  as Sunil did it\nAnd prepare at the s\nand  um and maybe also to  to write somehow a document where you describe your approach , and what you have done .", "topic_id": 4, "keywords": "utterance, noisy, speechdat, noise, speech", "dialogue_id": 23}, {"text": "Yeah , I was thinking to do that next week .\nYeah .\nYeah .\nYeah , I 'll  I 'll borrow the head back and  and agree . Yeah ,\nYeah , I wi I  I will do that next week .\nthat 's  that 's  Right . In fact , actually I g I guess the , uh  the Spanish government , uh , requires that anyway . They want some kind of report from everybody who 's in the program .\nMm - hmm .\nSo . And of course I 'd  we 'd  we 'd like to see it too . So ,\nOK .\nyeah .\nSo , um , what 's  Do you think we , uh , should do the digits or skip it ? Or what are  what do you think ?\nUh , we have them now ?\nYeah , got them .\nUh , why don why don't we do it ?\nOK .\nJust   just take a minute .\nI can send yet .\nWould you pass those down ?\nOh ! Sorry .\nOK , um , so I guess I 'll go ahead . Um ,\nSeat ?\nDave ? Is it the channel , or the mike ? I don't remember . It 's the mike ?\nMike ?\nIt 's not four .\nThis is date and time . No . On the channel , channel .\nWhat is this ?\nt\nOK , if you could just leave , um , your mike on top of your , uh , digit form I can fill in any information that 's missing .\nOK .\nThat 's uh  I didn't get a chance to fill them out ahead of time . Yeah , we 're gonna have to fix that . Uh , let 's see , it starts with one here , and then goes around and ends with nine here .\nSeven . So I  I 'm eight ,\nSo he 's eight ,\nyou 're seven .\nyou 're seven ,\nYeah .", "topic_id": 5, "keywords": "spanish, digit, digits, minute, skip", "dialogue_id": 23}, {"text": "headphones that aren't so uncomfortable .\nI think  Well , this should be off the record ,\nHmm .\nbut I think\nUh , OK .\nWe 're not recording yet , are we ?\nWell , I don't think\nNo , uh , that  that wasn't recorded .\nNo . Um , I don't think they 're designed to be over your ears .\nYeah , I know . It just  it really hurts . It gives you a headache , like if you  On your temple\nTemple squeezers .\nYeah .\nYep .\nYeah .\nMm - hmm .\nBut I definitely  haven't figured it out .\nUm , Meeting Recorder meeting .\nI guess I have to d stop doing this sigh of contentment , you know , after sipping cappuccino or something .\nYeah , with the  We kno I know .\n\" Sip , sigh . \"\nWe know exactly how much you have left in your cup .\nI was just noticing a big s\nSo are we recording now ? Is this\nYeah .\nOh ! We 're  we 're  we 're live . OK .\nYeah .\nSo , uh ,  what were we gonna talk about again ? So we said  we said data collection , which we 're doing .\nWere we gonna do digits ?\nOK . Do we do th do you go around the room  and do names or anything ?\nI think that\nIt 's a good idea .\nu usually we 've done that and also we 've s done digits as well , but I forgot to print any out . So . Besides with this big a group ,\nYou can write them on the board , if you want .\nNo . I it 'd be even better with this big\nit would take too much time .\nWhich way is\nYeah , but it takes too much time .\nMari ?\nWhat\nWhat ?\nIt 's not that long .\nY I think your  your  your thing {nonvocalsound} may be pointing in a funny direction . Sort of it 's  it helps if it points sort of upwards .\nWhoops .\nSort of it  you know .\nWould it  m\nYeah .\nw u\nSo that thing  the little  th that part should be pointing upwards .\nSo  Oh , this thing .\nThat 's it . Yeah .\nYeah .\nOtherwise you just get a heartbeats .\nIt 's kind of\nOh , yeah , the element , yeah , n should be as close to you  your mouth as possible .\nYeah . OK .\nThat 's good . That kind of thing is good .\nIt 's a\nThis w Alright .\nYeah .\nHow 's that working ?\nYeah .\nOh , yeah . It 's a  It 's working .\nOK .\nAlright . So what we had  was that we were gonna talk about data collection , and , um , uh , you  you put up there data format ,\nUm .\nand other tasks during data collection ,\nSo , I think the goal  the goal was what can we do  how can you do the data collection differently to get\nand\nwhat can you add to it to get , um , some information that would be helpful for the user - interface design ? Like\nUh , especially for querying .\nEspecially for querying . So , getting people to do queries afterwards , getting people to do summaries afterwards . Um .\nWell , one thing that came up in the morning  in the morning was the , um , i uh , if he  I , um  if he has  s I  I don't remember , Mister Lan - Doctor Landry ?\nLanday . James .\nLa - Landay ? So he has , um , these , uh , um , tsk  note - taking things ,\nMm - hmm .\nthen that would sort of be a summary which you wouldn't have to solicit . y if  if we were able to  to do that .\nWell , if  if you actually take notes as a summary as opposed to n take notes in the sense of taking advantage of the time - stamps . So action item or uh , reminder to send this to so - and - so , blah - blah - blah .\nMm - hmm .\nSo that wouldn't be a summary . That would just be  that would b relate to the query side .\nBut if we had the CrossPads , we could ask people , you know , if  if something comes up  write it down and mark it   somehow ,\nMm - hmm .\nRight . I mean , we  because you 'd have several people with these pads , you could collect different things .\nyou know .\nRight .\nI mean , cuz I tend to take notes which are summaries . And so , you know\nI mean , the down - side to that is that he sort of indicated that the , uh , quality of  the handwriting recognition was quite poor .\nWell\nBut that 's alright . I don't think there 'd be so many that you couldn't have someone clean it up\nSo\npretty easily .\nYeah . We also could come up with some code for things that people want to do so that  for frequent things .\nYeah .\nAnd the other things , people can write whatever they want . I mean , it 's to some extent , uh , for his benefit . So , if that  you know , if  if we just keep it simple then maybe it 's still useful .\nRight .\nYeah .\nI just realized we skipped the part that we were saying we were gonna do at the front where we each said who we were .\nThe roll call .\nRight . I thought you did that on purpose .\nRoll call .\nBut anyway , shall we do the roll call ?\nNo , not a No , I just  My mind went elsewhere . So , uh , yeah , I 'm Morgan , and where am I ? I 'm on channel three .\nAnd I 'm Adam Janin on channel A .\nI 'm Jane Edwards , I think on channel B .\nI 'm Dan Ellis .\nEric on channel nine .\nLiz , on channel one .\nMari on channel zero .\nKatrin on channel two .\nShould we have used pseudo - names ? Should we do it a second time with pseudo No .  No .\nI 'm Rocky Raccoon  on channel\nLet me , uh , turn that off .\nAnd , uh , do you want to do the P D As and the  P Z\nOh . PZM nearest , nearest , next nearest . Next one .\nNext nearest .\nFurthest .\nFar .\nPDM - right , PZA - right  PDA - right , PDA - left .\nOK .\nThanks .\nYeah , and eventually once this room gets a little more organized , the Jimlets  will be mounted under the table , and these guys will be permanently mounted somehow . You know , probably with double - sided tape , but  So . You  So we won't have to go through that .\nHmm .\nI have a question on protocol in these meetings , which is when you say \" Jimlet \" and the person listening won't know what that is , sh shou How  how do we get  Is that important information ? You know , the Jimlet  I mean , the box that contains the\nWell , I mean , suppose we broaden out and go to a range of meetings besides just these internal ones . There 's gonna be lots of things that any group of people who know each other have in column  common  that we will not know .\nRight .\nMm - hmm .\nRight .\nOK .\nSo the there will be jargon that we he There 'll be transcription errors .\nGood .\nYeah .\nOK .\nI mean , we  we were originally gonna do this with VLSI design , and  and  and the reason we didn't go straight to that was because immediately ninety percent of what we heard would be  jargon to  to us . So .\nWell , that was just one of the reasons . But , yeah , definitely .\nYeah .\nOK . Good .\nThat  that 's right . There were others of course . Yeah .\nOK , so we were on the data collection   and the summary issue .\nRight . We can go back .\nSo , uh , u u So , actually there 's kind of three issues . There 's the CrossPad issue . Should we do it and , if so , what 'll we have them do ? Um , do we have s people write summaries ? Everybody or one person ? And then , do we ask people for how they would query things ? Is that\nThere 's  there 're sub - problems in that , in that where  or when do you actually ask them about that ?\nRight .\nI mean , that was  One thing I was thinking about was is that Dan said earlier that , you know , maybe two weeks later , which is when you would want to query these things , you might ask them then .\nRight .\nBut there 's a problem with that in that if  you 're not  If you don't have an interactive system , it 's gonna be hard to go beyond sort of the first level of question .\nRight .\nRight . And furth id explore the data further .\nRight .\nSo .\nThere 's  there 's another problem\nAnd\nwhich is , um , we certainly do want to branch out beyond , uh , uh , recording meetings about Meeting Recorder . And , uh , once we get out beyond our little group , the people 's motivation factor , uh , reduces enormously . And if we start giving them a bunch of other things to do , how  you know , we  we did n you know another meeting here for another group and  and , uh , they were fine with it . But if we 'd said , \" OK , now all eight of you have to   have to come up with , uh , the summar \"\nWell , I asked them to and none of them did .\nt See ? There we go .\nSo , I  I asked them to send me ideas for queries after the meeting\nMm - hmm .\nThey\nand no one ever did .\nMm - hmm .\nI didn't follow up either .\nYeah .\nSo I didn't track them down and say \" please do th do it now \" . But , uh , no one spontaneously provided anything .\nI I 'm worried that if you did  even if you did push them into it , it  it  it might be semi - random ,\nRight .\nuh , as opposed to what you 'd really want to know if you were gonna use this thing .\nRight .\nOK .\nI just don't know how else to generate the queries other than getting an expert to actually listen to the meeting and say \" that 's important , that might be a query \" .\nTsk . Well , there is this other thing which y which you were alluding to earlier , which is , um , there are certain key words like , you know , \" action item \" and things like that , which could be used in , uh , t to some degree finding the structure .\nYeah .\nAlthough\nW\nAnd  and I also , um , was thinking , with reference to the n uh , note - taking , the advantage there is that you get structure without the person having to do something artificial later . And the fir third thing I wanted to say is the summaries afterwards , um , I think they should be recorded instead of written because I think that , um , it would take so long for people to write that I think you wouldn't get as good a summary .\nHow about this idea ? That normally at most meetings somebody is delegated to be a note - taker .\nYeah , good . Good point .\nAnd  So why don't we just use the notes that somebody takes ?\nYeah .\nI mean , that gives you a summary but it doesn't really  How do you generate queries from that ?\nWell . But , I mean , maybe a summary is one of the things we 'd want from the output of the system .\nYeah .\nRight .\nRight ? I mean , they 're something . It 's a  a kind of output you 'd like .\nActually  And so\nUh , James and I were talking about this during one of the breaks . And the problem with that is , I 'm definitely going to do something with information retrieval even if it 's sort of not full full - bore what I 'm gonna do for my thesis .\nRight .\nI 'm gonna do something . I 'm not gonna do anything with summarization . And so if someone wants to do that , that 's fine , but it 's not gonna be me .\nWell , I think that we  I mean , the  the f the core thing is that you know once we get some of these issues nailed down , we need to do a bunch of recordings\nWell\nand send them off to IBM and get a bunch of transcriptions even if they 're slightly flawed\nYep .\nor need some other  And then we 'll have some data there .\nYeah .\nAnd then , i i we can start l looking and thinking , what do we want to know about these things and  at the very least .\nMm - hmm .\nYeah\nI actually want to say something about the note pad . So , if you could sense just when people are writing , and you tell them not to doodle , or try not to  be using that for other purposes ,  and each person has a note pad . They just get it when they come in the room . Then you c you can just have a fff  plot of wh you know , who 's writing when .\nHmm .\nThat 's all you\nActivity . Yeah .\nAnd , you can also have notes of the meeting . But I bet that 's  that will allow you to go into the  sort of the hot places where people are writing things down .\nMm - hmm .\nOh , I see .\nI mean , you can tell when you 're in a meeting when everybody stops to write something down that something was just said .\nMm - hmm .\nIt may not be kept in the later summary , but at that point in time is was something that was important .\nMm - hmm .\nAnd that wouldn't take any extra\nThat 's a nice idea .\nMm - hmm .\nOr someone could just pu you could just put your hand on the pad\nIt\nMm - hmm .\nand go like that if you want to . It 's", "topic_id": 0, "keywords": "recordings, headphones, recording, recorder, listening", "dialogue_id": 24}, {"text": "That 's a good idea but that doesn't  Maybe I 'm missing something , but that doesn't get to the question of how we come up with queries , right ?\nWell , what it does\nWell , then you can go to the points where the  you could actually go to those points in time and find out what they were talking about . And you r\nWell , what it does is provide a different\nYeah .\nAnd\nUh , y\nI  I think it 's an interesting thing . I don't think it gets at the  the queries per - se , but it does give us an information fusion sort of thing that , you know , you wanna i say \" what were the hot - points of the meeting ? \"\nYeah .\nThat  that 's what I mean , is that I think it gets at something interesting but if we were asking the question , which I thought we were , of  of  of , um , \" how do we figure out what 's the nature of the queries that people are gonna want to ask of such a system ? \" , knowing what 's important doesn't tell you what people are going to be asking .\nBut I bet it 's a good  superset of it .\nDoes it ?\nWell , yeah .\nWell , see , there are th\nI think you could say they 're gonna ask about , uh , when  uh , when did so - and - so s talk about blah . And at least that gives you the word  that they might run a query on .\nAt least you can find the locations where there are maybe keywords\nMaybe .\nI mean , i this would tell you what the hit is ,\nand\nnot what the query is .\nRight .\nRight , right .\nWhat\nIt 'll tell you the hit but not the query .\nBut I think  I think thinking about queries is a little bit dangerous right now .\nAnd so you could  you can generate a query from the hits ,\nRight .\nbut\nWe don't even know what  I mean , if you want to find out what any user will use , that might be true for one domain and one user ,\nMm - hmm .\nbut I mean a different domain and a different user\nMm - hmm .\nYeah , but we 're just looking for a place to start with that\nUm .\nbecause , you know , th what  what  what James is gonna be doing is looking at the user - interface and he 's looking at the query in  in  i We  we have five hours of pilot data of the other stuff but we have zero hours of  of  of queries . So he 's just sort of going \" where  where do I  where do I start ? \"\nw Well , th you could do  I think the summaries actually may help get us there ,\nOK .\nfor a couple reasons . One , if you have a summary  if you have a bunch of summaries , you can do a word frequency count and see what words come up in different types of meetings .\nMm - hmm .\nSo \" action item \" is gonna come up whether it 's a VLSI meeting , or speech meeting , or whatever . So words that come up in different types of meetings may be something that you would want to query about .\nMm - hmm .\nUm , the second thing you could possibly do with it is just run a little pilot experiment with somebody saying \" here 's a summary of a meeting , what questions might you want to ask about it to go back ? \"\nYeah , I think that 's difficult because then they 're not gonna ask the questions that are in the summary .\nWell\nBut , I think it would give\nThat 's one possi one possible scenario , though , is you have the summary ,\nMm - hmm .\nand you want to ask questions to get more detail .\nth Yeah , I think it has to be a participant . Well , it doesn't have to be . OK . So that  that is another use of Meeting Recorder that we haven't really talked about , which is for someone else , as opposed to as a  remembrance agent , which is what had been my primary thought in the information retrieval part of it would be . But , uh , I guess if you had a meeting participant , they could use the summary to refresh themselves about the meeting and then make up queries . But it 's not\nMm - hmm .\nI don't know how to do it if  until you have a system .\nThe summary is actually gonna drive the queries then .\nMmm .\nYeah .\nI mean , your research is going to be very circular .\nYeah .\nYeah , that  that 's what I was saying .\nBut th there is this , um     There is this class of queries , which are the things that you didn't realize were important at the time but some in retrospect you think \" oh , hang on , didn't we talk about that ? \" And it 's something that didn't appear in the summary but you\nMm - hmm .\nAnd that 's kind of what this kind of , uh , complete data capture is kind of nicest for .\nRight . Right .\nRight .\nCuz it 's the things that you wouldn't have bothered to make an effort to record but they get recorded . So , I mean  And th there 's no way of generating those , u u until we just  until they actually occur .\nBut you could always post - hoc label them .\nYou know , it 's like  Right , right . Exactly .\nYeah . Yeah .\nBut I mean , it 's difficult to sort of say \" and if I was gonna ask four questions about this , what would they be ? \" Those aren't the kind of things that come up .\nBut at least it would get us started .\nOh , yeah . Yeah , sure .\nI also think that w if  if you can use the summaries as an indication of the important points of the  of the meeting , then you might get something like  y So if th if the obscure item you want to know more about was some form of data collection , you know , maybe the summary would say , you know , \" we discussed types of na data collection \" . And , you know  And  and maybe you could get to it by that . If you  if you had the  the larger structure of the  of the discourse , then if you can categorize what it is that you 're looking for with reference to those l those larger headings , then you can find it even if you don't have a direct route to that .\nMmm . Although it seems like that 's , um , a high burden on the note - taker .\nI think that\nThat 's a pretty fine grain that the note - taker will have to take .\nMaybe Landay can put a student in to be a note - taker .\nI th No . I think you got to have somebody who knows the pro knows the topic or  you know , whose job it is delegated to be the note - taker .\nNo ?\nMm - hmm .\nSomebody who 's part of the meeting .\nNo , I mean , but someone who can come sit in on the meetings and then takes the notes with them that the real note - taker\nBut they\nAnd that way that one student has , you know , a rough idea of what was going on , and they can use it for their research . I mean , this isn't really necessarily what you would do in a real system ,\nMm - hmm .\nbecause that that 's a lot of trouble\nMm - hmm .\nand maybe it 's not the best way to do it . But if he has some students that want to study that then they should sort of get to know the people and attend those meetings ,\nMm - hmm .\nand get the notes from the note - taker or something .\nRight .\nHmm .\nWell , I think that 's a little bit of a problem . Their sort of note - taking application stuff they 've been doing for the last couple of years , and I don't think anyone is still working on it .\nYeah .\nI think they 're done . Um , so I 'm not sure that they have anyone currently working on notes . So what we 'd have to interest someone in is the combination of note and speech .\nMm - hmm .\nAnd so the question is \" is there such a person ? \" And I think right now , the answer is \" no \" .\nWell\nI 've b been thinking\nWe 'll just have to see .\nI 've been thinking about it a little bit here  about the  uh , th this , e um  I think that the  now I 'm thinking that the summary  a summary , uh , is actually a reasonable , uh , bootstrap into this  into what we 'd like to get at . It 's  it 's not ideal , but we  you know , we  we have to get started someplace . So I was  I was just thinking about , um , suppose we wanted to get  w We have this collection of meeting . We have five hours of stuff . Uh , we get that transcribed . So now we have five hours of meetings and , uh , you ask me , uh , uh , \" Morgan , what d you know , what kind of questions do you want to ask ? \" Uh , I wouldn't have any idea what kind of questions I want to ask . I 'd have to get started someplace . So in fact if I looked at summary of it , I 'd go \" oh , yeah , I was in that meeting , I remember that , um , what was the part that  \" And  and th I think that might then help me to think of things  even things that aren't listed in the summary , but just as a  as a  as a refresh of what the general thing was going on in the meeting .\nMm - hmm .\nI think it serves two purpo purposes . One , as sort of a refresh to help bootstrap queries ,\nMm - hmm . Yeah .\nbut also , I mean , maybe we do want to generate summaries . And then it 's  you know , it 's kind of a key .\nWell , yeah . That 's true too .\nHmm .\nYeah , absolutely . Then you want to have it .\nUh\nSo how does the summary get generated ?\nWell , i i  ?\nI 'm not against the idea of a summary ,\nBy hand .\nbut I wanted to think carefully about who 's generating it\nOr , d o\nand how  because the summary will drive the queries .\nWhat I  I think , you know , in most meetings ,\nSo\nthis one being  different , but in most meetings that I attend , there 's somebody t explicitly taking notes , frequently on a laptop  Um , you can just make it be on a laptop ,\nMm - hmm .\nso then yo you 're dealing with ASCII and not somebody  you don't have to go through handwriting recognition . Um , and then they post - edit it into , uh , a summary and they email it out for minutes . I mean , that happens in most meetings .\nI I  I think that , um , there 's  we 're using \" summary \" in two different ways . So what you just described I would describe as \" minutes \" .\nMinutes .\nRight .\nYeah .\nYeah .\nAnd what I originally thought was , um , if you asked someone \" what was the meeting about ? \"\nOK .\nHmm .\nAnd then they would say \" well , we talked about this and then we talked about that , and so - and - so talked about  \" And then you 'd have , like  I  e My thought was to have multiple people summarize it , on recording rather than writing because writing takes time and you get irrelevant other things that u take time , that\nMm - hmm .\nWhereas if you just say it immediately after the meeting , you know , a two - minute summary of what the meeting was about , I think you would get , uh , with mult See , I  I also worry about having a single note - taker because that 's just one person 's perception . And , um , you know , it  it 's releva it 's relative to what you 're focus was on that meeting ,\nMm - hmm .\nand  and people have different  major topics that they 're interested in .\nA\nSo , my proposal would be that it may be worth considering both of those types , you know , the note - taking and a spontaneous oral summary afterwards ,\nOK .\nYeah .\nno longer than two minutes ,\nAdam , you can\nfrom multiple people .\nyou can correct me on this ,\nYeah .\nbut  but , uh , my impression was that , uh , pretty much , uh , true that the meetings here , nobody sits with a w uh , with a laptop\nNever .\nand\nNever . I 've never seen it at ICSI . Does anyone  ?\nDan ?\nI\nI mean , Dan is the one who  who most frequently would take notes ,\nYeah .\nand\nI 've d When we  when we have other meetings . When I have meetings on the European projects , we have someone taking notes .\nOh , really ?\nYeah , but those are bigger deal things .\nIn fact , I often do it .\nRight ? Where you 've got fifteen peo\nYeah .\nI mean , most  th this is one of the larger meetings . Most of the meetings we have are four or five people\nThat 's true  are four or five people .\nYeah .\nand you 're not  you don't have somebody sitting and taking minutes for it .\nRight .\nYou just  get together and talk about where you are .\nSo , I think it depends on whether it 's a business meeting or a technical discussion .\nCulture .\nYeah .\nAnd I agree ,\nYeah .\ntechnical discussions you don't usually have somebody taking notes .\nYeah . Yeah .\nThe IRAM meeting , they  they take notes every\nDo they ?\nThere 's uh a person with a laptop  at each meeting .\nHow many people are those meetings ?\nThere are more . I mean , there are ten - ish .\nYeah .\nY you should also have a record of what 's on the board .\nYeah .\nThey 're very sparse .\nI mean , I find it very  hard to reconstruct what 's going on . I  I don't know how\nYeah . This is something early in the project we talked a lot about .\nI don't know how , but for instance , I mean , the outline is sort of up here and that 's what people are seeing . And if you have a  Or you shou could tell people not to  to use the boards . But there 's sort of this missing information otherwise .\nWe sh we should\nI agree , but  but you  you just  you g end up with video ,\nI agree .\nWell , I don't know .\nand  and instrumented rooms . And  that 's a different project , I think .\nf u I think for this data capture , it would be nice to have a digital camera\nYeah , different\nUh , y\njust to take pictures of who 's there , where the microphones are , and then we could also put in what 's on the board . You know , like three or four snaps for every\nRight .\nI agree .\nYeah . People who were never at the meeting will have a very hard time understanding it otherwise .\nfor every meeting .\nThat 's wonderful .\nMm - hmm .\nBut don't you think that 's  Don't you think that  But\nI agree .\nMm - hmm .\nEven people who were at the meeting .\nWell , no . I mean , I  I just think  I mean , I think that right now we don't make a record of where people are sitting on the tables .\nRight .\nHuh .\nAnd that  the  at some point that might be awfully useful .\nRight . But I think adding photographs adds a whole nother level of problems .\nMm - hmm .\nMmm .\nYeah . We n uh ,\nIt 's just a digital record .\nNot  not as part of the  not as a part of the data that you have to recover .\nI don't mean that you model it .\nJust  just in terms of\nWe should just  Like archiving it or storing it .\nYeah .\nYes , I agree . I agree .\nMm - hmm .\nIt 's i because discourse is about things ,\nBecause someone\nand then you have the things that are about , and it 's recoverable .\nsomeone later might be able to take these and say \" OK , they , you know  at least these are the people who were there\nSo\nand here 's sort of what they started talking about , and  \" and just\nYes . And it 's so simple .\nLi\nLike you said , three snapshots\nuh , L L L\nand\nLiz , you\nJust to archive .\nu uh , Liz , you sa you sat in on the , uh ,  subcommittee meeting or whatever\nActually\nuh , on  you  on the subcommittee meeting for  for  at the , uh  that workshop we were at that , uh , uh , Mark Liberman was  was having . So I  I wasn't there . They  they  they  they h must have had some discussion about video and the visual aspect , and all that .\nBig , big interest . Huge .\nYeah .\nI mean , it  personally , I don't  I would never want to deal with it . But I 'm just saying first of all there 's a whole bunch of fusion issues that DARPA 's interested in .\nYeah . Yeah .\nYou know , fusing gesture and face recognition ,\nYeah .\neven lip movement and things like that , for this kind of task . And there 's also I think a personal interest on the part of Mark Liberman in this kind of  in storing these images in any data we collect\nMm - hmm .\nso that later we can do other things with it .\nYeah . So  so to address what  what Adam 's saying ,\nMmm . Mm - hmm .\nAnd\nI mean , I think you  uh , that the key thing there is that this is a description of database collection effort that they 're talking about doing .\nMm - hmm .\nAnd if the database exists and includes some visual information that doesn't mean that an individual researcher is going to make any use of it . Right ?\nMm - hmm .\nSo , uh\nBut that  it 's gonna be a lot of effort on our part to create it , and store it , and get all the standards , and to do anything with it .\nRight . So we 're gonna  So we 're gonna do what we 're gonna do , whatever 's reasonable for us .\nYeah .\nI think even doing something very crude\nBut having\nLike I know with ATIS , we just had a tape recorder running all the time .\nMm - hmm .\nAnd later on it turned out it was really good that you had a tape recorder of what was happening , even though you w you just got the speech from the machine . So if you can find some really , you know , low , uh , perplexity ,\nLow fidelity .\nyeah ,  way of  of doing that , I think it would be worthwhile .\nYeah .\nI agree . And if it 's simple as  I mean , as simple as just the digital\nOtherwise you 'd  you lose it .\nWell , minimally , I mean , what  what Dan is referring to at least having some representation of the p the spatial position of the people ,\nYeah .\ncuz we are interested in some spatial processing .\nMm - hmm .\nMm - hmm .\nAnd so\nRight .\nso , um\nWell , once the room is a little more fixed that 's a little easier\nYeah .\ncuz you 'll\nYeah .\nWell , the wireless .\nYeah .\nBut\nAlso CMU has been doing this and they were the most vocal at this meeting , Alex Waibel 's group . And they have  said , I talked to the student who had done this ,  that with two fairly inexpensive cameras they  they just recorded all the time\nMm - hmm .\nand were able to get all the information from  or maybe it was three  from all the parts of the room . So I think we would be  we might lose the chance to use this data for somebody later who wants to do some kind of processing on it if we don't collect it  at all .\nYeah . I  I  I don't disagree . I think that if you have that , then people who are interested in vision can use this database . The problem with it is you 'll have more people who don't want to be filmed than who don't want to be recorded .\nMmm .\nSo that there 's going to be another group of people who are gonna say \" I won't participate \" .\nWell , she 's not  making\nThat 's true .\nMm - hmm .\nOr you could put a paper bag over everybody 's head\nUm\nand not look at each other and not look at boards , and just all be sitting  talking .\nUh - huh .\nThat would be an interes  Bu\nWell\nGreat idea .\nWell , there 's  that 'd be the  the parallel , yeah . But I think y she 's  we 're just proposing  a minimal preservation of things on boards ,\nYeah . I definitely won't participate if there 's a camera .\nsp spatial organization  And you could anonymize the faces for that matter . You know , I mean , this is\nBut , you know , that 's a lot of infrastructure and work .\nWe can talk about the\nTo set it up and then anonymize it ?\nIt 's just one snapshot .\nNo , it wa n not , um\nNo , no , no , no .\nWe 're not talking about a movie .\nSo\nNot for  not for CMU .\nWe 're talking about a snapshot .\nMm - hmm .\nThey have a pretty crude set - up . And they had\nMm - hmm .\nYeah .\nthey just turn on these cameras . They were  they were not moving or anything .\nCouldn't find it ?\nAnd stored it on analog media .\nHmm ?\nHmm .\nAnd they  they didn't actually align it or anything . They just  they have it , though .\nYeah . Well , it 's worth considering . Maybe we don't want to  spend that much more time discussing it ,\nDid they store it digitally , or  ?\nbut\nHmm - mm . I think they just\nor just put it on videotape ?\nI think they just had the videotapes with a c you know , a counter or something . Um ,\nMm - hmm . Well , I think for  I mean , for our purposes we probably will d\nI 'm not sure .\nwe  we might try that some and  and we certainly already have some recordings that don't have that , uh , which , you know , we we 'll  we 'll get other value out of , I think .\nYeah .\nYeah .\nTh The thing is , if it 's easy to collect it  it th then I think it 's a wise thing to do because once it 's gone it 's gone . And\nI 'm just  The community  If LDC collects this data  u I mean , and L - if Mark Liberman is a strong proponent of how they collect it and what they collect , there will probably be some video data in there .\nThere you go .\nAnd so that could argue for us not doing it or it could argue for us doing it . The only place where it sort of overlaps is when some of the summarization issues are  actually could be , um , easier  made easier if you had  the video .\nI think at the moment we should be determining this on the basis of our own , uh , interests and needs rather than hypothetical ones from a community thing .\nMm - hmm .\nAs you say , if they   if they decide it 's really critical then they will collect a lot more data than we can afford to , uh , and  and will include all that .\nMmm .\nUm ,\ne\nI  I  I 'm not worried about the cost of setting it up . I 'm worried about the cost of people looking at it . In other words , it 's  it  it 'd be kind of silly to collect it all and not look at it at all . And so I  I  I think that we do have to do some picking and choosing of the stuff that we 're doing . But I  I am int I do think that we m minimally want  something  we might want to look at  at some  some , uh , subsets of that . Like for a meeting like this , at least , uh , take a Polaroid of the   of the  of the boards ,\nOf the board .\nYeah .\nOr at least make sure that the note - taker takes a sh you know , a snapshot of the board .\nand\nExactly .\na and know the position of the people\nThat 'll make it a lot easier for meetings that are structured .\nExactly .\nMm - hmm .\nI mean , otherwise later on if nobody wrote this stuff on the board down we 'd have a harder time summarizing it or agreeing on a summary .\nWe  And it  Especially since this is common knowledge . I mean , this is shared knowledge among all the participants , and it 's a shame to keep it off the recording .\nUh , except in\ns\ner , if we weren't recording this , this  this would get lost . Right ?\nYeah .\nWell , I don't understand that point . I mean , I just think that the\nThe point is that we 're not saving it anyway . Right ? In  in  our real - life setting .\nWell\nWhat do you mean we 're not saving it anyway ? I 've written all of this down and it 's getting emailed to you .\nAnd you 're gonna send it out by email , too .\nWell , uh , in that case we don't need to take pictures of it .\nRight . That would be the other alternative , to make sure that anything that was on the board , um , is in the record .\nYeah .\nYeah .\nWell\nWell , that 's why  that 's why I 'm saying that I think the note - taking would be  I think in many  for many meetings there will be some sort of note - taking , in which case , that 's a useful thing to have  Uh , I mean , we  uh , we don't need to require it . Just like the\nMm - hmm .\nI mean , I think it would be great if we try to get a picture with every meeting . Um ,\nI agree .\nso  so we won't worry about requiring these things , but the more things that we can get it for , the more useful it will be for various applications . So .\nSo  So , I mean , departing for the moment from the data collection question but actually talking about , you know , this group and what we actually want to do , uh , so I guess that 's th the way  what you were figuring on doing was  was  was , uh , putting together some notes and sending them to  to everybody from  from today ? OK . So . Um\nThat 's great .", "topic_id": 1, "keywords": "queries, questions, discussing, discussions, meeting", "dialogue_id": 24}, {"text": "So   so the question  that  that we started with was whether there was anything else we should do during  during th during the collection .\nOw .\nAnd I guess the CrossPads was certainly one idea , uh , and we 'll get them from him and we 'll just do that . Right ? And then the next thing we talked about was the  was the summaries and are we gonna do anything about that .\nWell , before we leave the CrossPads and  and call it done .\nOh , OK .\nSo , if I 'm collecting data then there is this question of do I use CrossPads ?\nYeah .\nSo , I think that if we really seriously have me collect data and I can't use CrossPads , it 's probably less useful for you guys to go to the trouble of using it , um , unless you think that the CrossPads are gonna  n I 'm not  I 'm not sure what they 're gonna do . But  but having a small percentage of the data with it , I 'm not sure whether that 's useful or not . Maybe  maybe it 's no big deal .\nWhat\nMaybe we just do it and see what happens .\nI guess the point was to try  again , to try to collect more information that could be useful later for  for the UI stuff .\nMm - hmm .\nSo it 's sort of Landay supplying it so that Landay 's stuff can be easier to do .\nRight .\nSo it  it  Right now he 's g operating from zero ,\nNothing .\nand so even if we didn't get it done from UW , it seems like that would  could still  You shou\nOK .\nI mean , at least try it .\nI think it 'd be useful to have a small amount of it just as a proof of concept .\nYeah .\nIt will\nRight . OK .\nYou know , what you can do with things .\nAnd  and they seem to  not be able to give enough of them away , so we could probably get more as well .\nYeah . But not  not to rely on them for  basic modeling .\nThat 's true . So if it  if it seems to be really useful to you guys , we could probably get a donation to me .\nYeah , I 'm not sure . I think it it  it will again depend on Landay , and if he has a student who 's interested , and how much infrastructure we 'll need . I mean , if it 's easy , we can just do it .\nYeah .\nUm , but if it requires a lot of our time , we probably won't do it .\nRight .\nI guess a lot of the stuff we 're doing now really is pilot in one sense or another .\nYeah . Yeah , we have to sort of figure out what we 're gonna do .\nAnd so we try it out and see how it works .\nRight .\nYeah .\nI just wouldn't base any of the modeling on having those .\nRight .\nYeah .\nRight . I ag I think I agree with that .\nIt 's just\nRight . OK .\nI think , though , the importance marking is a  good idea , though . That if  if people have something in front of them\nI 'd be sort of cool . I mean , it would  Yeah . That w shouldn't be hard for\nYeah . Do it on pilots or laptops or something . OK , if something 's important everyone clap .\nOK . So CrossPads , we 're just gonna try it and see what happens .\nOK .\nYeah . Um , I think that 's right .\nOK .\nOK .\nThe note - taking  So , I  I think that this is gonna be useful . So if we record data I will definitely ask for it . So , I j I think we should just say this is not  we don't want to put any extra burden on people , but if they happen to generate minutes , could  could they send it to us ?\nYeah . Oh , OK . That 's fine . Absolutely .\nMm - hmm .\nMm - hmm .\nAnd then\nYeah . What I was gonna say is that I don't want to ask people to do something they wouldn't normally do in a meeting . It 's ver I just want to keep away from the artificiality .\nMm - hmm .\nBut I think it  definitely if they exist . And then Jane 's idea of summarization afterward I think is not a bad one . Um , picking out  basically to let you pick out keywords , um , and , uh , construct queries .\nSo who  who does this summarization ?\nYeah , I 'm thinking that\nPeople in the meeting .\nYeah .\nYou know , just at  at the end of the meeting , before you go ,\nUh - huh .\nWithout hearing each other though , probably .\ngo around the table .\nYeah .\nYeah .\nOr even just have one or two people stay behind .\nYeah . Ugh . Yeah .\nYeah .\nPeople with radio mikes can go into separate rooms and continue recording without hearing each other . That 's the nice thing .\nWell , then you should try them a few weeks later\nHow fascinating .\nand  They have all these memory experiments about how little you actually retain\nAnd see  score them ?\nThat 's right . Well , that 's the interesting thing , though .\nand wasn't\nIf we do  if we collect four different summaries , you know , we 're gonna get all this weird data about how people perceive things differently .\nOh .\nIt 's like  this is not what we meant to research .\nHmm .\nRight , right .\nOh . Yeah .\nThat could be very interesting .\nMm - hmm .\nHmm .\nYeah .\nBut  but again , like the CrossPads , I don't think I would base a lot of stuff on it ,\nRu\nI d yeah , I don't know how you would do it , though .\nbecause I think  I know when I see the  the clock coming near the end of the meeting , I 'm like inching towards the door .\nMm - hmm . Running to  Yeah ,\nSo ,\nfff !\nHmm .\nyou 're probably not gonna get  a lot of people wanting to do this .\nMaybe e Is email easier ?\nWell , I think if\nI mean , I  when you first said do  do it , um , spoken , what I was thinking is , oh then people have to come up\nMm - hmm .\nand you have to hook them up to the recorder . So , if they 're already here I think that 's good ,\nRight .\nbut if they 're not already here for  I 'd rather do email . I 'm much faster typing than anything else .\nYeah , I 'd just try  Well , however the least intrusive and  and quickest way is , and th and closest to the meeting time too , cuz people will start to forget it as soon as they l leave .\nYeah .\nYeah . I think that  I think doing it orally at the end of the meeting is the best time .\nI don't know . At\nI just don't\nMm - hmm .\nbecause they 're kind of a captive audience . Once they leave ,\nMm - hmm .\nyou know , forget it . But  but i\nYeah , read the digits , do the summary .\nRight . But , uh , I don't think that they 'll necessarily  you 'll  you 'll get many people willing to stay .\nHmm .\nBut , you know , if you get even one\nw\nWell , I think it 's like the note - taking thing ,\nI would s Yeah .\nthat  that y that you can't  certainly can't require it or people aren't gonna want to do this . But  but if there 's some cases where they will , then it would be helpful .\nHmm .\nAnd I 'm also wondering , couldn't that be included in the data sample so that you could increase the num you know , the words that are , uh , recognized by a particular individual ? If you could include the person 's meeting stuff and also the person 's summary stuff , maybe that would be uh ,\nYeah . It 's kind of nice .\nan ad addition to their database .\nYeah .\nHmm .\nUnder the same acoustic circumstance , cuz if they just walk next door with their set - up , nothing 's changed ,\nRight .\njust\nSo I have a question about queries ,\nGod , that 's bugging me .\nwhich is , um ,\nCan we turn that light off ?\nYou turn\nuh\nIf  can we turn that just  that  that let\nThe fl the fluorescent light is flickering .\nUh , let the record show the light is flickering .\nI don't know .\nYeah .\nYeah , there 's a\nOh , it is  it is like  OK .\nYeah .\nYeah .\nVery annoying .\nThere you go . OK .\nOh , much better .\nFor a little while I thought it was just that I was really tired .\nOh , yeah .\nYeah .\nThat 's better .\nGood .\nThat and y  Too much caffeine and really tired ,\nToo much caffeine .\nbut then I thought \" no , maybe that 's real \" .\nOK .\nSo ,\nI thought it was the projector for a moment . It was like , \" what 's going on ? \"\nYeah .", "topic_id": 2, "keywords": "crosspads, collecting, data, memory, collect", "dialogue_id": 24}, {"text": "the question I had about queries was , um , so what we 're planning to do is have people look at the summaries and then generate queries ? Are  are we gonna try and o\nWe  we 've just been talking , how do we generate queries ?\nYeah . Well , I mean ,\nAnd so that was one suggestion .\nso , the question I had is is have we given any thought to how we would generate queries automatically given a summary ? I mean , I think that 's a whole research topic un unto itself ,\nMmm .\nso that it may not be a feasible thing . But\nHello . Dan here .\nn\nShouldn't Landay and his group be in charge of figuring out how to do this ?\nYeah .\nI mean , this is an issue that goes a little bit beyond where  we are right now .\nOK .\nThey 're the expert\nMari ?\nYeah ?\nSomeone wants to know when you 're getting picked up . Is someone picking you up ?\nUm ,  what 's our schedule ?\nWell , you still wanted to talk with Liz .\nLet 's see , you and I need dis Uh , no , we did the Liz talk .\nAnd you and I need to Oh , oh . You already did the Liz talk .\nYeah . So  so that was the prosody thing .\nOK .\nWe -  I don't remember it .\nUm , we need to finish the\nOh , OK .\nIt 's already four - fifteen .\nI have like no recall memory .\nUh , after .\nYeah .\nWe need to  finish this discussion , and you and I need a little time for wrap - up and quad chart . So ,\nAnd what ?\num\nI 'm at your disposal . So , up to you .\nUm , what  what 's the plan for this discussion ? We should\nUm , I think we should be able to wind up in another half - hour or something , you think ?\nAt least . Yeah .\nUh , less .\nm i Even if that much ?\nYeah .\nLess ?\nLess .\nSo , I think\nIt 's interesting that he 's got , like ,  this discussion free\nWell , I mean , we still haven't talked about the action items from here and so on .\nAction  Yeah . So ,\nyet it 's separate .\nAnd\ne e why don't you say five - thirty ? I don't\nOK , five - thirty .\nIs that OK ? We 'll probably hit horrible traffic .\nSounds  OK . h Thanks , bye .\nThat 's not a lot of time ,\nThat 's that .\nbut\nYeah .\nWell , in answer to \" is it Landay 's problem ? \" , um , he doesn't have a student who 's interested right now in doing anything . So he has very little manpower . Um , there 's very little allocated for him and also he 's pretty focused on user interface . So I don't think he wants to do information retrieval , query generation , that sort of stuff .\nYeah , well there 's gonna be these student projects that can do some things but it can't be , yeah , very deep . u I  I actually think that  that , uh , again , just as a bootstrap ,  if we do have something like summaries , then having the people who are involved in the meetings themselves , who are cooperative and willing to do yet more , come up with  with  with queries , uh , could at least give  give Landay an idea of the kind of things that people might want to know . I mean , ye Right ? If he doesn't know anything about the area , and  the people are talking about and  and , uh\nBut the people will just look at the summaries or the minutes and re and sort of back - generate the queries . That 's what I 'm worried about . So you might as well just give him the summaries .\nMm - hmm .\nAnd\nMaybe .\nWell , I 'm not sure  I 'm not sure that 's a solved problem .\ny Well , but I think\nOh , OK .\nRight ? Of how to  how to generate queries from a\nHow to do this from the summary .\nYeah .\nI , uh\nThat was sort of what my  question was  aimed towards .\nSo what you want to h to do is , people who were there , who later see , uh , minutes and s put in summary form , which is not gonna be at the same time as the meeting . There 's no way that can happen . Are we gonna later go over it\nHmm .\nRight .\nRight .\nand , like , make up some stuff to which these notes would be an answer , or  or a deeper  Yeah . I mean\nOr  or just a memory refresher .\nBut that 's done off  they have to do that off - line .\nYep . I agree .\nYou\nI 'm also wondering if we could ask the  the people a  a question which would be \" what was the most interesting thing you got out of this meeting ? \" Becau - in terms of like informativeness ,\nThat 's a good one .\nit might be , you know , that the summary would  would not in even include what the person thought was the most interesting fact .\nI would think that would be the most likely thing .\nDan doesn't know what sex he is .\nYeah , really .\nBut actually I would say that 's a better thing to ask than have them summarize the meeting .\nI think you get two different types of information .\nYou get two  Yeah , that 's true .\nYeah .\nBecause you get , like , the general structure of important points and what the  what the meeting was about .\nHey .\nAh\nYeah .\nWe 're still here .\nSo you get the general structure , the important points of what the meeting was about  with the summary . But with the \" what 's the most interesting thing you learned ? \"  Uh , so the fact that , uh , I know that Transcriber uses Snack is something that I thought was interesting\nGoing to see the kids .\nYou  you can keep it on .\nand that  and that Dan worked on  on that . So I thought that was really  you know . So , I mean , you could ge pick up some of the micro items that wouldn't even occur as major headings\nMm - hmm .\nbut could be very informative .\nYeah , that 's actually a really good idea .\nI think it wouldn't be too , uh , uh , cost - intensive either . You know , I mean , it 's like something someone can do pretty easily on the spur of the moment .\nAre you thinking about just asking one participant or all of them ?\nAs many are willing to do it .\nMake it a voluntary thing ,\nYeah . Cuz you 'll get  cuz you 'll get very different answers from everybody , right ?\nand then  Yeah . That 's why I was wondering .\nSo\nWell , maybe one thing we could do is for the meetings we 've already done  I mean , I  we didn't take minutes and we don't have summaries . But , uh , people could , like , listen to them a little bit and  generate some queries .\nYeah .\nOf course Jane doesn't need to . I 'm sure you have that meeting memorized by now .\nYeah .\nBut actually it would be an easy thing to just go around the room and say  what was the most interesting thing you learned ,\nMmm .\nYeah . Yeah .\nfor those pe people willing to stay .\nAnd that  I think it would pick up the micro - structure , the  some  some of the little things that would be hidden .\nAnd  and that might be something people are willing to stay for .\nBoy , I  I don't know how we get at this\nThat would be interesting .\nYeah , but when you go around the room you might just get the effect that somebody says something\nOr want to get up and leave .\nand then you go around the room and they say \" yeah , me too , I agree . \"\nMe too , me too , me too .\nYeah .\nThat 's fine .\nSo\nOn the other hand people might try and come up with different ones , right ?\nWell\nThey might say \" oh , I was gonna say that one but now I have to think of something else \" .\nWell , you have the other thing , that  that they know why we 're doing it . We 'll  I mean , we 'll  we 'll be telling them that the reason we 're trying to do this is  is to d generate queries in the future , so try to pick things that other people didn't say .\nIt 's gonna take some thought . I mean , It seemed   The kind of , uh , interest that I had in this thing initially was , uh , that i basically the form that you 're doing something else  later ,\nMm - hmm .\nand you want to pick up something from this meeting related to the something else . So it 's really the imp the  the list of what 's important 's in the something else\nRight .\nrather than the\nMmm .\nAnd it might be something minor  of minor importance to the meeting .\nMm - hmm .\nRight .\nUh , in fact if  if it was really major , if it 's the thing that really stuck in your head , then you might not need to go back and  and  and check on it even . So it 's  it 's that you 're trying to find   You 're  you 've now  You weren't interested  Say I  I said \" well , I wasn't that much interested in dialogue , I 'm more of an acoustics person \" .\nRight .\nBut  but thr three months from now if for some reason I get really interested in dialogue , and I 'm \" well what is  what was that part that  that  that , uh , Mari was saying ? \"\nYeah , like Jim Bass says \" add a few lines on dialogue in your next perf \"\nUh\nYeah . Yeah .\nYeah .\nAnd then I 'm trying to fi I mean , that 's  that 's when I look  in general when I look things up most , is when it 's something that  didn't really stick in my head the first time around and  but for some  new reason I 'm  I 'm  I 'm interested in  in  in the old stuff .\nBut that  that 's gonna be very hard to generate .\nWell , I  That 's hard to generate\nSo , I don't  I don't know .\nMm - hmm .\nDo we\nand  and I think that 's half of what i I would use it for . But I also a lot of times um , make  you know , think to myself \" this is interesting ,\nMm - hmm .\nI 've gotta come back and follow up on it \" .\nMm - hmm . Mm - hmm .\nSo , things that I think are interesting , um , I would be , uh , wanting to do a query about . And also , I like the idea of going around the room , because if somebody else thought something was interesting , I 'd kind of want to know about it and then I 'd want to follow up on it .\nHmm .\nYeah . That  that might get at some of what I was  I was concerned about , uh , being interested in something later that w uh , I didn't consider to be important the first time , which for me is actually the dominant thing , because if I thought it was really important it tends to stick more than if I didn't , but some new  task comes along that makes me want to look up .\nBut  But what 's interesting to me may not b have been interesting to you .\nYeah . So having multiple people might get at some of that .\nBy  so by going around  Yeah .\nYeah .\nYeah , I  I think  you can't get at all of it ,\nYeah .\nright ? W we just need to start somewhere .\nYeah , and this is a starting point .\nUh - huh .", "topic_id": 3, "keywords": "queries, summarize, summaries, retrieval, planning", "dialogue_id": 24}, {"text": "The question  the question then is h h how much bias do we introduce by  you know , introduce by saying , you know , this was important now and , you know , maybe tha something else is important later ?\nMm - hmm .\nI mean , does it  does the bias matter ? I  I don't know . I mean , uh , that 's , I guess , a question for you guys . But\nWell , and  and one thing , we  we 're saying \" important \" and we 're saying \" interesting \" .\nUh , yeah , yeah .\nAnd  and those  those can be two different things .\nMm - hmm .\nSure , sure . But I  I  I guess that 's the question , really , is that  I mean ,\nMm - hmm .\nW\ndoes building queries based on what 's important now introduce an irreversible bias on being able to do what Morgan wants to do later ?\nWell , irreversible .\nOK , good .\nThat 's  that 's\nI  I  I mean , I guess what I what I  I keep coming back to in my own mind is that , um , the soonest we can do it , we need to get up some kind of system\nYeah .\nRight .\nso that people who 've been involved in the meeting can go back later , even if it 's a poor system in some ways , and , uh  and ask the questions that they actually want to know . If  you know , if  uh , as soon as we can get that going at any kind of level , then I think we 'll have a much better handle on what kind of questions people want to ask than in any  anything we do before that . But obviously we have to bootstrap somehow ,\nRight .\nand\nSure .\nMm - hmm .\nRight .\nI agree .\nI will say that  that I  I chose \" interesting \" because I think it includes also \" important \" in some cases . But , um , I  I  I feel like the summary gets  at a different type of information .\nI think \" important \" can often be uninteresting .\nMmm .\nMmm . And \" interesting \" is more interesting than \" important \" .\nHmm .\nWell , and  and also  i it puts a lot of burden on the person to  to evaluate . You know , I think inter \" interesting \" is  is non - threatening in\nOK - OK .\nYeah .\nIn the interest of , um ,\nImportance ?\nYeah .\ngenerati  generating an interesting summary ,  um\nMm - hmm . Yeah .\nNo , i in the interest of generating some minutes here , uh , and also moving on to action items and other things , let me just go through the things that I wrote down as being important , um , that we at least decided on . CrossPads we were going to try , um , if Landay can get the , uh  get them to  to you guys , um , and see if they 're interesting . And if they are , then we 'll try to get m do it more . Um , getting electronic summary from a note - taking person if they happen to do it anyway .\nMm - hmm .\nUm , getting  just , uh , digital pictures  a couple digital pictures of the  the table and boards to set the context of the meeting . Uh , and then going around the room at the end to just say  qu ask people to mention something interesting that they learned . So rather than say the most interesting thing , something interesting ,\nk\nand that way you 'll get more variety .\nSure .\nMm - hmm .\nI wouldn't even say that \" that they learned \" .\nThat 's good . I like that . I like that .\nOK .\nYeah .\nUh , you might want to mention something that  that you brought up .\n\" Thing  that was  discussed . \" And then the last thing c would be for those people who are willing to stay afterwards and give an oral summary .\nMm - hmm .\nOK ? Does that pretty much cover everything we talked about ? That  well , that we want to do ?\nMm - hmm . A And one  and one qualification on  on the oral summaries . They 'd be s they 'd be separate . They wouldn't be hearing each other 's summaries .\nOK .\nYeah , that 's like  n I think that 's gonna predominantly end up being whoever  takes down the equipment then .\nAnd  and that would also be that the data would be included in the database .\nYeah , that would be , let 's see , me .\nMm - hmm .\nMm - hmm .\nI mean , there is still this hope that people might actually think of real queries they really want to ask at some point .\nOK .\nAnd that if  if that ever should happen , then we should try and write them down .\nMm - hmm .\nRight .\nMm - hmm .\nGive them a reward , a dollar a query ?\nYeah , really .\nYeah .\nIf they 're real queries .\nOK . So\nWell , and again , if we can figure out a way to jimmy a  a  a  a very rough system , say in a year , then  uh , so that in the second and third years we  we actually have something to\nYeah .\nYeah .\nPlay with and generate real queries from .\nask queries .\nRight . OK .\nYeah .\nYeah .\nSo . Yeah .\nUh\nI think  I just wanted to say one thing about queries . I mean ,   the level of the query could be , you know , very low - level or very high - level . And it gets fuzzier and fuzzier as you go up , right ?\nWell , we 're gonna\nSo you need to have some sort of  if you start working with queries , some way of identifying what the  you know , if this is something that requires a  a one - word answer or it 's one place in the recording versus was there general agreement on this issue of all the people who ha\nHmm .\nYou know , you can gen you can ask queries that are meaningful for people .\nYep .\nIn fact , they 're very meaningful cuz they 're very high - level . But they won't exist anywhere in the  a you know\nAbsolutely . So I think we 're gonna have to start with keywords\nMm - hmm .\nand  and if someone becomes more interested we could work our way up .\nI I 'm  I I 'm not so sure I agree with that .\nIt  But it may well\nBut\nBecause  uh , b because it depends on , uh , what our goal is .\nReally ?\nIf our goal is Wizard of Oz - ish , we might want to know what is it that people would really like to know about this data .\nOh , that 's true .\nAnd if it 's  if  if it 's something that we don't know how to do yet , th great ,\nYeah .\nRight .\nYeah .\nthat 's , you know , research project for year four or something .\nMm - hmm .\nResearch , yeah .\nYou know ?\nMm - hmm .\nYeah , I was thinking about Wizard of Oz , but it requires the wizard to know all about the meetings .\nWe 'd have to listen to all the data .\nUm , well , not  maybe not true Wizard of Oz\nSo .\nbecause people are too\nOh , yeah . I  I understand .\nuh , aware of what 's going on .\nWell just imagine if\nBut  but just\nGet people to ask questions that they def the machine definitely can't answer at the moment ,\nYeah . w Just \" what would you like to know ? \"\nbut\nYep .\nYeah .\nBut that  neither could anyone else , though , is what , uh , my point is .\nYes .\nI I was wondering if  if there might be one s more source of queries which is indicator phrases like \" action item \" ,\nOK .\nwhich could be obtained from the text  from the transcript .\nRight . Since we have the transcript .\nYeah .\nDates maybe . I don't know . That 's something I always forget .\nYeah , that 's something to be determined , something to be specified ,\nWell , probably if you have to sit there at the end of a meeting and say one thing you remember , it 's probably whatever action item was assigned to you .\nbut text - oriented .\nI mean , in gen that 's all I remember from most meetings .\nThat  that 's all I wrote down .\nI think you 'd remember that , yeah .\nSo , in general , I mean , that could be something you could say , right ? I 'm supposed to  do this . It  it doesn't\nYeah , that 's true . Well , but then you could  you could prompt them to say , you know , \" other than your action item \" , you know , whatever .\nWell\nBut  but the action item would be a way to get , uh , maybe an additional query .\nI mean , that 's realistically what people might  well be remembering .\nSo .\nSo .\nHmm .\nYeah . Well , but  you know , but you could get again @ @\nWell , we 're piloting . We 'll just do it and see what happens .\nYeah . Yeah .\nYeah .\nYeah .\nI usually don't remember my action items . But   I 'd  I", "topic_id": 4, "keywords": "bias, morgan, questions, thinking, importance", "dialogue_id": 24}, {"text": "OK - OK . Speaking of action items , can we move on to action items ?\nYeah . Mm - hmm .\nSure . Can you hand me my note pad ?\nYeah . yeah .\nUm , or maybe we should wait until the summary of this  until this meeting is transcribed and then we will hav\nWe  we had  I mean ,\nYeah . Then we 'll know .\nThanks .\nsomewhere up there we had milestones , but I guess  Did y did you get enough milestone , uh , from the description things ?\nI got  Yeah . In fact , why don't you hand me those transparencies so that I remember to take them . eee ,\nOK .\nOK .\nAnd , you know , there 's obviously  detail behind each of those , as much as is needed . So , you just have to  let us know .\nOK . What I have down for action items is we 're supposed to find out about our human subject , um ,  requirements .\nGood .\nUh ,\nYep .\npeople are supposed to send me U R for their  for web pages , to c and I 'll put together an overall cover . And you 're s\nRight . We\nHmm ?\nwe need to look at our web page\nAnd  and you also need to look at your web page\nand make one that 's  that 's p\nand clean it up by mid - July .\nPDA - free .\nRight .\nYeah .\nUm ,\nRight .\nlet 's see . Choo - choo - choo . We\nMailing lists .\nMailing list ? Uh , you need to put together a mailing list .\nThree of them .\nUh , I think w\nWell   I mean ,\nYeah .\nuh ,\nUm ,\nmostly together .\nuh , I need to email Adam or Jane , um , about getting the data . Who should I email ?\nUh , how quickly do you want it ?\nUm .\nMy July is really very crowded . And so , uh\nHow about if I just c Uh , Right now all I want  I personally only want text data . I think the only thing Jeff would do anything with right now  But I 'm just speaking fr based on a conversation with him two weeks ago I had in Turkey . But I think all he would want is the digits . Um , but I 'll just speak for myself . I 'm interested in getting the language model data . Eh , so I 'm just interested in getting transcriptions .\nMm - hmm .\nSo then just email you ?\nOK . So y Sure , sure , sure .\nOK .\nWh\nYou could email to both of us , uh , just  I mean , if you wanted to .\nMm - hmm .\nI mean , I don't think either of us would mind recei\nOK .\ni\nThat 's right .\nbut  but in any case I 'd be happy to send you the\nAnd your email is ?\ni\nEdwards at ICSI .\nOK .\nw\nDot Berkeley dot EDU , of course .\nAnd then\nIn  in our phone call , uh , before , we  we , uh  It turns out the way we 're gonna send the data is by , uh , And , uh  and then what they 're gonna do is take the CD - ROM and transfer it to analog tape and  give it to a transcription service , uh , that will\nOh , is this IBM ?\nYeah .\nYeah , using foot pedals\nYeah , foot  foot pedals\nand\nand\nUh , so do they  How are they gonna do the multi - channel ?\nSee , that 's a good question .\nYeah . They  they don't have a way .\nI thought so .\nNo , I mean , it 'll be\nBut they have a verification .\nprobably about like you did ,\nMix ?\nand then there will be some things  you know , many things that don't work out well . And that 'll go back to IBM and they 'll  they 'll , uh  they run their aligner on it and it kicks out things that don't work well , which  you know , the overlaps will certainly be examples of that . And , uh  I mean , what w we will give them all of it . Right ?\nOK . That 's , uh , my question .\nWe 'll give them all the  the multi - channel stuff\nSo we 'll give them all sixteen channels\nand\nand they 'll do whatever they want with it .\nYeah .\nBut you also should probably give them the mixed  You know , equal sound - level\nYeah .  Good idea .\nMm - hmm .\nI mean , they 're not gonna easily be able to do that , probably .\nIt 's not hard .\nWell\nAh , yeah .\nSo .\nMm - hmm .\nIt 's also won't be adding much to the data to give them the mixed .\nBut w\nI\nIt 's not\nRight .\nRight . It doesn't  it isn't difficult for us to do ,\nYep . Absolutely .\ni You should  Yeah .\nso we might as well just do it .\nYou should  that may be all that they want to send off to their  transcribers .\nAbsolutely . So , sure .\nOK . Related to  to the conversation with Picheny , I need to email him , uh , my shipping address and you need to email them something which you already did .\nI did . I  I m emailed them the Transcriber URL , um , the on - line , uh , data that Adam set up , The URL so they can click on an utterance and hear it . and I emailed them the str streamlined conventions which you got a copy of today .\nRight . And I was gonna m email them the  which I haven't yet , a pointer to  to the web pages that we  that we currently have , cuz in particular they want to see the one with the  the way the recording room is set up\nGood .\nand so on , your  your page on that .\nOh , excellent . Good .\nAnd then p possibly\nI C - I CC ' ed Morgan . I should have sent  I should have CC ' ed you as well .\nOK .\nNot an immediate action item but something we do have to worry about is data formats for  for higher - level information .\nOK .\nOh , yeah . We were gonna\nWell , or d or not even higher level , different level , prosody and all that sort of stuff . We 're gonna have to figure out how we 're gonna annotate that .\nYeah . We never had our data format discussion .\nYeah , we w Right .\nOh , I thought we did . We discussed , uh , musi musical score notation\nOh , OK .\nBut that 's not  That 's display .\nand  and its XML\nThat 's different than format .\nThat 's\nWell , um\nW My  my u feeling right now on format is you guys have been doing all the work\nWell  uh , yeah .\nand whatever you want , we 're happy to live with .\nYeah .\nUm ,\nOK , excellent .\nother people may not agree with that ,\nOK . So , what n important thing\nbut  Cuz I 'm not actually touching the data ,\nWell , it c\nRight .\nso I shouldn't be the one to talk . But\nNo , I think that 's fine .\nSo a key thing will be that you  we tell you\nGreat .\nYeah .\nwhat it is . Uh , we also had\n\" Here 's a mysterious file\nYeah .\nand  \"\nWe also had the , uh , uh  that we were s uh , that you were gonna get us the eight - hundred number\nOh , yeah .\nand we 're all gonna  we 're gonna call up your Communicator thing and  and we 're gonna be good slash bad , depending on how you define it , uh , users .\nNow , something that I mentioned earlier to Mari and Liz is that it 's probably important to get as many non - technical and non - speech people as possible in order to get some realistic users . So if you could ask other people to call and use our system , that 'd be good . Cuz we don't want people who already know how to deal with dialogue systems ,\nYeah . Or ,  like if you have a\nwho know that you shouldn't hyper - articulate , for instance , and things like that .\nOr , like if you have somebody who makes your  your plane reservations for you ,\nSo .\nYeah .\num , which is\nYeah , we can do that .\nthe n\nGet my parents to do it .\nYeah . Yeah . Seriously .\nYeah , for instance .\nYeah .\nYour grandmother .\nHmm .\nYeah . e You know , it could  result in some good bloopers , which is always good for presentations . So  Um , anyway\nYeah .\nI think my father would last through the second prompt before he hang  hung up .\nMmm .\nMy mother would have a very interesting conversation with it\nHe would never use it .\nbut it wouldn't have anything to do with the travel .\nOK . Um , other\nOK .\nLet 's see , other action items . So I have the\nWe talked about that we 're getting the recording equipment running at UW . And so it depends , w e e e they 're  you know , they 're p m If that comes together within the next month , there at least will be , uh , uh , major communications between Dan and  UW folks\nYeah . I mean ,\nI 'm  I 'm shooting to try to get it done  get it put together by  the beginning of August .\nas to\nwe should talk about it , but\nMmm .\nSo , um , you know , if\nBut we have  it  it 's  it 's pretty  We don't know . I mean , he  he s uh , he said that it was sitting in some room collecting dust\nWe don't know .\nand  and so we don't know ,\ni It 's probably unlikely that we 'll pull this off ,\ni e\nbut a at least it 's worth trying .\nMm - hmm . What is it ?\nWe don't know .\nOh , OK .\n\" Recording equipment . \"\nYeah .\nIt 's a tape recorder .\nW We know it 's eight channels . Uh , we know it 's digital .\nIt 's eight tape recorders .\nWe don't even know if there 're microphones . So , we 'll find out .\nOK . Um , and I will email these notes  Um , I 'm not sure what to do about action items for the data stuff , although , then somebody  I guess somebody needs to tell Landay that you want the pads .\nYeah , OK . I 'll do that .\nOK .\nUm , and he also said something about outside  there  that came up about the outside text sources , that he  he may have\nMm - hmm .\nOh !\nsome text sources that are close enough to the sort of thing that we can play with them for a language model .\nHmm .\nYeah , that was  uh , that was  What he was saying was this  he  this thing that , uh , Jason had been working on finds web pages that are thematically related to what you 're talking about . Well , that 's the idea . So that that  that would be a source of text which is  supposedly got the right vocabulary .\nMm - hmm .\nRight .\nBut it 's obviously very different material . It 's not spoken material , for instance ,\nYeah . But it 's p it might be\nso\nBut  but that 's actually what I wanna do . That 's  that 's what I wanna work with ,\nOK .\nis  is things that s the wrong material but the right da the right source .\nYeah .\nYeah .\nYeah .\nUn - unfortunately Landay told me that Jason is not gonna be working on that anymore .\nYeah .\nHe 's switching to other stuff again .\nYeah . He seemed  when I asked him if he could actually supply data , he seemed a little bit more reluctant . So , I 'll  I 'll send him email . I 'll put it in an action item that I send him email about it . And if I get something , great . If I don't get something\nWho ? Landay or Jason ?\nLanday . And , uh , um ,\nOK .\nOK .\nyou know , otherwise , if you guys have any papers or  I could  I could use , uh  I could use your web pages . That 's what we could do . You 've got all the web pages on the Meeting Recor\nYeah , why search for them ?\nYeah !\nThey 're  we know where they are .\nTrue .\nYeah , that 's true .\nAbsolutely .\nOh , forget this !\nSure .\nWell , but that 's not very much .\nI  One less action item . I can use what web pages there are out there on meeting recorders .\nYep .\nRight .\nI mean , that  that 's  Yeah . Basically what his software does is h it picks out keywords and does a Google - like search .\nYeah .\nYeah . Yeah .\nYeah . So we can  we can  we can do better than that .\nWe can do that . Yeah .\nSo you could\nYeah .\nYeah .\nMm - hmm .\nThere 's  there 's some , uh , Carnegie Mellon stuff , right ? On  on meeting recording ,\nYep .\nAnd Xerox .\nSo , there 's  there 's ICSI , Xerox ,\nand\nAnd there 's  You should l look under , like , intelligent environments ,\nAnd Xerox . Yeah .\nsmart rooms ,\nUm , the \" Georgia Tech Classroom Two Thousand \" is a good one .\num\nCMU ,\nRight . And then  Right . J There 's  th That 's where I thought you would want to eventually be able to have a board or a camera ,\nMm - hmm .\nbecause of all these classroom\nWell , Georgia Tech did a very elaborate instrumented room .\nMm - hmm .\nYeah .\nAnd I want to try to stay away from that . So\nOK . Great . That solves that problem . One less action item . Um  OK . I think that 's good enou that 's  that 's pretty much all I can think of .\nCan I ask , uh , one thing ? It relates to data  data collection and I  and I 'd  and we mentioned earlier today , this question of  um , so , um , I s I know that from  with the near - field mikes some of the problems that come with overlapping speech , uh , are lessened . But I wonder if  Uh , is that sufficient or should we consider maybe getting some data gathered in such a way that , um , u w we would c uh , p have a meeting with less overlap than would otherwise be the case ? So either by rules of participation , or whatever .", "topic_id": 5, "keywords": "milestones, milestone, action, items, notes", "dialogue_id": 24}, {"text": "Oh , yeah .\nNow , I mean , you know , it 's true , I mean , we were discussing this earlier , that depending on the task  so if you 've got someone giving a report you 're not gonna have as much overlap .\nAdam !\nBut , um , i i uh , so we 're gonna have s you know , non - overlapping samples anyway . But , um , in a meeting which would otherwise be highly overlapping , is the near - field mike enough or should we have some rules of participation for some of our samples to lessen the overlap ?\nHmm .\nturn off\nI don't think we should have rules of participation , but I think we should try to  get a variety of meetings . That 's something that if we get the  the meeting stuff going at UW , that I probably can do more than you guys ,\nOK .\ncuz you guys are probably mostly going to get ICSI people here . But we can get anybody in EE , uh , over\nMm - hmm .\nand  and possibly also some CS people , uh , over at UW . So , I think that  that there 's a good chance we could get more variety .\nOK . Just want to be sure there 's enough data to\nUm ,\nThey 're still gonna overlap ,\nOK , good .\nbut  Mark and others have said that there 's quite a lot of found data  from the discourse community that has this characteristic and also the political  Y you know , anything that was televised for a third party has the characteristic of not very much overlap .\nMm - hmm .\nMm - hmm .\nWasn - but w I think we were saying before also that the natural language group here had less overlap .\nMm - hmm .\nSo .\nSo it also depends on the style of the group of people .\nRight .\nLike the , um , dominance relations of the people in the meeting .\nMm - hmm . On the task , and the task .\nMm - hmm .\nIt 's just  I just wanted to  uh ,\nYeah .\nbecause you know , it is true people can modify the amount of overlap that they do if  if they 're asked to .\nYeah .\nNot  not entirely modify it , but lessen it if  if it 's desired . But if  if that 's sufficient data  I just wanted to be sure that we will not be having a lot of data which can't be processed .\nOK . So I 'm just writing here , we 're not gonna try to specify rules of interaction but we 're gonna try to get more variety by i using different  groups of people\nTime .\nand different sizes .\nFine . And I  you know , I  I know that the near f near - field mikes will take care of also the problems to s to a certain degree .\ne e Yeah . And then the other thing might be , um , uh , technical versus administrative .\nI just wanted to be sure .\nCuz if I recorded some administrative meetings then that may have less overlap , because you might have more overlap when you 're doing something technical and disagreeing or whatever .\nMm - hmm . Mm - hmm . Well , I  just as  as  as a contributary  eh , so I  I know that in l in legal depositions people are pr are prevented from overlapping . They 'll just say , you know  you know , \" wait till each person is finished before you say something \" . So it is possible to lessen if we wanted to . But  but these other factors are fine . I just wanted to raise the issue .\nWell , the reason why I didn't want to is be why I personally didn't want to  is because I wanted it to be  as , uh , unintrusive as possi\nMm - hmm . Mm - hmm .\nas you could be with these things hanging on you .\nOh , yeah . Yeah , I think that 's always desired . I just want to be sure we don't  that we 're able to process , i u uh , you know , as much data as we can . Yeah .\nYeah . Did they discuss any of that in the  the meeting they had with L Liberman ?\nMm - hmm .\nWhat\nAnd there was a big division ,\nWhat  what do they\nso Liberman and others  were interested in a lot of found data .\nYeah .\nSo there 's lots of recordings that  They 're not close - talk mike ,\nYeah .\nbut  And  and there 's lots of television , you know , stuff on , um , political debates and things like that , congre congressional hearings . Boring stuff like that . Um , and then the CMU folks and I were sort of on the other side in  cuz they had collected a lot of meetings that were sort of like this and said that those are nothing like these meetings . Um , so there 're really two different kinds of data . And , I guess we just left it as  @ @  that  if there 's found data that can be transformed for use in speech recognition easily , then of course we would do it ,\nMm - hmm .\nbut newly collected data would  would be natural meetings . So .\nActually , th @ @  the CMU folk have collected a lot of data . Is that  is that going to be publicly available ,\nAs far as I know , they h have not .\nor  ?\nUm , but e\nOK .\nIt 's also  it 's not  it 's not near - far , right ?\nI 'm not sure . Um , if people were interested they could talk to them , but I  I got the feeling there was some politics involved .\nI think @ @ gonna add that to one of my action items .\nNo .\nJust to check .\nI  I don't know .\nYeah . W we should know what 's out there certainly .\nYeah .\nI mean , the\nYeah .\nCuz I had thought they 'd only done far - field ,\nI think you need to talk to Waibel and\nintelligent - room sorts of things .\nOh , really ? It 's those guys .\nI hadn't known that then  they 'd done any more than that .\nOh , they only did the far - field ? I see .\nYeah .\nBut they had multiple mikes and they did do recognition , and they did do real conversations . But as far as I know they didn't offer that data to the community at this meeting .\nMm - hmm .\nBut that could change cuz Mark  you know , Mark 's really into this . We should keep in touch with him .\nYeah . Well , once we send out\nYeah , I think\nI mean , we still haven't sent out the first note saying \" hey , this list exists \" . But  but , uh , once we do that\nIs that an action item ?\nYeah . It 's on  I already added that one on my board to do that . So , uh  uh , hopefully everybody here is on that list . We should at least check that everybody here  ?\nI think everyone here is on the list .\nYeah .\nI 'm not .\nu e e\nI think you are .\nWe haven't sent anything to the list yet .\nOh ! OK .\nYeah .\nWe 're just compiling the list .\nI see .\nI  I added a few people who didn't  who I knew had to be on it even though they didn't tell me .\nMm - hmm .\nWho specifically ask not to be .\nLike Jane , for example .\nYeah .\nYou are on it , aren't you ?\nYeah , I am .\nYeah .\nSo , I w uh , just  just for clarification . So \" found data \" , they mean like established corpora of linguistics and  and other fields , right ?\nWhat they mean is stuff they don't have to fund to collect ,\nIt sounds like such a t\nand especially good\nYeah , OK .\nWell , I mean , \" found \" has , uh , also the meaning that 's it very natural . It 's things occur without any  You know , the pe these people weren't wearing close - talking mikes , but they were recorded anyway , like the congressional hearings and , you know , for legal purposes or whatever .\nOK . But it includes like standard corpora that have been used for years in linguistics and  other fields .\nMark 's aware of those , too .\n\" Hey , look what we found ! \"\nOK .\nThat would be found data because they found it  and it exists .\nHmm .\nExactly .\n\" I found this great corpora . \" Yeah .\nThey didn't have to collect it . Of course it 's not \" found \" in the sense that at the time it was collected for the purpose .\n\" Psst .  Want to buy a corpora ? \"\nYeah . OK , OK .\nBut what he means is that  You know , Mark was really a fan of getting as much data as possible from  you know , reams and reams of stuff , of broadcast stuff ,\nThat 's interesting .\nweb stuff ,\nMm - hmm .\nTV stuff , radio stuff . But he well understands that that 's very different than these  this type of meeting .\nIt 's not the same .\nBut , so what ? It 's still  it 's interesting for other reasons .\nOK . Yeah . Just wanted to know .\nSo , seems like we 're winding down .\nMm - hmm .\nRight ? Many  ways .\nYou can  tell  by the  prosody .\nSo we should go  go around and s\nYeah .\nWe should go around and say something interesting that happened at the meeting ?\nOh . Yes , we should do that .\nRrrh !\nNow , I was already thinking about it , so\nOh ! Good man .\nThis is painful task .\nHmm .\nI\nSo , um , I really liked the idea of  what I thought was interesting was the combination of the CrossPad and the speech . Especially , um , the interaction of them rather than just note - taking . So , can you  determine the interesting points by who 's writing ? Can you do special gestures and so on that  that have , uh , special meaning to the corpora ? I really liked that .\nWell , I  I just realized there 's another category of interesting things which is that , um , I  I found this discussion very , uh , i this  this question of how you get at queries really interesting . And  and the  and I  and the fact that it 's sort of , uh , nebulous , what  what that  what kind of query it would be because it depends on what your purpose is . So I actually found that whole process of  of trying to think of what that would involve to be interesting . But that 's not really a specific fact . I just sort of thought we  we went around a nice discussion of the factors involved there , which I thought was worthwhile .\nI had a real revelation about taking pictures . I don't know why I didn't do this before and I regret it . So that was very interesting for me .\nMm - hmm .\nDid you take pictures of the boards ?\nNot that I\nYeah .\nThe boards aren't really related to this meeting . I mean , I will take pictures of them , but\nThat 's a good point .\nThey 're related to this morning 's meeting .\nBut\nYeah .\nTo the pre previous meeting . That 's right .\nOK . Well , that 's why I 'll take pictures of them , then .\nI 'm gonna pass because I can't  I mean , of the  Jane took my answer .\nAh !\nSo .\nOh .\nUm , so I 'm gonna pass for the moment but y come  come back to me .\nFor the moment .\nPass .\nI think  I think \" pass \" is socially acceptable . But I will say  uh , I will actually  uh , a spin on different  slightly different spin on what you said , this issue of , uh , realizing that we could take minutes , and that actually may be a goal . So that  that may be kind of the test  in a sense , test data , uh , the  the template of what we want to test against , generating a summary . So that 's an interesting new twist on what we can do with this data .\nI agree with Jane and Eric . I think the question of how to generate queries automatically was the most interesting question that came up , and it 's something that , as you said , is a whole research topic in itself , so I don't think we 'll be able to do anything on it because we don't have funding on it , uh , in this project . But , um ,  it 's definitely something I would  want to do something on .\nI wonder if work 's already been done on it .\nLike e expert systems and stuff ,\nHmm .\nor  ? Uh - huh .\nWell , being more management lately than   than research , I think the thing that impressed me most was the people dynamics and not any of the facts . That is , I  I really enjoyed hanging out with this group of people today . So that 's what really impressed me .\nHow are we gonna find that in the data ?\nWell , if we had people wearing the wireless mikes all the time\nOh , yeah .\nYeah , I think\nWell , I mean , one thing you could search for is were people laughing a lot .\nRight .\nRight ? So .\nYeah .\nHow happy were they ?\nI 'd probably search for something like that .\nThat actually has come up a couple times in queries . I was talking to Landay\nYeah .\nand that was one of his examples .\nYeah .\nWhen  when did people laugh ?\nThat 's great .\nFind me a funny thing that Jeff said . Yeah .\nSo we need a laugh detector .\nYeah .\nMm - hmm .\nPerfect .\nYeah .\nCuz that seems to be pretty common . Not in the congressional hearings .\nNo .\nQuiet sobbing .\nSo I think we 're done .\nOK .", "topic_id": 6, "keywords": "overlap, meetings, meeting, overlapping, participation", "dialogue_id": 24}, {"text": "OK .\nGreat .\nGreat .\nOK .\nI think we 're done .\nGreat .\nh Do we need  do I need to turn something off here , or I do unplug this , or  ?\nNow these we turn off . Right ?", "topic_id": 7, "keywords": "unplug, turn, think, great, ok", "dialogue_id": 24}, {"text": "Now can you give me the uh  remote T ?\nOK , so Eva , co uh  could you read your numbers ?\nGo ahead and read . OK .\nYeah .\nAlright .\nYeah , let 's get started . Um  Hopefully Nancy will come , if not , she won't .\nUh , Robert , do you uh have any way to turn off your uh screensaver on there so that it 's not going off every  uh , it seems to have about at two minute\nYeah , I 've  I  uh  it 's not that I didn't try .\nOK .\nand um I  I told it to stay on forever and ever , but if it 's not plugged in it just doesn't obey my commands .\nOK .\nIt has a mind .\nGot it .\nBut I I just  You know , sort of keep on wiggling .\nWants to conserve .\nYeah , OK .\nBut uh  we 'll just be m m working on it at intensity so it doesn't happen . We 'll see . Should we plunge right into it ?\nYeah .\nSo , would you like to\nI think so .\nSo what I 've tried to do here is list all the decision nodes that we have identified on this  side . Commented and  what they 're about and sort of  the properties we may um give them . And here are the uh  tasks to be implemented via our data collection . So all of these tasks  The reading is out of these tasks more or less imply that the user wants to go there , sometime or the other . And analogously for example , here we have our EVA um  intention . And these are the data tasks where w we can assume the person would like to enter , view or just approach the thing . Analogously the same on the object information we can see that , you know , we have sort of created these tasks before we came up with our decision nodes so there 's a lot of things where we have no analogous tasks , and  that may or may not be a problem . We can change the tasks slightly if we feel that we should have data for e sort of for every decision node so  trying to im um  implant the intention of going to a place now , going to a place later on the same tour , or trying to plant the intention of going sometime on the next tour , or the next day or whenever .\nRight , right .\nBut I think that might be overdoing it a little .\nSo  Yeah . So let me pop up a level . And uh s s make sure that we 're all oriented the same . So What we 're gonna do today is two related things . Uh one of them is to work on the semantics of the belief - net which is going to be the main inference engine for thi the system uh making decisions . And decisions are going to turn out to be parameter choices for calls on other modules . so f the natural language understanding thing is uh , we think gonna only have to choose parameters , but You know , a fairly large set of parameters . So to do that , we need to do two things . One of which is figure out what all the choices are , which we 've done a fair amount . Then we need to figure out what influences its choices and finally we have to do some technical work on the actual belief relations and presumably estimates of the probabilities and stuff . But we aren't gonna do the probability stuff today . Technical stuff we 'll do  uh  another day . Probably next week . But we are gonna worry about all the decisions and the things that pert that contribute to them . And we 're also , sort of uh in the same process , going to work with Fey on what there should be in the dialogues . So One of the s steps that 's coming up real soon is to actually get subjects uh  in here , and have them actually record like this . Uh record dialogues more or less . And  depending on what Fey sort of provokes them to say , we 'll get information on different things .\nWell how people phrase different intentions more or less ,\nSo  Fo - v yeah people with the  phrase them\nhuh ?\nand so  Uh for , you know , Keith and people worrying about what constructions people use , uh  we have some i we have some ways to affect that by the way the dialogues go . So what Robert kindly did , is to lay out a table of the kinds of uh  things that  that might come up , and , the kinds of decisions . So the uh  uh  on the left are decision nodes , and discreet values . So if  if we 're right , you can get by with um just this middle column worth of decisions , and it 's not all that many , and it 's perfectly feasible technically to build belief - nets that will do that . And he has a handout .\nYeah . Maybe it was too fast plunging in there , because j we have two updates .\nYeah .\nUm you can look at this if you want , these are what our subject 's going to have to fill out . Any comments I can  can still be made and the changes will be put in correspondingly .\nm       Yes .\nLet me summarize in two sentences , mainly for Eva 's benefit , who probably has not heard about the data collection , at all .\nOK .\nOr have you heard about it ?\nNot that much you didn't .\nNo . OK . We were gonna put this in front of people . They give us some information on themselves .\nOK .\nThen  then they will read uh  a task where lots of German words are sort of thrown in between . And um  and they have to read isolated proper names And these change\nS I don't see a release\nNo , this is not the release form . This is the speaker information form .\nGot it . OK , fine . OK .\nThe release form is over there in that box .\nAlright , fair enough .\nAnd um  And then they gonna have to f um um choose from one of these tasks , which are listed here . They  they pick a couple , say three  uh  uh six as a matter of fact . Six different things they sort of think they would do if they were in Heidelberg or traveling someplace  and um  and they have a map .\nHmm .\nLike this . Very sketchy , simplified map . And they can take notes on that map . And then they call this computer system that works perfectly , and understands everything .\nOK .\nAnd um\nThis is a fictional system obviously ,\nThe comp Yeah , the computer system sits right in front of you ,\nhuh .\nthat 's Fey .\nI 've  I understand everything .\nAnd she does know everything .\nYes I do .\nAnd she has a way of making this machine talk . So she can copy sentences into a window , or type really fast and this machine will use speech synthesis to produce that . So if you ask \" How do I get to the castle \" then a m s several seconds later it 'll come out of here \" In order to get to the castle you do  \"", "topic_id": 0, "keywords": "screensaver, remote, commands, stay, let", "dialogue_id": 25}, {"text": "Yeah .\nOK ? And um  And then after three tasks the system breaks down . And Fey comes on the phone as a human operator . And says \" Sorry the system broke down but let 's continue . \" And we sort of get the idea what people do when they s think they speak to a machine and what people say when they think they speak to a human , or know , or assume they speak to a human .\nOK . Huh .\nMm - hmm . Mm - hmm .\nThat 's the data collection . And um  And Fey has some thirty subjects lined up ? Something ?\nYeah .\nAnd um  And they 're  r ready uh  to roll .\nAnd more and more every day .\nAnd we 're gonna start tomorrow at three ? four ? one ?\nTomorrow , well we don't know for sure . Because we don't know whether that person is coming or not ,\nOK . Around four - ish .\nbut\nAnd um we 're still l looking for a room on the sixth floor because they stole away that conference room . Um  behind our backs . But\nWell , there are these  uh  uh  oh , I see , we have to  Yeah , it 's tricky . We 'll  let 's  let  we 'll do that off - line , OK .\nYeah , but I  i i it 's happening . David and  and Jane and  and Lila are working on that as we speak .\nOK .\nOK . That was the uh  the data collection in a nutshell . And um  I can report a  so I did this but I also tried to do this  so if I click on here , Isn't this wonderful ? we get to the uh  uh belief - net just focusing on  on the g Go - there node . uh  Analogously this would be sort of the reason node and the timing node and so forth .\nMm - hmm .\nAnd what w what happened is that um design - wise I 'd sort of n noticed that we can  we still get a lot of errors from a lot of points to one of these sub Go - there User Go - there Situation nodes . So I came up with a couple of additional nodes here where um whether the user is thrifty or not , and what his budget is currently like , is going to result in some financial state of the user . How much will he  is he willing to spend ? Or can spend . Being the same at this  just the money available , which may influence us , whether he wants to go there if it is  you know  charging tons of dollars for admission or its gonna g cost a lot of t e whatever . Twenty - two million to fly to International Space Station , you know . just  Not all people can do that .\nRight .\nSo , and this actually turned out to be pretty key , because having specified sort of these  uh  this  this  intermediate level Um and sort of noticing that everything that happens here  let 's go to our favorite endpoint one is again more or less  we have  um  then the situation nodes contributing to the  the endpoint situation node , which contributes to the endpoint and so forth . um  I can now sort of draw straight lines from these to here , meaning it g of course goes where the sub - S  everything that comes from situation , everything that comes from user goes with the sub - U , and whatever we specify for the so - called \" Keith node \" , or the discourse , what comes from the  um  parser , construction parser , um will contribute to the D and the ontology to the sub - O node . And um one just s sort of has to watch which  also final decision node so it doesn't make sense  t to figure out whether he wants to enter , view or approach an object if he never wants to go there in the first place . But this makes the design thing fairly simple . And um now all w that 's left to do then is the CPG 's , the conditional probabilities , for the likelihood of a person having enough money , actually wanting to go a place if it costs , you know this or that . And um  OK . and once um Bhaskara has finished his classwork that 's where we 're gonna end up doing . You get involved in that process too . And um  And for now uh the  the question is \" How much of these decisions do we want to build in explicitly into our data collection ? \" So  Um , one could  sort of  think of  you know we could call the z see or  you know , people who visit the zoo we could s call it \" Visit the zoo tomorrow \" , so we have an intention of seeing something , but not now  but later .\nRight . Yeah . Yeah , so  let 's s uh s see I th I think that from one point of view , Uh , um , all these places are the same , so that d d That , um  in terms of the linguistics and stuff , there may be a few different kinds of places , so I th i it seems to me that We ought to decide you know , what things are k are actually going to matter to us . And um , so the zoo , and the university and the castle , et cetera . Um are all big - ish things that um  you know  have different parts to them , and one of them might be fine .\nHmm . Hmm , hmm . Yeah  The  the reason why we did it that way , as a  as a reminder , is uh  no person is gonna do all of them .\nAnd\nThey 're just gonna select u um , according to their preferences .\nYeah , yeah .\n\" Ah , yeah , I usually visit zoos , or I usually visit castles , or I usually  \" And then you pick that one .\nRight , no no , but  but s th point is to  to y to  build a system that 's got everything in it that might happen you do one thing .\nThey 're redundant .\nT to build a system that um  had the most data on a relatively confined set of things , you do something else . And the speech people , for example , are gonna do better if they  if  things come up uh  repeatedly . Now , of course , if everybody says exactly the same thing then it 's not interesting . So , all I 'm saying is i th there 's  there 's a kind of question of what we 're trying t to accomplish . and  I think my temptation for the data gathering would be to uh , you know  And each person is only gonna do it once , so you don't have to worry about them being bored , so if  if it 's one service , one luxury item , you know , one big - ish place , and so forth and so on , um  then my guess is that  that the data is going to be easier to handle . Now of course you have this I guess possible danger that somehow there 're certain constructions that people use uh when talking about a museum that they wouldn't talk about with a university and stuff , um  but I guess I 'm  I uh m my temptation is to go for simpler . You know , less variation . But I don't know what other people think about this in terms of\nSo I don't exactly understand\nuh\nlike I I  I guess we 're trying to  limit the detail of our ontology or types of places that someone could go , right ? But who is it that has to care about this , or what component of the system ?\nOh , well , uh  th I think there are two places where it comes up . One is uh  in the  th these people who are gonna take this and  and try to do speech with it .\nMm - hmm .\nuh  Lots of pronunciations of th of the same thing are going to give you better data than l you know , a few pronunciations of lots more things .\nOK .\nThat 's one .\nSo we would rather just ask  uh have a bunch of people talk about the zoo , uh and assume that that will  that the constructions that they use there will give us everything we need to know about these sort of zoo , castle , whatever type things , these bigger places .\nBigger  Y yeah thi well this is a question for\nAnd that way you get the speech data of people saying \" zoo \" over and over again or whatever too .\nYeah . Yeah .\nOK .\nYeah . So this is a question for you ,\nMm - hmm .\nand , you know , if we  if we do , and we probably will , actually try to uh build a prototype , uh probably we could get by with the prototype only handling a few of them anyway . So , Um\nYeah , the this was sort of  these are all different sort of activities . Um But I think y I  I got the point and I think I like it . We can do  put them in a more hierarchical fashion . So , \" Go to place \" and then give them a choice , you know either they 're the symphony type or opera type or the tourist site guide type or the nightclub disco type person and they say \" yeah this is  on that \" go to big - ish place \" ,\nMm - hmm .\nthis is what I would do . \" And then we have the \" Fix \" thing , and then maybe \" Do something the other day \" thing , so . My question is  I guess , to some extent , we should  y we just have to try it out and see if it works . It would be challenging , in  in a sense , to try to make it so  so complex that they even really should schedule , or to plan it , uh , a more complex thing in terms of OK , you know , they should get the feeling that there are these s six things they have to do and they sh can be done maybe in two days .\nWell  yeah .\nSo they make these decisions ,\nWell I think th th\n\" Can I go there tomorrow ? \"\nyeah .\nor  you know  influences\nMm - hmm .\nYeah . Well , I think it 's easy enough to set that up if that 's your expectation . So , the uh system could say , \" Well , uh we 'd like to  to set up your program for two days in Heidelberg , you know , let 's first think about all the things you might like to do . So there  th i i in  I mean  in  I th I  I 'm sure that if that 's what you did then they would start telling you about that , and then you could get into um various things about ordering , if you wanted .\nMm - hmm . Yeah . Yeah , but I think this is part of the instructor 's job . And that can be done , sort of to say , \" OK now we 've picked these six tasks . \" \" Now you have you can call the system and you have two days . \"\nI 'm sorry .\nAnd th w\nNo , we have to help  we have to decide . Fey will p carry out whatever we decide . But we have to decide you know , what is the appropriate scenario . That 's what we 're gonna talk about t yeah .\nYep , yep .\nBut these are two different scenarios entirely . I mean , one is a planner  The other , it kind of give you instructions on the spot\nYeah , but th the  I don't  I 'm not really interested in sort of \" Phase planning \" capabilities . But it 's more the  how do people phrase these planning requests ? So are we gonna masquerade the system as this  as you said simple response system , \" I have one question I get one response \" , or should we allow for a certain level of complexity . And a I w think the data would be nicer if we get temporal references .\nWell , so Keith , what do you think ?\nWell , um it seems that  Yeah , I mean , off the top of my head it kinda seems like you would probably just want , you know , richer data , more complex stuff going on , people trying to do more complex sets of things . I mean  you know , if our goal is to really sort of be able to handle a whole bunch of different stuff , then throwing harder situations at people will get them to do more linguistic  more interesting linguistic stuff . But I mean  I 'm  I 'm not really sure Uh , because I don't fully understand like what our choices are of ways to do this here yet .\nI mean w we have tested this and a y have you heard  listen to the f first two or th as a matter of fact the second person is uh  is  was faced with exactly this kind of setup .\nI started to listen to one and it was just like , um , uh , sort of depressing .\nAnd\nI thought I 'd just sort of listen to the beginning part and the person was just sort of reading off her script or something . And .\nOh , OK . That was the first subject .\nYeah .\nYeah .\nFirst one wasn't very good .\nYeah .\nYeah .\nSo um , I\nUm , it is  already with this it got pretty  with this setup and that particular subject it got pretty complex .\nAlthough\nMm - hmm .\nMaybe  I suggest we make some fine tuning of these , get  sort of  run through ten or so subjects\nMm - hmm .\nand then take a breather , and see whether we wanna make it more complex or not , depending on what  what sort of results we 're getting .\nRight . Yeah . It  In fact , um , I am just you know  today , next couple days gonna start really diving into this data . I 've basically looked at one of the files  you know one of these  l y y y you gave me those dozens of files and I looked at one of them which was about ten sentences , found fifteen , twenty different construction types that we would have to look for and so on and like , \" alright , well , let 's start here . \" Um . So I haven't really gone into the , you know  looked at all of the stuff that 's going on . So I don't really  Right , I mean , once I start doing that I 'll have more to say about this kind of thing .\nOK .\nAnd y and always\nBut well th but you did say something important , which is that um you can probably keep yourself fairly well occupied uh  with the simple cases for quite a while .\nYeah .\nAlthough , obviously th so  so that sa s does suggest that  Uh , now , I have looked at all the data , and it 's pre it 's actually at least to an amateur , quite redundant .\nYeah , Yeah .\nThat  that it was  it was very stylized , and quite a lot of people said more or less the same thing .\nI um  I did sort of scan it at first and noticed that , and then looked in detail at one of them .\nYeah .\nBut yeah , yeah I noticed that , too .\nSo , we  we  we wanna do more than that .\nAnd with this we 're getting more . No question .\nOK . Right . So\nuh w do we wanna get going beyond more , which is sort of the\nWell , OK , so let 's  let 's take  let 's I  I think your suggestion is good , which is we 'll do a b uh  a batch . OK . And , uh , Fey , How long is it gonna be till you have ten subjects ? Couple days ? Or thr f a A week ? Or  I don't  I don't have a feel for th\nUm  I can  Yeah , I mean I s I think can probably schedule ten people , uh , whenever .\nWell , it 's  it 's up to you , I mean I j I  uh e We don't have any huge time pressure . It 's just  when you have t\nHow long will it be ?\nYeah .\nUm  I  I would say maybe two weeks .\nOh , OK . So let 's do this . Let 's plan next Monday , OK , to have a review of what we have so far .\nThis means audio , but\nand  Huh ?\nno transcriptions of course , yeah .\nNo , we won't have the transcriptions , but what we should be able to do and I don't know if , Fey , if you will have time to do this , but it would be great if you could , um , not transcribe it all , but pick out uh , some stuff . I mean we could lis uh  just sit here and listen to it all . Are you gonna have the audio on the web site ? OK .\nUntil we reach the gigabyte thing and David Johnson s ki kills me . And we 're gonna put it on the web site . Yeah .\nOh , we could get  I mean , you can buy another disk for two hundred dollars , right ? I mean it 's  it 's not like  OK . So , we 'll take care of David Johnson .\nNo , he  uh , he  he has been solving all our problems or  is wonderful ,\nOK .\nTake  care of him .\nOK .\nso s\nAlright . So we 'll buy a disk . But anyway , so , um , If you  if you can think of a way  to uh , point us to th to interesting things , sort of as you 're doing this or  or something uh , make your  make notes or something that  that this is , you know , something worth looking at . And other than that , yeah I guess we 'll just have to uh , listen  although I guess it 's only ten minutes each , right ? Roughly .\nWell , I guess . I 'm not sure how long it 's actually going to take .\nThe reading task is a lot shorter . That was cut by fifty percent . And the reading , nobody 's interested in that except for the speech people .\nRight . No , we don't care about that at all .\nSo . It 's actually like five minutes dialogue .\nI b My guess is it 's gonna be ten .\nTen minutes is long .\nPeople  I understand , but people  people  you know uh\nIt feels like a long time\nYeah .\nbut .\nIt feels like forever when you 're doing it ,\nYeah .\nbut then it turns out to be three minutes and forty five seconds .\nYeah .\nYeah .\nCould be . OK . I was thinking people would , you know , hesitate and  Whatever . Whatever it is we 'll  we 'll deal with it .\nYeah , it 's not  And it 's fun .\nOK , so that 'll be  that 'll be  um  on  on the web page .\nOK .\nThat 's great . Um But anyway  yeah , so I think  it 's a good idea to start with the sort of relatively straight forward res just response system . And then if we want to uh  get them to start doing  uh  multiple step planning with a whole bunch of things and then organize them an um tell them which things are near each other and  you know , any of that stuff . uh  You know , \" Which things would you like to do Tuesday morning ? \"\nYeah .\nSo yeah I  th that seems  pretty straight forward .\nBut were you saying that\nI need those back by the way .\nOK .\nOK .\nYeah .\nThat 's for\nI 'm sorry , Fey , what ?\nThat w maybe one thing we should do is go through this list and sort of select things that are categories and then o offer only one member of that category ?\nThat 's what I was suggesting for the first round , yeah .\nOK .\nSo rather than having zoo and castle .\nAnd then , I mean , they could be alternate versions of the same  If you wanted data on different constructions .\nThey could , but i but i uh tha eh they c yeah , but  uh  but\nLike one person gets the version with the zoo as a choice , and the other person gets the\nYou could , but i but I  I  I think in the short run ,\nAnd no , th the per the person don't get it . I mean , this is why we did it , because when we gave them just three tasks for w part - A and three tasks for part - B a\nRight . Yeah .\nWell no , they could still choose . They just wouldn't be able to choose both zoo and say , touring the castle .\nExactly . This is limiting the choices , but yeah . Right . OK , sorry . But um I  I think this approach will very well work , but the person was able to look at it and say \" OK , This is what I would actually do . \"\nYeah .\nYeah .\nOK .\nOK .\nHe was vicious .\nOK , we gotta  we gotta disallow uh  traveling to zoos and uh castles at the same time , sort of\nI mean there  they are significantly different , but .\nBut no , they 're  I mean they 're sort of  this is where tour becomes  you know tourists maybe a bit different\nYeah , I guess so .\nand , um , these are just places where you  you enter um , much like here .\nYeah .\nBut we can uh\nYeah , in fact if y if y if you use the right verb for each in common , like at you know , \" attend a theater , symphony or opera \" is  is a group , and \" tour the university , castle or zoo \" ,\nmm - hmm Yeah .\nall of these d do have this kind of \" tour \" um  aspect about the way you would go to them . And uh , the movie theater is probably also uh  e is a \" attend \" et cetera .\nAttend , yeah .\nSo it may turn out to be not so many different kinds of things ,\nHmm , mm - hmm .\nand then , what one would expect is that  that the sentence types would  uh their responses would tend to be grouped according to the kind of activity , you would expect .\nMm - hmm .\nBut I mean i it seem that um  there is a difference between going  to see something , and things like \" exchange money \" or \" dine out \"\nOh , absolutely . Yeah .\nuh  @ @ function , yeah .\nYeah , this is where  yeah  th the function stuff is definitely different and the getting information or g stuff  yeah . OK . But this is open . So since people gonna still pick something , we we 're not gonna get any significant amount of redundancy . And for reasons , we don't want it , really , in that sense . And um we would be ultimately more interested in getting all the possible ways of people asking , oh , for different things with  or with a computer . And so if you can think of any other sort of high level tasks a tourist may do just always  just m mail them to us and we 'll sneak them into the collection . We 're not gonna do much statistical stuff with it .\nWe don't have enough .\nNo . But it seems like since we  since we are getting towards uh subject  uh fifty subjects and if we can keep it up um to a  uh  sort of five four - ish per week rate , we may even reach the one hundred before Fey t takes off to Chicago .\nThat means that one hundred people have to be interested .\nGood luck .\nYeah .\nWell , um , these are all f people off campus s from campus so far ,\nYeah .\nright ?\nYeah .\nSo we  yeah we don't know how many we can get next door at the  uh shelter for example .\nHmm .\nUh for ten bucks , probably quite a few .\nYeah . That 's right .\nYeah . So , alright , so let 's go  let 's go back then , to the  the chart with all the decisions and stuff , and see how we 're doing .\nYep .\nDo  do people think that , you know this is  is gonna  um cover what we need , or should we be thinking about more ?\nOkay , in terms of decision nodes ? I mean , Go - there is  is a yes or no .\nYep .\nRight ?\nMm - hmm .\nYep .\nI 'm also interested in th in this \" property \" uh line here , so if you look at  sorry , look at that um , timing was um  I have these three . Do we need a final differentiation there ? Now , later on the same tour , sometimes on the next tour .\nWhat 's this idea of \" next tour \" ? I mean\nIt 's sort of next day , so you 're doing something now and you have planned to do these three four things ,\nMm - hmm .\nand you can do something immediately ,\nMm - hmm .\nyou could sort of tag it on to that tour\nOr  OK .\nor you can say this is something I would do s I wanna do sometime l in my life , basically .\nOK . OK . So  so this tour is sort of just like th the idea of current s round of  of touristness or whatever ,\nRight .\nOK .\nYeah . Yeah , probably between stops back at the hotel .\nOK . Got it .\nI mean if you  if  if you wanted precise about it , uh you know ,\nGot it .\nuh  and I think that 's the way tourists do organize their lives .\nSure , sure , sure .\nYou know , \" OK , we 'll go back to the hotel and then we 'll go off\nOK .\nand  \"\nSo all tours  b a tour happens only within one day ?\nYes .\nOK .\nIt\nSo the next tour will be tomorrow ?\nRight . For this .\nOK . Just to be totally clear . OK .\nWell , my visit to Prague there were some nights where I never went back to the hotel , so whether that counts as a two - day tour or not we 'll have to  think .\nYou just spend the whole time at U Fleku or something ,\nYeah .\nI  w we will  we will not ask you more .\nri\nRight .\nRight .\nThat 's enough .\nI don't know . What is the uh  the  the English co uh um cognate if you want , for \" Sankt Nimmerlandstag \" ?\nKeine Ahnung\nSort of \" We 'll do it on  when you say on that d day it means it 'll never happen .\nYeah .\nOK .\nRight .\nDo you have an expression ? Probably you sh\nNot that I know of actually .\nYeah , when hell  Yep , we 'll do it when hell freezes over .\nYeah .\nSo maybe that should be another  property in there .\nRight .\nYeah . Yeah .\nNever .\nNo .\nOK . Um , the reason why  why do we go there in the first place IE uh  it 's either uh  for sightseeing , for meeting people , for running errands , or doing business . Entertainment is a good one in there , I think . I agree .\nSo , business is supposed to uh , be sort of  it  like professional type stuff , right , or something like that ?\nYep .\nOK . Um .\nI mean  this w this is uh an old uh Johno thing . He sort of had it in there . \" Who is the  the tour is the person ? \" So it might be a tourist ,\nMm - hmm .\nit might be a business man who 's using the system , who wants to sort of go to some\nYeah .\nYeah , or  or both .\nYeah . Yeah , I mean like for example my  my father is about to travel to Prague .\nYep .\nHe 'll be there for two weeks . He is going to uh  He 's there to teach a course at the business school but he also is touring around and so he may have some mixture of these things .\nYep .\nMmm .\nYep .\nSure . Right .\nHe would\nWhat ab What do you have in mind in terms of um  socializing ? What kind of activities ?\nEh , just meeting people , basically . \" I want to meet someone somewhere \" , which be puts a very heavy constraint on the \" EVA \"\nOh\nYeah .\nyou know , because then if you 're meeting somebody at the town hall , you 're not entering it usually , you 're just  want to approach it .\nSo  I mean , does this capture , like , where do you put  \" Exchange money \" is an errand , right ? But what about uh\nYep .\nMm - hmm\nSo , like \" Go to a movie \" is now entertainment , \" Dine out \" is\nSocializing , I guess .\nNo , I I well , I dunno . Let  Let  well , we 'll put it somewhere ,\nSo I mean  Right .\nbut  but  um  I would say that if \" Dine out \" is a special c uh  if you 're doing it for that purpose then it 's entertainment .\nYeah .\nAnd  we 'll also as y as you 'll s further along we 'll get into business about \" Well , you 're  you know  this is going over a meal time , do you wanna stop for a meal or pick up food or something ? \"\nMm - hmm .\nAnd that 's different . That 's  that 's sort of part of th that 's not a destination reason , that 's sort of \" en passant , \" right .\nRight .\nThat goes with the \" energy depletion \" function , blech .\nYeah .\nRight , yeah .\nOK , \" endpoint \" .\n\" Tourist needs food , badly \"", "topic_id": 1, "keywords": "fey, tasks, task, dialogue, thinking", "dialogue_id": 25}, {"text": "Right .\n\" Endpoint \" is pretty clear . Um , \" mode \" , uh , I have found three , \" drive there \" , \" walk there \" uh  or \" be driven \" , which means bus , taxi , BART .\nOK .\nYeah . Yep .\nObviously taxis are very different than buses , but on the other hand the system doesn't have any public transport  This  the planner system doesn't have any public transport in it yet .\nSo this granularity would suffice , I think w if we say the person probably , based on the utterance we on the situation we can conclude wants to drive there , walk there , or use some other form of transportation .\nH How much of Heidelberg can you get around by public transport ? I mean in terms of the interesting bits . There 's lots of bits where you don't really I 've only ev was there ten years ago , for a day , so I don't remember , but . I mean , like the  sort of the tourist - y bits\nMm - Well ,\nEverywhere .\nis it like\nyou can't get to the Philosophers ' Way very well ,\nYeah .\nbut , I mean there are hikes that you can't get to , but\nOK .\nYeah .\nbut I think other things you can , if I remember right .\nSo is like \" biking there \"  part of like \" driving there \" ,\nYeah , um we actually  biking should be  should be a separate point because we have a very strong bicycle planning component .\nor  ?\nSo .\nOh !\nMmm g that 's good .\nUm .\nPut it in .\nBicycles c should be in there , but , will we have bic I mean is this realistic ? I mean\nYeah .\nOK , we can leave it out , I guess .\nYeah .\nWe can  we can sort of uh , drive\nI would  I would lump it with \" walk \" because hills matter .\nYeah .\nRight ? You know . Things like that .\nYeah .\nOK . Skateboards right , anyway .\nRight .\nScooters ,\nYep .\nright ?\nOK , \" Length \" is um , you wanna get this over with as fast as possible ,\nAlright .\nyou wanna use some part of what  of the time you have . Um , they can . But we should just make a decision whether we feel that they want to use some substantial or some fraction of their time .\nYe\nHmm .\nYou know , they wanna do it so badly that they are willing to spend uh  you know the necessary and plus time . And um  And y you know , if we feel that they wanna do nothing but that thing then , you know , we should point out that  to the planner , that they probably want to use all the time they have . So , stretch out that visit for that .\nMm - hmm .\nWow  It seems like this would be really hard to guess . I mean , on the part of the system . It seems like it  I mean you 're  you 're talking about rather than having the user decide this you 're supposed t we 're supposed to figure it out ?\nw well\nTh - the user can always s say it , but it 's just sort of we  we hand over these parameters if we make  if we have a feeling that they are important .\nOverrider\nYeah .\nMm - hmm .\nAnd that we can actually infer them to a significant de degree , or we ask .\nAnd\nOK .\nAnd par yeah , and part of the system design is that if it looks to be important and you can't figure it out , then you ask .\nYeah .\nOK .\nBut hopefully you don't ask you know , a all these things all the time .\nYeah .\nOr  eh so , y but there 's th but definitely a back - off position to asking .\nYeah . Right . Yeah .\nAnd if no  no part of the system ever comes up with the idea that this could be important , no planner is ever gonna ask for it .\nYeah .\ny so  And I like the idea that , you know , sort of  Jerry pushed this idea from the very beginning , that it 's part of the understanding business to sort of make a good question of what 's s sort of important in this general picture , what you need t\nMm - hmm .\nIf you wanna simulate it , for example , what parameters would you need for the simulation ? And , Timing , uh , uh , Length would definitely be part of it , \" Costs \" , \" Little money , some money , lots of money \" ?\nMm - hmm .\nActually , maybe uh F  uh so , F Yeah , OK . Hmm ?\nYou could say \" some \" in there .\nI must say that thi this one looks a bit strange to me . Um  maybe  It seems like appropriate if I go to Las Vegas . Well  but I decide k kind of how much money uh I 'm willing to lose . But a I as a tourist , I 'll just paying what 's  what 's more or less is required .\nWell , no . I think there are  there 're different things where you have a ch choice ,\nMmm .\nYeah .\nfor example , uh this t interacts with \" do am I do oh are you willing to take a taxi ? \"\nDinner .\nOr uh , you know , if  if you 're going to the opera are you gonna l look for the best seats or the peanut gallery\nThe best seat or  or  Right .\nor , you know ,\nOK . So\nwhatever ? S so I think there are a variety of things in which um  Tour - tourists really do have different styles eating . Another one ,\nYeah .\nyou know .\nRight .\nRight , that 's true .\nThe  what  what my sort of sentiment is they 're  Well , I  I once had to write a  a  a  a charter , a carter for a  a student organization . And they had  wanted me to define what the quorum is going to be . And I looked at the other ones and they always said ten percent of the student body has to be present at their general meeting otherwise it 's not a  And I wrote in there \" En - Enough \" people have to be there . And it was hotly debated , but people agreed with me that everybody probably has a good feeling whether it was a farce , a joke , or whether there were enough people .\nYeah .\nAnd if you go to Turkey , you will find when people go shopping , they will say \" How much cheese do you want ? \" and they say \" Ah , enough . \" And the  and the  this used all over the place . Because the person selling the cheese knows , you know , that person has two kids and you know , a husband that dislikes cheese , so this is enough .\nMm - hmm .\nAnd um so the middle part is always sort of the  the golden way , right ? So you can s you can be really  make it as cheap as possible , or you can say \" I want , er , you know , I don't care \"\nMoney is no object . Mm - hmm .\nMoney is no object ,\nYeah .\nor you say \" I just want to spend enough \" .\nMm - hmm .\nOr the sufficient , or the the appropriate amount .\nYeah .\nBut , Then again , this may turn out to be insufficient for our purposes . But well , this is my first guess ,\nI mean y Yeah .\nin much the same way as how  how d you know  should the route be ? Should it be the easiest route , even if it 's a b little bit longer ?\nMm - hmm .\nNo steep inclinations ? Go the normal way ? Whatever that again means , er  or do you  does the person wanna rough it ?\nMm - hmm . I mean  th so there 's a couple of different ways you can interpret these things right ? You know  \" I want to go there and I don't care if it 's really hard . \" Or if you 're an extreme sport person , you know . \" I wanna go there and I insist on it being the hard way . \"\nRight .\nRight ? you know , so I assume we 're going for the first interpretation ,\nRight .\nright ? Something like  I 'll go th I mean  I 'd li I dunno . It 's different from thing to\nNo , I think he was going for the second one ar actually .\nYeah ? I  I\nAnyway , we 'll sort th yeah , we 'll sort that out .\nOK .\nRight .\nYeah .\nAbsolutely .\nWell , this is all sort of um , top of my head .\nYeah .\nNo  no research behind that . Um  \" Object information \" , \" Do I  do I wanna know anything about that object ? \" is either true or false . And . if I care about it being open , accessible or not , I don't think there 's any middle ground there . Um , either I wanna know where it is or not , I wanna know about it 's history or not , or , um I wanna know about what it 's good for or not . Maybe one could put scales in there , too . So I wanna know a l lot about it .\nYeah , now ob OK , I 'm sorry , go ahead , what were you gonna say ?\nOne could put scales in there . So I wanna know a lot about the history , just a bit .\nYeah , right well y i w if we  w right . So \" object \" becomes \" entity \" , right ?\nYep , that 's true .\nYeah , but we don't have to do it now .\nYep . That was the wrong shortcut anyhow .\nAnd we think that 's it , interestingly enough , that um , you know , th or  or  or something very close to it is going to be uh  going to be enough . And\nStill wrong .\nYeah .\nOK .\nAlright , so um  So I think the order of things is that um , Robert will clean this up a little bit , although it looks pretty good . And\nWhat , well this is the part that\nHuh ?\nthis is the part that needs the work .\nRight .\nYeah .\nYeah , so  right , so  So , um In parallel , uh  three things are going to happen . Uh Robert and Eva and Bhaskara are gonna actually  build a belief - net that  that , um , has CPT 's and , you know , tries to infer this from various kinds of information . And Fey is going to start collecting data , and we 're gonna start thinking a about  uh  what constructions we want to elicit . And then w go it may iterate on uh , further data collection to elicit\nD Do you mean  Do you mean eliciting particular constructions ? Or do you mean like what kinds of things we want to get people talking about ? Semantically speaking , eh ?\nWell , yes .\nOK .\nBoth . Uh , and  Though for us , constructions are primarily semantic , right ?\nRight . Sure .\nAnd  And so  uh\nI mean from my point of view I 'm  I 'm trying to care about the syntax , so you know\nWell that too ,\nOK .\nbut um  You know if th if we in  if we you know , make sure that we get them talking about temporal order .\nYeah .\nOK , that would be great and if th if they use prepositional phrases or subordinate clauses or whatever ,\nMm - hmm . Right . OK .\num  W You know , whatever form they use is fine .\nOK .\nBut I  I think that probably we 're gonna try to look at it as you know , s what semantic constructions d do we  do we want them to uh do direc\nOK .\nyou know , um , \" Caused motion \" , I don't know , something like that .\nOK .\nUh But , Eh - uh this is actually a conversation you and I have to have about your thesis fantasies , and how all this fits into that .\nGot it . Yeah . Uh Yeah . OK .\nBut uh\nWell , I will tell you the German tourist data .\nOK .\nBecause I have not been able to dig out all the stuff out of the m ta thirty D V\nOK .\nUm  If you\nIs that roughly the equivalent of  of what I 've seen in English or is it\nNo , not at all .\nOK .\nDialogues . SmartKom\nOK .\nSmartKom  Human . Wizard of Oz .\nOK . Same  OK , that . Got it . Like what  What have I got now ? I mean I have uh what  what I 'm loo what I  Those files that you sent me are the user side of some interaction with Fey ?\nA little bit of data , I\nIs that what it is ? Or  ?\nWith nothing .\nJust talking into a box and not hearing anything back .\nNo , no .\nYep .\nOK .\nYep . Some data I collected in a couple weeks for training recognizers and email way back when .\nOK . OK .\nNothing to write home about .\nOK .\nAnd um  the  see this  this  this  uh  ontology node is probably something that I will try to expand . Once we have the full ontology API , what can we expect to get from the ontology ? And hopefully you can sort of also try to find out , you know , sooner or later in the course of the summer what we can expect to get from the discourse that might , you know  or the\nMm - hmm .\nnot the discourse , the utterance as it were , uh ,\nmm - hmm .\nMm - hmm .\nRight .\nin terms of uh\nRight , but we 're not expecting Keith to actually build a parser .\nRight , Right .\nNo , no , no , no , no .\nOK . We are expecting Johno to build a parser ,\nUh , this is  Yes .\nBy the end of the summer , too .\nbut that 's a  No .\nNo .\nNo . Uh  He 's g he 's hoping to do this for his masters ' thesis s by a year from now .\nBut it 's sort of  it 's\nRight . Hmm . Still , pretty formidable actually .\nEh - absolutely . Uh  limited . I mean , you know , the idea is  is ,\nYeah .\nWell , the hope is that the parser itself is , uh , pretty robust . But it 's not popular  it 's only p only\nRight , Right . Existence proof , you know . Set up the infrastructure ,\nRight . It 's only popula\nyeah .\nRight .\nUm sometime , I have to talk to some subset of the people in this group , at least about um what sort of constructions I 'm looking for . I mean , you know obviously like just again , looking at this one uh thing , you know , I saw y things from  sort of as general as argument structure constructions . Oh , you know , I have to do Verb Phrase . I have to do uh  uh  unbounded dependencies , you know , which have a variety of constructions in  uh  uh  instantiate that . On the other hand I have to have , you know , there 's particular uh , fixed expressions , or semi - fixed expressions like \" Get \" plus path expression for , you know , \" how d ho how do I get there ? \" ,\nMm - hmm .\n\" How do I get in ? \" , \" How do I get away ? \"\nRight .\nand all that kind of stuff . Um , so there 's a variety of sort of different sorts of constructions\nAbsolutely .\nand it  you know it 's  it 's sort of like anything goes . Like\nOK , so this is  I think we 're gonna mainly work on with George .\nOK .\nOK , and hi let me f th  say what I think is  is  so the idea is  uh  first of all I misspoke when I said we thought you should do the constructions . Cause apparently for a linguist that means to do completely and perfectly . So what I  yeah , OK ,  So what  what I meant was \" Do a first cut at \" .\ner  that 's what Yeah , yeah .\nOK , Because uh  we do wanna get them r u perfectly  but I think we 're gonna have to do a first cut at a lot of them to see how they interact .\nOf course . Right , exactly . Now it  w we talked about this before , right . And I  I me it would it would be completely out of the question to really do more than , say , like , oh I don't know , ten , over the summer ,\nYeah .\nbut uh , but you know obviously we need to get sort of a general view of what things look like , so yeah .\nRight . So the idea is going to be to do  sort of like Nancy did in some of the er these papers where you do enough of them so you can go from top to bottom  so you can do f you know , f f uh  have a complete story ov of s of some piece of dialogue .\nMm - hmm .\nAnd that 's gonna be much more useful than having all of the clausal constructions and nothing else , or  or  or something like that .\nYeah . Sure . Yeah .\nSo that the  the trick is going to be t to take this and pick a  some sort of lattice of constructions ,\nMm - hmm .\nso some lexical and some phrasal , and  and , you know ,\nMm - hmm .\nwhatever you need in order to uh , be able to then , uh , by hand , you know , explain , some fraction of the utterances .\nMm - hmm . Yeah .\nAnd so , exactly which ones will partly depend on your research interests and a bunch of other things .\nMm - hmm . Sure . OK . But I mean in terms of the s th sort of level of uh  of analysis , you know , these don't necessarily have to be more complex than like the \" Out of \" construction in the BCP paper where it 's just like , you know , half a page on each one or something .\nCorrect . Oh yeah  yeah . V a half a page is  is what we 'd like .\nYeah .\nAnd if  if there 's something that really requires a lot more than that then it does and we have to do it ,\nYeah .\nbut\nFor the first cut , that should be fine , yeah .\nYeah .\nWe could sit down and think of sort of the  the ideal speaker utterances ,\nMm - hmm .\nand I mean two or three that follow each other , so , where we can also sort of , once we have everything up and running , show the tremendous , insane inferencing capabilities of our system .\nMm - hmm .\nSo , you know , as  as the SmartKom people have . This is sort of their standard demo dialogue , which is , you know , what the system survives and nothing but that .\nMm - hmm . Mm - hmm .\nUm , we could also sor sort of have the analogen of o our sample sentences , the ideal sentences where we have complete construction coverage and , sort of , they match nicely .\nMm - hmm .\nSo the  the \" How do I get to X ? \" ,\nYeah .\nyou know , that 's definitely gonna be uh , a major one .\nYeah . That 's about six times in this little one here , so uh ,  yeah .\nYep .\nRight .\n\" Where is X ? \" might be another one which is not too complicated .\nYeah . Mm - hmm .\nAnd um \" Tell me something about X . \"\nYeah .\nAnd hey , that 's  that 's already covering eighty percent of the system 's functionality .\nYe - Right , but it 's not covering eighty percent of the intellectual interest .\nYeah .\nNo , we can w throw in an \" Out of Film \" construction if you want to , but\nNo , no , no . Well the  th the thing is there 's a lot that needs to be done to get this right .\nOK .\nOK , I th We done ?\nI have one bit of news .\nGood .\nUm , the action planner guy has wrote  has written a  a p lengthy  proposal on how he wants to do the action planning .\nGood .\nAnd I responded to him , also rather lengthy , how he should do the action planning . And\n\" Action planning \" meaning \" Discourse Modeling \" ?\nYes . And I tacked on a little paragraph about the fact that the whole world calls that module a dis disc dialogue manager ,\nRight .\nand wouldn't it make sense to do this here too ?\nRight .\nAnd also Rainer M Malaka is going to be visiting us shortly , most likely in the beginning of June .\nUh - huh , I 'll be gone .\nYeah . He - he 's just in a conference somewhere and he is just swinging through town .\nSure , OK .\nAnd um  m making me incapable of going to NAACL , for which I had funding . But . No , no Pittsburg this year .\nHmm .\nWhen is the uh Santa Barbara ?\nS\nWho is going to ? uh should a lot of people . That 's something I will  would  sort of enjoy .\nProbably should go . That was  that 's one you should probably go to .\nYep .\nHow much does it cost ?\nThere 's\nI haven't planned to go .\nUh , probably we can uh  pay for it .\nOK .\nUm a student rate shouldn't be very high . So , if we all decide it 's a good idea for you to go then you 'll  we 'll pay for it .\nRight . Sure .\nThen you can go .\nI mean I  I don't have a feeling one way or the other at the moment ,\nOK .\nbut it probably is . OK , great .\nThanks .", "topic_id": 2, "keywords": "transport, transportation, heidelberg, buses, endpoint", "dialogue_id": 25}, {"text": "OK . So , uh You can fill those out , uh  after , actually , so So , I got , uh  these results from , uh , Stephane . Also , um , I think that , uh  um  we might hear later today , about other results . I think s that , uh , there were some other very good results that we 're gonna wanna compare to . But ,  r our results from other  other places , yeah .\nI I 'm sorry ? I didn't\nUm , I got this from you\nYeah .\nand then I sent a note to Sunil about the  cuz he has been running some other systems\nMm - hmm .\nother than the  the ICSI OGI one .\nOh yeah .\nSo  um , I wan wanna  wanna see what that is . But , uh , you know , so we 'll see what it is comparatively later . But  it looks like , um\nM yeah .\nYou know most of the time , even  I mean even though it 's true that the overall number for Danish  we didn't improve it If you look at it individually , what it really says is that there 's , um , uh Looks like out of the six cases , between the different kinds of , uh , matching conditions  out of the six cases , there 's basically , um , a couple where it stays about the same , uh , three where it gets better , and one where it gets worse .\nYeah .\nUh , go ahead .\nY Actually , uh , um , for the Danish , there 's still some kind of mystery because , um , um , when we use the straight features , we are not able to get these nice number with the ICSI OGI one , I mean . We don't have this ninety - three seventy - eight , we have eight\nEighty - nine forty - four .\nyeah . Uh , so , uh , that 's probably something wrong with the features that we get from OGI . Uh , and Sunil is working on  on trying to  to check everything .\nOh , and  and we have a little time on that  and  actually so\nHmm ?\nWe have a little bit of time on that , actually .\nYeah .\nWe have a day or so , so When  when  when do you folks leave ?\nUh , Sunday .\nSunday ? So So , uh Yeah , until Saturday midnight , or something , we have W we  we have time , yeah . Well , that would be good . That 'd be good .\nYeah .\nYeah . Uh , and , you know , i u when whenever anybody figures it out they should also , for sure , email Hynek because Hynek will be over there  telling people  what we did , so he should know .\nMmm . Yeah .\nGood , OK . So , um So , we 'll  we 'll hold off on that a little bit . I mean , even with these results as they are , it 's  it 's  it 's really not that bad . But  but , uh , um And it looks like the overall result as they are now , even without , you know , any  any bugs being fixed is that , uh , on the  the other tasks , we had this average of , uh , forty uh  nine percent , or so , improvement . And here we have somewhat better than that than the Danish , and somewhat worse than that on the German , but I mean , it sounds like , uh , one way or another , the methods that we 're doing can reduce the error rate from  from mel ceptrum  down by , you know  a fourth of them to , uh , a half of them . Somewhere in there , depending on the  exact case . So So that 's good . I mean , I think that , uh , one of the things that Hynek was talking about was understanding what was in the other really good proposals and  and trying to see if what should ultimately be proposed is some , uh , combination of things . Um , if , uh  Cuz there 's things that they are doing  there that we certainly are not doing . And there 's things that we 're doing that  they 're not doing . And  and they all seem like good things .\nYeah .\nSo\nMmm , yeah .\nHow much  how much better was the best system than ours ?\nSo Well , we don't know yet .\nMmm .\nUh , I mean , first place , there 's still this thing to  to work out , and second place  second thing is that the only results that we have so far from before were really development set results .\nOh , OK .\nSo , I think in this community that 's of interest . It 's not like everything is being pinned on the evaluation set . But , um , for the development set , our best result was a little bit short of fifty percent . And the best result of any system was about fifty - four , where these numbers are the , uh , relative , uh , reduction in , uh , word error rate .\nOh , OK .\nAnd , um , the other systems were , uh , somewhat lower than that . There was actually  there was much less of a huge range than there was in Aurora one . In Aurora one there were  there were systems that ba basically didn't improve things .\nHmm .\nAnd here the  the worst system  still reduced the error rate by thirty - three percent , or something , in development set .\nOh , wow .\nSo  so , you know , sort of everybody is doing things between , well , roughly a third of the errors , and half the errors being eliminated ,  uh , and varying on different test sets and so forth .\nMm - hmm .\nSo I think Um  It 's probably a good time to look at what 's really going on and seeing if there 's a  there 's a way to combine the best ideas while at the same time not blowing up the amount of , uh , resources used , cuz that 's  that 's critical for this  this test .\nDo we know anything about  who  who 's was it that had the lowest on the dev set ?\nUm , uh , the , uh , the there were two systems that were put forth by a combination of  of , uh , French Telecom and Alcatel . And , um they  they differed in some respects , but they e em one was called the French Telecom Alcatel System the other was called the Alcatel French Telecom System ,  uh , which is the biggest difference , I think . But  but there 're  there 're  there 're some other differences , too . Uh , and  and , uh , they both did very well ,\nUh - huh .\nyou know ? So ,  um , my impression is they also did very well on  on the  the , uh , evaluation set , but , um , I  I we haven't seen  you 've - you haven't seen any final results for that\nAnd they used  the main thing that  that they used was spectral subtraction ?\nyeah .\nOr\nThere is a couple pieces to it . There 's a spectral subtraction style piece  it was basically , you know , Wiener filtering . And then  then there was some p some modification of the cepstral parameters , where they\nYeah , actually , something that 's close to cepstral mean subtraction . But , uh , the way the mean is adapted  um , it 's signal dependent . I 'm  I 'm , uh So , basically , the mean is adapted during speech and not during silence .\nYeah .\nBut it 's very close to  to cepstral mean subtraction .\nBut some people have done   exactly that sort of thing , of  of  and the  I mean it 's not  To  to look in  speech only , to try to m to measure these things during speech ,\nYeah , yeah .\nthat 's p that 's not that uncommon . But i it it  so it looks like they did some  some , uh , reasonable things , uh , and they 're not things that we did , precisely . We did unreasonable things ,  which  because we like to try strange things , and  and , uh , and our things worked too .\nHmm .\nAnd so , um , uh , it 's possible that some combination of these different things that were done would be the best thing to do . But the only caveat to that is that everybody 's being real conscious of how much memory and how much CPU they 're using\nMm - hmm .\nbecause these ,    uh , standards are supposed to go on cell phones with m moderate resources in both respects .\nDid anybody , uh , do anything with the models as a  an experiment ? Or\nUh , they didn't report it , if they did .\nN nobody reported it ?\nYeah . I think everybody was focused elsewhere . Um , now , one of the things that 's nice about what we did is , we do have a  a , uh  a filtering , which leads to a  a , uh  a reduction in the bandwidth in the modulation spectrum , which allows us to downsample . So , uh , as a result of that we have a reduced , um , transmission rate for the bits .\nMm - hmm .\nThat was misreported the first time out . It  it said the same amount because for convenience sake in the particular way that this is being tested , uh , they were repeating the packets . So it was  they were s they  they had twenty - four hundred bits per second , but they were literally creating forty - eight hundred bits per second ,  um , even though y it was just repeated .\nOh . Mm - hmm . Right .\nSo , uh , in practice\nSo you could 've had a repeat count in there or something .\nWell , n I mean , this was just a ph phoney thing just to  to fit into the  the software that was testing the errors  channel errors and so on .\nOh . Oh .\nSo  so in reality , if you put this  this system in into , uh , the field , it would be twenty - four hundred bits per second , not forty - eight hundred . So , um , so that 's a nice feature of what  what we did . Um , but , um , well , we still have to see how it all comes out .\nHmm .\nUm , and then there 's the whole standards process , which is another thing altogether .\nWhen is the development set  I mean , the , uh , uh , test set results due ? Like the day before you leave or something ?", "topic_id": 0, "keywords": "results, icsi, differed, evaluation, danish", "dialogue_id": 26}, {"text": "Uh , probably the day after they leave , but we 'll have to   we 'll have to stop it the day before  we leave .\nYeah , yeah . So\nHuh .\nI think tha I think the  the meeting is on the thirteenth or something .\nYeah , this Tuesday , yeah .\nAnd , uh , they , uh Right . And the  the , uh , results are due like the day before the meeting or something . So\nYeah , probably , well\nI th I think  I I think they are ,\nYeah , well\nyeah . So   um , since we have a bit farther to travel than  some of the others ,  uh , we 'll have to get done a little quicker . But , um , I mean , it 's just tracing down these bugs . I mean , just exactly this sort of thing of , you know , why  why these features seem to be behaving differently , uh , in California than in Oregon .\nHmm .\nMight have something to do with electricity shortage . Uh , we didn't  we didn't have enough electrons here and Uh , but , um Uh , I think , you know , the main reason for having  I mean , it only takes w to run the  the two test sets in  just in computer time is just a day or so , right ?\nYeah ,\nSo\nit 's very short interval .\nyeah . So , I think the who the whole reason for having as long as we have , which was  like a week and a half , is  is because of bugs like that . So Huh So , we 're gonna end up with these same kind of sheets that have the  the percentages and so on just for the\nYeah , so there are two more columns in the sheets ,\nOh , I guess it 's the same sheets ,\ntwo . Yeah , it 's the same sheets ,\nyeah , yeah\nyeah .\njust with the missing columns filled in .\nYeah .\nYeah . Well , that 'll be good . So , I 'll dis I 'll disregard these numbers . That 's  that 's  that 's good .\nSo , Hynek will try to push for trying to combine , uh , different things ? Or Hmm ?\nUh , well that 's  um yeah I mean , I think the question is \" Is there  is there some advantage ? \" I mean , you could just take the best system and say that 's the standard . But the thing is that if different systems are getting at good things , um , a again within the constraint of the resources , if there 's something simple that you can do Now for instance , uh , it 's , I think , very reasonable to have a standard for the terminal 's side and then for the server 's side say , \" Here 's a number of things that could be done . \" So , um , everything that we did could probably just be added on to what Alcatel did , and i it 'd probably work pretty well with them , too . So , um , uh , that 's one  one aspect of it . And then on the terminal 's side , I don't know how much , um , memory and  and CPU it takes , but it seems like the filtering  Uh , I mean , the VAD stuff they both had , right ? And , um , so  and they both had some kind of on - line normalization , right ?\nUh , yeah .\nOf sorts , yeah ? So  so , it seems like the main different there is the  is the , uh , filtering . And the filtering  I think if you can  shouldn't take a lot of memory to do that Uh , and I also wouldn't think the CPU , uh , would be much either for that part . So , if you can  if you can add those in  um  then , uh , you can cut the data rate in half .\nYeah .\nSo it seems like the right thing to do is to  on the  on the terminal 's side , take what they did , if it  if it does seem to generalize well to German and Danish , uh , take what they did add in a filter , and add in some stuff on the server 's side and  and  and that 's probably a reasonable standard . Um  Uh\nThey are working on this already ? Because  yeah , Su - Sunil told me that he was trying already to put some kind of , uh , filtering in the   France Telecom .\nYeah , so that 's  that 's  that 's what That would be ideal  would be is that they could , you know , they could actually show that , in fact , a combination of some sort ,  uh , would work even better than what  what any of the systems had . And , um , then it would  it would , uh  be something to  to discuss in the meeting . But , uh , not clear what will go on . Um , I mean , on the one hand , um , sometimes people are just anxious to get a standard out there . I mean , you can always have another standard after that , but  this process has gone on for a while on  already and  and people might just wanna pick something and say , \" OK , this is it . \" And then , that 's a standard . Uh , standards are always optional . It 's just that , uh , if you disobey them , then you risk not being able to sell your product , or   Uh  um And people often work on new standards while an old standard is in place and so on . So it 's not final even if they declared a standard . The other hand , they might just say they just don't know enough yet to  to declare a standard . So you  you  you will be  you will become experts on this and know more  far more than me about the tha this particular standards process once you  you go to this meeting . So , be interested in hearing . So , uh , I 'd be , uh , interested in hearing , uh , your thoughts now I mean you 're almost done . I mean , you 're done in the sense that , um , you may be able to get some new features from Sunil , and we 'll re - run it . Uh , but other than that , you 're  you 're basically done , right ? So , uh , I 'm interested in hearing  hearing your thoughts about  where you think we should go from this .\nYeah .\nI mean , we tried a lot of things in a hurry , and , uh , if we can back off from this now and sort of take our time with something , and not have doing things quickly be quite so much the constraint , what  what you think would be the best thing to do .\nUh , well Hmm Well , first , uh , to really have a look at  at the speech   from these databases because , well , we tried several thing , but we did not really look  at what what 's happening , and  where is the noise , and\nOK .\nEh\nIt 's a novel idea . Look at the data . OK .\nYeah .\nOr more generally , I guess , what  what is causing the degradation .\nYeah , yeah . Actually , there is one thing that  well  Um , generally we  we think that  most of the errors are within phoneme classes , and so I think it could be interesting to  to see if it  I don't think it 's still true when we add noise , and  so we have  I  I guess the confusion ma the confusion matrices are very different when  when we have noise , and when it 's clean speech . And probably , there is much more  between classes errors for noisy speech .\nMm - hmm .\nAnd  so , um Yeah , so perhaps we could have a  a large gain , eh , just by looking at improving the , uh , recognition , not of phonemes , but of phoneme classes , simply .\nMm - hmm .\nAnd  which is a s a s a simpler problem , perhaps , but  which is perhaps important for noisy speech .\nThe other thing that strikes me , just looking at these numbers is , just taking the best cases , I mean , some of these , of course , even with all of our  our wonderful processing , still are horrible kinds of numbers . But just take the best case , the well - matched  uh , German case after  er well - matched Danish after we\nMm - hmm .\nthe kind of numbers we 're getting are about eight or nine  uh  p percent  error  per digit .\nMm - hmm . Yeah .\nThis is obviously not usable ,\nNo .\nright ?\nSure .\nI mean , if you have ten digits for a phone number  I mean , every now and then you 'll get it right . I mean , it 's  it 's , uh ,  um So , I mean , the other thing is that , uh  And  and  a and  and also , um  part of what 's nice about this is that this is , uh ,  um  a realistic  almost realistic database . I mean , it 's still not people who are really trying to accomplish something , but  but , uh , within the artificial setup , it isn't noise artificially added , you know , simulated , uh , additive noise .\nMm - hmm .\nIt 's real noise condition . And , um ,  the  the training  the training , I guess , is always done on the close talking\nNo , actually  actually the well - matched condition  is  still quite di still quite difficult .\nNo ?\nI mean , it 's  they have all these data from the close mike and from the distant mike ,  from different driving condition , open window , closed window ,\nYeah .\nand they take all of this and they take seventy percent , I think , for training and thirty percent for testing .\nMm - hmm .\nSo , training is done  on different conditions and different microphones , and testing also is done  on different microphone and conditions . So , probably if we only take the close microphones ,  I guess the results should be much much better than this .\nI see .\nMmm .\nOh , OK ,\nUh\nthat explains it partially . Wha - what about i in  so the  the\nYeah , so  there is this , the mismatched is , um  the same kind of thing ,\ngo ahead .\nbut  the driving conditions , I mean the speed and the kind of road , is different for training and testing , is that right ?\nYeah .\nAnd the last condition is close microphone for training and distant for testing . Yeah .\nUh , OK ,\nSo   s so\nso I see . So , yeah , so the high  so the  right  so the highly mismatched  case  is in some sense a good model for what we 've been , you know , typically talking about when we talk about additive noise in  And so  and i i k it does correspond to a realistic situation in the sense that ,  um , people might really be trying to , uh , call out telephone numbers or some or something like that , in  in their cars\nYeah .\nand they 're trying to connect to something .\nMmm .\nUm\nActually , yeah , it 's very close to clean speech training because , well , because the close microphone  and noisy speech testing ,\nYeah . Yeah .\nyeah . Mmm .\nYeah . And the well - matched condition  is what you might imagine that you might be able to approach , if you know that this is the application . You 're gonna record a bunch on people in cars and so forth , and do these training . And then , uh , when y you sell it to somebody , they will be a different person with a different car , and so on . So it 's  this is a an optim somewhat optimistic view on it , uh , so , you know , the real thing is somewhere in between the two .\nYeah .\nUh , uh , but\nBut the  I mean , the  th th\nEven the optimistic one is\nit doesn't work .\nYeah ,", "topic_id": 1, "keywords": "bugs, meeting, shortage, electricity, oregon", "dialogue_id": 26}, {"text": "It\nright . Right , it doesn't work . So , in a way , that 's , you know , that 's sort of the dominant thing is that even , say on the development set stuff that we saw , the , uh , the numbers that , uh , that Alcatel was getting when choosing out the best single numbers ,  it was just  you know , it wasn't good enough for  for  a  a  for a real system .\nMmm . Mm - hmm .\nYou  you  you ,  um So , uh , we still have stuff to do .\nYeah .\nUh , and , uh I don't know So , looking at the data , where , you know  what 's the  what 's  what 's th what 's characteristic i e yeah , I think that 's  that 's a good thing . Does a any you have any thoughts about what else  y you 're thinking that you didn't get to that you would like to do if you had more time ? Uh\nOh , f a lot of thing . Because we trying a lot of s  thing , and we doesn't work ,  we remove these . Maybe  we trying again with the articulatory feature . I don't know exactly because we tried  we  some  one experiment that doesn't work . Um , forgot it , something  I don't know exactly\nMm - hmm .\nbecause , tsk   maybe do better some step the general ,  eh , diagram .\nMm - hmm .\nI don't know exactly s to think what we can improve .\nYeah , cuz a lot of time it 's true , there were a lot of times when we 've tried something and it didn't work right away , even though we had an intuition that there should be something there . And so then we would just stop it . Um And , uh , one of the things  I don't remember the details on , but I remember at some point , when you were working with a second stream , and you tried a low - pass filtering to cepstrum , in some case you got\nMSG Yeah .\nWell , but it was  an MSG - like thing , but it wasn't MSG , right ? Uh , you  y I think in some case you got some little improvement , but it was , you know , sort of a small improvement , and it was a  a big added complication , so you dropped it . But , um , that was just sort of one try , right ? You just took one filter , threw it there ,\nYeah ,\nright ? And it seems to me that , um , if that is an important idea , which , you know , might be , that one could work at it for a while , as you 're saying .\nHmm .\nAnd , uh Uh , and you had , you know , you had the multi - band things also , and , you know , there was issue of that .\nYeah ,\nUm , Barry 's going to be , uh , continuing working on multi - band things as well .\nMm - hmm .\nWe were just talking about , um ,  some , uh , some work that we 're interested in . Kind of inspired by the stuff by Larry Saul with the , uh  uh , learning articulatory feature in  I think , in the case of his paper  with sonorance based on , uh , multi - band information where you have a  a combination of gradient learning an and , uh , EM .\nMm - hmm .\nUm , and    Um , so , I think that , you know , this is a , uh  this is a neat data set . Um , and then , uh , as we mentioned before , we also have the  the new , uh , digit set coming up from recordings in this room . So , there 's a lot of things to work with . Um and , uh what I like about it , in a way , is that , uh , the results are still so terrible . Uh   Uh   I mean , they 're much better than they were , you know . We 're talking about thirty to sixty percent , uh , error rate reduction . That 's  that 's really great stuff to  to do that in relatively short time . But even after that it 's still , you know , so poor that  that , uh , no one could really use it . So , um I think that 's great that  because  and y also because again , it 's not something  sometimes we 've gotten terrible results by taking some data , and artificially , you know , convolving it with some room response , or something  we take a very  Uh , at one point , uh , Brian and I went downstairs into the  the basement where it was  it was in a hallway where it was very reverberant and we  we made some recordings there . And then we   we , uh  uh , made a simulation of the  of the room acoustics there and  and applied it to other things ,\nMm - hmm .\nand uh But it was all pretty artificial , and  and , you know , how often would you really try to have your most crucial conversations in this very reverberant hallway ? Um  So , uh  This is what 's nice about the Aurora data and the data here , is that  is that it 's sort of a realistic room situation  uh , acoustics  acoustic situation , both terms in noise and reflections , and so on and n n And , uh , uh , with something that 's still relatively realistic , it 's still very very hard to do very well . So Yeah .\nYeah , so d well Actually , this is  tha that 's why we  well , it 's a different kind of data . We 're not  we 're not used to work with this kind of data . That 's why we should have a loo more closer look at what 's going on .\nYeah .\nMm - hmm .\nUm Yeah . So this would be the first thing , and then , of course , try to  well ,  kind of debug what was wrong , eh , when we do Aurora test on the MSG  particularly , and on the multi - band .\nYeah . Yeah . Yeah .\nUh\nYeah . Yeah . No , I  I think there 's lots of  lots of good things to do with this . So Um So let 's  I guess  You were gonna say something else ? Oh , OK . What do you think ?\nAbout\nAnything\nAbout other experiments ? Uh , now , I 'm interested in , um , uh  looking at the experiments where you use , um  uh , data from multiple languages to train the neural net . And I don't know how far , or if you guys even had a chance to try that , but  that would be some it 'd be interesting to me .\nYeah , but\nS b\nAgain , it 's the kind of  of thing that , uh , we were thin thinking  thinking that it would work , but it didn't work . And , eh , so there is kind of  of  not a bug , but something wrong in what we are doing , perhaps .\nYeah .\nRight . Right .\nUh , something wrong , perhaps in the  just in the  the fact that the labels are\nRight .\nwell\nMm - hmm .\nWhat worked best is the hand - labeled data .\nMm - hmm .\nUm Uh , so , yeah . I don't know if we can get some hand - labeled data from other languages .\nYeah .\nIt 's not so easy to find .\nRight .\nBut  that would be something interesting t to  to see .\nYeah , yeah .\nYeah . Also , uh ,  I mean , there was just the whole notion of having multiple nets that were trained on different data . So one form of different data was  is from different languages , but the other Well , i in fact , uh , m in those experiments it wasn't so much combining multiple nets , it was a single net that had different\nYeah .\nSo , first thing is would it be better if they were multiple nets , for some reason ? Second thing is , never mind the different languages , just having acoustic conditions rather than training them all up in one , would it be helpful to have different ones ? So , um That was a question that was kind of raised by Mike Shire 's thesis , and on  in that case in terms of reverberation . Right ? That  that sometimes it might be better to do that . But , um ,  I don't think we know for sure . So , um Right . So , next week , we , uh , won't meet because you 'll be in Europe . Whe - when are you two getting back ?\nUm , I 'm\nYou on Friday or S on Saturday or  ?\nSunday\nS oh yeah , Sunday , yeah .\nbecause it 's  it 's less expensive , the price  the price the ticket .\nYeah , that 's right . You 've gotta S have a Saturday overnight , right ?\nI 'll be back on Tuesday .\nTuesday .\nWhere  where 's the meeting ?\nUh , Amsterdam , I think , yeah ?\nYeah , Amsterdam .\nUh - huh .\nYeah . Yeah , yeah . Yep . Um  So , we 'll skip next week , and we 'll meet two weeks from now . And , uh , I guess the main topic will be , uh , you telling us what happened .\nYeah .\nYeah .\nUh , so Yeah , well , if we don't have an anything else to discuss , we should , uh , turn off the machine and then say the real nasty things .\nShould we do digits first ?\nYeah .\nOh , yeah , digits .\nOh yeah , digits ! Yeah . Good point . Yeah , good thinking . Why don't you go ahead .\nOK . OK .", "topic_id": 2, "keywords": "articulatory, intuition, things, thinking, data", "dialogue_id": 26}, {"text": "Hey , you 're not supposed to be drinking in here dude .\nOK .\nDo we have to read them that slowly ? OK . Sounded like a robot . Um , this is t\nOK .\nWhen you read the numbers it kind of reminded me of beat poetry .\nI tried to go for the EE Cummings sort of feeling , but\nThree three six zero zero . Four two zero zero one seven . That 's what I think of when I think of beat poetry .\nBeat poetry .\nYou ever seen \" So I married an axe murderer \" ?\nUh parts of it .\nMm - hmm .\nThere 's a part wh there 's parts when he 's doing beat poetry .\nOh yeah ?\nAnd he talks like that . That 's why I thi That uh probably is why I think of it that way .\nHmm . No , I didn't see that movie . Who did  who made that ?\nMike Meyers is the guy .\nOh . OK .\nIt - it 's his uh  it 's his cute romantic comedy . That 's  that 's  That 's his cute romantic comedy , yeah . The other thing that 's real funny , I 'll spoil it for you . is when he 's  he works in a coffee shop , in San Francisco , and uh he 's sitting there on this couch and they bring him this massive cup of espresso , and he 's like \" excuse me I ordered the large espresso ? \"\nUh . We 're having ,  a tiramisu tasting contest this weekend .\nWait  do are y So you 're trying to decide who 's the best taster of tiramisu ?\nNo ? Um . There was a  a  a fierce argument that broke out over whose tiramisu might be the best and so we decided to have a contest where those people who claim to make good tiramisu make them ,\nAh .\nand then we got a panel of impartial judges that will taste  do a blind taste  and then vote .\nHmm .\nShould be fun .\nSeems like  Seems like you could put a s magic special ingredient in , so that everyone know which one was yours . Then , if you were to bribe them , you could uh\nMm - hmm . Well , I was thinking if um  y you guys have plans for Sunday ? We 're  we 're not  it 's probably going to be this Sunday , but um we 're sort of working with the weather here because we also want to combine it with some barbecue activity where we just fire it up and what  whoever brings whatever you know , can throw it on there . So only the tiramisu is free , nothing else .\nWell , I 'm going back to visit my parents this weekend , so , I 'll be out of town .\nSo you 're going to the west Bay then ? No ,\nNo , the South Bay ,\nsouth Bay ?\nyeah .\nSouth Bay .\nWell , I should be free , so .\nOK , I 'll let you know .\nOK .\nWe are . Is Nancy s uh gonna show up ? Mmm . Wonder if these things ever emit a very , like , piercing screech right in your ear ?\nThey are gonna get more comfortable headsets . They already ordered them . OK .\nUh\nLet 's get started . The uh  Should I go first , with the uh , um , data . Can I have the remote  control . Thank you . OK . So . On Friday we had our wizard test data test and um  these are some of the results . This was the introduction . I actually uh , even though Liz was uh kind enough to offer to be the first subject , I sort of felt that she knew too much , so I asked uh Litonya . just on the spur of the moment , and she was uh kind enough to uh serve as the first subject .\nMm - hmm .\nSo , this is what she saw as part of  as uh for instr introduction , this is what she had to read  aloud . Uh , that was really difficult for her and uh\nBecause of l all the names , you mean ?\nThe names and um this was the uh first three tasks she had to  to master after she called the system , and um then of course the system broke down , and those were the l uh uh I should say the system was supposed to break down and then um these were the remaining three tasks that she was going to solve , with a human  Um . There are  here are uh the results . Mmm . And I will not  We will skip the reading now . D Um . And um . The reading was five minutes , exactly . And now comes the  This is the phone - in phase of\nWait , can I  I have a question . So . So there 's no system , right ? Like , there was a wizard for both uh  both parts , is this right ?\nYeah . It was bo it both times the same person .\nOK .\nOne time , pretending to be a system , one time , to  pretending to be a human , which is actually not pretending .\nOK . And she didn't\nI should\nI mean . Well . Isn't this kind of obvious when it says \" OK now you 're talking to a human \" and then the human has the same voice ?\nNo no no . We u Wait . OK , good question , but uh you  you just wait and see .\nOK .\nIt 's  You 're gonna l learn . And um the wizard sometimes will not be audible , Because she was actually  they  there was some uh lapse in the um wireless , we have to move her closer .\nIs she mispronouncing \" Anlage \" ? Is it \" Anlaga \" or \" Anlunga \"\nThey 're mispronouncing everything ,\nOK .\nbut it 's  This is the system breaking down , actually . \" Did I call Europe ? \" So , this is it . Well , if we  we um\nSo , are  are you trying to record this meeting ?\nThere was a strange reflex . I have a headache . I 'm really sort of out of it . OK , the uh lessons learned . The reading needs to be shorter . Five minutes is just too long . Um , that was already anticipated by some people suggested that if we just have bullets here , they 're gonna not  they 're  subjects are probably not gonna  going to follow the order . And uh she did not .\nReally ?\nShe  No .\nOh , it 's surprising .\nShe  she jumped around quite a bit .\nS so if you just number them \" one \" , \" two \" , \" three \" it 's\nYeah , and make it sort of clear in the uh\nOK . Right .\nUm . We need to  So that 's one thing . And we need a better introduction for the wizard . That is something that Fey actually thought of a  in the last second that sh the system should introduce itself , when it 's called .\nMm - hmm . True .\nAnd um , um , another suggestion , by Liz , was that we uh , through subjects , switch the tasks . So when  when they have task - one with the computer , the next person should have task - one with a human , and so forth .\nMm - hmm .\nSo we get nice um data for that . Um , we have to refine the tasks more and more , which of course we haven't done at all , so far , in order to avoid this rephrasing , so where , even though w we don't tell the person \" ask  blah - blah - blah - blah - blah \" they still try , or at least Litonya tried to um repeat as much of that text as possible .\nSay exactly what 's on there ? Yeah .\nAnd uh my suggestion is of course we  we keep the wizard , because I think she did a wonderful job ,\nGreat .\nin the sense that she responded quite nicely to things that were not asked for , \" How much is a t a bus ticket and a transfer \" so this is gonna happen all the time , we d you can never be sure .\nMm - hmm .\nUm . Johno pointed out that uh we have maybe a grammatical gender problem there with wizard .\nYes .\nSo um .\nI wasn't  wasn't sure whether wizard was the correct term for  uh \" not a man \" .\nThere 's no female equivalent of\nBut uh\nAre you sure ?\nNo , I don't know .\nRight .\nNot that I know of .\nWell , there is witch and warlock ,\nYeah , that 's so @ @ .\nRight .\nYeah , that 's what I was thinking , but\nand uh\nRight . Uh .\nOK . And um  So , some  some work needs to be done , but I think we can uh  And this , and  in case no  you hadn't seen it , this is what Litonya looked at during the uh  um while taking the  while partaking in the data collection .\nAh .\nOK , great . So  first of all , I agree that um we should hire Fey , and start paying her . Probably pay for the time she 's put in as well . Um , do you know exactly how to do that , or is uh Lila  I mean , you know what exactly do we do to  to put her on the payroll in some way ?\nI 'm completely clueless , but I 'm willing to learn .\nOK . Well , you 'll have to . Right . So anyway , um\nN\nSo why don't you uh ask Lila and see what she says about you know exactly what we do for someone in th\nStudent - type worker ,\nWell , yeah she 's un she 's not a  a student ,\nor  ?\nshe just graduated but anyway .\nHmm .\nSo i if  Yeah , I agree , she sounded fine , she a actually was  uh , more uh , present and stuff than  than she was in conversation , so she did a better job than I would have guessed from just talking to her .\nYeah .\nSo I think that 's great .\nThis is sort of what I gave her , so this is for example h how to get to the student prison ,\nYeah .\nand I didn't even spell it out here and in some cases I  I spelled it out a little bit um more thoroughly ,\nRight .\nthis is the information on  on the low sunken castle , and the amphitheater that never came up , and um , so i if we give her even more um , instruments to work with I think the results are gonna be even better .\nOh , yeah , and then of course as she does it she 'll  she 'll learn @ @ . So that 's great . Um  And also if she 's willing to take on the job of organizing all those subjects and stuff that would be wonderful .\nMmm .\nAnd , uh she 's  actually she 's going to graduate school in a kind of an experimental paradigm , so I think this is all just fine in terms of h her learning things she 's gonna need to know uh , to do her career .\nMmm .\nSo , I  my guess is she 'll be r r quite happy to take on that job . And , so\nYep . Yeah she  she didn't explicitly state that so .\nGreat .\nAnd um I told her that we gonna um figure out a meeting time in the near future to refine the tasks and s look for the potential sources to find people . She also agrees that you know if it 's all just gonna be students the data is gonna be less valuable because of that so .\nWell , as I say there is this s set of people next door , it 's not hard to\nWe 're already  Yeah .\nuh\nHowever , we may run into a problem with a reading task there . And um , we 'll see .\nYeah . We could talk to the people who run it and um see if they have a way that they could easily uh tell people that there 's a task , pays ten bucks or something ,\nMm - hmm . Yeah .\nbut um you have to be comfortable reading relatively complicated stuff . And  and there 'll probably be self - selection to some extent .", "topic_id": 0, "keywords": "poetry, comedy, cummings, movie, conversation", "dialogue_id": 27}, {"text": "Mmm . Yep .\nUh , so that 's good . Um . Now ,  I signed us up for the Wednesday slot , and part of what we should do is this .\nOK .\nSo , my idea on that was  uh , partly we 'll talk about system stuff for the computer scientists , but partly I did want it to get the linguists involved in some of this issue about what the task is and all  um you know , what the dialogue is , and what 's going on linguistically , because to the extent that we can get them contributing , that will be good . So this issue about you know re - formulating things ,\nYep .\nmaybe we can get some of the linguists sufficiently interested that they 'll help us with it , uh , other linguists , if you 're a linguist , but in any case ,\nYep .\num , the linguistics students and stuff . So my idea on  on Wednesday is partly to uh  you  I mean , what you did today would  i is just fine . You just uh do \" this is what we did , and here 's the  thing , and here 's s some of the dialogue and  and so forth . \" But then , the other thing of course is we should um give the computer scientists some idea of  of what 's going on with the system design , and where we think the belief - nets fit in and where the pieces are and stuff like that . Is  is this  make sense to everybody ?\nYep .\nYeah . So , I don't  I don't think it 's worth a lot of work , particularly on your part , to  to  to make a big presentation . I don't think you should  you don't have to make any new  uh PowerPoint or anything . I think we got plenty of stuff to talk about . And , then um just see how a discussion goes .\nMm - hmm . Sounds good . The uh other two things is um we 've  can have Johno tell us a little about this\nGreat .\nand we also have a l little bit on the interface , M - three - L enhancement , and then um that was it , I think .\nSo , what I did for this  this is  uh , a pedagogical belief - net because I was  I  I took  I tried to conceptually do what you were talking about with the nodes that you could expand out  so what I did was I took  I made these dummy nodes called Trajector - In and Trajector - Out that would isolate the things related to the trajector .\nYep .\nAnd then there were the things with the source and the path and the goal .\nYep .\nAnd I separated them out . And then I um did similar things for our  our net to  uh with the context and the discourse and whatnot , um , so we could sort of isolate them or whatever in terms of the  the top layer .\nMm - hmm .\nAnd then the bottom layer is just the Mode . So .\nSo , let 's  let 's  Yeah , I don't understand it . Let 's go  Slide all the way up so we see what the p the p very bottom looks like , or is that it ?\nYeah , there 's just one more node and it says \" Mode \" which is the decision between the\nYeah .\nOK , great . Alright .\nSo basically all I did was I took the last  belief - net\nSo  Mm - hmm .\nand I grouped things according to what  how I thought they would fit in to uh image schemas that would be related . And the two that I came up with were Trajector - landmark and then Source - path - goal as initial ones .\nYep . Mm - hmm .\nAnd then I said well , uh the trajector would be the person in this case probably .\nRight , yep .\nUm , you know , we have  we have the concept of what their intention was , whether they were trying to tour or do business or whatever ,\nRight .\nor they were hurried . That 's kind of related to that . And then um in terms of the source , the things  uh the only things that we had on there I believe were whether  Oh actually , I kind of ,  I might have added these cuz I don't think we talked too much about the source in the old one but uh whether the  where I 'm currently at is a landmark might have a bearing on whether\nMm - hmm .\nor the \" landmark - iness \" of where I 'm currently at . And \" usefulness \" is basi basically means is that an institutional facility like a town hall or something like that that 's not  something that you 'd visit for tourist 's  tourism 's sake or whatever . \" Travel constraints \" would be something like you know , maybe they said they can  they only wanna take a bus or something like that , right ? And then those are somewhat related to the path ,\nMm - hmm .\nso that would determine whether we 'd  could take  we would be telling them to go to the bus stop or versus walking there directly . Um , \" Goal \" . Similar things as the source except they also added whether the entity was closed and whether they have somehow marked that is was the final destination . Um , and then if you go up , Robert , Yeah , so  um , in terms of Context , what we had currently said was whether they were a businessman or a tourist of some other person . Um , Discourse was related to whether they had asked about open hours or whether they asked about where the entrance was or the admission fee , or something along those lines .\nMm - hmm .\nUh , Prosody I don't really  I 'm not really sure what prosody means , in this context , so I just made up you know whether  whether what they say is  or h how they say it is  is that .\nRight , OK .\nUm , the Parse would be what verb they chose , and then maybe how they modified it , in the sense of whether they said \" I need to get there quickly \" or whatever .\nMm - hmm .\nAnd um , in terms of World Knowledge , this would just basically be like opening and closing times of things , the time of day it is , and whatnot .\nWhat 's \" tourbook \" ?\nTourbook ? That would be , I don't know , the \" landmark - iness \" of things ,\nMm - hmm .\nwhether it 's in the tourbook or not .\nCh - ch - ch - ch . Now . Alright , so I understand what 's  what you got . I don't yet understand  how you would use it . So let me see if I can ask\nWell , this is not a working Bayes - net .\na s Right . No , I understand that , but  but um So , what  Let 's slide back up again and see  start at the  at the bottom and Oop - bo - doop - boop - boop . Yeah . So , you could imagine w Uh , go ahead , you were about to go up there and point to something .\nWell I  OK , I just  Say what you were gonna say .\nGood , do it !\nOK .\nNo no , go do it .\nUh  I  I 'd  No , I was gonna wait until\nOh , OK . So , so if you  if we made  if we wanted to make it into a  a real uh Bayes - net , that is , you know , with fill  you know , actually f uh , fill it @ @ in , then uh\nSo we 'd have to get rid of this and connect these things directly to the Mode .\nWell , I don't  That 's an issue . So , um\nCuz I don't understand how it would work otherwise .", "topic_id": 1, "keywords": "linguists, linguistics, linguist, linguistically, discourse", "dialogue_id": 27}, {"text": "Well , here 's the problem . And  and uh  Bhaskara and I was talking about this a little earlier today  is , if we just do this , we could wind up with a huge uh , combinatoric input to the Mode thing . And uh\nWell I  oh yeah , I unders I understand that , I just  uh it 's hard for me to imagine how he could get around that .\nWell , i But that 's what we have to do .\nOK .\nOK , so , so , uh . There  there are a variety of ways of doing it . Uh . Let me just mention something that I don't want to pursue today which is there are technical ways of doing it , uh I I slipped a paper to Bhaskara and  about Noisy - OR 's and Noisy - MAXes and there 're ways to uh sort of back off on the purity of your Bayes - net - edness .\nMmm .\nUh , so . If you co you could ima and I now I don't know that any of those actually apply in this case , but there is some technology you could try to apply .\nSo it 's possible that we could do something like a summary node of some sort that  OK .\nYeah . Yeah . And , um So .\nSo in that case , the sum we 'd have  we  I mean , these wouldn't be the summary nodes . We 'd have the summary nodes like where the things were  I guess maybe if thi if things were related to business or some other\nYeah .\nYeah .\nSo what I was gonna say is  is maybe a good at this point is to try to informally  I mean , not necessarily in th in this meeting , but to try to informally think about what the decision variables are . So , if you have some bottom line uh decision about which mode , you know , what are the most relevant things .\nMmm .\nAnd the other trick , which is not a technical trick , it 's kind of a knowledge engineering trick , is to make the n  each node sufficiently narrow that you don't get this combinatorics . So that if you decided that you could characterize the decision as a trade - off between three factors , whatever they may be , OK ? then you could say \" Aha , let 's have these three factors \" , OK ? and maybe a binary version f for each , or some relatively compact decision node just above the final one .\nMmm .\nAnd then the question would be if  if those are the things that you care about , uh can you make a relatively compact way of getting from the various inputs to the things you care about . So that y so that , you know , you can sort of try to do a knowledge engineering thing\nOK .\ngiven that we 're not gonna screw with the technology and just always use uh sort of orthodox Bayes - nets , then we have a knowledge engineering little problem of how do we do that . Um and\nSo what I kind of need to do is to take this one and the old one and merge them together ?\n\" Eh - eh - eh . \" Yeah .\nSo that\nWell , mmm , something . I mean , so uh , Robert has thought about this problem f for a long time , cuz he 's had these examples kicking around , so he may have some good intuition about you know , what are the crucial things .\nMmm .\nand , um , I understand where this  the uh  this is a way of playing with this abs Source - path - goal trajector exp uh uh abstraction and  and sort of sh displaying it in a particular way .\nYeah .\nUh , I don't think our friends uh on Wednesday are going to be able to  Well , maybe they will . Well , let me think about whether  whether I think we can present this to them or not . Um , Uh ,\nWell , I think this is still , I mean , ad - hoc . This is sort of th the second  version and I  I  I  look at this maybe just as a , you know , a  a  whatever , UML diagram or , you know , as just a uh screen shot , not really as a Bayes - net as John  Johno said .\nWe could actually , y yeah draw it in a different way , in the sense that it would make it more abstract .\nYeah . But the uh  the  the nice thing is that you know , it just is a  is a visual aid for thinking about these things which has comple clearly have to be specified m more carefully\nAlright , well , le let me think about this some more ,\nand uh\nand uh see if we can find a way to present this to this linguists group that  that is helpful to them .\nI mean , ultimately we  we may w w we regard this as sort of an exercise in  in thinking about the problem and maybe a first version of uh a module , if you wanna call it that , that you can ask , that you can give input and it it 'll uh throw the dice for you , uh throw the die for you , because um I integrated this into the existing SmartKom system in  in the same way as much the same way we can um sort of have this uh  this thing . Close this down . So if this is what M - three - L um will look like and what it 'll give us , um  And a very simple thing . We have an action that he wants to go from somewhere , which is some type of object , to someplace .\nMm - hmm .\nAnd this  these uh  this changed now only um , um  It 's doing it twice now because it already did it once . Um , we 'll add some action type , which in this case is \" Approach \" and could be , you know , more refined uh in many ways .\nMm - hmm . Good .\nOr we can uh have something where the uh goal is a public place and it will give us then of course an action type of the type \" Enter \" . So this is just based on this one  um , on this one feature , and that 's  that 's about all you can do . And so in the f if this pla if the object type um here is  is a m is a landmark , of course it 'll be um \" Vista \" . And um this is about as much as we can do if we don't w if we want to avoid uh uh a huge combinatorial explosion where we specify \" OK , if it 's this and this but that is not the case \" , and so forth , it just gets really really messy .\nOK , I 'm sorry . You 're  you 're\nHmm ?\nIt was much too quick for me . OK , so let me see if I understand what you 're saying . So , I  I do understand that uh you can take the M - three - L and add not  and it w and you need to do this , for sure , we have to add , you know , not too much about um object types and stuff , and what I think you did is add some rules of the style that are already there that say \" If it 's of type \" Landmark \" , then you take  you 're gonna take a picture of it . \"\nExactly .\nF full stop , I mean , that 's what you do . Ev - every landmark you take a picture of ,\nEvery public place you enter , and statue you want to go as near as possible .\nyou enter  You approach . OK . Uh , and certainly you can add rules like that to the existing SmartKom system . And you just did , right ? OK .\nYeah . And it  it would do us no good .\nAh .\nThat  Ultimately .\nWell . So , s well , and let 's think about this .\nW\nUm , that 's a  that 's another kind of baseline case , that 's another sort of thing \" OK , here 's a  another kind of minimal uh way of tackling this \" . Add extra properties , a deterministic rule for every property you have an action , \" pppt ! \" You do that . Um , then the question would be Uh Now , if that 's all you 're doing , then you can get the types from the ontology , OK ? because that 's all  you 're  all you 're using is this type  the types in the ontology and you 're done .\nHmm ?\nRight ? So we don't  we don't use the discourse , we don't use the context , we don't do any of those things .\nNo .\nAlright , but that 's  but that 's OK , and I mean it it 's again a kind of one minimal extension of the existing things . And that 's something the uh SmartKom people themselves would  they 'd say \" Sure , that 's no problem  you know , no problem to add types to the ont \" Right ?\nYeah . No . And this is  just in order to exemplify what  what we can do very , very easily is , um we have this  this silly uh interface and we have the rules that are as banal as of we just saw , and we have our content .\nHmm .\nNow , the content  I  whi which is sort of what  what we see here , which is sort of the Vista , Schema , Source , Path , Goal , whatever .\nYeah . Yeah .\nThis will um be um a job to find ways of writing down Image schema , X - schema , constructions , in some  some form , and have this be in a  in a  in the content , loosely called \" Constructicon \" . And the rules we want to throw away completely . And um  and here is exactly where what 's gonna be replaced with our Bayes - net , which is exactly getting the input feeding into here . This decides whether it 's an whether action  the  the Enter , the Vista , or the whatever\nUh , \" approach \" , you called it , I think this time .\nuh Approach um construction should be activated , IE just pasted in .\nThat 's what you said  Yeah , that 's fine . Yeah , but  Right . But it 's not construction there , it 's action . Construction is a d is a different story .\nYeah .\nRight . This is uh  so what we 'd be generating would be a reference to a semantic uh like parameters for the  for the X - schema ?\nFor  for  for  Yes .\nOK .\nYeah . So that  that uh i if you had the generalized \" Go \" X - schema and you wanted to specialize it to these three ones , then you would have to supply the parameters .\nRight .\nAnd then uh , although we haven't worried about this yet , you might wanna worry about something that would go to the GIS and use that to actually get you know , detailed route planning . So , you know , where do you do take a picture of it and stuff like that .", "topic_id": 2, "keywords": "abstraction, bayes, constructions, bhaskara, knowledge", "dialogue_id": 27}, {"text": "Mm - hmm .\nBut that 's not  It 's not the immediate problem .\nRight .\nBut , presumably that  that  that functionality 's there when  when we\nSo the immediate problem is just deciding w which\nAspects of the X - schema to add .\nYeah , so the pro The immediate problem is  is back t t to what you were  what you are doing with the belief - net .\nYeah .\nYou know , uh what are we going to use to make this decision\nRight and then , once we 've made the decision , how do we put that into the content ?\nYeah . Right . Right . Well , that  that actually is relatively easy in this case .\nOK .\nThe harder problem is we decide what we want to use , how are we gonna get it ? And that the  the  that 's the hardest problem . So , the hardest problem is how are you going to get this information from some combination of the  what the person says and the context and the ontology . The h So , I think that 's the hardest problem at the moment is  is\nOK .\nwhere are you gonna  how are you gonna g get this information . Um , and that 's  so , getting back to here , uh , we have a d a technical problem with the belief - nets that we  we don't want all the com\nThere 's just too many factors right now .\ntoo many factors if we  if we allow them to just go combinatorially .\nRight .\nSo we wanna think about which ones we really care about and what they really most depend on , and can we c you know , clean this  this up to the point where it\nSo what we really wanna do i cuz this is really just the three layer net , we wanna b make it  expand it out into more layers basically ?\nRight . We might . Uh , I mean that  that 's certainly one thing we can do . Uh , it 's true that the way you have this , a lot of the times you have  what you 're having is the values rather than the variable . So uh\nRight . So instead of in instead it should really be  just be \" intention \" as a node instead of \" intention business \" or \" intention tour \" .\nOK ? So you  Yeah , right , and then it would have values , uh , \" Tour \" , \" Business \" , or uh \" Hurried \" .\nRight .\nBut then  but i it still some knowledge design to do , about i how do you wanna break this up , what really matters .\nRight .\nI mean , it 's fine . You know , we have to  it 's  it 's iterative . We 're gonna have to work with it some .\nI think what was going through my mind when I did it was someone could both have a business intention and a touring intention and the probabilities of both of them happening at the same time\nWell , you  you could do that . And it 's perfectly OK  to uh insist that  that , you know , th um , they add up to one , but that there 's uh  that  that it doesn't have to be one zero zero .\nMmm . OK .\nOK . So you could have the conditional p So the  each of these things is gonna be a  a  a probability . So whenever there 's a choice , uh  so like landmark - ness and usefulness ,\nWell , see I don't think those would be mutually\nOK\nit seems like something could both be\nAbsolutely right .\nOK .\nAnd so that you might want to then have those b Th - Then they may have to be separate . They may not be able to be values of the same variable .\nObject type , mm - hmm .\nSo that 's  but again , this is  this is the sort of knowledge design you have to go through . Right . It 's  you know , it 's great  is  is , you know , as one step toward uh  toward where we wanna go .\nAlso it strikes me that we  we m may want to approach the point where we can sort of try to find a  uh , a specification for some interface , here that um takes the normal M - three - L , looks at it . Then we discussed in our pre - edu  EDU meeting um how to ask the ontology , what to ask the ontology um the fact that we can pretend we have one , make a dummy until we get the real one , and so um we  we may wanna decide we can do this from here , but we also could do it um you know if we have a  a  a belief - net interface . So the belief - net takes as input , a vector , right ? of stuff . And it  Yeah . And um it Output is whatever , as well . But this information is just M - three - L , and then we want to look up some more stuff in the ontology and we want to look up some more stuff in the  maybe we want to ask the real world , maybe you want to look something up in the GRS , but also we definitely want to look up in the dialogue history um some s some stuff . Based on we  we have uh  I was just made some examples from the ontology and so we have for example some information there that the town hall is both a  a  a building and it has doors and stuff like this , but it is also an institution , so it has a mayor and so forth and so forth and we get relations out of it and once we have them , we can use that information to look in the dialogue history , \" were any of these things that  that are part of the town hall as an institution mentioned ? \" ,\nMm - hmm .\n\" were any of these that make the town hall a building mentioned ? \" ,\nRight .\nand so forth , and maybe draw some inferences on that . So this may be a  a sort of a process of two to three steps before we get our vector , that we feed into the belief - net ,\nYeah . I think that 's  I think that 's exactly right .\nand then\nThere will be rules , but they aren't rules that come to final decisions , they 're rules that gather information for a decision process . Yeah ,\nYeah .\nno I think that 's  that 's just fine . Uh , yeah . So they 'll  they  presumably there 'll be a thread or process or something that \" Agent \" , yeah , \" Agent \" , whatever you wan wanna say , yeah , that uh is rule - driven , and can  can uh  can do things like that . And um there 's an issue about whether there will be  that 'll be the same agent and the one that then goes off and uh carries out the decision , so it probably will . My guess is it 'll be the same basic agent that um can go off and get information , run it through a  a c this belief - net that  turn a crank in the belief - net , that 'll come out with s uh more  another vector , OK , which can then be uh applied at what we would call the simulation or action end . So you now know what you 're gonna do and that may actually involve getting more information . So on once you pull that out , it could be that that says \" Ah ! Now that we know that we gonna go ask the ontology something else . \" OK ? Now that we know that it 's a bus trip , OK ? we didn't  We didn't need to know beforehand , uh how long the bus trip takes or whatever , but  but now that we know that 's the way it 's coming out then we gotta go find out more .\nMm - hmm .\nSo I think that 's OK .\nMm - hmm . So this is actually , s if  if we were to build something that is um , and , uh , I had one more thing , the  it needs to do  Yeah . I think we  I  I can come up with a  a code for a module that we call the \" cognitive dispatcher \" , which does nothing ,\nOK .\nbut it looks of complect object trees and decides how  are there parts missing that need to be filled out , there 's  this is maybe something that this module can do , something that this module can do and then collect uh sub - objects and then recombine them and put them together . So maybe this is actually some  some useful tool that we can use to rewrite it , and uh get this part ,\nOh , OK . Uh .\nthen . Yeah .\nI confess , I 'm still not completely comfortable with the overall story . Um . I i This  this is not a complaint , this is a promise to do more work . So I 'm gonna hafta think about it some more . Um . In particular  see what we 'd like to do , and  and this has been implicit in the discussion , is to do this in such a way that you get a lot of re - use . So . What you 're trying to get out of this deep co cognitive linguistics is the fact that w if you know about source  source , paths and goals , and nnn  all this sort of stuff , that a lot of this is the same , for different tasks . And that  uh there 's  there 's some  some important generalities that you 're getting , so that you don't take each and every one of these tasks and hafta re - do it . And I don't yet see how that goes . Alright .\nThere 're no primitives upon which  uh\nu u What are the primitives , and how do you break this\nyeah .\nSo I y I 'm just  just there saying eee  well you  I know how to do any individual case , right ? but I don't yet  see what 's the really interesting question is can you use uh deep uh cognitive linguistics to  get powerful generalizations . And\nYep .\num\nMaybe we sho should we a add then the \" what 's this ? \" domain ? N I mean , we have to \" how do I get to X \" . Then we also have the \" what 's this ? \" domain , where we get some slightly different\nCould . Uh .\nRight .\nUm Johno , actually , does not allow us to call them \" intentions \" anymore .\nYeah .\nSo he  he dislikes the term .\nWell , I  I don't like the term either , so I have n i uh i i y w i i It uh\nBut um , I 'm sure the \" what 's this ? \" questions also create some interesting X - schema aspects .\nCould be . I 'm not a  I 'm not op particularly opposed to adding that or any other task ,\nSo .\nI mean , eventually we 're gonna want a whole range of them .\nMm - hmm .\nUh ,\nThat 's right .\nI 'm just saying that I 'm gonna hafta do some sort of first principles thinking about this . I just at the moment don't know .\nMm - hmm .\nH No . Well , no the Bayes  the Bayes - nets  The Bayes - nets will be dec specific for each decision . But what I 'd like to be able to do is to have the way that you extract properties , that will go into different Bayes - nets , be the  uh general . So that if you have sources , you have trajectors and stuff like that , and there 's a language for talking about trajectors , you shouldn't have to do that differently for uh uh going to something , than for circling it , for uh telling someone else how to go there ,\nGetting out of\nwhatever it is . So that  that , the  the decision processes are gonna be different What you 'd really like of course is the same thing you 'd always like which is that you have um a kind of intermediate representation which looks the same o over a bunch of inputs and a bunch of outputs . So all sorts of different tasks  and all sorts of different ways of expressing them use a lot of the same mechanism for pulling out what are the fundamental things going on . And that 's  that would be the really pretty result . And pushing it one step further , when you get to construction grammar and stuff , what you 'd like to be able to do is say you have this parser which is much fancier than the parser that comes with uh SmartKom , i that  that actually uses constructions and is able to tell from this construction that there 's uh something about the intent  you know , the actual what people wanna do or what they 're referring to and stuff , in independent of whether it  about  what is this or where is it or something , that you could tell from the construction , you could pull out deep semantic information which you 're gonna use in a general way . So that 's the  You might . You might . You might be able to  to uh say that this i this is the kind of construction in which the  there 's  Let 's say there 's a uh cont there  the  the land the construction implies the there 's a con this thing is being viewed as a container . OK . So just from this local construction you know that you 're gonna hafta treat it as a container you might as well go off and get that information . And that may effect the way you process everything else . So if you say \" how do I get into the castle \" OK , then um  Or , you know , \" what is there in the castle \" or  so there 's all sorts of things you might ask that involve the castle as a container and you 'd like to have this orthogonal so that anytime the castle 's referred to as a container , you crank up the appropriate stuff . Independent of what the goal is , and independent of what the surrounding language is .\nMm - hmm .\nAlright , so that 's  that 's the  that 's the thesis level\nMm - hmm .\nuh\nIt 's unfortunate also that English has sort of got rid of most of its spatial adverbs because they 're really fancy then , in  in  for these kinds of analysis . But uh .\nWell , you have prepositional phrases that\nYeah , but they 're  they 're easier for parsers .\nRight .\nParsers can pick those up but  but the  with the spatial adverbs , they have a tough time . Because the  mean the semantics are very complex in that .\nRight .\nOK , yeah ? I had one more  thing . I don't remember . I just forgot it again . No . Oh yeah , b But an architecture like this would also enable us maybe to  to throw this away and  and replace it with something else , or whatever , so that we have  so that this is sort of the representational formats we 're  we 're  we 're talking about that are independent of the problem , that generalize over those problems , and are oh , t of a higher quality than an any actual whatever um belief - net , or \" X \" that we may use for the decision making , ultimately . Should be decoupled , yeah . OK .", "topic_id": 3, "keywords": "semantics, ontology, semantic, schema, belief", "dialogue_id": 27}, {"text": "Right . So , are we gonna be meeting here from now on ? I 'm  I 'm happy to do that . We  we had talked about it , cuz you have th th the display and everything , that seems fine .\nYeah , um , Liz also asks whether we 're gonna have presentations every time . I don't think we will need to do that but it 's\nRight .\nso far I think it was nice as a visual aid for some things and  and\nOh yeah . No I  I think it 's worth it to ass to meet here to bring this , and assume that something may come up that we wanna look at .\nYeah .\nI mean . Why not .\nAnd um . Yeah , that was my\nShe was good . Litonya was good .\nYeah ? The uh  um , she w she was definitely good in the sense that she  she showed us some of the weaknesses\nRight .\nand um also the um   the fact that she was a real subject you know , is  is\nRight . Yeah , and  and  and  yeah and  and she took it seriously and stuff l No , it was great .\nYeah .\nYeah .\nSo I think that um  I mean , w Looking  just looking at this data , listening to it , what can we get out of it in terms of our problem , for example , is , you know , she actually m said  you know , she never s just spoke about entering , she just wanted to get someplace , and she said for buying stuff . Nuh ? So this is definitely interesting , and\nYeah , right .\nUm , and in the other case , where she wanted to look at the stuff at the graffiti , also , of course , not in the sentence \" How do you get there ? \" was pretty standard . Nuh ? except that there was a nice anaphora , you know , for pointing at what she talked about before , and there she was talking about looking at pictures that are painted inside a wall on walls , so\nRight .\nActually , you 'd need a lot of world knowledge . This would have been a classical um uh \" Tango \" , actually . Um , because graffiti is usually found on the outside and not on the inside ,\nYeah .\nbut OK . So the mistake  would have make a mistake  the system would have made a mistake here .\nYep .\nClick ? Alright .", "topic_id": 4, "keywords": "meeting, presentations, meet, talking, listening", "dialogue_id": 27}, {"text": "Are we on ? We 're on . OK .\nIs it on ?\nYeah .\nYeah . OK ,\nOne , two  u OK .\nWhy is it so cold in here ?\nso , uh , we haven't sent around the agenda . So , i uh , any agenda items anybody has , wants to talk about , what 's going on ?\nI c I could talk about the meeting .\nDoes everyone  has everyone met Don ?\nYeah .\nIt 's on ?\nNow , yeah .\nYeah .\nYeah ? OK .\nYeah .\nHello .\nOK , agenda item one ,\nWe went\nYeah .\nintroduce Don . OK , we did that . Uh\nWell , I had a  just a quick question but I know there was discussion of it at a previous meeting that I missed , but just about the  the wish list item of getting good quality close - talking mikes on every speaker .\nOK , so let 's  let 's  So let 's just do agenda  building right now . OK , so let 's talk about that a bit .\nI mean , that was\nUh , @ @ tuss close talking mikes , better quality . OK ,  uh , we can talk about that . You were gonna  starting to say something ?\nWell , you  you , um , already know about the meeting  that 's coming up and I don't know if  if this is appropriate for this . I don't know . I mean , maybe  maybe it 's something we should handle outside of the meeting .\nNo , no , that 's OK .\nWhat meeting ?\nWe can  so  we can ta so n NIST is  NIST folks are coming by next week\nOK .\nand so we can talk about that .\nYeah .\nI think\nWho 's coming ?\nUh , uh , John Fiscus\nMm - hmm .\nand , uh , I think George Doddington will be around as well . Uh , OK , so we can talk about that . Uh , I guess just hear about how things are going with , uh , uh , the transcriptions . That 's right .\nSure . Mm - hmm .\nThat would sorta be an obvious thing to discuss . Um , An - anything else , uh , strike anybody ?\nUh , we started  running recognition on  one conversation but it 's the r  isn't working yet . So , But if anyone has\nOK .\nWha\nuh , the main thing would be if anyone has , um , knowledge about ways to , uh , post - process the wave forms that would give us better recognition , that would be helpful to know about .\nUm ,\nDome yeah , it sounds like a topic of conversation .\nYeah , so , uh\nWhat about , uh , is there anything new with the speech , nonspeech stuff ?\nYeah , we 're working more on it but ,  it 's not finished .\nOK . Alright , that seems like a  a good collection of things . And we 'll undoubtedly think of  other things .\nI had thought under my topic that I would mention the , uh , four items that I  I , uh , put out for being on the agenda f on that meeting , which includes like the pre - segmentation and the  and the developments in multitrans .\nOh , under the NIST meeting .\nYeah , under the NIST thing .\nOK .\nYeah .\nAlright , why don't we start off with this , u u I guess the order we brought them up seems fine .\nYeah .\nUm , so , better quality close talking mikes . So the one issue was that the  the , uh , lapel mike , uh , isn't as good as you would like . And so , uh , it  it 'd be better if we had close talking mikes for everybody . Right ?\nRi - um ,\nIs that  is that basically the point ?\nyeah , the  And actually in addition to that , that the  the close talking mikes are worn in such a way as to best capture the signal . And the reason here is just that for the people doing work not on microphones but on sort of like dialogue and so forth , uh  or and even on prosody , which Don is gonna be working on soon , it adds this extra , you know , vari variable for each speaker to  to deal with when the microphones aren't similar .\nMm - hmm .\nRight .\nSo  And I also talked to Mari this morning and she also had a strong preference for doing that . And in fact she said that that 's useful for them to know in starting to collect their data too .\nMm - hmm . Right , so one th\nWell , so\nuh , well one thing I was gonna say was that , um , i we could get more , uh , of the head mounted microphones even beyond the number of radio channels we have because I think whether it 's radio or wire is probably second - order . And the main thing is having the microphone close to you ,\nMm - hmm .\nu although , not too close .\nRight , so , uh , actually the way Jose is wearing his is  is c  correct .\nYeah . Is\nThe good way . So you want to\nYeah .\nI it 's not cor it 's correct ?\nIs .\nYeah , th that 's good .\nYes .\nYeah .\nSo it 's towards the corner of your mouth so that breath sounds don't get on it .\nYeah . Yeah .\nAnd then just sort of about , uh , a thumb or  a thumb and a half away from your  from your mouth .\nYeah . Yeah . Uh , yeah .\nRight .\nBut we have more than one type of\nHow am I d\nI mean , for instance , you 're\nYeah .\nAnd this one isn't very adjustable ,\nYeah .\nso this about as good as I can get\nRight .\nYeah .\ncuz it 's a fixed boom .\nIs fixed . Yeah .\nBut if we could actually standardize , you know , the  the microphones , uh , as much as possible that would be really helpful .\nYeah .\nMm - hmm .\nYeah .\nMm - hmm .\nWell , I mean it doesn't hurt to have a few extra microphones around ,\nYeah .\nso why don't we just go out and  and get an order of  of if this microphone seems OK to people , uh , I 'd just get a half dozen of these things .\nWell the onl the only problem with that is right now , um , some of the Jimlets aren't working . The little  the boxes under the table .\nYeah .\nAnd so , w Uh , I 've only been able to find three jacks that are working .\nYeah .\nCan we get these , wireless ?\nSo\nNo , but my point is\nBut y we could just record these signals separately and time align them with the start of the meeting .\nR r right\nI  I 'm not sure I 'm follow . Say that again ?\nRight now , we 've got , uh , two microphones in the room , that are not quote - unquote standard . So why don't we replace those\nOK , just two .\nWell , however many we can plug in . You know , if we can plug in three , let 's plug in three .\nOK .\nMm - yeah .\nAlso what we 've talked before about getting another , uh , radio ,\nRight .\nand so then that would be , you know , three  more .\nRight . OK .\nMm - hmm .\nSo , uh  so we should go out to our full complement of whatever we can do , but have them all be the same mike . I think the original reason that it was done the other way was because , it w it was sort of an experimental thing and I don't think anybody knew whether people would rather have more variety or   or , uh , more uniformity ,\nRight .\nbut  @ @  but uh , sounds  sounds fine .\nSounds like uniformity wins .\nRight .\nWell , for short term research it 's just  there 's just so much effort that would have to be done up front n uh ,\nYeah .\nWell\nso  yeah , uniformity would be great .\nYeah .\nIs it because  You  you 're saying the  for dialogue purposes , so that means that the transcribers are having trouble with those mikes ? Is that what you mean ?\nWell Jane would know more about the transcribers .\nOr  ?\nAnd that 's true . I mean , I  we did discuss this . Uh , and  and\nYep . Couple times .\na couple times , so , um , yeah , the transcribers notice  And in fact there 're some where , um  ugh well , I mean there 's  it 's the double thing . It 's the equipment and also how it 's worn .\nRight .\nAnd he 's always  they always  they just rave about how wonderful Adam 's  Adam 's channel is .\nWhat can I say .\nAnd then ,\nSo does the recognizer .\nYeah .\nYeah .\nOh , really ? Yeah , I 'm not surprised . I mean , \" Baaah ! \"\nEven if  if you 're talking on someone else 's mike it 's still  you w\nYeah , but I mean it 's not just that , it 's also you know you\nYeah .\nYeah .\nIt 's also like n no breathing , no  You know , it 's like it 's  it 's um ,\nYeah .\nit 's really  {nonvocalsound} it makes a big difference from the transcribers ' point of view\nYeah , it 's an advantage when you don't breath .\nand also from the research s point of view .\nRight .\nWhen we 're doing\nYeah , I think that the point of doing the close talking mike is to get a good quality signal . We 're not doing research on close talking mikes .\nYeah .\nYeah .\nSo we might as well get it as uniform as we can .\nRight .\nNow , this is locking the barn door after the horse was stolen . We do have thirty hours , of  of speech , which is done this way .\nYeah .\nThat 's OK .\nBut  but , uh , yeah , for future ones we can get it a bit more uniform .\nGreat , great .\nSo I think just do a field trip at some point .\nYeah , probably  yeah , to the store we talked about and that\nYep .\nAnd there was some talk about , uh , maybe the h headphones that are uncomfortable for people , to\nYep . So , as  as I said , we 'll do a field trip and see if we can get all of the same mike that 's more comfortable than  than these things , which I think are horrible .\nOK . Good .\nSo .\nGreat , thank you very much .\nEspecially for people with big heads .\nIt 's makes our job a lot easier .\nOK . OK .\nAnd , you know , we 're researchers , so we all have big heads .\nOK .\nYeah .\nYeah . Uh , OK , second item was the , uh , NIST visit , and what 's going on there .\nYeah . OK , so , um , uh , Jonathan Fiscus is coming on the second of February and I 've spoken with , uh ,  u u a lot of people here , not everyone . Um , and , um , he expressed an interest in seeing the room and in , um , seeing a demonstration of the modified multitrans , which I 'll mention in a second , and also , um , he was interested in the pre - segmentation and then he 's also interested in the transcription conventions .\nMm - hmm .\nAnd , um  So , um , it seems to me in terms of like , um , i i it wou You know , OK . So the room , it 's things like the audio and c and audi audio and acoustic  acoustic properties of the room and how it  how the recordings are done , and that kind of thing . And , um . OK , in terms of the multi - trans , well that  that 's being modified by Dave Gelbart to , uh , handle multi - channel recording .\nOh , I should 've  I was just thinking I should have invited him to this meeting . I forgot to do it .\nYeah , OK .\nSo .\nYeah .\nYeah . Well that 's OK , I mean we 'll\nSorry .\nYeah , and it 's t and it looks really great . He  he has a prototype . I  I , uh , @ @  didn't  didn't see it , uh , yesterday but I 'm going to see it today . And , uh , that 's  that will enable us to do  nice um , tight time marking of the beginning and ending of overlapping segments . At present it 's not possible with limitations of  of the , uh , original  design of the software . And um . So , I don't know . In terms of , like , pre - segmentation , that  that continues to be , um , a terrific asset to the  to the transcribers . Do you  I know that you 're al also supplementing it further . Do you want to mention something about that c Thilo , or  ?\nUm , yeah . What  what I 'm doing right now is I 'm trying to include some information about which channel , uh , there 's some speech in . But that 's not working at the moment . I 'm just trying to do this by comparing energies , uh  normalizing energies and comparing energies of the different channels .\nOK .\nAnd so to  to give the transcribers some information in which channel there 's  there 's speech in addition to  to the thing we  we did now which is just , uh , speech - nonspeech detection on the mixed file . So I 'm  I 'm relying on  on the segmentation of the mixed file\nThis is good . Mm - hmm .\nbut I 'm  I 'm trying to subdivide the speech portions into different portions if there is some activity in  in different channels .\nExcellent , so this 'd be like w e providing also speaker ID  potentially .\nBut  Yeah . Yeah .\nWonderful . Wonderful .\nUm , something I guess I didn't put in the list but , uh , on that , uh , same day later on in  or maybe it 's  No , actually  it 's this week , uh , Dave Gelbart and I will be , uh , visiting with John Canny who i you know , is a CS professor ,\nOh .\nwho 's interested in ar in array microphones .\nHCC . Oh , he 's doing array mikes .\nYeah . And so we wanna see what commonality there is here . You know , maybe they 'd wanna stick an array mike here when we 're doing things\nThat would be cool .\nYeah , that would be neat .\nor  or maybe it 's  it 's not a specific array microphone they want\nYeah .\nThat would be really neat .\nbut they might wanna just ,  uh , you know , you could imagine them taking the four signals from these  these table mikes and trying to do something with them  Um , I also had a discussion  So , w uh , we 'll be over  over there talking with him , um , after class on Friday . Um , we 'll let you know what  what goes with that . Also had a completely unrelated thing . I had a , uh , discussion today with , uh , Birger Kollmeier who 's a , uh , a German , uh , scientist who 's got a fair sized group  doing a range of things . It 's sort of auditory related , largely for hearing aids and so on . But  but , uh , he does stuff with auditory models and he 's very interested in directionality , and location , and  and , uh , head models and  microphone things . And so , uh , he 's  he and possibly a student , there w there 's , uh , a student of his who gave a talk here last year , uh , may come here , uh , in the fall for , uh , sort of a five month , uh , sabbatical . So he might be around . Get him to give some talks and so on . But anyway , he might be interested in  this stuff .\nMm - hmm .\nThat  that reminds me , I had a  a thought of an interesting project that somebody could try to do with  the data from here , either using , you know , the  the mikes on the table or using signal energies from the head worn mikes ,\nMm - hmm .\nand that is to try to construct a map of where people were sitting ,\nRight .\nUh - huh .\nuh , based on\nWell Dan  Dan had worked on that . Dan Ellis ,\nUh - huh .\nOh , did he ? Oh , that 's interesting .\nyeah . So that  that 's the cross - correlation stuff , was  was doing b beam - forming .\nYeah .\nAnd so you could plot out who was sitting next to who\nA little bit ,\nand\nI mean , he didn't do a very extreme thing but just  it was just sort of\nYeah , yeah .\nNo , he did start on it .\ne e given that , the  the  the block of wood with the  the  the two mikes  on either side ,\nMm - hmm .\nif I 'm speaking , or if you 're speaking , or someone over there is speaking , it  if you look at cross - correlation functions , you end up with a\nYeah .\nif  if someone who was on the axis between the two is talking , then you  you get a big peak there . And if  if someone 's talking on  on  on , uh , one side or the other , it goes the other way .\nMm - hmm .\nAnd then , uh , it  it  it even looks different if th t if the two  two people on either side are talking than if one in the middle . It  it actually looks somewhat different , so .\nHmm . Well I was just thinking , you know , as I was sitting here next to Thilo that um , when he 's talking , my mike probably picks it up better than  your guys 's mikes .\nYeah .\nYeah .\nSo if you just looked at\nOh , that 's another cl cue ,\nYeah .\nyeah ,  looked at  the energy on my mike and you could get an idea about who 's closest to who .\nthat 's true .\nYeah .\nMm - hmm .\nYeah .\nRight .\nYeah .\nAnd\nOr who talks the loudest .\nYeah .\nYeah .\nYeah , well you have to  the appropriate normalizations are tricky , and  and  and are probably the key .\nYeah .\nYeah .\nYou just search for Adam 's voice on each individual microphone , you pretty much know where everybody 's sitting .\nYeah .\nYeah . We 've switched positions recently so you can't  Anyway . OK . So those are just a little couple of news items .\nCan I ask one thing ? Uh , so , um , Jonathan Fiscus expressed an interest in , uh , microphone arrays .\nYes .\nUm , is there  I mean  b And I also want to say , his  he can't stay all day . He needs to uh , leave for  uh , from here to make a two forty - five flight\nOh , so just morning .\nfrom  from Oakland .\nRight .\nSo it makes the scheduling a little bit tight but do you think that , um  that , uh , i John Canny should be involved in this somehow or not . I have no idea .\nProbably not but I  I 'll  I 'll  I 'll know better after I see him this Friday what  what kind of level he wants to get involved .\nIt 's premature . Fine . Good .\nUh , he might be excited to and it might be very appropriate for him to , uh , or he might have no interest whatsoever . I  I just really don't know .\nOK .\nIs he involved in  Ach !  I 'm blanking on the name of the project . NIST has  has done a big meeting room  instrumented meeting room with video and microphone arrays , and very elaborate software . Is  is he the one working on that ?\nWell that 's what they 're starting up .\nOK .\nYeah . No , I mean , that 's what all this is about . They  they haven't done it yet . They wanted to do it\nOK . I had read some papers that looked like they had already done some work .\nUh , well I think they 've instrumented a room but I don't  think they  they haven't started recordings yet . They don't have the t the transcription standards . They don't have the\nAre they going to do video as well ?\nHmm .\nYeah . I think .\nHmm .\nI think they are .\nOh , cuz what  what I had read was , uh , they had a uh very large amount of software infrastructure for coordinating all this , both in terms of recording and also live room where you 're interacting  the participants are interacting with the computer , and with the video , and lots of other stuff .\nWell , I 'm  I 'm  I 'm not sure .\nSo .\nAll  all I know is that they 've been talking to me about a project that they 're going to start up recording people meet in meetings .\nOK . Well\nAnd , uh , it is related to ours . They were interested in ours . They wanted to get some uniformity with us , uh , about the transcriptions and so on .\nAlright .\nAnd one  one notable difference  u u actually I can't remember whether they were going to routinely collect video or not , but one  one , uh , difference from the audio side was that they are interested in using array mikes . So , um , I mean , I 'll just tell you the party line on that . The reason I didn't go for that here was because , uh , the focus , uh , both of my interest and of Adam 's interest was uh , in impromptu situations . And we 're not recording a bunch of impromptu situations but that 's because it 's different to get data for research than to actually apply it .\nHmm .\nAnd so , uh , for scientific reasons we thought it was good to instrument this room as we wanted it . But the thing we ultimately wanted to aim at was a situation where you were talking with , uh , one or more other people i uh , in  in an p impromptu way , where you didn't  didn't actually know what the situation was going to be . And therefore it would not  it 'd be highly unlikely that room would be outfitted with  with some very carefully designed array of microphones . Um , so it was only for that reason . It was just , you know , yet another piece of research and it seemed like we had enough troubles just\nSo there 's no like portable array of mikes ?\nNo . So there 's  there 's  uh , there 's a whole range of things  there 's a whole array of things ,  that people do on this .\nHmm .\nSo , um , the , uh  the big arrays , uh , places , uh , like uh , Rutgers , and Brown , and other  other places , uh , they have , uh , big arrays with , I don't know , a hundred  hundred mikes or something .\nXerox .\nAnd so there 's a wall of mikes . And you get really , really good beam - forming  with that sort of thing .\nWow .\nAnd it 's  and , um , in fact at one point we had a  a proposal in with Rutgers where we were gonna do some of the sort of per channel signal - processing and they were gonna do the multi - channel stuff , but  it d it d we ended up not doing it . But\nI 've seen demonstrations of the microphone arrays . It 's amazing how  how they can cut out noise .\nYeah , it 's r It 's really neat stuff .\nAnd then they have little ones too\nAnd then they had the little ones , yeah .\nbut I mean  but they don't have our block of wood , right ?\nYeah , our block of wood is unique .\nYeah .\nBut the  But the No , there are these commercial things now you can buy that have four mikes or something\nMm - hmm .\nand  and , uh , um  So , yeah , there 's  there 's  there 's a range of things that people do .\nHuh .\nUm , so if we connected up with somebody who was interested in doing that sort of thing that 's  that 's a good thing to do . I mean , whenever I 've described this to other people who are interested on the  with the acoustic side that 's invariably the question they ask . Just like someone who is interested in the general dialogue thing will always ask  \" um , are you recording video ? \"\nRight ,\nUm , right ?\nright .\nAnd  and the acoustic people will always say , \" well are you doing , uh , uh , array microphones ? \" So it 's  it 's a good thing to do , but it doesn't solve the problem of how do you solve things when there 's one mike or at best two mikes in  in this imagined PDA that we have . So maybe  maybe we 'll do some more of it .\nWell one thing I  I mean , I don't know . I mean , I know that having an array of  I mean , I would imagine it would be more expensive to have a  an array of microphones . But couldn't you kind of approximate the natural sis situation by just shutting off uh , channels when you 're  later on ? I mean , it seems like if the microphones don't effect each other then couldn't you just , you know , record them with an array and then just not use all the data ?\nIt 's  it 's just a lot of infrastructure that for our particular purpose we felt we didn't need to set up .\nI see .\nYeah .\nFine .\nYeah , if ninety - nine percent of what you 're doing is c is shutting off most of the mikes , then going through the\nOK .\nBut if you get somebody who 's  who  who has that as a primary interest then that put  then that drives it in that direction .\nThat 's right , I mean if someone  if someone came in and said we really want to do it ,\nRight .\nI mean , we don't care . That would be fine ,\nSo to save that data you  You have to have one channel recording per mike in the array ?\nBuy more disk space .\nWell , uh , at some level  at some level .\nIs that\nI usually do a mix .\nBut then , you know , there 's  it  there 's\nWhat you save , I mean , if you 're going to do research with it . yeah\nThere 's  I  I don't know what they 're going to do and I don't know how big their array is . Obviously if you were gonna save all of those channels for later research you 'd use up a lot of space .\nYeah .\nAnd , th\nHmm .\nWell their software infrastructure had a very elaborate design for plugging in filters , and mixers , and all sorts of processing . So that they can do stuff in real time and not save out each channel individually .\nYeah . Yeah .\nMmm .\nSo it was , uh\nYeah .\nBut I mean , uh , for optimum flexibility later you 'd want to save each channel . But I think in practical situations you would have some engine of some sort doing some processing to reduce this to some  to the equivalent of a single microphone that was very directional .\nUh , oh , OK , I see .\nRight ?\nI mean , it seems\nSo\nSort of saving the result of the beam - forming .\nYeah .\nit seems to me that there 's  you know , there are good political reasons for  for doing this , just getting the data , because there 's a number of sites  like right now SRI is probably gonna invest a lot of internal funding into recording meetings also , which is good , um , but they 'll be recording with video and they 'll be  You know , it 'd be nice if we can have at least , uh , make use of the data that we 're recording as we go since it 's sort of  this is the first site that has really collected these really impromptu meetings , um , and just have this other information available . So , if we can get the investment in just for the infra infrastructure and then , I don't know , save it out or have whoever 's interested save that data out , transfer it there , it 'd be g it 'd be good to have  have the recording . I think .\nYou mean to  to actually get a microphone array and do that ?\nWell , if  Even if we 're not\nAnd video and\nI 'm not sure about video . That 's sort of an  video has a little different nature since right n right now we 're all being recorded but we 're not being taped . Um , but it  definitely in the case of microphone arrays , since if there was a community interested in this , then\nWell , but I think we need a researcher here who 's interested in it . To push it along .\nSee the problem is it  it took , uh , uh , it took at least six months for Dan to get together the hardware and the software , and debug stuff in  in the microphones , and in the boxes . And it was a really big deal . And so I think we could get a microphone array in here pretty easily and , uh , have it mixed to  to one channel of some sort .\nMm - hmm .\nBut , e I think for I mean , how we 're gonna decide  For  for maximum flexibility later you really don't want to end up with just one channel that 's pointed in the direction of the  the  the p the person with the maximum energy or something like that . I mean , you  you want actually to  you want actually to have multiple channels being recorded so that you can  And to do that , it  we 're going to end up greatly increasing the disk space that we use up , we also only have boards that will take up to sixteen channels and in  this meeting , we 've got eight people and  and six mikes . And there we 're already using fourteen .\nAnd we actually only have fifteen .\nE\nOne of them 's\nYeah .\nDetails .\nMm - hmm .\nYeah .\nBut fifteen , not sixteen .\nWell if there 's a way to say time  to sort of solve each of these f those\nYeah .\nSo suppose you can get an array in because there 's some person at Berkeley who 's interested and has some  equipment , uh , and suppose we can  as we save it we can , you know , transfer it off to some other place that  that holds this  this data , who 's interested , and even if ICSI it itself isn't . Um , and it  it seems like as long as we can time align the beginning , do we need to mix it with the rest ? I don't know . You know ? The\nYeah . So I think you 'd need a separate  a separate set up\nSo  Yeah .\nand the assumption that you could time align the two .\nI mean it 's just  it 's worth considering as sort of\nAnd y it 'd certainly gets skew .\nonce you make the up front investment  and can sort of save it out each time , and  and not have to worry about the disk space factor , then it mi it might be worth having the data .\nI 'm not so much worried about disk space actually . I mentioned that , b as a practical matter ,\nJust\nbut the real issue is that , uh , there is no way to do a recording extended to what we have now with low skew . So  you would have a t completely separate set up ,\nRight .\nwhich would mean that the sampling times and so forth would be all over the place compared to this . So it would depend on the level of pr processing you were doing later , but if you 're d i the kind of person who 's doing array processing you actually care about funny little times . And  and so you actually wou would want to have a completely different set up than we have ,\nI see .\none that would go up to thirty - two channels or something .", "topic_id": 0, "keywords": "conversation, talks, talking, talk, meeting", "dialogue_id": 28}, {"text": "Mmm .\nSo basically\nOr a hundred thirty - two .\nor a hun Yeah . So , I 'm kinda skeptical , but um I think that\nMmm .\nSo , uh , I don't think we can share the resource in that way . But what we could do is if there was someone else who 's interested they could have a separate set up which they wouldn't be trying to synch with ours which might be useful for  for them .\nRight , I mean at least they 'd have the data and the transcripts ,\nAnd then we can offer up the room ,\nand  Right .\nYeah , we can o offer the meetings , and the physical space , and  and  yeah , the transcripts , and so on .\nOK . Right , I mean , just  it 'd be nice if we have more information on the same data . You know , and\nYeah .\nBut it 's  if it 's impossible or if it 's a lot of effort then you have to just balance the two ,\nWell I thi\nso\nyeah , the thing will be , u u in  in  again , in talking to these other people to see what  you know , what  what we can do .\nRight .\nUh , we 'll see .\nIs there an interest in getting video recordings for these meetings ?\nRight , so we have  we\nI mean\nYes , absolutely . But it 's exactly the same problem , that you have an infrastructure problem , you have a problem with people not wanting to be video taped , and you have the problem that no one who 's currently involved in the project is really hot to do it .\nHmm . So there 's not enough interest to overcome all of\nMm - hmm .\nRight . Internally , but I know there is interest from other places that are interested in looking at meeting data and having the video . So it 's just\nYeah , w although I  m  I  I have to u u mention the human subjects problems ,  that i increase with video .\nRight , that 's true .\nYeah , so it 's , uh , people  people getting shy about it .\nYeah .\nThere 's this human subjects problem . There 's the fact that then um , if  i I I 've heard comments about this before , \" why don't you just put on a video camera ? \" But you know , it 's sort of like saying , \" uh , well we 're primarily interested in  in some dialogue things , uh , but , uh , why don't we just throw a microphone out there . \" I mean , the thing is , once you actually have serious interest in any of these things then you actually have to put a lot of effort in .\nMmm .\nAnd , uh , you really want to do it right .\nI know . Yep .\nSo I think NIST or LDC , or somebody like that I think is much better shape to do all that . We  there will be other meeting recordings . We won't be the only place doing meeting recordings . We are doing what we 're doing .\nMm - hmm .\nAnd , uh , hopefully it 'll be useful .\nI  it  it occurred to me , has Don signed a human subject 's form ?\nOh ! Probably not .\nA permission form ?\nHas Don  have you s did you si I thought you did actually .\nI was   Yeah , I was  I was here  I was here before once .\nDidn't you read a digit string ?\nYou were here at a meeting before .\nYou were here at a meeting before .\nYeah .\nSo .\nYeah , and you  and you signed a form .\nOh , I think so .\nDid you sign a form ?\nDid I ? I don't know .\nI 'm pretty sure . Well I 'll  I 'll get another one before the end of the meeting .\nOK .\nYeah .\nThank you .\nYeah .\nOK .\nYeah .\nYou don't  you don't have to leave for it .\nYeah , we  we\nBut I just\nCan I verbally consent ?\nyou know .\nWell I can't , I 'm wired in .\nWe  we  we  we don't , uh\nYeah . You 're on recor you 're being recorded\no\nYeah .\nand\nwe don't  we don't perform electro - shock during these meetings ,\nI don't care . You can do whatever you want with it .\nand\nUsually .\nThat 's fine .\nYeah . OK . Uh , transcriptions .\nTranscriptions , OK . Um , I thought about  there are maybe three aspects of this . So first of all , um , I 've got eight transcribers . Uh , seven of them are linguists . One of them is a graduate student in psychology . Um , Each  I gave each of them , uh , their own data set . Two of them have already finished the data sets . And  the meetings run , you know , let 's say an hour . Sometimes as man much as an hour and a half .\nHow big is the data set ?\nOh , it 's  what I mean is one meeting .\nAh , OK .\nEach  each person got their own meeting . I didn't want to have any conflicts of , you know , of  of when to stop transcribing this one or  So I wanted to keep it clear whose data were whose , and  and  and so\nUh - huh .\nAnd , uh , meetings , you know , I think that they 're  they go as long as a  almost two hours in some  in some cases . So , you know , that means  you know , if we 've got two already finished and they 're working on  Uh , right now all eight of them have differe uh , uh , additional data sets . That means potentially as many as ten might be finished by the end of the month .\nWow .\nHope so . But the pre - segmentation really helps a huge amount .\nOK .\nAnd , uh , also Dan Ellis 's innovation of the , uh  the multi - channel to here really helped a r a lot in terms of clearing  clearing up h hearings that involve overlaps . But , um , just out of curiosity I asked one of them how long  it was taking her , one of these two who has already finished her data set . She said it takes about , uh , sixty minutes transcription for every five minutes of real time . So it 's about twelve to one , which is what we were thinking .\nor Yep .\nIt 's well in the range .\nIt 's pretty good .\nOK . Uh , these still , when they 're finished , um , that means that they 're finished with their pass through . They still need to be edited and all but  But it 's word level , speaker change , the things that were mentioned . OK , now I wanted to mention the , um , teleconference I had with , uh , Jonathan Fiscus . We spoke for an hour and a half and , um , had an awful lot of things in common .\nHmm .\nHe , um , um , he in indicated to me that they 've  that he 's been , uh , looking , uh , uh , spending a lot of time with  I 'm not quite sure the connection , but spending a lot of time with the ATLAS system . And I guess that  I mean , I  I need to read up on that . And there 's a web site that has lots of papers . But it looks to me like that 's the name that has developed for the system that Bird and Liberman developed  for the annotated  graphs approach .\nMm - hmm .\nSo what he wants me to do and what we  what we will do and  uh , is to provide them with the u already transcribed meeting for him to be able to experiment with in this ATLAS System . And they do have some sort of software , at least that 's my impression , related to ATLAS and that he wants to experiment with taking our data and putting them in that format , and see how that works out . I  I  I explained to him in  in detail the , uh , conventions that we 're using here in this  in this word level transcript . And , um , you know , I  I explained , you know , the reasons that  that we were not coding more elaborately and  and the focus on reliability . He expressed a lot of interest in reliability . It 's like he 's  he 's really up on these things . He 's  he 's very  Um , independently he asked , \" well what about reliability ? \" So ,  he 's interested in the consistency of the encoding and that sort of thing . OK , um\nSorry , can you explain what the ATLAS  I 'm not familiar with this ATLAS system .\nWell , you know , at this point I think  Uh , well Adam 's read more  in more detail than I have on this . I need to acquaint myself more with it . But , um , there  there is a way of viewing  Uh , whenever you have coding categories , um , and you 're dealing with uh , a taxonomy , then you can have branches that  that have alternative , uh , choices that you could use for each  each of them . And it just ends up looking like a graphical representation .\nIs  is  Is ATLAS the  his annotated transcription graph stuff ? I don't remember the acronym . The  the one  the  what I think you 're referring to , they  they have this concept of an an annotated transcription graph representation .\nOh . Oh .\nYeah .\nAnd that 's basically what I based the format that I did  I based it on their work almost directly , in combination with the TEI stuff . And so it 's very , very similar . And so it 's  it 's a data representation and a set of tools for manipulating transcription graphs of various types .\nIs this the project that 's sort of , uh , between , uh , NIST and  and , uh , a couple of other places ?\nMm - hmm .\nThe  the\nIncluding LDC .\nYeah ,\nI think so .\nYep .\ny right , OK .\nMm - hmm . Then there 's their web site that has lots of papers . And I looked through them and they mainly had to do with this , um , this , uh , tree structure , uh , annotated tree diagram thing .\nMmm .\nSo , um , um  and , you know , in terms of like the conventions that I 'm a that I 've adopted , it  there  there 's no conflict at all .\nRight .\nAnd he was , you know , very interested . And , \" oh , and how 'd you handle this ? \" And I said , \" well , you know , this way \" and  And  and we had a really nice conversation . Um , OK , now I also wanted to say in a different  a different direction is , Brian Kingsbury . So , um , I corresponded briefly with him . I , uh , c I  He still has an account here . I told him he could SSH on and use multi - trans , and have a look at the already done , uh , transcription . And he  and he did . And what he said was that , um , what they 'll be providing is  will not be as fine grained in terms of the time information . And , um , that 's , uh  You know , I need to get back to him and  and , uh , you know , explore that a little bit more and see what they 'll be giving us in specific ,\nHmm .\nThe p the people\nbut I just haven't had time yet .\nThe  the folks that they 're , uh , subcontracting out the transcription to , are they like court reporters\nSorry , what ? Yes .\nor\nApparently  Well , I get the sense they 're kind of like that . Like it 's like a pool of  of somewhat uh , secretarial  I don't think that they 're court reporters . I don't think they have the special keyboards and that  and that type of training .\nMm - hmm .\nI  I get the sense they 're more secretarial . And that , um , uh , what they 're doing is giving them\nHmm . Like medical transcriptionist type people\nNu - it 's mostly  it 's for their speech recognition products ,\nBut aren't  they 're\nYep .\nthat they 've hired these people to do .\nOh , so they 're hiring them , they 're coming . It 's not a service they send the tapes out to .\nWell they  they do send it out but my understanding is that that 's all this company does is transcriptions for IBM for their speech product .\nAh ! Oh . OK . I gotcha .\nSo most of it 's ViaVoice , people reading their training material for that .\nI see .\nMm - hmm .\nI see .\nUp to now it 's been monologues , uh , as far my understood .\nYep , exactly .\nAnd  and what they 're doing is\nMm - hmm .\nYep .\nBrian himself downloaded  So  So , um , Adam sent them a CD and Brian himself downloaded  uh , cuz , you know , I mean , we wanted to have it so that they were in familiar f terms with what they wanted to do . He downloaded  from the CD onto audio tapes . And apparently he did it one channel per audio tape . So each of these people is  transcribing from one channel .\nRight .\nOh .\nAnd then what he 's going to do is check it , a before they go be beyond the first one . Check it and , you know , adjust it , and all that .\nSo each person gets one of these channels\nRight .\nSo if they hear something off in the distance they don't  they just go\nOK .\nI  I don't know .\nWell , but that 's OK , because , you know , you 'll do all them and then combine them .\nBut there could be problems , right ? with that .\nI have t I , you know I\nYep .\nI think it would be difficult to do it that way . I really\nYeah .\nWell if you 're tran if you got that channel right there\nd uh , in my case\nYeah .\nNo , no . We 're talking about close talking , not the  not the desktop .\nNo , close talk .\nAre you ?\nYes . Well I th I think so .\nI sure hope so . It 'd be really foolish to do otherwise .\nYeah , I  I would think that it would be kind of hard to come out with  Yeah .\nI  I think it 's sort of hard just playing the  you know , just having played the individual files . And I  I mean , I know you . I know what your voice sounds like . I 'm sort of familiar with\nYeah .\nUh , it 's pretty hard to follow , especially\nOne side .\nthere are a lot of words that are so reduced phonetically that make sense when you know what the person was saying before .\nI agree .\nYeah .\nYeah , that 's\nUh , it sort of depends where you are in\nAnd especially since a lot of these\nYeah .\nBut I mean we had this  we 've had this discussion many times .\nYeah , we have .\nAnd the answer is we don't actually know the answer because we haven't tried both ways .\nWell , except I can say that my transcribers use the mixed signal mostly\nSo . Mm - hmm .\nMm - hmm .\nRight .\nunless there 's a huge disparity in terms of the volume on  on the mix . In which case , you know , they  they wouldn't be able to catch anything except the prominent  channel ,\nRight .\nYeah .\nthen they 'll switch between .\nWell I think that  that might change if you wanted really fine time markings .\nBut  but really  Well , OK .\nSo .\nBut they 're not giving f really fine time markings .\nYeah , well\nActually , are th so  are they giving any time markings ?\nRight .\nIn other words , if\nWell , I have to ask him .\nYeah .\nAnd that 's  that 's my email to him . That needs to be forthcoming .\nCuz  OK .\nBut  but the , uh  I did want to say that it 's hard to follow one channel of a conversation even if you know the people , and if you 're dealing furthermore with highly abstract network concepts you 've never heard of  So , you know , one of these people was  was transcribing the , uh , networks group talk and she said , \" I don't really know what a lot of these abbreviations are , \" \" but I just put them in parentheses cuz that 's the  that 's the convention and I just \"  Cuz you know , if you don't know\nOh , I 'd be curious to  to look at that .\nJust out of curiosity , I mean\nThey also all have h heavy accents .\nYeah .\nYeah .\nYeah .\nThe networks group meetings are all\nGiven all of the effort that is going on here in transcribing why do we have I B M doing it ? Why not just do it all ourselves ?\nUm , it 's historical . I mean , uh , some point ago we thought that uh , it  \" boy , we 'd really have to ramp up to do that \" ,\nUh - huh .\nNo , just\nyou know , like we just did , and , um , here 's , uh , a  a , uh , collaborating institution that 's volunteered to do it .\nMm - hmm . Mm - hmm .\nSo , that was a contribution they could make . Uh in terms of time , money , you know ?\nMm - hmm .\nAnd it still might be a good thing\nI 'm just wondering now\nActu yeah , Mar - Mari asked me the same question as sort of\nbut\nWell , I 'm  I 'm wondering now if it 's\nWell we can talk about more details later .\num , you know , yeah , whether to\nYeah . Yeah . Yeah , so .\nHmm .\nWe 'll see . I mean , I think , th you know , they  they  they 've proceeded along a bit . Let 's see what comes out of it , and  and , uh , you know , have some more discussions with them .\nMm - hmm . It 's very  a real benefit having Brian involved because of his knowledge of what the  how the data need to be used and so what 's useful to have in the format .\nYeah .\nMm - hmm . Yeah .\nSo , um , Liz , with  with the SRI recognizer ,  can it make use of some time marks ?\nOK , so this is a , um ,\nI  I guess I don't know what that means .\nand actually I should say this is what Don has b uh , he 's already been really helpful in , uh , chopping up these  So  so first of all you  um , I mean , for the SRI front - end , we really need to chop things up into pieces that are f not too huge . Um , but second of all , uh  in general because some of these channels , I 'd say , like , I don't know , at least half of them probably  on average are g are ha are  have a lot of cross - ta sorry , some of the segments have a lot of cross - talk . Um , it 's good to get sort of short segments if you 're gonna do recognition , especially forced alignment . So , uh , Don has been taking a first stab actually using Jane 's first  the fir the meeting that Jane transcribed which we did have some problems with , and Thilo , uh , I think told me why this was , but that people were switching microphones around  in the very beginning , so  the SRI re\nNo , th Yeah . No . They  they were not switching them but what they were  they were adjusting them ,\nand they  They were not\nso .\nMmm .\nAdjusting . Oh .\nYeah .\nAnd aft after a minute or so it 's  it 's way better .\nSo we have to sort of normalize  the front - end and so forth , and have these small segments .\nSo  Yep .\nSo we 've taken that and chopped it into pieces based always on your  your , um , cuts that you made on the mixed signal . And so that every  every speaker has the same cuts . And if they have speech in it we run it through . And if they don't have speech in it we don't run it through . And we base that knowledge on the transcription .\nOn  Just on the marks . Right ?\nUm , the problem is if we have no time marks , then for forced alignment we actually don't know where  you know , in the signal the transcriber heard that word . And so\nOh , I see ,\nI mean , if  if it 's a whole conversation and we get a long , uh , you know , par paragraph of  of talk ,\nit 's for the length . I see .\nuh , I don't know how they do this . Um , we actually don't know which piece goes where .\nI understand .\nAnd , um , I think with\nWell you would need to  like a forced alignment before you did the chopping , right ?\nNo , we used the fact that  So when Jane transcribes them the way she has transcribers doing this , whether it 's with the pre - segmentation or not ,\nIt 's already chunked .\nthey have a chunk and then they transcribes  the words in the chunk . And maybe they choose the chunk or now they use a pre - segmentation and then correct it if necessary . But there 's first a chunk and then a transcription .\nMm - hmm .\nThen a chunk , then a transcription . That 's great , cuz the recognizer can\nUh , it 's all pretty good sized for the recognizer also .\nRight , and it  it helps that it 's made based on sort of heuristics and human ear I think .\nGood . Oh good .\nTh - but there 's going to be a real problem , uh , even if we chop up based on speech silence these , uh , the transcripts from I B M , we don't actually know where the words were , which segment they belonged to .\nRight .\nSo that 's sort of what I 'm  worried about right now .\nWhy not do a  a  a forced alignment ?\nThat 's what she 's saying , is that you can't .\nIf you do a forced alignment on something really\nGot uh six sixty minutes of\nwell even if you do it on something really long you need to know  you can always chop it up but you need to have a reference of which words went with which , uh , chop .\nNow wasn't  I thought that one of the proposals was that IBM was going to do an initial forced alignment ,\nSo\nafter they\nYeah , but\nI  I think that they are ,\nWe 'll have to talk to Brian .\num , yeah , I 'm sure they will and so we  we have to have a dialogue with them about it .\nYeah .\nI mean , it sounds like Liz has some concerns\nMaybe they have some  you know , maybe actually there is some , even if they 're not fine grained , maybe the transcribers\nand\nuh , I don't know , maybe it 's saved out in pieces or  or something . That would help .\nYeah .\nBut , uh , it 's just an unknown right now .\nYeah . I  I need to  to write to him .\nSo .\nI just  you know , it 's like I got over - taxed with the timing .\nRight . But the  it is true that the segments  I haven't tried the segments that Thilo gave you but the segments that in your first meeting are great .\nMm - hmm .\nI mean , that 's  that 's a good length .\nA good size . Good .\nRight , cuz\nWell , I  I was thinking it would be fun to  to  uh , uh , if  if you  wouldn't mind ,   to give us a pre - segmentation .\ny yeah .\nYeah .\nUh , maybe you have one already of that first m of the meeting that uh , the first transcribed meeting , the one that I transcribed .\nUm , I 'm sure I have some\nDo you have a  could you generate a pre - segmentation ?\nFebruary sixteenth I think .\nbut  but that 's the one where we 're , um , trai training on , so that 's a little bit\nOh .\nOh , I see .\nIt 's a little bit at odd to\nOh , darn . Of course , of course , of course . Yeah , OK .\nYeah .\nAnd actually as you get transcripts just , um , for new meetings ,  um , we can try\nUh - huh .\nI mean , the  the more data we have to try the  the alignments on , um , the better . So it 'd be good for  just to know as transcriptions are coming through the pipeline from the transcribers , just to sort of  we 're playing around with sort of uh , parameters f on the recognizer ,\nMm - hmm .\ncuz that would be helpful . Especially as you get , en more voices .\nExcellent , good .\nThe first meeting had I think just four people ,\nFour speakers , yeah .\nMm - hmm .\nyeah .\nYeah , Liz and I spoke d w at some length on Tuesday and  and I  and I was planning to do just a  a preliminary look over of the two that are finished and then give them to you .\nOh , great , great .\nYeah .\nSo .\nThat 's great . I guess the other thing , I  I can't remember if we discussed this in the meeting but , uh , I know you and I talked about this a little bit , there was an issue of , uh , suppose we get in the , uh , I guess it 's enviable position although maybe it 's just saying where the weak link is in the chain , uh , where we  we , uh  uh , we have all the data transcribed and we have these transcribers and we were  we 're  the  we 're still a bit slow on feeding  at that point we 've caught up and the  the  the , uh , the weak link is  is recording meetings . OK , um , two questions come , is you know what  how  how do we  uh , it 's not really a problem at the moment cuz we haven't reached that point but how do we step out the recorded meetings ? And the other one is , um , uh , is there some good use that we can make of the transcribers to do other things ? So , um , I  I can't remember how much we talked about this in this meeting but there was\nWe had spoken with them about it .\nAnd there is one use that  that also we discussed which was when , uh , Dave finishes the  and maybe it 's already finished  the  the modification to multi - trans which will allow fine grained encoding of overlaps . Uh , then it would be very  these people would be very good to shift over to finer grain encoding of overlaps . It 's just a matter of , you know , providing  So if right now you have two overlapping segments in the same time bin , well with  with the improvement in the database  in  in the , uh , sorry , in the interface , it 'd be possible to , um , you know , just do a click and drag thing , and get the  uh , the specific place of each of those , the time tag associated with the beginning and end of  of each segment .\nRight , so I think we talking about three level  three things .\nMm - hmm .\nOne  one was uh , we had s had some discussion in the past about some very high level labelings ,\nYeah . The types of overlaps\ntypes of overlaps , and so forth that  that someone could do . Second was , uh , somewhat lower level\nMm - hmm .\njust doing these more precise timings . And the third one is  is , uh , just a completely wild hair brained idea that I have which is that , um , if , uh  if we have time and people are able to do it , to take some subset of the data and do some very fine grained analysis of the speech . For instance , uh , marking in some overlapping  potentially overlapping fashion , uh , the value of , uh , ar articulatory features .\nYeah .\nYou know , just sort of say , OK , it 's voiced from here to here , there 's  it 's nasal from here to here , and so forth . Um , as opposed to doing phonetic  uh , you know , phonemic and the phonetic analysis ,\nand , uh , assuming , uh , articulatory feature values for those  those things . Um , obviously that 's extremely time - consuming . Uh\nThat would be really valuable I think .\nbut , uh , we could do it on some small subset .\nAlso if you 're dealing with consonants that would be easier than vowels , wouldn't it ? I mean , I would think that  that , uh , being able to code that there 's a  a fricative extending from here to here would be a lot easier than classifying precisely which vowel that was .\nWhich one .\nMmm .\nMm - hmm .\nI think vowels  vowels are I think harder .\nWell , yeah ,\nYeah .\nbut I think also it 's just the issue that  that when you look at the  u w u u when you look at Switchboard for instance very close up there are places where whether it 's a consonant or a vowel you still have trouble calling it a particular phone\nMm - hmm .\nat that point\nMm - hmm , OK .\nYeah , but  but just saying what the\nbecause it 's  you know , there 's this movement from here to here\nYeah , I 'm sure . Uh , yeah , I  I know .\nRight .\nand  and  and it 's  so I\nYou 're saying r sort of remove the high level constraints and go bottom - up .\nYeah , describe  describe it .\nThen just say\nYep , just features .\nMmm .\nNow I 'm suggesting articulatory features . Maybe there 's  there 's even a better way to do it but it  but  but that 's , you know , sort of a traditional way of describing these things ,\nMm - hmm .\num , and  uh , I mean , actually this might be a g neat thing to talk to\nThat 's nice .\nAcoustic features versus psychological categories .\nSort of . I mean , it 's still\nYeah .\nYeah .\nsome sort of categories but  but something that allows for overlapping change of these things and then this would give some more ground work for people who were building statistical models that allowed for overlapping changes , different timing changes as opposed to just \" click , you 're now in this state , which corresponds to this speech sound \" and so on .\nMm - hmm . Mm - hmm .\nSo this is like gestural  uh , these g\nYeah , something like that .\nRight . OK .\nI mean , actually if we get into that it might be good to , uh , uh , haul John Ohala into this\nRight .\nand ask his  his views on it I think .\nYeah .\nBut is  is the goal there to have this on meeting data ,\nExcellent .\nlike so that you can do far field studies  of those gestures or  um , or is it because you think there 's a different kind of actual production in meetings  that people use ? Or  ?\nNo , I think  I think it 's  for  for  for that purpose I 'm just viewing meetings as being a  a neat way to get people talking naturally . And then you have i and then  and then it 's natural in all senses ,\nJust a source of data ?\nI see .\nin the sense that you have microphones that are at a distance that you know , one might have , and you have the close mikes , and you have people talking naturally . And the overlap is just indicative of the fact that people are talking naturally ,\nUh - huh .\nYeah .\nRight .\nright ? So  so I think that given that it 's that kind of corpus ,\nYeah .\nif it 's gonna be a very useful corpus um , if you say w OK , we 've limited the use by some of our , uh , uh , censored choices , we don't have the video , we don't  and so forth , but there 's a lot of use that we could make of it by expanding the annotation choices .\nMm - hmm .\nAnd , uh , most of the things we 've talked about have been fairly high level , and being kind of a bottom - up person I thought maybe we 'd ,  do some of the others .\nHmm .\nRight . Yeah , that would be good .\nIt 's a nice balance .\nYeah .\nThat would be really nice to offer those things with that wide range .\nRight .\nYeah and hopefully someone would make use of it .\nReally nice .\nI mean , people didn't\nYeah .\nuh , I mean , people have made a lot of use of  of TIMIT and , uh w due to its markings , and then  the Switchboard transcription thing , well I think has been very useful for a lot of people .\nRight .\nThat 's true .\nSo\nI guess I wanted to , um , sort of make a pitch for trying to collect more meetings .\nCool .\nUm ,\nYeah .\nI actually I talked to Chuck Fillmore and I think they 've what , vehemently said no before but this time he wasn't vehement and he said you know , \" well , Liz , come to the meeting tomorrow\nYeah .\nand try to convince people \" . So I 'm gonna  try . Go to their meeting tomorrow and see if we can try , uh , to convince them\nMm - hmm . Good .\nCuz they have something like three or four different meetings ,\nbecause they have  And they have very interesting meetings from the point of view of a very different type of  of talk than we have here\nright ?\nMm - hmm .\nTalk\nand definitely than the front end meeting , probably . Um\nYou mean in terms of the topic  topics ?\nWell , yes and in terms of the  the fact that they 're describing abstract things and , uh , just dialogue - wise ,\nMm - hmm .\nright .\nMm - hmm .\nUm , so I 'll try . And then the other thing is , I don't know if this is at all useful , but I asked Lila if I can maybe go around and talk to the different departments in this building to see if there 's any groups that , for a free lunch ,\nYes .\nif we can still offer that , might be willing\nGreat .\nYou mean non - ICSI ?\nnon - ICSI , non - academic ,\nYeah , I guess you  you can try\nyou know , like government people ,\nbut\nI don't know .\nThe problem is so much of their stuff is confidential .\nSo .\nYeah .\nYeah .\nIt would be very hard for them .\nIs  is it in these departments ?\nYeah .\nAlso it does seem like it takes us way out of the demographic . I mean , it seems like we  we had this idea before of having like linguistics students brought down for free lunches\nWell , tha I think that 's her point .\nand that 's a nice idea .\nRight , and then we could also  we might try advertising again because I think it 'd be good if  if we can get a few different sort of non - internal types of meetings\nYeah .\nYeah .\nand just also more data . So .\nDoes  does John Ohala have weekly phonetics lab meetings ?\nMm - hmm .\nAnd I think , uh , if we could get\nSo I actually wrote to him and he answered , \" great , that sounds really interesting \" . But I never heard back because we didn't actually advertise openly . We a I mean w I told  I d asked him privately . Um , and it is a little bit of a trek for campus  folks .\nMm - hmm .\nYeah . You might give them a free lunch .\nUm , so it 's still worthwhile .\nBut , um , it would be nice if we got someone other than me who knew how to set it up and could do the recording\nSo\nso u I didn't have to do it each time .\nExactly , and  and\nYeah . That 's right .\nand I was thinking\nHe - he 's supposed  he 's supposed to be trained  to do it .\nYeah . Plus we could also get you know , a s a student .\nOK , next week  you 're going to do it all .\nYeah .\nAnd I 'm willing to try to learn . I mean , I 'm  I would do my best . Um , the other thing is that  there was a number of things at the transcription side that , um , transcribers can do , like dialogue act tagging ,\nIt 's not that hard .\ndisfluency tagging , um , things that are in the speech that are actually something we 're y  working on for language modeling . And Mari 's also interested in it , Andreas as well . So if you wanna process a utterance and the first thing they say is , \" well \" , and that \" well \" is coded as some kind of interrupt u tag . Uh , and things like that , um , th\nOf course some of that can be li done lexically .\nA lot of it can be done\nAnd I also  they are doing disfluency tagging to some degree already .\nGreat . So a  a lot of this kind of\nYeah .\nI think there 's a second pass and I don't really know what would exist in it . But there 's definitely a second pass worth doing to maybe encode some kinds of , you know , is it a question or not ,\nMm - hmm .\nor  um , that maybe these transcribers could do . So  Yeah .\nThey 'd be really good . They 're  they 're very  they 're very consistent .\nThat 'd be great .\nMm - hmm .\nUh , I wanted to  whi while we 're  Uh , so , to return just briefly to this question of more meeting data , um  I have two questions . One of them is , um , Jerry Feldman 's group , they  they , uh , are they  I know that they recorded one meeting . Are they willing ?\nI think they 're open to it . I think , you know , all these things are\nOh , yeah .\nI think there 's  we should go beyond , uh , ICSI but , I mean , there 's a lot of stuff happening at ICSI that we 're not getting now that we could .\nOh , that we could .\nSo it 's just\nMm - hmm .\nOK . I thought that all these people had sort of said \" no \" twice already .\nYeah . So the\nIf that 's not the case then\nNo , no . No . So th there was the thing in Fillmore 's group but even there he hadn't  What he 'd said \" no \" to was for the main meeting . But they have several smaller meetings a week ,\nSo .\nand , uh , the notion was raised before that that could happen . And it just , you know  it just didn't come together\nJust  OK .\nWell , and  and the other thing too is when they originally said \" no \" they didn't know about this post - editing capability thing .\nbut\nRight .\nOh .\nYeah .  Yeah .\nRight . That was a big fear .\nSo .\nThat 's important .\nYeah , so I mean there 's possibilities there . I think Jerry 's group , yes .\nOK .\nUh , there 's  there 's , uh , the networks group , uh , I don't  Do they still meeting regularly or  ?\nWell , I don't know if they meet regularly or not but they are no longer recording .\nBut I mean , ha ha have they said they don't want to anymore or  ?\nUm , ugh , what was his name ?\nUh , i i\nJoe Sokol ?\nYeah .\nYeah .\nWhen  with him gone , it sorta trickled off .\nOK , so they 're down to three or four people\nThey  and they stopped  Yeah .\nMm - hmm .\nbut the thing is three or four people is OK .\nYep .\nWe might be able to get the administration\nWell he was sort of my contact , so I just need to find out who 's running it now .\nOK .\nSo .\nI see that Lila has a luncheon meeting in here periodically .\nYeah , I mean , it  One thing that would be nice\nI don't know\nand this  it sounds bizarre but , I 'd really like to look at  to get some meetings where there 's a little bit of heated discussion , like ar arguments and  or emotion , and things like that . And so I was thinking if there 's any like Berkeley political groups or something . I mean , that 'd be perfect . Some group , \" yes , we must  \"\nWho 's willing to get recorded and distributed ?\nWell , you know , something\nYeah .\nYeah , I don't think the more political argumentative ones would be willing to\nUm\nYeah , with  with  with potential use from the defense department .\nYeah .\nWell , OK .\nYeah .\nNo , but maybe stu student , uh , groups or , um , film - makers , or som Something a little bit colorful .\nYeah .\nYeah .  Exactly .\nYeah .\nYeah .\nYeah .\nYeah .     Yeah , th there 's a problem there in terms of , uh , the um commercial value of  of st uh ,\nYeah , of course there is this problem though , that if we give them the chance to excise later we e  might end up with like five minutes out of a f   of m one hour\nFilm - maker .\nOf beeps ,\nYeah . Yeah .\nyeah .\nAnd I don't mean that they 're angry\nIs\nof   Yes . Really .\nbut just something with some more variation in prosodic contours and so forth would be neat . So if anyone has ideas , I 'm willing to do the leg work to go try to talk to people but I don't really know which groups are worth pursuing .\nWell there was this K P F A\nNo that 's\nbut  OK .\nLegal .\nOK , OK .\nit  it  it  it turned out to be a bit of a problem .\nOr\nAnd I had one other  one other aspect of this which is , um , uh , uh , Jonathan Fiscus expressed primar uh y a major interest in having meetings which were all English speakers . Now he wasn't trying to shape us in terms of what we gather\nMm - hmm .\nbut that 's what he wanted me to show him . So I 'm giving him our , um  our initial meeting because he asked for all English . And I think we don't have a lot of all English meetings right now .\nOf all  all nat all native speakers .\nDid he mean , uh  did he mean and non - British ?\nWell\nThe all native .\nThat 's what I mean , yeah .\nWell if he meant and non - British I think we have zero .\nHe doesn't care . No . Eh , well , British is OK .\nHe said British was OK ?\nBut  but  Sure , sure , sure .\nWhy ?\nBritish is English ?\nYeah . Different varieties of English .\nOoo , ooo .\nWell , I don't  I don't  I don't think  if he didn't say that\nNative speaking . Native speaking English .\nI bet he meant native speaking American .\nYes .\nI bet he did .\nAmerican English ?\nOh , really .\nSo , why would he care ?\nKnowing the application\nThat 's\nI remember wh I I remember a study\nI was thinking , knowing the , uh , n National Institute of Standards , it is all\nI remember a study that BBN did where they trained on  this was in Wall Street Journal days or something , they trained on American English and then they tested on , uh , different native speakers from different areas . And , uh , uh , the worst match was people whose native tongue was Mandarin Chinese . The second worst was British English .\nThat 's funny .\nSo h it 's , you know , t\nAlright . And so that would make sense .\nthe  the  the  German was much better ,\nOoo , ooo .\nI didn't have the context of that .\nit was Swiss w Yeah , so it 's  so I think , you know , if he 's  if he 's thinking in terms of recognition kind of technology I  I  I think he would probably want , uh  American English ,\nAll America , OK .\nI wonder if we have any .\nyeah . It  it  yeah , unless we 're gonna train with a whole bunch of\nI think that the  Feldman 's meetings tend to be more that way , aren't they ? I mean , I sort of feel like they have\nI think so ,\nMaybe .\nYeah ,\nyeah .\nMaybe .\nmm - hmm .\nYeah .\nMmm .\nAnd maybe there are a few of  with us where it was\nYeah .\nyou know , Dan wasn't there and before Jose started coming ,\nYeah .\nYeah .\nand\nIt 's pretty tough , uh , this group . Yeah .\nYeah .\nMmm .\nSo , uh , what about  what about people who involved in some artistic endeavor ?\nYeah .\nI mean , film - making or something like that .\nExactly , that 's what I was\nYou 'd think like they would be\nA film - maker .\nsomething where there  there is actually discussion where there 's no right or wrong answer but  but it 's a matter of opinion kind of thing . Uh , anyway , if you  if you have ideas\nIt 's be fun .\nRASTA . PLP . RASTA . PLP .\nYes .\nWe can just discu we can just have a political discussion one day .\nYeah , we could\nA any department that calls itself science\nDepartment .\nUh , I could make that pretty\nYeah .\nWell , like computer science .\nComputer sci\nThat\nWe could get Julia Child . I know .\nI 'm  I 'm actually serious\nThat 's\nbecause , uh , you know , we have the set up here\nGot a ticket .\nYeah , I know you are .\nand  and that  that has a chance to give us some very interesting fun data . So if anyone has ideas ,\nYeah .\nif you know any groups that are m you know ,\nYeah .\nYeah .\nWell I had asked some  some of the students at the business school .\nstudent groups c like clubs , things like that .\nI know\nI could\nNot  not\nPut a little ad up saying , \" come here and argue \" .\nYeah . \" If you 're really angry at someone use our conference room . \"\nThe Business school . Uh , the business school might be good . I actually spoke with some students up there\nOh , OK .\nand they  they  they expressed willingness back when they thought they would be doing more stuff with speech .\nReally .\nBut when they lost interest in speech they also  stopped answering my email about other stuff , so .\nHmm .\nOr people who are really h\nThey could have a discussion about te\nI\nWe should probably bleep that out .\nabout  about tax cuts or something .\nI heard that at Cal Tech they have a special room  someone said that they had a special room to get all your frustrations out that you can go to and like throw things and break things .\nYeah , now that is not actually what we\nSo we can like post a\nTh - that 's not what we want .\nNo , not to that extent\nWell , far field mikes can pick up where they threw stuff on the wall .\nbut , um . Yeah .\nYeah , but we don't want them to throw the far field mikes is the thing .\nOh .  Yeah , right .", "topic_id": 1, "keywords": "collaborating, synch, transcripts, meetings, conversation", "dialogue_id": 28}, {"text": "That 's right .\nThe fa\nYeah .\n\" Please throw everything in that direction . \"\nYeah . Anyway .\nPadded cell .\nIt 'd be fun to get like a  a p visit from the\nThere was a dorm room at Tech that , uh , someone had coated the walls and the ceiling , and , uh , the floor with mattresses .\nMmm .\nThe entire room .\nI had as my fourth thing here processing of wave forms .\nYeah .\nWhat did we mean by that ? Remember @ @ ?\nUh , Liz wanted to talk about methods of improving accuracy by doing pre - processing .\nPre - processing .\nWell I think that  that was just sort of  I I already asked Thilo\nOh , you already did that .\nbut that , um , it would be helpful if I can stay in the loop somehow with , um , people who are doing any kind of post - processing , whether it 's to separate speakers or to improve the signal - to - noise ratio , or both , um , that we can sort of try out as we 're running recognition . Um , so , i is that  Who else is work I guess Dan Ellis and you\nDan , yeah .\nYeah , and Dave uh  Gel - Gelbart again ,\nYep .\nand Dave .\nYep .\nOK .\nYeah .\nhe 's  he 's interested in  in fact we 're look starting to look at some echo cancellation kind of things .\nOK .\nWhich uh\nI am not sure how much that 's an issue with the close talking mikes ,\nHmm ?\nbut who knows ?\nWell , let 's  w i isn't that what  what you want\nI don't know . I 'm bad\nt No , so  No , i w wha what you  what you want  when you 're saying improving the wave form you want the close talking microphone to be better .\nIt 's like    like\nRight ?\nRight .\nAnd the question is to w to what extent is it getting hurt by , uh  by any room acoustics or is it just  uh , given that it 's close it 's not a problem ?\nIt doesn't seem like big room acoustics problems to my ear\nUh\nbut I 'm not an expert . It seems like a problem with cross - talk .\nOK , so it 's\nYeah .\ne I bet with the lapel mike there 's plenty , uh , room acoustic\nThat  that may be true .\nbut I I think the rest is cross - talk .\nBut I don't know how good it can get either by those  the  those methods\nYeah .\nThat 's true .\nOK .\nSo I  I think it 's just ,\nOh , I don't know .\nyeah , what you said , cross - talk .\nAll I meant is just that as sort of  as this pipeline of research is going on we 're also experimenting with different ASR , uh , techniques .\nMm - hmm .\nAnd so it 'd be w good to know about it .\nSo the problem is like , uh , on the microphone of somebody who 's not talking they 're picking up signals from other people  and that 's  causing problems ?\nR right , although if they 're not talking , using the  the inhouse transcriptions , were sort of O K because the t no one transcribed any words there and we throw it out .\nMm - hmm .\nBut if they 're talking at all and they 're not talking the whole time , so you get some speech and then a \" mm - hmm \" , and some more speech , so that whole thing is one chunk . And the person in the middle who said only a little bit is picking up the speech around it , that 's where it 's a big problem .\nYou know , this does like seem like it would relate to some of what Jose 's been working on as well , the encoding of the\nYeah .\nAnd  and he also , he was\nThe energy ,\nYeah ,\nright . Exactly .\nenergy .\nI was t I was trying to remember , you have this interface where you  i you ha you showed us one time on your laptop that you  you had different visual displays as speech and nonspeech events .\nYeah , c Yeah . May  I  I only display the different colors for the different situation . But , eh , for me and for my problems , is uh  is enough . Because , eh , it 's possible , eh , eh , in a simp sample view , uh , to , nnn , to compare with c with the segment , the  the kind of assessment what happened with the  the different parameters . And only with a different bands of color for the , uh , few situation , eh , I consider for acoustic event is enough to @ @ .\nMm - hmm .\nI  I   I see that , eh , you are considering now , eh , a very sophisticated , eh , ehm , eh , @ @  set of , eh , graphic s eh , eh , ehm , si symbols to  to transcribe . No ? Because , uh , before , you  you are talking about the  the possibility to include in the Transcriber program eh , um , a set of symbols , of graphic symbol to  t to mark the different situations during the transcription\nOh , I w Uh - huh .\nduring the transcription . No ?\nWell , you 're saying  So , uh , symbols for differences between laugh , and sigh , and  and  and slam the door and stuff ?\nYeah . Yeah , yeah . The s the symbols , you  you talk of before .\nOr some other kind of thing ?\nNo ? To  to mark\nWell , I wouldn't say  symbols so much . The  the main change that I  that I see in the interface is  is just that we 'll be able to more finely c uh , time things .\nYeah . Yeah .\nBut I  I also st there was another aspect of your work that I was thinking about when I was talking to you\nHmm .\nwhich is that it sounded to me , Liz , as though you  and , uh , maybe I didn't q understand this , but it sounded to me as though part of the analysis that you 're doing involves taking segments which are of a particular type and putting them together .\nYeah .\nAnd th so if you have like a p a s you know , speech from one speaker ,  then you cut out the part that 's not that speaker ,\nMm - hmm .\nand you combine segments from  that same speaker to   and run them through the recognizer . Is that  right ?\nWell we try to find as close of start and end time of  as we can to the speech from an individual speaker ,\nMm - hmm .\nbecause then we  we 're more guaranteed that the recognizer will  for the forced alignment which is just to give us the time boundaries , because from those time boundaries then the plan is to compute prosodic features .\nMm - hmm .\nAnd the sort of more space you have that isn't the thing you 're trying to align the more errors we have . Um , so , you know , that  that  it would help to have either pre - processing of a signal that creates very good signal - to - noise ratio ,\nMm - hmm . Cuz i OK .\nwhich I don't know how possible this is for the lapel , um , or to have very  to have closer ,  um , time  you know , synch times , basically , around the speech that gets transcribed in it , or both . And it 's just sort of a open world right now of exploring that . So I just wanted to  see , you know , on the transcribing end from here things look good . Uh , the IBM one is more  it 's an open question right now . And then the issue of like global processing of some signal and then , you know , before we chop it up is  is yet another way we can improve things in that .\nWhat about increasing the flexibility of the alignment ?\nOK .\nDo you remember that thing that Michael Finka did ?\nMm - hmm .\nthat experiment he did a while back ?\nRight . You can , um  The problem is just that the acoustic  when the signal - to - noise ratio is too low , um , you  you 'll get , a uh  an alignment with the wrong duration pattern or it\nOh , so that 's the problem , is the  the signal - to - noise ratio .\nYeah . It 's not the fact that you have like  I mean , what he did is allow you to have , uh , words that were in another segment move over to the  at the edges of  of segmentations .\nMm - hmm . Or even words inserted that weren't  weren't there .\nRight , things  things near the boundaries where if you got your alignment wrong\nMm - hmm .\ncuz what they had done there is align and then chop .\nMm - hmm .\nUm , and this problem is a little bit j more global . It 's that there are problems even in inside the alignments , uh , because of the fact that there 's enough acoustic signal there t for the recognizer to  to eat ,  as part of a word . And it tends to do that . S So , uh ,\nYeah .\nbut we probably will have to do something like that in addition . Anyway . So , yeah , bottom  bottom line is just I wanted to make sure I can be aware of whoever 's working on these signal - processing techniques for , uh , detecting energies ,\nYeah .\nbecause that  that 'll really help us .\nO K , uh tea has started out there I suggest we c run through our digits and ,\nOK .\nUh , So , OK , we 're done .", "topic_id": 2, "keywords": "processing, signals, wave, involves, signal", "dialogue_id": 28}, {"text": "OK , we 're going .\nEight , eight ?\nThis is three .\nThree .\nYep . Yep .\nTest . Hmm . Let 's see . Move it bit . Test ? Test ? OK , I guess it 's alright . So , let 's see . Yeah , Barry 's not here and Dave 's not here . Um , I can say about  just q just quickly to get through it , that Dave and I submitted this ASRU .\nThis is for ASRU .\nYeah . So . Um . Yeah , it 's  it 's interesting . I mean , basically we 're dealing with rever reverberation , and , um , when we deal with pure reverberation , the technique he 's using works really , really well . Uh , and when they had the reverberation here , uh , we 'll measure the signal - to - noise ratio and it 's , uh , about nine DB . So ,\nHmm .\num ,\nYou mean , from the actual , uh , recordings ?\na fair amount of\nk\nIt 's nine DB ?\nYeah . Yeah . Um  And actually it brought up a question which may be relevant to the Aurora stuff too . Um , I know that when you figured out the filters that we 're using for the Mel scale , there was some experimentation that went on at  at , uh  at OGI . Um , but one of the differences that we found between the two systems that we were using ,  the  the Aurora HTK system baseline system  and the system that we were  the  the uh , other system we were using , the uh , the SRI system , was that the SRI system had maybe a , um , hundred hertz high - pass . And the , uh , Aurora HTK , it was like twenty .\nYep . S sixty - four .\nUh .\nS sixty - four .\nSixty - four ? Uh .\nYeah , if you 're using the baseline .\nIs that the ba band center ?\nNo , the edge .\nThe edge is really , uh , sixty - four ?\nYeah .\nFor some reason , uh , Dave thought it was twenty ,\nSo the , uh , center would be somewhere around like hundred\nbut .\nand  hundred and  hundred  hundred and  maybe  it 's like  fi hundred hertz .\nBut do you know , for instance , h how far down it would be at twenty hertz ? What the  how much rejection would there be at twenty hertz , let 's say ?\nAt twenty hertz .\nYeah , any idea what the curve looks like ?\nTwenty hertz frequency  Oh , it 's  it 's zero at twenty hertz , right ? The filter ?\nYea - actually , the left edge of the first filter is at sixty - four .\nSixt - s sixty - four .\nSo\nSo anything less than sixty - four is zero .\nMmm .\nIt 's actually set to zero ? What kind of filter is that ?\nYeah .\nYeah .\nIs this  oh , from the  from\nIt  This is the filter bank in the frequency domain that starts at sixty - four .\nOh , so you , uh  so you really set it to zero , the FFT ?\nYeah ,\nYeah .\nyeah . So it 's  it 's a weight on the ball spectrum . Triangular weighting .\nRight . OK . Um  OK . So that 's  that 's a little different than Dave thought , I think . But  but , um , still , it 's possible that we 're getting in some more noise . So I wonder , is it  @ @ Was there  their experimentation with , uh , say , throwing away that filter or something ? And , uh\nUh , throwing away the first ?\nYeah .\nUm , yeah , we  we 've tried including the full  full bank . Right ? From zero to four K .\nMm - hmm .\nAnd that 's always worse than using sixty - four hertz .\nRight , but the question is , whether sixty - four hertz is  is , uh , too , uh , low .\nYeah , I mean , make it a hundred or so ?\nYeah .\nI t I think I 've tried a hundred and it was more or less the same , or slightly worse .\nOn what test set ?\nOn the same , uh , SpeechDat - Car , Aurora .\nUm , it was on the SpeechDat - Car .\nYeah . So I tried a hundred to four K . Yeah .\nUm ,\nSo it was\nand on  and on the , um , um ,  TI - digits also ?\nNo , no , no . I think I just tried it on SpeechDat - Car .\nMmm . That 'd be something to look at sometime because what , um , eh , he was looking at was performance in this room .\nMm - hmm .\nWould that be more like  Well , you 'd think that 'd be more like SpeechDat - Car , I guess , in terms of the noise . The SpeechDat - Car is more , uh , sort of roughly stationary , a lot of it . And  and TI - digits maybe is not so much as\nYeah .\nMm - hmm .\nYeah .\nYeah .\nMm - hmm . OK . Well , maybe it 's not a big deal . But , um  Anyway , that was just something we wondered about . But , um , uh , certainly a lot of the noise , uh , is , uh , below a hundred hertz . Uh , the signal - to - noise ratio , you know , looks a fair amount better if you  if you high - pass filter it from this room .\nYeah .\nBut , um  but it 's still pretty noisy . Even  even for a hundred hertz up , it 's  it 's still fairly noisy . The signal - to - noise ratio is  is  is actually still pretty bad .\nMm - hmm .\nHmm .\nSo , um , I mean , the main  the  the\nSo that 's on th that 's on the f the far field ones though , right ? Yeah .\nYeah , that 's on the far field . Yeah , the near field 's pretty good .\nSo wha what is , uh  what 's causing that ?\nWell , we got a  a video projector in here , uh , and , uh  which we keep on during every  every session we record ,\nYeah .\nwhich , you know , I  I  w we were aware of\nUh - huh .\nbut  but we thought it wasn't a bad thing .\nYeah .\nI mean , that 's a nice noise source . Uh , and there 's also the , uh  uh , air conditioning .\nHmm .\nWhich , uh , you know , is a pretty low frequency kind of thing .\nMm - hmm .\nBut  but , uh  So , those are  those are major components , I think ,\nI see .\nuh , for the stationary kind of stuff .\nMmm .\nUm , but , um , it , uh  I guess , I  maybe I said this last week too but it  it  it really became apparent to us that we need to  to take account of noise . And , uh , so I think when  when he gets done with his prelim study I think  one of the next things we 'd want to do is to take this , uh  uh , noise , uh , processing stuff and  and , uh  uh , synthesize some speech from it .\nWhen are his prelims ?\nAnd then  Um , I think in about , um , a little less than two weeks .\nOh . Wow .\nYeah . Yeah . So . Uh , it might even be sooner . Uh , let 's see , this is the sixteenth , seventeenth ? Yeah , I don't know if he 's before  It might even be in a week .\nSo , I\nA week ,\nHuh . I  I guessed that they were gonna do it some time during the semester\nweek and a half .\nbut they 'll do it any time , huh ?\nThey seem to be  Well , the semester actually is starting up .\nIs it already ?\nYeah , the semester 's late  late August they start here .\nYikes .\nSo they do it right at the beginning of the semester .\nYeah .\nYeah . So , uh  Yep . I mean , that  that was sort of one  I mean , the overall results seemed to be first place in  in  in the case of either , um , artificial reverberation or a modest sized training set . Uh , either way , uh , i uh , it helped a lot . And  But if you had a  a really big training set , a recognizer , uh , system that was capable of taking advantage of a really large training set  I thought that  One thing with the HTK is that is has the  as we 're using  the configuration we 're using is w s is  being bound by the terms of Aurora , we have all those parameters just set as they are . So even if we had a hundred times as much data , we wouldn't go out to , you know , ten or t or a hundred times as many Gaussians or anything . So , um , it 's kind of hard to take advantage of  of  of big chunks of data . Uh , whereas the other one does sort of expand as you have more training data .\nMm - hmm .\nMmm , yeah .\nIt does it automatically , actually . And so , um , uh , that one really benefited from the larger set . And it was also a diverse set with different noises and so forth . Uh , so , um , that , uh  that seemed to be  So , if you have that  that better recognizer that can  that can build up more parameters , and if you , um , have the natural room , which in this case has a p a pretty bad signal - to - noise ratio , then in that case , um , the right thing to do is just do  u use speaker adaptation . And  and not bother with  with this acoustic , uh , processing . But I think that that would not be true if we did some explicit noise - processing as well as , uh , the convolutional kind of things we were doing .\nMm - hmm .\nSo . That 's sort of what we found .\nHmm .\nI , um   uh , started working on the uh  Mississippi State recognizer . So , I got in touch with Joe and  and , uh , from your email and things like that .\nOh , OK .\nAnd , uh , they added me to the list  uh , the mailing list .\nOK , great .\nAnd he gave me all of the pointers and everything that I needed . And so I downloaded the , um  There were two things , uh , that they had to download . One was the , uh , I guess the software . And another wad  was a , um , sort of like a sample  a sample run . So I downloaded the software and compiled all of that . And it compiled fine .\nEight .\nNo problems .\nOh , eh , great .\nAnd , um , I grabbed the sample stuff but I haven't , uh , compiled it .\nThat sample was released only yesterday or the day before , right ?\nNo  Well , I haven't grabbed that one yet . So there 's two .\nOh , there is another short sample set\nThere was another short one , yeah .\no o sample .\nAnd so I haven't grabbed the latest one that he just , uh , put out yet .\nOK . Oh , OK . F Yeah , OK .\nSo . Um , but , the software seemed to compile fine and everything , so . And , um , So .\nIs there any word yet about the issues about , um , adjustments for different feature sets or anything ?\nNo , I  I d You asked me to write to him and I think I forgot to ask him about that . Or if I did ask him , he didn't reply .\nYeah .\nI  I don't remember yet . Uh , I 'll  I 'll d I 'll double check that and ask him again .\nYeah . Yeah , it 's like that  that could r turn out to be an important issue for us .\nHmm . Mmm .\nYeah . Yeah .\nYeah .\nCuz they have it\nMaybe I 'll send it to the list . Yeah .\nCuz they have , uh , already frozen those in i insertion penalties and all those stuff is what  I feel . Because they have this document explaining the recognizer .\nUh - huh .\nAnd they have these tables with , uh , various language model weights , insertion penalties .\nOK , I haven't seen that one yet .\nu\nSo .\nUh , it 's th it 's there on that web .\nOK .\nAnd , uh , on that , I mean , they have run some experiments using various insertion penalties and all those\nAnd so they 've picked  the values .\nYeah , I think they pi p\nOh , OK .\nyeah , they picked the values from\nOK .\nFor r w what test set ?\nUh , p the one that they have reported is a NIST evaluation , Wall Street Journal .\nBut that has nothing to do with what we 're testing on , right ?\nMm - hmm .\nYou know . No . So they 're , like  um  So they are actually trying to , uh , fix that  those values using the clean , uh , training part of the Wall Street Journal . Which is  I mean , the Aurora . Aurora has a clean subset .\nRight .\nI mean , they want to train it and then this  they 're going to run some evaluations .\nSo they 're set they 're setting it based on that ?\nYeah .\nOK . So now , we may come back to the situation where we may be looking for a modification of the features to account for the fact that we can't modify these parameters .\nYeah .\nBut , um ,\nYeah .\nuh  but it 's still worth , I think , just  since  you know , just chatting with Joe about the issue .\nYeah , OK . Do you think that 's something I should just send to him\nUm\nor do you think I should send it to this  there 's an  a m a mailing list .\nWell , it 's not a secret . I mean , we 're , you know , certainly willing to talk about it with everybody , but I think  I think that , um  um , it 's probably best to start talking with him just to\nOK .\nUh @ @  you know , it 's a dialogue between two of you about what  you know , what does he think about this and what  what  you know  what could be done about it .\nYeah . OK .\nUm , if you get ten people in  involved in it there 'll be a lot of perspectives based on , you know , how\nYeah .\nyou know .\nRight .\nUh  But , I mean , I think it all should come up eventually ,\nOK .\nbut if  if  if there is any , uh , uh , way to move in  a way that would  that would , you know , be more open to different kinds of features . But if  if , uh  if there isn't , and it 's just kind of shut down and  and then also there 's probably not worthwhile bringing it into a larger forum where  where political issues will come in .\nYeah . OK .\nOh . So this is now  it 's  it 's compiled under Solaris ?\nYeah .\nYeah , OK .\nYep .\nBecause he  there was some mail r saying that it 's  may not be stable for Linux and all those .\nYeah . Yeah , i that was a particular version .\nSUSI\nYeah , SUSI or whatever it was\nyeah . Yeah , yeah .\nbut we don't have that .\nYeah , OK .\nSo . Should be OK .\nOK , that 's fine .\nYeah , it compiled fine actually .\nYeah .\nNo  no errors . Nothing . So .\nUh , this is slightly off topic\nThat 's good .\nbut , uh , I noticed , just glancing at the , uh , Hopkins workshop , uh , web site that , uh , um  one of the thing I don't know  Well , we 'll see how much they accomplish , but one of the things that they were trying to do in the graphical models thing was to put together a  a , uh , tool kit for doing , uh r um , arbitrary graphical models for , uh , speech recognition .\nHmm .\nSo  And Jeff , uh  the two Jeffs were\nWho 's the second Jeff ?\nUh  Oh , uh , do you know Geoff Zweig ?\nNo .\nOh . Uh , he  he , uh  he was here for a couple years\nOh , OK .\nand he , uh  got his PHD . He  And he 's , uh , been at IBM for the last couple years .\nOh , OK .\nSo .\nWow . That would be neat .\nUh , so he did  he did his PHD on dynamic Bayes - nets , uh , for  for speech recognition . He had some continuity built into the model , presumably to handle some , um , inertia in the  in the production system , and , um\nHmm .\nSo .\nHmm .", "topic_id": 0, "keywords": "reverberation, recordings, rever, aurora, noise", "dialogue_id": 29}, {"text": "Um , I 've been playing with , first , the , um , VAD . Um ,  so it 's exactly the same approach , but the features that the VAD neural network use are , uh , MFCC after noise compensation . Oh , I think I have the results .\nWhat was it using before ?\nBefore it was just P L\nSo .\nYeah , it was actually  No . Not  I mean , it was just the noisy features I guess .\nYeah ,\nYeah , yeah , yeah ,\nnoisy  noisy features .\nnot compensated .\nUm  This is what we get after  This  So , actually , we , yeah , here the features are noise compensated and there is also the LDA filter . Um , and then it 's a pretty small neural network which use , um ,  nine frames of  of six features from C - zero to C - fives , plus the first derivatives . And it has one hundred hidden units .\nIs that nine frames u s uh , centered around the current frame ? Or\nYeah . Mm - hmm .\nS so , I 'm  I 'm sorry , there 's  there 's  there 's how many  how many inputs ?\nSo it 's twelve times nine .\nTwelve times nine inputs , and a hundred , uh , hidden .\nHidden and\nTwo outputs .\ntwo outputs .\nTwo outputs . OK . So I guess about eleven thousand parameters , which  actually shouldn't be a problem , even in  in small phones . Yeah .\nMm - hmm .\nSo , I 'm  I 'm  s so what is different between this and  and what you\nIt should be OK . So the previous syst It 's based on the system that has a fifty - three point sixty - six percent improvement . It 's the same system . The only thing that changed is the n a p eh  a es the estimation of the silence probabilities .\nAh . OK .\nWhich now is based on , uh , cleaned features .\nAnd , it 's a l it 's a lot better .\nWow .\nYeah .\nThat 's great .\nUm  So it 's  it 's not bad , but the problem is still that the latency is too large .\nWhat 's the latency ?\nBecause  um  the  the latency of the VAD is two hundred and twenty milliseconds . And , uh , the VAD is used uh , i for on - line normalization , and it 's used before the delta computation . So if you add these components it goes t to a hundred and seventy , right ?\nI  I 'm confused . You started off with two - twenty and you ended up with one - seventy ?\nWith two an two hundred and seventy .\nTwo - seventy .\nIf  Yeah , if you add the c delta comp delta computation\nOh .\nwhich is done afterwards . Um\nSo it 's two - twenty . I the is this  are these twenty - millisecond frames ? Is that why ? Is it after downsampling ? or\nThe two - twenty is one hundred milliseconds for the um  No , it 's forty milliseconds for t for the , uh , uh , cleaning of the speech . Um  then there is , um , the neural network which use nine frames . So it adds forty milliseconds .\na OK .\nUm , after that , um , you have the um , filtering of the silence probabilities . Which is a million filter it , and it creates a one hundred milliseconds delay . So , um\nPlus there is a delta at the input .\nYeah , and there is the delta at the input which is ,\nOne hundred milliseconds for smoothing .\num  So it 's  @ @\nUh , median .\nIt 's like forty plus  forty  plus\nAnd then forty\nMmm . Forty  This forty plus twenty , plus one hundred .\nforty p\nUh\nSo it 's two hundred actually .\nYeah , there are twenty that comes from  There is ten that comes from the LDA filters also . Right ?\nOh , OK .\nUh , so it 's two hundred and ten , yeah .\nIf you are using\nUh\nPlus the frame ,\nt If you are using three frames\nso it 's two - twenty .\nIf you are phrasing f  using three frames , it is thirty here for delta .\nYeah , I think it 's  it 's five frames , but .\nSo five frames , that 's twenty . OK , so it 's who un  two hundred and ten .\nUh , p Wait a minute . It 's forty   forty for the  for the cleaning of the speech ,\nSo . Forty cleaning .\nforty for the I N  ANN , a hundred for the smoothing .\nYeah .\nWell , but at ten  ,\nTwenty for the delta .\nTwenty for delta .\nAt th {nonvocalsound} At the input . I mean , that 's at the input to the net .\nYeah .\nDelta at input to net ?\nAnd there i\nYeah .\nYeah . So it 's like s five , six cepstrum plus delta at nine  nine frames of\nAnd then ten milliseconds for\nFi - There 's an LDA filter .\nten milliseconds for LDA filter , and t and ten  another ten milliseconds you said for the frame ?\nFor the frame I guess . I computed two - twenty  Yeah , well , it 's  I guess it 's for the fr  the\nOK . And then there 's delta besides that ?\nSo this is the features that are used by our network and then afterwards , you have to compute the delta on the , uh , main feature stream ,\nOK .\nwhich is um , delta and double - deltas , which is fifty milliseconds .\nYeah . No , I mean , the  after the noise part , the forty  the  the other hundred and eighty  Well , I mean , Wait a minute . Some of this is , uh  is , uh  is in parallel , isn't it ? I mean , the LDA  Oh , you have the LDA as part of the V D - uh , VAD ? Or\nThe VAD use , uh , LDA filtered features also .\nOh , it does ?\nMm - hmm .\nAh . So in that case there isn't too much in parallel . Uh\nNo . There is , um , just downsampling , upsampling , and the LDA .\nUm , so the delta at the end is how much ?\nIt 's fifty .\nIt 's\nFifty . Alright . So\nBut well , we could probably put the delta , um ,  before on - line normalization . It should not that make a big difference ,\nWhat if you used a smaller window for the delta ?\nbecause\nCould that help a little bit ? I mean , I guess there 's a lot of things you could do to\nYeah .\nYeah .\nYeah ,\nSo\nbut , nnn\nYeah . So if you  if you put the delta before the , uh , ana on - line  If  Yeah\nMm - hmm .\nuh  then  then it could go in parallel .\nCuz i\nAnd then y then you don't have that additive\nYeah ,\nYep .\ncuz the time constant of the on - line normalization is pretty long compared to the delta window ,\nOK .\nso . It should not make\nOK . And you ought to be able to shove tw , uh  sh uh  pull off twenty milliseconds from somewhere else to get it under two hundred , right ? I mean\nIs two hundred the d\nThe hundred milla\nMm - hmm .\nmill a hundred milliseconds for smoothing is sort of an arbitrary amount . It could be eighty and  and probably do @ @\nYeah ,\ni a hun\nyeah .\nuh  Wh - what 's the baseline you need to be under ? Two hundred ?\nWell , we don't know . They 're still arguing about it .\nOh .\nI mean , if it 's two  if  if it 's , uh  if it 's two - fifty , then we could keep the delta where it is if we shaved off twenty . If it 's two hundred , if we shaved off twenty , we could  we could , uh , meet it by moving the delta back .", "topic_id": 1, "keywords": "lda, noise, noisy, vad, mfcc", "dialogue_id": 29}, {"text": "So , how do you know that what you have is too much if they 're still deciding ?\nUh , we don't , but it 's just  I mean , the main thing is that since that we got burned last time , and  you know , by not worrying about it very much , we 're just staying conscious of it .\nUh - huh . Oh , OK , I see .\nAnd so , th I mean , if  if  if a week before we have to be done someone says , \" Well , you have to have fifty milliseconds less than you have now \" , it would be pretty frantic around here . So\nAh , OK .\nUh\nBut still , that 's  that 's a pretty big , uh , win . And it doesn't seem like you 're  in terms of your delay , you 're , uh , that\nHe added a bit on , I guess , because before we were  we were  had  were able to have the noise , uh , stuff , uh , and the LVA be in parallel .\nHmm .\nAnd now he 's  he 's requiring it to be done first .\nWell , but I think the main thing , maybe , is the cleaning of the speech , which takes forty milliseconds or so .\nRight . Well , so you say  let 's say ten milliseconds  seconds for the LDA .\nAnd  and  but  the LDA is , well , pretty short right now .\nWell , ten . And then forty for the other .\nYeah .\nYeah , the LDA  LDA  we don't know , is , like  is it very crucial for the features , right ?\nNo . I just  This is the first try .\nYeah .\nRight ,\nI mean , I  maybe the LDA 's not very useful then .\nso you could start pulling back ,\nS s h\nbut\nYeah ,\nBut I think you have\nl\nI mean , you have twenty for delta computation which y now you 're sort of doing twice , right ? But yo w were you doing that before ?\nMmm . Well , in the proposal , um , the input of the VAD network were just three frames , I think .\nOn the  in the  Mm - hmm . Just  Yeah , just the static , no delta .\nRight .\nUh , static features .\nSo , what you have now is fort uh , forty for the  the noise , twenty for the delta , and ten for the LDA . That 's seventy milliseconds of stuff which was formerly in parallel ,\nright ? So I think ,\nMm - hmm .\nyou know , that 's  that 's the difference as far as the timing , right ?\nYeah .\nUm , and you could experiment with cutting various pieces of these back a bit , but  I mean , we 're s we 're not  we 're not in terrible shape .\nYeah , that 's what it seems like to me . It 's pretty good .\nYeah .\nMm - hmm .\nIt 's  it 's not like it 's adding up to four hundred milliseconds or something .\nWhere  where is this  where is this fifty - seven point O two in  in comparison to the last evaluation ?\nWell , it 's  I think it 's better than anything , uh , anybody got .\nOh , is that right ?\nYeah . The best was fifty - four point five .\nYeah .\nPoint s\nOh .\nYeah . Uh\nAnd our system was forty - nine , but with the neural network .\nWow . So this is almost ten percent .\nWith the f with the neural net . Yeah , and r and\nIt would\nYeah , so this is  this is like the first proposal . The proposal - one . It was forty - four , actually .\nYeah . Yeah . And we still don't have the neural net in . So  so it 's\nWow .\nYou know . So it 's  We 're  we 're doing better .\nThis is  this is really good .\nI mean , we 're getting better recognition . I mean , I 'm sure other people working on this are not sitting still either , but\nYeah .\nbut  but , uh  Uh , I mean , the important thing is that we learn how to do this better , and , you know . So . Um , Yeah . So , our , um  Yeah , you can see the kind of  kind of numbers that we 're having , say , on SpeechDat - Car which is a hard task , cuz it 's really , um  I think it 's just sort of  sort of reasonable numbers , starting to be . I mean , it 's still terri\nMm - hmm . Yeah , even for a well - matched case it 's sixty percent error rate reduction ,\nYeah .\nwhich is\nYeah . Probably half . Good !\nUm , Yeah . So actually , this is in between  what we had with the previous VAD and what Sunil did with an IDL VAD . Which gave sixty - two percent improvement , right ?\nYeah , it 's almost that .\nSo\nIt 's almost an average somewhere around\nYeah .\nYeah .\nWhat was that ? Say that last part again ?\nSo , if you use , like , an IDL VAD , uh , for dropping the frames ,\no o Or the best we can get .\nthe best that we can get  i That means that we estimate the silence probability on the clean version of the utterances . Then you can go up to sixty - two percent error rate reduction , globally .\nMmm .\nMmm  Yeah .\nSo that would be even  That wouldn't change this number down here to sixty - two ?\nYeah .\nYeah . So you  you were get\nIf you add a g good v very good VAD , that works as well as a VAD working on clean speech ,\nYeah . Yeah .\nthen you wou you would go\nSo that 's sort of the best you could hope for .\nMm - hmm .\nI see .\nProbably . Yeah . So fi si fifty - three is what you were getting with the old VAD .\nYeah .\nAnd , uh  and sixty - two with the  the , you know , quote , unquote , cheating VAD . And fifty - seven is what you got with the real VAD .\nMm - hmm .\nThat 's great .\nUh , yeah , the next thing is , I started to play  Well , I don't want to worry too much about the delay , no . Maybe it 's better to wait\nOK .\nfor the decision\nYeah .\nfrom the committee . Uh , but I started to play with the , um ,   uh , tandem neural network . Mmm I just did the configuration that 's very similar to what we did for the February proposal . And  Um . So . There is a f a first feature stream that use uh straight MFCC features .\nMm - hmm .\nWell , these features actually . And the other stream is the output of a neural network , using as input , also , these , um , cleaned MFCC . Um\nThose are th those are th what is going into the tandem net ?\nI don't have the comp Mmm ?\nThose two ?\nSo there is just this feature stream ,  the fifteen MFCC plus delta and double - delta .\nNo .\nYeah ?\nUm , so it 's  makes forty - five features  that are used as input to the HTK . And then , there is  there are more inputs that comes from the tandem MLP .\nOh , oh . OK . I see .\nYeah , h he likes to use them both ,\nUh - huh .\ncuz then it has one part that 's discriminative ,\nYeah . Um\none part that 's not .\nRight . OK .\nSo , um , uh , yeah . Right now it seems that  i I just tested on SpeechDat - Car while the experiment are running on your  on TI - digits . Well , it improves on the well - matched and the mismatched conditions , but it get worse on the highly mismatched . Um ,\nCompared to these numbers ?\nCompared to these numbers , yeah . Um ,\ny\nlike , on the well - match and medium mismatch , the gain is around five percent relative , but it goes down a lot more , like fifteen percent on the HM case .\nYou 're just using the full ninety features ?\nThe\nY you have ninety features ?\ni I have , um  From the networks , it 's twenty - eight . So\nAnd from the other side it 's forty - five .\nSo , d i It 's forty - five .\nSo it 's  you have seventy - three features ,\nYeah .\nand you 're just feeding them like that .\nYeah .\nThere isn't any KLT or anything ?\nMm - hmm . There 's a KLT after the neural network , as  as before .\nThat 's how you get down to twenty - eight ?\nYeah .\nWhy twenty - eight ?\nI don't know .\nOh .\nUh . It 's  i i i It 's because it 's what we did for the first proposal . We tested , uh , trying to go down\nAh .\nIt 's a multiple of seven .\nand Yeah .\nYeah .\nSo  Um .\nYeah .\nI wanted to do something very similar to the proposal as a first  first try .\nYeah .\nI see .\nYeah .\nYeah . That makes sense .\nBut we have to  for sure , we have to go down , because the limit is now sixty features .\nYeah .\nSo , uh , we have to find a way to decrease the number of features . Um\nSo , it seems funny that  I don't know , maybe I don't u quite understand everything ,  but that adding features  I guess  I guess if you 're keeping the back - end fixed . Maybe that 's it . Because it seems like just adding information shouldn't give worse results . But I guess if you 're keeping the number of Gaussians fixed in the recognizer , then\nWell , yeah .\nMmm .\nBut , I mean , just in general , adding information  Suppose the information you added , well , was a really terrible feature and all it brought in was noise .\nYeah .\nRight ? So  so , um  Or  or suppose it wasn't completely terrible , but it was completely equivalent to another one feature that you had , except it was noisier .\nUh - huh .\nRight ? In that case you wouldn't necessarily expect it to be better at all .\nOh , yeah , I wasn't necessarily saying it should be better . I 'm just surprised that you 're getting fifteen percent relative worse on the wel\nUh - huh .\nBut it 's worse .\nOn the highly mismatched condition .\nOn the highly mismatch .\nYeah , I\nYeah .\nSo , \" highly mismatched condition \" means that in fact your training is a bad estimate of your test .\nUh - huh .\nSo having  having , uh , a g a l a greater number of features , if they aren't maybe the right features that you use , certainly can e can easily , uh , make things worse . I mean , you 're right . If you have  if you have , uh , lots and lots of data , and you have  and your  your  your training is representative of your test , then getting more sources of information should just help . But  but it 's  It doesn't necessarily work that way .\nHuh .\nMm - hmm .", "topic_id": 2, "keywords": "delay, timing, seconds, utterances, speech", "dialogue_id": 29}, {"text": "So I wonder , um , Well , what 's your  what 's your thought about what to do next with it ?\nUm , I don't know . I 'm surprised , because I expected the neural net to help more when there is more mismatch , as it was the case for the\nMm - hmm .\nSo , was the training set same as the p the February proposal ? OK .\nYeah , it 's the same training set , so it 's TIMIT with the TI - digits ' , uh , noises , uh , added .\nMm - hmm .\nUm\nWell , we might  uh , we might have to experiment with , uh better training sets . Again . But ,\nMm - hmm .\nI  The other thing is , I mean , before you found that was the best configuration , but you might have to retest those things now that we have different  The rest of it is different , right ? So , um , uh , For instance , what 's the effect of just putting the neural net on without the o other  other path ?\nMm - hmm .\nI mean , you know what the straight features do .\nYeah .\nThat gives you this . You know what it does in combination .\nMm - hmm .\nYou don't necessarily know what\nWhat if you did the  Would it make sense to do the KLT on the full set of combined features ? Instead of just on the\nYeah . I g I guess . Um . The reason I did it this ways is that in February , it  we  we tested different things like that , so , having two KLT , having just a KLT for a network , or having a global KLT .\nOh , I see .\nAnd\nSo you tried the global KLT before\nWell\nand it didn't really\nYeah . And , uh , th Yeah .\nI see .\nThe differences between these configurations were not huge , but  it was marginally better with this configuration .\nUh - huh . Uh - huh .\nBut , yeah , that 's obviously another thing to try ,\nUm .\nsince things are  things are different .\nMm - hmm . Mm - hmm .\nAnd I guess if the  These are all  so all of these seventy - three features are going into , um , the , uh  the HMM .\nYeah .\nAnd is  are  i i are  are any deltas being computed of tha of them ?\nOf the straight features , yeah .\nn Not of the\nSo . But n th the , um , tandem features are u used as they are .\nAre not .\nSo , yeah , maybe we can add some context from these features also as  Dan did in  in his last work .\nCould . i Yeah , but the other thing I was thinking was , um  Uh , now I lost track of what I was thinking . But .\nWhat is the  You said there was a limit of sixty features or something ?\nMm - hmm .\nWhat 's the relation between that limit and the , um , forty - eight  uh , forty eight hundred bits per second ?\nOh , I know what I was gonna say .\nUm , not  no relation .\nNo relation .\nSo I  I  I don't understand ,\nThe f the forty - eight hundred bits is for transmission of some features .\nbecause i I mean , if you 're only using h\nAnd generally , i it  s allows you to transmit like , fifteen , uh , cepstrum .\nThe issue was that , um , this is supposed to be a standard that 's then gonna be fed to somebody 's recognizer somewhere which might be , you know , it  it might be a concern how many parameters are use  u used and so forth . And so , uh , they felt they wanted to set a limit . So they chose sixty . Some people wanted to use hundreds of parameters and  and that bothered some other people .\nUh - huh .\nu And so they just chose that . I  I  I think it 's kind of r arbitrary too . But  but that 's  that 's kind of what was chosen . I  I remembered what I was going to say . What I was going to say is that , um , maybe   maybe with the noise removal , uh , these things are now more correlated . So you have two sets of things that are kind of uncorrelated , uh , within themselves , but they 're pretty correlated with one another .\nMm - hmm .\nAnd , um , they 're being fed into these , uh , variants , only Gaussians and so forth , and  and , uh ,\nMm - hmm .\nso maybe it would be a better idea now than it was before to , uh , have , uh , one KLT over everything , to de - correlate it .\nMm - hmm . Yeah , I see .\nMaybe . You know .\nWhat are the S N Rs in the training set , TIMIT ?\nIt 's , uh , ranging from zero to clean ? Yeah . From zero to clean .\nMm - hmm .\nYeah . So we found this  this , uh  this Macrophone data , and so forth , that we were using for these other experiments , to be pretty good .\nMm - hmm .\nSo that 's  i after you explore these other alternatives , that might be another way to start looking , is  is just improving the training set .\nMm - hmm .\nI mean , we were getting , uh , lots better recognition using that , than  Of course , you do have the problem that , um , u i  we are not able to increase the number of Gaussians , uh , or anything to , uh , uh , to match anything . So we 're only improving the training of our feature set , but that 's still probably something .\nSo you 're saying , add the Macrophone data to the training of the neural net ? The tandem net ?\nYeah , that 's the only place that we can train .\nYeah .\nWe can't train the other stuff with anything other than the standard amount ,\nRight .\nso . Um , um\nWhat  what was it trained on again ? The one that you used ?\nIt 's TIMIT with noise .\nUh - huh .\nYeah .\nSo , yeah , it 's rather a small\nHow big is the net , by the way ?\nUm , Uh , it 's , uh , five hundred hidden units . And\nAnd again , you did experiments back then where you made it bigger and it  and that was  that was sort of the threshold point . Much less than that , it was worse ,\nYeah .\nand\nYeah .\nmuch more than that , it wasn't much better . Hmm .\nYeah . @ @ ?\nSo is it  is it though the performance , big relation in the high ma high mismatch has something to do with the , uh , cleaning up that you  that is done on the TIMIT after adding noise ?\nSo  it 's  i All the noises are from the TI - digits ,\nYeah .\nright ? So you  i\nUm  They  k uh\nWell , it it 's like the high mismatch of the SpeechDat - Car after cleaning up , maybe having more noise than the  the training set of TIMIT after clean  s after you do the noise clean - up .\nMmm .\nI mean , earlier you never had any compensation , you just trained it straight away .\nMm - hmm .\nSo it had like all these different conditions of S N Rs , actually in their training set of neural net .\nMm - hmm . Mm - hmm .\nBut after cleaning up you have now a different set of S N Rs , right ?\nYeah .\nFor the training of the neural net .\nMm - hmm .\nAnd  is it something to do with the mismatch that  that 's created after the cleaning up , like the high mismatch\nYou mean the  the most noisy occurrences on SpeechDat - Car might be a lot more noisy than\nMm - hmm . Of  that  I mean , the SNR after the noise compensation of the SpeechDat - Car .\nOh , so  Right . So the training  the  the neural net is being trained with noise compensated stuff .\nMaybe .\nYeah .\nYeah , yeah .\nWhich makes sense ,\nYeah .\nbut , uh , you 're saying  Yeah , the noisier ones are still going to be , even after our noise compensation , are still gonna be pretty noisy .\nYeah .\nMm - hmm .\nYeah , so now the after - noise compensation the neural net is seeing a different set of S N Rs than that was originally there in the training set . Of TIMIT . Because in the TIMIT it was zero to some clean .\nRight . Yes .\nSo the net saw all the SNR @ @ conditions .\nRight .\nNow after cleaning up it 's a different set of SNR .\nRight .\nAnd that SNR may not be , like , com covering the whole set of S N Rs that you 're getting in the SpeechDat - Car .\nRight , but the SpeechDat - Car data that you 're seeing is also reduced in noise by the noise compensation .\nYeah .\nYeah , yeah , yeah , yeah , it is . But , I 'm saying , there could be some  some issues of\nSo .\nMm - hmm .\nYeah .\nWell , if the initial range of SNR is different , we  the problem was already there before . And\nYeah .\nBecause  Mmm\nYeah , I mean , it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set .\nHmm .\nUh\nOn the test set , yeah .\nRight ? I mean , you 're saying there 's a mismatch in noise that wasn't there before ,\nHmm . Mm - hmm .\nbut if they were both the same before , then if they were both reduic reduced equally , then , there would not be a mismatch .\nMm - hmm .\nSo , I mean , this may be  Heaven forbid , this noise compensation process may be imperfect , but . Uh , so maybe it 's treating some things differently .\nYeah , uh\nWell , I  I don't know . I  I just  that could be seen from the TI - digits , uh , testing condition because , um , the noises are from the TI - digits , right ? Noise\nYeah . So\nSo cleaning up the TI - digits and if the performance goes down in the TI - digits mismatch  high mismatch like this\nClean training , yeah .\non a clean training , or zero DB testing .\nYeah , we 'll  so we 'll see . Uh .\nYeah .\nMaybe .\nThen it 's something to do .\nMm - hmm .\nI mean , one of the things about\nYeah .\nI mean , the Macrophone data , um , I think , you know , it was recorded over many different telephones .\nMm - hmm .\nAnd , um , so , there 's lots of different kinds of acoustic conditions . I mean , it 's not artificially added noise or anything . So it 's not the same . I don't think there 's anybody recording over a car from a car , but  I think it 's  it 's varied enough that if  if doing this adjustments , uh , and playing around with it doesn't , uh , make it better , the most  uh , it seems like the most obvious thing to do is to improve the training set . Um  I mean , what we were  uh  the condition  It  it gave us an enormous amount of improvement in what we were doing with Meeting Recorder digits , even though there , again , these m Macrophone digits were very , very different from , uh , what we were going on here . I mean , we weren't talking over a telephone here . But it was just  I think just having a  a nice variation in acoustic conditions was just a good thing .\nMm - hmm . Yep .\nMmm .", "topic_id": 3, "keywords": "neural, net, trained, training, network", "dialogue_id": 29}, {"text": "Yeah , actually  to s eh , what I observed in the HM case is that the number of deletion dramatically increases . It  it doubles .\nNumber of deletions .\nWhen I added the num the neural network it doubles the number of deletions . Yeah , so I don't you know  how to interpret that , but , mmm\nYeah . Me either .\nt\nAnd  and did  an other numbers stay the same ? Insertion substitutions stay the same ?\nThey p stayed the same ,\nRoughly ?\nthey  maybe they are a little bit uh , lower .\nUh - huh .\nThey are a little bit better . Yeah . But\nDid they increase the number of deletions even for the cases that got better ?\nMm - hmm .\nSay , for the  I mean , it\nNo , it doesn't .\nSo it 's only the highly mismatched ?\nNo .\nAnd it  Remind me again , the \" highly mismatched \" means that the\nClean training and\nUh , sorry ?\nIt 's clean training  Well , close microphone training and distant microphone , um , high speed , I think .\nClose mike training\nWell  The most noisy cases are the distant microphone for testing .\nRight . So  Well , maybe the noise subtraction is subtracting off speech .\nSeparating . Yeah .\nWh\nBut  Yeah . I mean , but without the neural network it 's  well , it 's better . It 's just when we add the neural networks .\nYeah , right .\nThe feature are the same except that\nUh , that 's right , that 's right . Um\nWell that  that says that , you know , the , um  the models in  in , uh , the recognizer are really paying attention to the neural net features .\nYeah .\nUh .\nMm - hmm .\nBut , yeah , actually  {nonvocalsound} the TIMIT noises  are sort of a range of noises and they 're not so much the stationary driving kind of noises , right ? It 's  it 's pretty different . Isn't it ?\nUh , there is a car noise . So there are f just four noises . Um , uh , \" Car \" , I think , \" Babble \" ,\n\" Babble . \"\n\" Subway \" , right ? and\n\" Street \" or \" Airport \" or something .\nand  \" Street \" isn't\nOr \" Train station \" .\n\" Train station \" , yeah .\nYeah .\nSo  it 's mostly  Well , \" Car \" is stationary ,\nMm - hmm .\n\" Babble \" , it 's a stationary background plus some voices ,\nMm - hmm .\nsome speech over it . And the other two are rather stationary also .\nWell , I  I think that if you run it  Actually , you  maybe you remember this . When you  in  in the old experiments when you ran with the neural net only , and didn't have this side path , um , uh , with the  the pure features as well , did it make things better to have the neural net ?\nMm - hmm .\nWas it about the same ? Uh , w i\nIt was  b a little bit worse .\nThan  ?\nThan just the features , yeah .\nSo , until you put the second path in with the pure features , the neural net wasn't helping at all .\nMm - hmm .\nWell , that 's interesting .\nIt was helping , uh , if the features are b were bad ,\nYeah .\nI mean . Just plain P L Ps or M F\nYeah .\nC Cs . as soon as we added LDA on - line normalization , and  all these things , then\nThey were doing similar enough things . Well , I still think it would be k sort of interesting to see what would happen if you just had the neural net without the side thing .\nYeah ,\nAnd  and the thing I  I have in mind is , uh , maybe you 'll see that the results are not just a little bit worse .\nmm - hmm .\nMaybe that they 're a lot worse . You know ? And , um  But if on the ha other hand , uh , it 's , say , somewhere in between what you 're seeing now and  and  and , uh , what you 'd have with just the pure features , then maybe there is some problem of a  of a , uh , combination of these things , or correlation between them somehow .\nMm - hmm .\nIf it really is that the net is hurting you at the moment , then I think the issue is to focus on  on , uh , improving the  the net .\nYeah ,\nUm .\nmm - hmm .\nSo what 's the overall effe I mean , you haven't done all the experiments but you said it was i somewhat better , say , five percent better , for the first two conditions , and fifteen percent worse for the other one ? But it 's  but of course that one 's weighted lower ,\nY yeah , oh . Yeah .\nso I wonder what the net effect is .\nI d I  I think it 's  it was one or two percent . That 's not that bad , but it was l like two percent relative worse on SpeechDat - Car . I have to  to check that . Well , I have  I will .\nWell , it will  overall it will be still better even if it is fifteen percent worse , because the fifteen percent worse is given like f w twenty - five  point two five eight .\nRight .\nMm - hmm . Hmm .\nRight . So the  so the worst it could be , if the others were exactly the same , is four ,\nIs it like\nand  and , uh , in fact since the others are somewhat better\nYeah , so it 's four . Is i So either it 'll get cancelled out , or you 'll get , like , almost the same .\nUh .\nYeah , it was  it was slightly worse .\nSlightly bad . Yeah .\nUm ,\nYeah , it should be pretty close to cancelled out .\nYeah .\nYou know , I 've been wondering about something .\nMm - hmm .\nIn the , um  a lot of the , um  the Hub - five systems , um , recently have been using LDA . and  and they , um  They run LDA on the features right before they train the models . So there 's the  the LDA is  is right there before the H M\nYeah .\nSo , you guys are using LDA but it seems like it 's pretty far back in the process .\nUh , this LDA is different from the LDA that you are talking about . The LDA that you  saying is , like , you take a block of features , like nine frames or something ,  and then do an LDA on it ,\nYeah . Uh - huh .\nand then reduce the dimensionality to something like twenty - four or something like that .\nYeah , you c you c you can .\nAnd then feed it to HMM .\nI mean , it 's  you know , you 're just basically i\nYeah , so this is like a two d two dimensional tile .\nYou 're shifting the feature space . Yeah .\nSo this is a two dimensional tile . And the LDA that we are f applying is only in time , not in frequency  high cost frequency . So it 's like  more like a filtering in time , rather than doing a r\nAh . OK . So what i what about , um  i u what i w I mean , I don't know if this is a good idea or not , but what if you put  ran the other kind of LDA , uh , on your features right before they go into the HMM ?\nUh , it\nMm - hmm . No , actually , I think  i\nm\nWell . What do we do with the ANN is  is something like that except that it 's not linear . But it 's  it 's like a nonlinear discriminant analysis .\nYeah . Right , it 's the  It 's  Right . The  So  Yeah , so it 's sort of like\nBut .\nThe tandem stuff is kind of like i nonlinear LDA .\nYeah . It 's\nI g\nYeah .\nYeah .\nYeah .\nBut I mean , w but the other features that you have , um , th the non - tandem ones ,\nUh . Mm - hmm . Yeah , I know . That  that  Yeah . Well , in the proposal , they were transformed u using PCA , but\nUh - huh .\nYeah , it might be that LDA could be better .\nThe a the argument i is kind of i in  and it 's not like we really know , but the argument anyway is that , um , uh , we always have the prob I mean , discriminative things are good . LDA , neural nets , they 're good .\nYeah .\nUh , they 're good because you  you  you learn to distinguish between these categories that you want to be good at distinguishing between . And PCA doesn't do that . It  PAC - PCA  low - order PCA throws away pieces that are uh , maybe not  not gonna be helpful just because they 're small , basically .\nRight .\nBut , uh , the problem is , training sets aren't perfect and testing sets are different . So you f you  you face the potential problem with discriminative stuff , be it LDA or neural nets , that you are training to discriminate between categories in one space but what you 're really gonna be g getting is  is something else .\nUh - huh .\nAnd so , uh , Stephane 's idea was , uh , let 's feed , uh , both this discriminatively trained thing and something that 's not . So you have a good set of features that everybody 's worked really hard to make ,\nYeah .\nand then , uh , you  you discriminately train it , but you also take the path that  that doesn't have that ,\nUh - huh .\nand putting those in together . And that  that seem So it 's kind of like a combination of the  uh , what , uh , Dan has been calling , you know , a feature  uh , you know , a feature combination versus posterior combination or something . It 's  it 's , you know , you have the posterior combination but then you get the features from that and use them as a feature combination with these  these other things . And that seemed , at least in the last one , as he was just saying , he  he  when he only did discriminative stuff , i it actually was  was  it didn't help at all in this particular case .\nYeah .\nThere was enough of a difference , I guess , between the testing and training . But by having them both there  The fact is some of the time , the discriminative stuff is gonna help you .\nMm - hmm .\nAnd some of the time it 's going to hurt you ,\nRight .\nand by combining two information sources if , you know  if  if\nSo you wouldn't necessarily then want to do LDA on the non - tandem features because now you 're doing something to them that\nThat i i I think that 's counter to that idea .\nYeah , right .\nNow , again , it 's  we 're just trying these different things . We don't really know what 's gonna work best . But if that 's the hypothesis , at least it would be counter to that hypothesis to do that .\nRight .\nUm , and in principle you would think that the neural net would do better at the discriminant part than LDA .\nRight . Yeah . Well  y\nThough , maybe not .\nYeah . Exactly . I mean , we , uh  we were getting ready to do the tandem , uh , stuff for the Hub - five system , and , um , Andreas and I talked about it , and the idea w the thought was , \" Well , uh , yeah , that i you know  th the neural net should be better , but we should at least have uh , a number , you know , to show that we did try the LDA in place of the neural net , so that we can you know , show a clear path .\nRight .\nYou know , that you have it without it , then you have the LDA , then you have the neural net , and you can see , theoretically . So . I was just wondering  I  I\nWell , I think that 's a good idea .\nYeah .\nDid  did you do that\nUm . No .\nor  tha that 's a\nThat 's what  that 's what we 're gonna do next as soon as I finish this other thing . So .\nYeah . Yeah . No , well , that 's a good idea . I  I\nWe just want to show .\ni Yeah .\nI mean , it  everybody believes it ,\nOh , no it 's a g\nbut you know , we just\nNo , no , but it might not  not even be true .\nYeah .\nI mean , it 's  it 's  it 's  it 's  it 's a great idea . I mean , one of the things that always disturbed me , uh , in the  the resurgence of neural nets that happened in the eighties was that , um , a lot of people  Because neural nets were pretty easy to  to use  a lot of people were just using them for all sorts of things without , uh , looking at all into the linear , uh  uh , versions of them .\nYeah . Mm - hmm . Yeah .\nAnd , uh , people were doing recurrent nets but not looking at IIR filters , and  You know , I mean , uh , so I think , yeah , it 's definitely a good idea to try it .\nYeah , and everybody 's putting that on their  systems now , and so , I that 's what made me wonder about this ,\nWell , they 've been putting them in their systems off and on for ten years ,\nbut .\nbut  but  but , uh ,\nYeah , what I mean is it 's  it 's like in the Hub - five evaluations , you know , and you read the system descriptions and everybody 's got ,  you know , LDA on their features .\nAnd now they all have that . I see .\nAnd so .\nYeah .\nUh .\nIt 's the transformation they 're estimating on  Well , they are trained on the same data as the final HMM are .\nYeah , so it 's different . Yeah , exactly . Cuz they don't have these , you know , mismatches that  that you guys have .\nMm - hmm .\nSo that 's why I was wondering if maybe it 's not even a good idea .\nMm - hmm .\nI don't know . I  I don't know enough about it ,\nMm - hmm .\nbut  Um .\nI mean , part of why  I  I think part of why you were getting into the KLT  Y you were describing to me at one point that you wanted to see if , uh , you know , getting good orthogonal features was  and combining the  the different temporal ranges  was the key thing that was happening or whether it was this discriminant thing , right ? So you were just trying  I think you r I mean , this is  it doesn't have the LDA aspect but th as far as the orthogonalizing transformation , you were trying that at one point , right ?\nMm - hmm .\nI think you were .\nMm - hmm . Yeah .\nDoes something . It doesn't work as well . Yeah . Yeah .", "topic_id": 4, "keywords": "mismatches, deletions, mismatched, neural, microphone", "dialogue_id": 29}, {"text": "So , yeah , I 've been exploring a parallel VAD without neural network with , like , less latency using SNR and energy , um , after the cleaning up . So what I 'd been trying was , um , uh  After the b after the noise compensation , n I was trying t to f find a f feature based on the ratio of the energies , that is , cl after clean and before clean . So that if  if they are , like , pretty c close to one , which means it 's speech . And if it is n if it is close to zero , which is  So it 's like a scale @ @ probability value . So I was trying , uh , with full band and multiple bands , m ps uh  separating them to different frequency bands and deriving separate decisions on each bands , and trying to combine them . Uh , the advantage being like it doesn't have the latency of the neural net if it  if it can\nMm - hmm .\ng And  it gave me like , uh , one point  One  more than one percent relative improvement . So , from fifty - three point six it went to fifty f four point eight . So it 's , like , only slightly more than a percent improvement ,\nMm - hmm .\njust like  Which means that it 's  it 's doing a slightly better job than the previous VAD ,\nMm - hmm .\nuh , at a l lower delay .\nMm - hmm .\nUm , so , um\nBut  i d I 'm sorry ,\nso  u\ndoes it still have the median  filter stuff ?\nIt still has the median filter .\nSo it still has most of the delay ,\nSo\nit just doesn't\nYeah , so d with the delay , that 's gone is the input , which is the sixty millisecond . The forty plus  twenty .\nWell , w i\nAt the input of the neural net you have this , uh , f nine frames of context plus the delta .\nOh , plus the delta ,\nMm - hmm .\nright . OK .\nYeah . So that delay , plus the LDA .\nMm - hmm .\nUh , so the delay is only the forty millisecond of the noise cleaning , plus the hundred millisecond smoothing at the output .\nMm - hmm . Mm - hmm .\nUm . So . Yeah . So the  the  di the biggest  The problem f for me was to find a consistent threshold that works  well across the different databases , because I t I try to make it work on tr SpeechDat - Car\nMm - hmm .\nand it fails on TI - digits , or if I try to make it work on that it 's just the Italian or something , it doesn't work on the Finnish .\nMm - hmm .\nSo , um . So there are  there was , like , some problem in balancing the deletions and insertions when I try different thresholds .\nMm - hmm .\nSo  The  I 'm still trying to make it better by using some other features from the  after the p clean up  maybe , some , uh , correlation  auto - correlation or some s additional features of  to mainly the improvement of the VAD . I 've been trying .\nNow this  this  this , uh , \" before and after clean \" , it sounds like you think that 's a good feature . That  that , it  you th think that the , uh  the  i it appears to be a good feature , right ?\nMm - hmm .\nWhat about using it in the neural net ?\nYeah .\nYeah , eventually we could  could just\nYeah , so  Yeah , so that 's the  Yeah . So we 've been thinking about putting it into the neural net also .\nYeah .\nBecause they did  that itself\nThen you don't have to worry about the thresholds and\nThere 's a threshold and  Yeah .\nYeah .\nbut just\nYeah . So that  that 's , uh\nYeah . So if we  if we can live with the latency or cut the latencies elsewhere , then  then that would be a , uh , good thing .\nYeah . Yeah .\nUm , anybody  has anybody  you guys or  or Naren , uh , somebody , tried the , uh , um , second th second stream thing ? Uh .\nOh , I just  I just h put the second stream in place and , uh ran one experiment , but just like  just to know that everything is fine .\nUh - huh .\nSo it was like , uh , forty - five cepstrum plus twenty - three mel  log mel .\nYeah .\nAnd  and , just , like , it gave me the baseline performance of the Aurora , which is like zero improvement .\nYeah . Yeah .\nSo I just tried it on Italian just to know that everything is  But I  I didn't export anything out of it because it was , like , a weird feature set .\nYeah .\nSo .\nYeah . Well , what I think , you know , would be more what you 'd want to do is  is  is , uh , put it into another neural net . Right ?\nMm - hmm .\nYeah , yeah , yeah , yeah .\nAnd then  But , yeah , we 're  we 're not quite there yet . So we have to  figure out the neural nets , I guess .\nYeah .\nThe uh , other thing I was wondering was , um , if the neural net , um , has any  because of the different noise con unseen noise conditions for the neural net , where , like , you train it on those four noise conditions , while you are feeding it with , like , a additional  some four plus some  f few more conditions which it hasn't seen , actually ,\nMm - hmm .\nfrom the  f f while testing .\nYeah , yeah . Right .\nUm  instead of just h having c uh , those cleaned up t cepstrum , sh should we feed some additional information , like  The  the  We have the VAD flag . I mean , should we f feed the VAD flag , also , at the input so that it  it has some additional discriminating information at the input ?\nHmm - hmm ! Um\nWh - uh , the  the VAD what ?\nWe have the VAD information also available at the back - end .\nUh - huh .\nSo if it is something the neural net is not able to discriminate the classes\nYeah .\nI mean  Because most of it is sil I mean , we have dropped some silence f We have dropped so silence frames ?\nMm - hmm .\nNo , we haven't dropped silence frames still .\nUh , still not . Yeah .\nYeah . So\nTh\nthe b b biggest classification would be the speech and silence . So , by having an additional , uh , feature which says \" this is speech and this is nonspeech \" , I mean , it certainly helps in some unseen noise conditions for the neural net .\nWhat  Do y do you have that feature available for the test data ?\nWell , I mean , we have  we are transferring the VAD to the back - end  feature to the back - end . Because we are dropping it at the back - end after everything  all the features are computed .\nOh , oh , I see .\nSo\nI see .\nso the neural  so that is coming from a separate neural net or some VAD .\nOK . OK .\nWhich is  which is certainly giving a\nSo you 're saying , feed that , also , into  the neural net .\nto  Yeah . So it it 's an  additional discriminating information .\nYeah . Yeah . Right .\nSo that\nYou could feed it into the neural net . The other thing  you could do is just , um , p modify the , uh , output probabilities of the  of the , uh , uh , um , neural net , tandem neural net ,  based on the fact that you have a silence probability .\nMm - hmm .\nRight ?\nMm - hmm .\nSo you have an independent estimator of what the silence probability is , and you could multiply the two things , and renormalize .\nYeah .\nUh , I mean , you 'd have to do the nonlinearity part and deal with that . Uh , I mean , go backwards from what the nonlinearity would , you know  would be .\nThrough  t to the soft max .\nBut  but , uh\nYeah , so  maybe , yeah , when\nBut in principle wouldn't it be better to feed it in ? And let the net do that ?\nWell , u Not sure .\nHmm .\nI mean , let 's put it this way . I mean , y you  you have this complicated system with thousands and thousand parameters\nYeah .\nand you can tell it , uh , \" Learn this thing . \" Or you can say , \" It 's silence ! Go away ! \" I mean , I mean , i Doesn't  ? I think  I think the second one sounds a lot more direct .\nWhat  what if you\nUh .\nRight . So , what if you then , uh  since you know this , what if you only use the neural net on the speech portions ?\nWell , uh ,\nThat 's what\nWell , I guess that 's the same . Uh , that 's similar .\nYeah , I mean , y you 'd have to actually run it continuously ,\nBut I mean  I mean , train the net only on\nbut it 's  @ @  Well , no , you want to train on  on the nonspeech also , because that 's part of what you 're learning in it , to  to  to generate , that it 's  it has to distinguish between .\nSpeech .\nBut I mean , if you 're gonna  if you 're going to multiply the output of the net by this other decision , uh , would  then you don't care about whether the net makes that distinction , right ?\nWell , yeah . But this other thing isn't perfect .\nAh .\nSo that you bring in some information from the net itself .\nRight , OK . That 's a good point .\nYeah . Now the only thing that  that bothers me about all this is that I  I  I  The  the fact  i i It 's sort of bothersome that you 're getting more deletions .\nYeah . But  So I might maybe look at , is it due to the fact that um , the probability of the silence at the output of the network , is , uh ,\nIs too high .\ntoo  too high or\nYeah . So maybe  So\nIf it 's the case , then multiplying it again by  i by something ?\nIt may not be  it\nYeah .\nMm - hmm .\nYeah , it  it may be too  it 's too high in a sense , like , everything is more like a , um , flat probability .\nYeah .\nOh - eee - hhh .\nSo , like , it 's not really doing any distinction between speech and nonspeech\nUh , yeah .\nor , I mean , different  among classes .\nYeah .\nMm - hmm .\nBe interesting to look at the  Yeah , for the  I wonder if you could do this . But if you look at the , um , highly mism high mismat the output of the net on the high mismatch case and just look at , you know , the distribution versus the  the other ones , do you  do you see more peaks or something ?\nYeah . Yeah , like the entropy of the  the output ,\nYeah .\nYeah , for instance .\nor\nBut I  bu\nIt  it seems that the VAD network doesn't  Well , it doesn't drop , uh , too many frames because the dele the number of deletion is reasonable . But it 's just when we add the tandem , the final MLP , and then\nYeah . Now the only problem is you don't want to ta I guess wait for the output of the VAD before you can put something into the other system ,\nu\ncuz that 'll shoot up the latency a lot , right ? Am I missing something here ?\nBut\nMm - hmm .\nYeah . Right .\nYeah . So that 's maybe a problem with what I was just saying . But  but  I I guess\nBut if you were gonna put it in as a feature it means you already have it by the time you get to the tandem net , right ?\nUm , well . We  w we don't have it , actually ,\nNo .\nbecause it 's  it has a high rate energy\nAh .\nthe VAD has a\nYeah .\nOK .\nIt 's kind of done in  I mean , some of the things are , not in parallel , but certainly , it would be in parallel with the  with a tandem net .\nRight .\nIn time . So maybe , if that doesn't work , um  But it would be interesting to see if that was the problem , anyway . And  and  and then I guess another alternative would be to take the feature that you 're feeding into the VAD , and feeding it into the other one as well .\nMm - hmm .\nAnd then maybe it would just learn  learn it better .\nMm - hmm .\nUm  But that 's  Yeah , that 's an interesting thing to try to see , if what 's going on is that in the highly mismatched condition , it 's , um , causing deletions by having this silence probability up  up too high ,\nMm - hmm .\nat some point where the VAD is saying it 's actually speech .\nYeah .\nWhich is probably true .\nSo , m\nCuz  Well , the V A if the VAD said  since the VAD is  is  is right a lot , uh\nYeah .\nHmm . Anyway . Might be .\nMm - hmm .\nYeah . Well , we just started working with it . But these are  these are some good ideas I think .\nMm - hmm . Yeah , and the other thing  Well , there are other issues maybe for the tandem , like , uh , well , do we want to , w uh n Do we want to work on the targets ? Or , like , instead of using phonemes , using more context dependent units ?\nFor the tandem net you mean ?\nWell , I 'm  Yeah .\nHmm .\nI 'm thinking , also , a w about Dan 's work where he  he trained  a network , not on phoneme targets but on the HMM state targets . And  it was giving s slightly better results .\nProblem is , if you are going to run this on different m test sets , including large vocabulary ,\nYeah . Yeah .\num ,\nUh\nI think\nMmm . I was just thinking maybe about , like , generalized diphones , and  come up with a  a reasonable , not too large , set of context dependent units , and  and  Yeah . And then anyway we would have to reduce this with the KLT .\nYeah .\nSo . But  I don't know .\nYeah . Well , maybe . But I d I d it  it  i it 's all worth looking at ,\nMm - hmm .\nbut it sounds to me like , uh , looking at the relationship between this and the  speech noise stuff is  is  is probably a key thing .\nMm - hmm .\nThat and the correlation between stuff .\nSo if , uh  if the , uh , high mismatch case had been more like the , uh , the other two cases  in terms of giving you just a better performance ,  how would this number have changed ?\nMm - hmm . Oh , it would be  Yeah . Around five percent better , I guess . If  if  i\ny Like sixty ?\nWell , we don't know what 's it 's gonna be the TI - digits yet . He hasn't got the results back yet .\nYeah . If you extrapolate the SpeechDat - Car well - matched and medium - mismatch , it 's around , yeah , maybe five .\nUh - huh . Yeah . So this would be sixty - two ?\nSixty - two .\nWhich is\nYeah .\nSixty - two , yeah .\nSomewhere around sixty , must be . Right ? Yeah .\nWell , it 's around five percent , because it 's  s Right ? If everything is five percent .\nYeah . Yeah .\nAll the other ones were five percent ,\nMm - hmm .\nthe\nYeah .\nI d I d I just have the SpeechDat - Car right now , so\nYeah .\nIt 's running  it shou we should have the results today during the afternoon ,\nHmm .\nbut  Well .\nHmm . Well  Um  So I won't be here for\nWhen  When do you leave ?\nUh , I 'm leaving next Wednesday . May or may not be in in the morning . I leave in the afternoon . Um ,\nBut you 're\nso I\nare you  you 're not gonna be around this afternoon ?\nYeah .\nOh .\nOh , well . I 'm talking about next week . I 'm leaving  leaving next Wednesday .\nUh - huh .\nThis afternoon  uh  Oh , right , for the Meeting meeting ? Yeah , that 's just cuz of something on campus .\nAh , OK , OK .\nYeah . But , um , yeah , so next week I won't , and the week after I won't , cuz I 'll be in Finland . And the week after that I won't . By that time you 'll be   Uh , you 'll both be gone  from here . So there 'll be no  definitely no meeting on  on September sixth . Uh ,\nWhat 's September sixth ?\nand  Uh , that 's during Eurospeech .\nOh , oh , right . OK .\nSo , uh , Sunil will be in Oregon . Uh , Stephane and I will be in Denmark . Uh  Right ? So it 'll be a few weeks , really , before we have a meeting of the same cast of characters . Um , but , uh  I guess , just  I mean , you guys should probably meet . And maybe Barry  Barry will be around . And  and then uh , uh , we 'll start up again with Dave and  Dave and Barry and Stephane and us on the , uh , twentieth . No . Thirteenth ? About a month ?\nSo , uh , you 're gonna be gone for the next three weeks or something ?\nI 'm gone for two and a half weeks starting  starting next Wed - late next Wednesday .\nSo that 's  you won't be at the next three of these meetings . Is that right ?\nUh , I won't  it 's probably four because of  is it three ? Let 's see , twenty - third , thirtieth , sixth . That 's right , next three . And the  the third one won't  probably won't be a meeting , cuz  cuz , uh , Su - Sunil , Stephane , and I will all not be here .\nOh , right . Right .\nUm  Mmm .  So it 's just , uh , the next two where there will be  there , you know , may as well be meetings ,\nOK .\nbut I just won't be at them . And then starting up on the thirteenth , {nonvocalsound} uh , we 'll have meetings again but we 'll have to do without Sunil here somehow .\nWhen do you go back ?\nSo .\nThirty - first , August .\nYeah . Yeah . So . Cool .\nWhen is the evaluation ? November , or something ?\nYeah , it was supposed to be November fifteenth . Has anybody heard anything different ?\nI don't know . The meeting in  is the five and six of December . So\np s It 's like  Yeah , it 's tentatively all full . Yeah .\nMm - hmm .\nUh , that 's a proposed date , I guess .\nYeah , um  so the evaluation should be on a week before or\nYeah .\nYep . But , no , this is good progress . So . Uh  OK .\nShould we do digits ?\nGuess we 're done . Digits ? Yep .\nOK .\nIt 's a wrap .", "topic_id": 5, "keywords": "neural, latencies, snr, latency, frequency", "dialogue_id": 29}, {"text": "We 're , I mean  we  We didn't have a house before .\nYeah . Yeah .\nOK .\nWe 're on again ? OK .\nMm - hmm . That is really great .\nYeah , so if  uh   So if anyone hasn't signed the consent form , please do so .\nThat 's terrific .\nOh , yeah !\nOK\nThe new consent form . The new and improved consent form .\nNow you won't be able to walk or ride your bike , huh ?\nOK .\nUh .\nRight .\nOK .\nAnd uh , shall I go ahead and do some digits ?\nUh , we were gonna do that at the end , remember ?\nOK , whatever you want .\nYeah . Just  just to be consistent , from here on in at least , that   that we 'll do it at the end .\nThe new consent form .\nIt 's uh   Yeah , it doesn't matter . OK .\nOK Um Well , it ju I mean it might be that someone here has to go ,\nTesting , one , two , three .\nand  Right ? That was  that was sort of the point . So , uh  I had asked actually anybody who had any ideas for an agenda  to send it to me and no one did . So ,\nSo we all forgot .\nUh ,\nFrom last time I wanted to  Uh   The  An iss uh  one topic from last time .\nRight , s OK , so one item for an agenda is uh  Jane has some uh  uh some research to talk about , research issues . Um  and  Uh , Adam has some short research issues .\nAnd I have some  short research issues .\nUm , I have a  list of things that I think were done over the last three months I was supposed to   send off , uh  and , um  I  I sent a note about it to uh  to Adam and Jane but I think I 'll just run through it  also and see if someone thinks it 's inaccurate or  uh insufficient .\nA list that you have to send off to who ?\nUh , to uh uh , IBM .\nOh .\nOK . They 're , you know\nSo . Um , So , uh  so , I 'll go through that . Um ,  And , Anything else ?  anyone wants to talk about ?\nWhat about the , um  your trip , yesterday ?\nNo . OK . Um . Sort of off - topic I guess .\nOh , OK .\nCuz that 's  Cuz that was all  all about the , uh  I  I  I can chat with you about that  off - line . That 's another thing . Um , And , Anything else ? Nothing else ? Uh , there 's a  I mean , there is a   a , um  uh  telephone call tomorrow ,  which will be a conference call  that some of us are involved in  for uh a possible proposal . Um , we 'll talk  we 'll talk about it next week if  if something\nDo you want me to  be there for that ? I noticed you C C ' ed me , but I wasn't actually a recipient . I didn't quite know what to make of that .\nUh Well , we 'll talk  talk about that after our meeting . OK .\nOK .\nUh , OK . So it sounds like the  the three main things that we have to talk about are , uh this list , uh Jane and  Jane and Adam have some research items , and , other than that , anything ,  as usual ,  anything goes beyond that . OK , uh , Jane , since  since you were sort of cut off last time why don't we start with yours , make sure we get to it .", "topic_id": 0, "keywords": "consent, proposal, testing, form, don", "dialogue_id": 30}, {"text": "OK , it 's  it 's very  eh  it 's  very brief , I mean  just let me  just hand these out . Oops .\nIs this the same as the email or different ?\nThanks .\nIt 's slightly different . I   basically the same .\nOK .\nSame idea ?\nBut , same idea . So , if you 've looked at this you 've seen it before , so  Basically ,  um  as you know , uh  part of the encoding  includes a mark that indicates  an overlap . It 's not indicated  with , um  uh , tight precision , it 's just indicated that  OK , so , It 's indicated to  to  so the people know  what parts of sp which  which stretches of speech were in the clear , versus being overlapped by others . So , I  used this mark and , um  and , uh  uh ,  divided the  I wrote a script  which divides things into individual minutes ,  of which we ended up with forty  five , and a little bit . And , uh  you know , minute zero , of course , is the first minute up to  sixty seconds .\nOK .\nAnd , um  What you can see is the number of overlaps  and then  to the right ,  whether they involve two speakers , three speakers , or more than three speakers . And ,  um  and , what I was looking for sp sp specifically was the question of  whether they 're distributed evenly throughout or whether they 're  bursts of them . Um . And  it looked to me as though  uh , you know  y this is just   eh  eh , this would  this is not statistically  verified ,  but it  did look to me as though there are bursts throughout , rather than being  localized to a particular region . The part down there , where there 's the maximum number of   of , um  overlaps is an area where we were discussing   whether or not it would be useful to indi to s to  code  stress ,  uh , sentence stress  as possible indication of , uh  information retrieval . So it 's like ,  you know , rather ,  lively discussion there .\nWhat was  what 's the  the parenthesized stuff  that says , like  e the first one that says six overlaps and then two point eight ?\nOh , th   That 's the per cent .\nMmm .\nSo , six is , uh  two point eight percent  of the total number of overlaps in the  session .\nMm - hmm .\nAh .\nMm - hmm .\nAt the very end , this is when people were ,  you know , packing up to go basically , there 's  this final stuff , I think we   I don't remember where the digits  fell . I 'd have to look at that . But  the final three there are no overlaps at all . And  couple times there  are not .\nMm - hmm .\nSo , i it seems like it goes through bursts  but , um  that 's kind of it .\nMm - hmm .\nNow ,  Another question is  is there  are there  individual differences in whether you 're likely to be overlapped with or to overlap with others . And , again  I want to emphasize this is just one  particular  um   one particular meeting , and also there 's been no statistical testing of it all , but  I , um  I took the coding of  the  I , you know , my  I had this script  figure out , um  who  was the first speaker , who was the second speaker involved in a two - person overlap , I didn't look at the ones involving three or more . And , um   this is how it breaks down in the individual cells of  who tended to be overlapping most often with who  who else , and  if you look at the marginal totals , which is the ones on the right side and across the bottom , you get  the totals for an individual . So ,  um  If you  look at the bottom , those are the , um  numbers of overlaps in which  um  Adam was involved as the person doing the overlapping and if you look  I 'm sorry , but you 're o alphabetical , that 's why I 'm choosing you And then if you look across the right ,  then  that 's where he was the  person who was the sp first speaker in the pair  and got overlap overlapped with by somebody .\nHmm !\nMm - hmm .\nAnd ,  then if you look down in the summary table ,  then you see that , um  th they 're differences in  whether a person got overlapped with or  overlapped by .\nIs this uh  just raw counts or is it\nRaw counts .\nSo it would be interesting to see how much each person spoke .\nMm - hmm .\nYeah .\nYeah  Yeah\nYes , very true  very true\nNormalized to how much\nit would be good to normalize with respect to that . Now on the table I did  take one step toward , uh  away from the raw frequencies by putting ,  uh  percentages . So that the percentage of time  of the  of the times that a person spoke ,  what percentage  eh , w so . Of the times a person spoke and furthermore was involved in a two two - person overlap ,   what percentage of the time were they the overlapper and what percent of the time were they th the overlappee ? And there , it looks like you see some differences , um ,  that some people tend to be overlapped  with more often than they 're overlapped , but , of course , uh i e  this is just one meeting ,  uh  there 's no statistical testing involved , and that would be  required for a  for a finding  of  any  kind of  scientific  reliability .\nS so , i it would be statistically incorrect to conclude from this that Adam talked too much or something .\nNo  no actually , that would be actually statistically correct ,\nYeah , yeah .\nNo , no , no .\nYeah , yeah . Yeah , yeah .\nbut\nYeah , that 's right .\nYeah . Excuse me .\nThat 's right . And I 'm  you know , I 'm  I don't see a point of singling people out ,\nB I  I  I rather enjoyed it , but  but this\nnow , this is a case where obviously\nBut the numbers speak for themselves .\nHe 's  Yeah , yeah , yeah .\nWell ,  you know , it 's like  I 'm not  I 'm not saying on the tape who did  better or worse\nYes , that 's right , so you don't nee OK .\nSure .\nbecause  I don't think that it 's  I  you know , and  and th here 's a case where of course , human subjects people would say be sure that you anonymize the results ,  and  and , so , might as well do this .\nYeah .\nYeah , when  this is what  This is actually  when Jane sent this email first , is what caused me to start thinking about anonymizing the data .\nWell , fair enough . Fair enough .\nYeah .\nAnd actually ,  you know , the point is not about an individual , it 's the point about  tendencies toward  you know , different styles , different speaker styles .\nOh sure .\nAnd  it would be , you know  of course ,  there 's also the question of what type of overlap was this , and w what were they , and i and I  and I know that I can distinguish at least three types and , probably more , I mean , the  general   cultural idea which w uh , the conversation analysts originally started with in the seventies was that we have this  strict model where politeness involves that you let the person finish th before you start talking , and  and you know , I mean ,  w we know that   an and they 've loosened up on that too s in the intervening time , that  that that 's  that 's viewed as being  a culturally - relative thing , I mean ,  that you have the high - involvement style from the East Coast where people  will overlap often as an indication of interest in what the other person is saying . And\nUh - huh .\nExactly !\nYeah , exactly !\nYeah\nWell , there you go . Fine , that 's alright , that 's OK . And  and ,  you know , in contrast , so Deborah  d and also Deborah Tannen 's  thesis she talked about differences of these types ,  that they 're just different styles , and it 's um  you  you can't impose a model of   there  of the ideal being no overlaps , and  you know , conversational analysts also agree with that , so it 's  now , universally  a ag agreed with . And  and , als I mean , I can't say universally , but anyway , the people who used to say it was strict ,  um  now , uh  don't . I mean they  they  also   you know , uh  uh , ack acknowledge the influence of  sub of subcultural norms and  cross - cultural norms and things . So , um Then it beco  though  so  just  just superficially to give  um  a couple ideas of the types of overlaps involved , I have at the bottom several that I noticed . So ,   uh , there are backchannels , like what Adam just did now and , um   um , anticipating the end of a question and  simply answering it earlier , and there are several of those in this  in these data where\nMm - hmm .\nbecause we 're  people who 've talked to each other , um  we know  basically what the topic is , what the possibilities are and w and we 've spoken with each other so we know basically what the other person 's style is likely to be and so  and t there are a number of places where someone just answered early . No problem . And places  also which I thought were interesting , where two or more people gave exactly th the same answer in unison  different words of course but you know , the  basically ,  you know everyone 's saying \" yes \" or  you know , or ev even more sp specific than that . So , uh , the point is that , um   overlap 's not necessarily a bad thing and that it would be im  i useful to subdivide these further and see if there are individual differences in styles with respect to the types involved . And that 's all I wanted to say on that ,  unless people have questions .\nWell , of course th the biggest ,  um  result here , which is one we 've   we 've talked about many times and isn't new to us , but which I think would be interesting to show someone who isn't familiar with this   is just the sheer number of overlaps .\nYep .\nThat  that  Right ?  that  that , um\nYes , yes !\nOh , OK  interesting .\nYeah .\nhere 's a relatively short meeting , it 's a forty   forty plus minute   meeting , and not only were there two hundred and fifteen overlaps   but ,  uh I think there 's one   one minute there where there  where  where there wasn't any overlap ?\nHundred ninety - seven .\nI mean , it 's    uh throughout this thing ?\nIt 'd be interesting\nIt 's  You have\nWell , at the bottom , you have the bottom three .\nYeah .\nS n are\nSo four  four minutes all together with none  none .\nBut it w\nOh , so the bottom three did have s stuff going on ? There was speech ?\nYes , uh - huh . Yeah . But just no overlaps .\nOK , so if  the  this\nIt 'd be interesting to see what the total amount of time is in the overlaps , versus\nYes , exactly and that 's  that 's where Jose 's pro project comes in .\nYeah , yeah , I h I have this that infor I have th that information now .\nI was about to ask\nYeah .\nYeah .\nHmm .\nOh , about how much is it ?\nThe  the duration of eh  of each of the overlaps .\nO oh , what 's  what 's the  what 's the average  length ?\nM I  I haven't averaged it now but , uh  I  I will , uh I will do the  the study of the   with the  with the program with the  uh , the different , uh  the , nnn ,  distribution of the duration of the overlaps .\nYou don't know ? OK , you  you don you don't have a feeling for roughly how  much it is ? Yeah .\nmmm ,  Because the  the uh , @ @ is @ @ .\nYeah .\nThe duration is , uh  the variation  the variation of the duration is uh , very big on the dat\nMm - hmm .\nI suspect that it will also differ ,  depending on the type of overlap  involved .\nbut eh\nOh , I 'm sure .\nYeah .\nSo backchannels will be very brief\nBecause , on your surface eh  a bit of zone of overlapping with the duration eh , overlapped and another very very short .\nand\nYeah . Yeah .\nUh , i probably it 's very difficult to  to  because the  the overlap is , uh on is only the  in the final \" S \" of the  of the  the fin the  the end  the end word of the , um  previous speaker  with the  the next word of the  the new speaker .\nMm - hmm .\nUm , I considered  that 's an overlap but it 's very short , it 's an \" X \" with a  and  the idea is probably , eh  when eh  when eh , we studied th th that zone , eh   eh , we h we have eh eh  confusion with eh eh noise .\nMm - hmm .\nWith eh  that fricative sounds , but uh  I have new information but I have to  to study .\nYeah . Yeah , but I  I 'd   u\nCan I\ngo ahead .\nYeah .\nYou split this by minute , um  so if an overlap straddles  the boundary between two minutes , that counts towards both of those minutes .\nYes . Mm - hmm . Actually , um  um  actually not . Uh , so  le let 's think about the case where  A starts speaking   and then B overlaps with A ,  and then the minute boundary happens . And let 's say that  after that minute boundary ,  um  B is still speaking ,  and A overlaps  with B , that would be a new overlap . But otherwise  um , let 's say B  comes to the conclusion of  of that turn without  anyone overlapping with him or her , in which case there would be no overlap counted in that second minute .\nNo , but suppose they both talk simultaneously   both a  a portion of it is in minute one and another portion of minute two .\nOK . In that case , um  my c  the coding that I was using   since we haven't ,  uh  incorporated Adam 's , uh  coding of overlap yets , the coding of Yeah , \" yets \" is not a word . Uh  since we haven't incorporated Adam 's method of handling overl overlaps yet  um  then  that would have fallen through the cra cracks . It would be an underestimate of the number of overlaps because , um  I wou I wouldn't be able to pick it up from the way it was  encoded so far .\nI I\nWe just haven't done th the precise second to sec you know ,  second to second coding of when they occur .\nI I I 'm  I 'm  I 'm confused now . So l l let me restate what I thought Andreas was saying and  and see .\nUh - huh .\nLet 's say that in  in second fifty - seven   of one minute ,  you start talking and I start talking and  we ignore each other and keep on talking for six seconds .\nYep . OK . Mm - hmm .\nSo we go over  So we were  we were talking over one another ,  and it 's just  in each case , it 's just sort of one  interval . Right ?\nMm - hmm ?\nSo , um  we talked over the minute boundary . Is this  considered as one overlap in each of the minutes , the way you have done this .\nNo , it wouldn't . It would be considered as an overlap in the first one .\nOK , so that 's  good , i I think , in the sense that I think Andreas meant the question ,\nThat 's   that 's good , yeah , cuz the overall rate is\nYeah .\nStatistical .\nYeah .\nMm - hmm .\nright ?\nYeah . They 're not double counted .\nOther - otherwise you 'd get double counts , here and there .\nYep .\nAh but , yeah .\nYeah .\nAnd then it would be harder\nYeah .\nYeah .\nI should also say I did a simplifying , uh  count in that  if A was speaking  B overlapped with A and then A came back again and overlapped with B again , I  I didn't count that as a three - person overlap , I counted that as a two - person overlap ,  and it was A being overlapped with by D .\nMm - hmm .\nBecause the idea was the first speaker  had the floor  and the second person  started speaking and then the f the first person reasserted the floor  kind of thing .\nYeah .\nThese are simplifying assumptions , didn't happen very often , there may be like three overlaps affected that way in the whole thing .\nI want to go back and listen to minute forty - one .\nYeah , yeah .\nCuz i i I find it interesting that there were a large number of overlaps and they were all two - speaker .\nYeah .\nI mean what I thought  what I would have thought in  is that when there were a large number of overlaps , it was because everyone was talking at once ,  but uh apparently not .\nThat 's interesting . That 's interesting .\nYeah . Yeah . Mmm .\nThat 's really neat .\nYeah .\nYeah , there 's a lot of backchannel , a lot o a lot of\nThis is  really interesting data .\nYeah , it is .\nI think what 's really interesting though , it is  before d  saying \" yes , meetings have a lot of overlaps \" is to actually find out how many more  we have than two - party .\nI think so too , I think\nCuz in two - party conversations , like Switchboard , there 's an awful lot too if you just look at backchannels , if you consider those overlaps ? it 's also ver it 's huge . It 's just that people haven't been  looking at that because they 've been doing single - channel processing for  speech recognition .\nMm - hmm .\nMm - hmm ?\nSo , the question is , you know , how many more overlaps   do you have  of , say the two - person type , by adding more people . to a meeting , and it may be a lot more but i it may   it may not be .\nWell , but see , I find it interesting even if it wasn't any more ,\nSo .\nbecause  since we were dealing with this full duplex sort of thing in Switchboard where it was just all separated out  we just  everything was just nice ,\nMm - hmm ?\nso that  so the issue is in  in a situation  where th that 's\nWell , it 's not really  \" nice \" . It depends what you 're doing . So if you were actually   having , uh  depends what you 're doing , if  Right now we 're do we have individual mikes on the people in this meeting . So the question is , you know  \" are there really more overlaps happening than there would be in a two - person  party \" .\nMm - hmm ?\nAnd  and there well may be , but\nLet  let m let me rephrase what I 'm saying cuz I don't think I 'm getting it across . What  what I  what  I shouldn't use words like \" nice \" because maybe that 's too  i too imprecise . But what I mean is  that , um in Switchboard ,  despite the many  many other problems that we have , one problem that we 're not considering is overlap . And what we 're doing now is ,  aside from the many other differences in the task , we are considering overlap and one of the reasons that we 're considering it ,  you know , one of them not all of them , one of them is  that w uh at least ,  you know I 'm very interested in  the scenario in which , uh  both people talking are pretty much equally  audible ,  and from a single microphone . And so ,  in that case , it does get mixed in ,  and it 's pretty hard to jus  to just ignore it , to just do processing on one and not on the other .\nI  I agree that it 's an issue here  but it 's also an issue for Switchboard and if you  think of meetings  being recorded over the telephone , which I think , you know , this whole point of studying meetings isn't just to have people in a room but to also have  meetings over different phone lines .\nMm - hmm .\nMaybe far field mike people wouldn't be interested in that but all the dialogue issues still apply ,\nMm - hmm .\nso if each of us was calling and having   a meeting that way  you kn you know like a conference call . And , just the question is ,  y you know , in Switchboard  you would think that 's the simplest case of a meeting of more than one person ,\nMm - hmm .\nand   I 'm wondering how much more  overlap  of  the types that  that Jane described happen with more people present . So it may be that having three people   is very different from having two people or it may not be .\nThat 's an important question to ask .\nSo .\nI think what I 'm   All I 'm s really saying is that I don't think we were considering that in Switchboard .\nNot you , me . But uh  but  but\nWere you ?\nThough it wasn't  in the design .\nWere you  were you  were you  were you measuring it ? I mean , w w were\nThere  there 's actually to tell you the truth , the reason why it 's hard to measure is because of so , from the point of view of studying dialogue , I mean , which  Dan Jurafsky and Andreas and I had some projects on , you want to know the sequence of turns .\nYeah .\nSo what happens is if you 're talking and I have a backchannel in the middle of your turn , and then you keep going what it looks like in a dialogue model is your turn and then my backchannel ,\nYeah .\neven though my backchannel occurred completely inside your turn .\nYeah ?\nSo , for things like language modeling or dialogue modeling   it 's  We know that that 's wrong in real time .\nYeah ?\nBut , because of the acoustic segmentations that were done and the fact that some of the acoustic data in Switchboard were missing , people couldn't study it , but that doesn't mean in the real world that people don't talk that way . So , it 's  um\nYeah , I wasn't saying that . Right ? I was just saying that w now we 're looking at it .\nWell , we 've als\nAnd  and  and , you  you maybe wanted to look at it before but , for these various technical reasons in terms of how the data was you weren't .\nRight . We 're looking at it here .\nSo that 's why it 's coming to us as new even though it may well be  you know , if your  if your hypothes The hypothesis you were offering  eh\nUm .\nRight ?  if it 's the null poth  hypothesis , and if actually you have as much overlap in a two - person ,  we don't know the answer to that . The reason we don't know the answer to is cuz it wasn't studied and it wasn't studied because it wasn't set up . Right ?\nYeah , all I meant is that if you 're asking the question from the point of view of  what 's different about a meeting , studying meetings of , say , more than two people versus  what kinds of questions you could ask with a two - person  meeting .\nMm - hmm ?\nIt 's important to distinguish  that , you know , this project  is getting a lot of overlap  but other projects were too , but we just couldn't study them . And and so uh\nMay have been . May have been . Right ?\nWell , there is a high rate ,\nWe do kn we don't know the numbers .\nSo . It 's  but I don't know how high , in fact\nWell , here I have a question .\nthat would be interesting to know .\nSee , I mean , i i le let me t I mean , my point was just if you wanted to say to somebody , \" what have we learned about overlaps here ? \" just never mind comparison with something else ,\nMm - hmm .\nwhat we 've learned about is overlaps in this situation , is that  the first   the first - order thing I would say is that there 's a lot of them . Right ?\nYeah .\nIn  in the sense that i if you said if  i i i\nYeah , I  I don't di I agree with that .\nIn a way , I guess what I 'm comparing to is more the common sense notion of  how  how much people overlap . Uh  you know the fact that when  when  when , uh , Adam was looking for a stretch of  of speech before , that didn't have any overlaps , and he w he was having such a hard time and now I look at this and I go , \" well , I can see why he was having such a hard time \" .\nRight . That 's also true of Switchboard .\nIt 's happening a lot .\nIt may not be\nI wasn't saying it wasn't .\nRight . So it 's just , um\nRight ? I was commenting about this .\nOK . All I 'm saying is that from the\nI 'm saying if I   I 'm saying if I have this complicated thing in front of me ,  and we sh which ,  you know we 're gonna get much more sophisticated about when we get lots more data , But  Then , if I was gonna describe to somebody what did you learn  right here , about , you know , the  the modest amount of data that was analyzed I 'd say , \" Well , the first - order thing was there was a lot of overlaps \" . In fact   and it 's not just an overlap  bunch of overlaps  second - order thing is  it 's not just a bunch of overlaps in one particular point ,  but that there 's overlaps , uh throughout the thing .\nRight .\nRight . No , I  I agree with that .\nAnd that 's interesting . That 's all .\nI 'm just   saying that it may   the reason you get overlaps may or may not be due to sort of the number of people in the meeting .\nOh yeah .\nAnd that 's all .\nYeah . Yeah , I wasn't making any statement about that .\nAnd  and it would actually be interesting to find out\nYeah .\nbecause some of the data say Switchboard , which isn't exactly the same kind of context , I mean these are two people who don't know each other and so forth , But we should still be able to somehow say what  what is the added contra contribution to sort of overlap time of each additional person , or something like that .\nYep .\nYeah , that would be good to know ,\nWhat\nbut w we\nOK , now .\nI could certainly see it going either way .\nWh - yeah , I  I agree  I agree with Adam .\nBut yeah .\nYeah .\nAnd the reason is because I think there 's a limit   there 's an upper bound  on how many you can have , simply  from the standpoint of audibility . When we speak we  we do make a judgment of  \" can  \" you know , as adults .\nRight .\nMm - hmm .\nI mean , children don't adjust so well , I mean , if a truck goes rolling past ,  adults will well , depending , but mostly , adults will  will   will hold off to what   to finish the end of the sentence till the  till the noise is past .\nMm - hmm .\nAnd I think we generally do  monitor things like that ,  about  whether we  whether our utterance will be in the clear or not .\nRight .\nAnd partly it 's related to rhythmic structure in conversation , so ,  you know , you  you t Yeah , this is d also um , people tend to time their  their   their , um  when they  come into the conversation based on the overall rhythmic ,  uh uh , ambient thing .\nWell\nRight .\nSo you don't want to be c cross - cutting . And  and , just to finish this , that um That I think that  there may be an upper bound on how many overlaps you can have , simply from the standpoint of audibility and how loud the other people are who are already  in the fray . But I  you know , of certain types . Now if it 's just backchannels ,  people  may be doing that  with less  intention of being heard ,  just sort of spontaneously doing backchannels , in which case  that  those might  there may be no upper bound on those .", "topic_id": 1, "keywords": "encoding, coding, utterance, encoded, overlapped", "dialogue_id": 30}, {"text": "I  I have a feeling that backchannels , which are the vast majority of overlaps in Switchboard ,  uh , don't play as big a role here , because it 's very unnatural I think , to backchannel if  in a multi - audience  you know , in a multi - person   audience .\nIf you can see them , actually . It 's interesting , so if you watch people are going like    Right  right , like this here ,\nRight .\nYeah .\nbut That may not be the case if you couldn't see them .\nu\nBut   but , it 's sort of odd if one person 's speaking and everybody 's listening , and it 's unusual to have everybody going \" uh - huh , uh - huh \"\nActually , I think I 've done it  a fair number of times today .\nYeah .\nBut .\nThere 's a lot of head - nodding , in this\nUm .\nYeah .\nYep , we need to put trackers on it .\nIn  in the two - person\nYeah , yeah , yeah .\nHe could , he could .\nPlus  plus  plus the  Yeah . So  so actually , um That 's in part because the nodding , if you have visual contact ,  the nodding has the same function , but on the phone , in Switchboard  you  you  that wouldn't work . So  so you need to use the backchannel .\nYeah , you don't have it . Your mike is\nSo , in the two - person conversations ,  when there 's backchannel , is there a great deal of  overlap  in the speech ?\nThat is an earphone , so if you just put it  so it 's on your ear .\nor  Cuz my impression is sometimes it happens when there 's a pause ,\nYes .\nThere you go .\nYeah .\nE for example .\nThank you .\nyou know , like you  you get a lot of backchannel , when somebody 's pausing\nYes . Right .\nShe 's doing that .\nSorry , what were you saying ?\nIt 's hard to do both , huh ? Um  no , when  when  when there 's backchannel , I mean , just  I was just listening , and  and when there 's two people talking and there 's backchannel it seems like ,  um the backchannel happens when , you know , the pitch drops and the first person\nOh .\nand a lot of times , the first person actually stops talking and then there 's a backchannel  and then they start up again , and so I 'm wondering about  h I just wonder how much overlap there is . Is there a lot ?\nI think there 's a lot of the kind that Jose was talking about , where   I mean , this is called \" precision timing \" in  conversation analysis , where   they come in overlapping ,  but at a point where the  information is mostly  complete . So all you 're missing is some last syllables or something or the last word or some highly predictable words .\nMmm . Mm - hmm .\nSo technically , it 's an overlap .\nBut maybe a  just a small overlap ?\nBut  you know , from information flow point of view it 's not an overlap in  the predictable information .\nMore , yeah .\nIt 'd be interesting if we could do prediction .\nI was just thinking more in terms of alignment , alignment overlap .\nYeah .\nLanguage model prediction of overlap , that would be really interesting .\nSo   so\nWell , that 's exactly , exactly why we wanted to study the precise timing of overlaps ins in uh Switchboard ,\nYeah .\nRight .\nRight .\nsay , because there 's a lot of that .\nSo  so here 's a  here 's a first interesting  labeling task . Uh , to distinguish between , say , backchannels   precision timing  Sort of  you know , benevolent overlaps , and  and    and w and  and sort of , um  I don't know , hostile overlaps , where  someone is trying to grab the floor from someone else .\nMm - hmm . Let 's pick a different word .\nYeah .\nUh , that  that might be an interesting , um  problem to look at .\nHostile takeovers .\nYeah .\nYeah .\nYeah . Yeah .\nWell , I mean you could do that . I ju I  I think that  in this meeting I really had the feeling that wasn't happening , that  the hostile  hostile type . These were  these were  benevolent types , as people  finishing each other 's sentences , and  stuff .\nOK .\nMm - hmm .\nUm , I could imagine that as  there 's a fair number of  um cases where , and this is sort of , not  really hostile , but sort of competitive , where  one person is finishing something and  you have , like , two or three people jumping  trying to   trying to   trying to , uh grab the next turn .\nTrying to get the floor .\nYeah .\nAnd so it 's not against the person who talks first  because actually we 're all waiting for that person to finish . But they all want to  be next .\nI have a feeling most of these things are  that   that are not  a benevolent kind are  are   are , uh  um   are  are competitive as opposed to real really  really hostile .\nRight .\nI wonder what determines who gets the floor ?\nBut .\nYeah , I agree . I agree .\nI mean\nWell , there are various things , you  you have the\nUh a vote  vote in Florida .\nIt 's been studied a lot .\nYeah .\nVoting for\nUm , o one thing  I  I wanted to  or you can tell a good joke and then everybody 's laughing and you get a chance to g break in .\nSeniority .\nBut . But . Um . You know , the other thing I was thinking was that ,  um  these  all these interesting questions are , of course , pretty hard to answer with , uh u  you know , a small amount of data .\nAch .\nSo , um  I wonder if what you 're saying suggests that we should make a conscious attempt to have , um  a  a fair number of meetings with , uh a smaller number of people . Right ? I mean  we  most of our meetings are  uh , meetings currently with say five , six , seven , eight people Should we  really try to have some two - person meetings ,  or some three - person meetings and re record them  just to  to  to beef up the  the statistics on that ?\nThat 's a control . Well ,  it seems like there are two possibilities there , I mean  i it seems like  if you have just  two people it 's not  really , y like a meeting , w is not as similar as the rest of the   of the sample . It depends on what you 're after , of course , but  It seems like that would be more a case of the control condition , compared to , uh  an experimental  condition , with more than two .\nMm - hmm .\nWell , Liz was raising the question of  of whether i it 's the number  there 's a relationship between the number of people and the number of overlaps or type of overlaps there ,\nMm - hmm .\nand , um  If you had two people meeting in this kind of circumstance then you 'd still have the visuals . You wouldn't have that difference  also that you have in the  say , in Switchboard data . Uh\nMm - hmm . Yeah , I 'm just thinking that 'd be more like a c control condition .\nYeah .\nMm - hmm .\nYeah .\nWell , but from the acoustic point of view , it 's all good .\nIs the same .\nYeah , acoustic is fine , but\nIf  if the goal were to just look at overlap you would  you could serve yourself  save yourself a lot of time but not even transcri transcribe the words .\nWell , I was thinking you should be able to do this from the  acoustics , on the close - talking mikes ,\nYep .\nYeah .\nWell , that 's  the  that was my  my status report ,\nright ?\nYou 've been working on that .\nRight , I mean Adam was\nYeah .\nYeah .\nso   Once we 're done with this stuff discussing ,\nright . I mean , not as well as what  I mean , you wouldn't be able to have any kind of typology , obviously ,\nYeah .\nbut you 'd get some rough statistics .\nMm - hmm .\nSo .\nBut  what  what do you think about that ? Do you think that would be useful ? I 'm just thinking that as an action item of whether we should try to record some two - person meetings or something .\nI guess my  my first comment was , um  only that  um we should n not attribute overlaps only to meetings , but maybe that 's obvious , maybe everybody knew that ,\nYeah .\nbut that  in normal conversation with two people there 's an awful lot of the same kinds of overlap , and that it would be interesting to look at  whether there are these kinds of constraints that Jane mentioned , that  what maybe the additional people add to this competition that happens right after a turn ,\nMm - hmm .\nyou know , because now you can have five people trying to grab the turn , but pretty quickly there 're  they back off and you go back to this sort of only one person at a time with one person interrupting at a time .\nMm - hmm .\nSo , I don't know . To answer your question I  it  I don't think it 's crucial to have controls but I think it 's worth recording all the meetings we  can .\nCan .\nSo , um  you know .\nWell ,  OK .\nYeah .\nI  I have an idea .\nD I wouldn't not record a two - person meeting just because it only has two people .\nRight .\nCould we  Could we , um  we have  have in the past and I think continue  will continue to have a fair number of  uh phone conference calls .\nUh - huh .\nAnd ,  uh ,  and as a  to , um  as another c  c comparison  condition ,  we could um see what  what what happens in terms of overlap , when you don't have visual contact .\nYeah , we talked about this repeatedly .\nSo , um\nCan we actually record ?\nIt just seems like that 's a very different  thing than what we 're doing .\nUh Well , we 'll have to set up for it .\nI mean  physically  can we record the o the other\nYeah . Well , we 're not really set up for it  to do that . But .\nOr , this is getting a little extravagant , we could put up some kind of blinds or something to   to remove , uh  visual contact .\nYeah .\nYeah .\nBarriers !\nThat 's what they did on Map Task , you know , this Map Task corpus ? They ran exactly the same pairs of people with and without visual cues and it 's quite interesting .\nWell , we  we record this meeting so regularly it wouldn't be that  I mean  a little strange .\nOK , we can record , but no one can look at each other .\nWell , we could just put  b blindfolds on .\nYeah .\nWell y no you  f\nClose your eyes .\nBlindf\nYeah , Yeah .\nTurn off the lights .\nand we 'd take a picture of everybody sitting here with blindfolds . That would\nOh , th that was the other thing , weren't we gonna take a picture  at the beginning of each of these meetings ?\nUm , what  I had thought we were gonna do is just take pictures of the whiteboards . rather than take pictures of the meeting .\nWell , linguistic\nAnd , uh\nYes .\nYeah . Linguistic anthropologists would  would suggest it would be useful to also take a picture of the meeting .\nThere 's a head nodding here vigorously , yeah .\nWhy  why do we want to have a picture of the meeting ?\nEe -  you mean , transc  no\nThe  because you get then the spatial relationship of the speakers .\nYeah Yeah .\nAnd that  could be\nWell , you could do that by just noting on the enrollment sheet the   the seat number .\nYeah .\nSeat number , that 's a good idea . I 'll do that .\nYeah .\nI 'll do that on the next set of forms .\nYeah .\nSo you 'd number them somehow .\nIs possible to get information from the rhythmic  f from the ge , eh  uh , files .\nI finally remembered to put , uh put native language on the newer forms .\nWe can  can't you figure it out from the mike number ?\nNo .\nOK .\nThe wireless ones . And even the jacks , I mean , I 'm sitting here and the jack is  over  in front of you .\nOh .\nBut probably from these you could 've  infer it .\nYeah , but It 's  it would be trivial\nIt would be another task .\nIt would be a research task .\nHaving  having ground tu truth would be nice , so  seat number would be good .\nYou know where you could get it ?\nYeah , yeah .\nBeam - forming during the digit  uh stuff .\nYeah .\nSo I 'm gonna put little labels on all the chairs with the seat number .\nMm - hmm .\nThat 's a good idea .\nBut you have to keep the chairs in the same pla like here .\nNot the chairs . The chairs are  Chairs are movable .\nBut , uh\nPut them   Like ,  put them on the table where they\nThe chair  Yeah .\nYep .\nYeah .\nYep .\nBut you know , they  the  s the linguistic anthropologists would say it would be good to have a digital picture anyway ,\nJust remembered a joke .\nbecause you get  a sense also of posture . Posture , and we could like ,  you know ,  block out the person 's face or whatever\nWhat people were wearing .\nYeah .\nThe fashion statement .\nbut   but , you know , these are important cues ,\nOh , Andreas was\nHow big their heads are .\nI mean the  the  how a person is sitting  is\nBut if you just f But from one picture , I don't know that you really get that .\nYeah . Andreas was wearing that same old sweater again .\nRight ? You 'd want a video for that , I think .\nIt 'd be better than nothing , is  is  i Just from a single picture I think you can tell some aspects .\nA video , yeah .\nThink so ?\nI mean I  I could tell you I mean , if I if I 'm in certain meetings I notice that there are certain people who really do  eh  The body language is very uh  is very interesting in terms of the dominance aspect .\nAnd  And\nHmm .\nYeah . And  and Morgan had that funny hair again .\nYeah .  Well , I mean you black out the  that part .\nHmm .\nBut it 's just , you know , the  the body\nHe agreed .\nyou know ?\nOf course , the  where we sit at the table , I find is very interesting , that we do tend to  cong  to gravitate to the same place each time .\nYeah .\nand it 's somewhat coincidental . I 'm sitting here so that I can run into the room if the hardware starts , you know , catching fire or something .\nOh , no , you  you just like to be in charge , that 's why you 're sitting\nI just want to be at the head of the table .\nYeah .\nTake control .\nSpeaking of taking control , you said you had some research to talk about .\nYeah . Yeah .", "topic_id": 2, "keywords": "backchannels, backchannel, conversations, talks, talking", "dialogue_id": 30}, {"text": "Yeah , I 've been playing with , um uh , using the close - talking mike to do  to try to figure out who 's speaking . So my first attempt was just using thresholding and filtering , that we talked about  about two weeks ago , and so I played with that a little bit , and  it works O K ,  except that  it 's very sensitive to your choice of  your filter width and your  threshold . So if you fiddle around with it a little bit and you get good numbers you can actually do a pretty good job of segmenting when someone 's talking and when they 're not . But if you try to use the same paramenters on another speaker , it doesn't work anymore , even if you normalize it based on the absolute loudness .\nBut does it work for that one speaker throughout the whole meeting ?\nIt does work for the one speaker throughout the whole meeting . Um Pretty well .\nHow did you do it Adam ?\nPretty well . How did I do it ?\nYeah .\nWhat do you mean ?\nI mean , wh what was the\nThe algorithm was , uh take o every frame that 's over the threshold , and then median - filter it ,  and then look for runs .\nYeah . Mm - hmm .\nSo there was a minimum run length ,\nEvery frame that 's over what threshold ?\nso that  A threshold that you pick .\nIn terms of energy ? Ah !\nYeah .\nOK .\nSay that again ? Frame over fres threshold .\nSo you take a  each frame , and you compute the energy and if it 's over the threshold you set it to one , and if it 's under the threshold you set it to zero ,  so now you have a bit stream  of zeros and ones .\nHmm . OK .\nAnd then I median - filtered that  using , um  a fairly long  filter length . Uh  well , actually I guess depends on what you mean by long , you know , tenth of a second sorts of numbers . Um and that 's to average out you know , pitch , you know , the pitch contours , and things like that . And then , uh looked for long runs .\nOK\nAnd that works O K , if you fil if you tune the filter parameters , if you tune  how long your median filter is and how high you 're looking for your thresholds .\nDid you ever try running the filter before you pick a threshold ?\nNo . I certainly could though . But this was just I had the program mostly written already so it was easy to do . OK and then the other thing I did , was I took  Javier 's speaker - change detector  acoustic - change detector , and I implemented that with the close - talking mikes , and  unfortunately that 's not working real well , and it looks like it 's  the problem is  he does it in two passes , the first pass  is to find candidate places to do a break . And he does that using a neural net doing broad phone classification and he has the  the , uh  one of the phone classes is silence . And so the possible breaks are where silence starts and ends . And then he has a second pass which is a modeling  a Gaussian mixture model . Um looking for  uh  whether it improves or  or degrades to split at one of those particular places . And what looks like it 's happening is that the  even on the close - talking mike the broad phone class classifier 's doing a really bad job .\nWho was it trained on ?\nUh , I have no idea .\nHmm .\nI don't remember . Does an do you remember , Morgan , was it Broadcast News ?\nI think so , yeah .\nUm  So , at any rate , my next attempt ,  which I 'm in the midst of and haven't quite finished yet was actually using the  uh , thresholding as the way of generating the candidates . Because one of the things that definitely happens is if you put the threshold low  you get lots of breaks . All of which are definitely acoustic events . They 're definitely  someone talking . But , like , it could be someone who isn't the person here , but the person over there or it can be the person breathing . And then feeding that into the acoustic change detector . And so I think that might work . But , I haven't gotten very far on that . But all of this is close - talking mike , so it 's , uh  just  just trying to get some ground truth .\nOnly with eh uh , but eh I  I  I think , eh when  when , y I   I saw the  the  the  the speech from PDA and , eh  close   talker . I  I think the there is a  a great difference in the  in the signal .\nOh , absolutely .\nUm but eh I  but eh I  I  I mean that eh eh  in the  in the mixed file  you can find , uh  zone with , eh  great different , eh  level of energy .\nSo  s my intention for this is  is as an aide for ground truth . not\nUm  I  I think for , eh  algorithm based on energy ,  eh , that um h mmm ,  more or less , eh , like eh  eh , mmm , first sound energy detector .\nSay it again ?\neh nnn . When y you the detect the  the  the first at  at the end of  of the  detector of , ehm princ um . What is the  the name in English ? the  the , mmm ,   the de detector of , ehm of a word in the  in the s in  an isolated word in  in the background That , uh\nI 'm  I 'm not sure what you 're saying , can you try\nI mean that when  when you use , eh  eh  any\nI think he 's saying the onset detector .\nYeah .\nOnset detector , OK .\nI  I think it 's probably to work well eh , because , eh  you have eh , in the mixed files a great level of energy . eh  and great difference between the sp speaker . And probably is not so easy when you use the  the PDA , eh that  Because the signal is , eh  the  in the e energy level .\nRight .\nin  in that , eh  eh  speech file  is , eh  more similar . between the different eh , speaker ,  um  I  I think is  eh , it will  i is my opinion .\nRight . But different speakers .\nIt will be , eh  more difficult to  to detect bass - tone energy . the  the change . I think that , um\nAh , in the clo in the P D A , you mean ?\nIn the PDA .\nAbsolutely .\nYeah . Yeah .\nYeah , no question . It 'll be much harder .\nYeah .\nMuch harder .\nAnd the  the another question , that when I review the  the  the work of Javier . I think the , nnn , the , nnn ,  that the idea of using a  neural network  to  to get a broad class of phonetic , eh  from , eh uh a candidate from the  the  the speech signal . If you have , eh  uh , I 'm considering , only because Javier , eh  only consider , eh  like candidate , the , nnn , eh  the silence , because it is the  the only model , eh  eh , he used that , eh   eh  nnn , to detect the  the possibility of a  a change between the  between the speaker ,\nRight .\nUm  another  another research thing , different groups , eh  working , eh  on Broadcast News  prefer to , eh  to consider hypothesis eh  between each phoneme .\nMm - hmm . Yeah , when a  phone changes .\nBecause , I  I  I think it 's more realistic that , uh  only consider the   the  the  the silence between the speaker . Eh  there  there exists eh  silence between  between , eh  a speaker . is  is , eh  eh  acoustic , eh  event , important to  to consider .\nMm - hmm . Mm - hmm .\nI  I found that the , eh  silence in  in many occasions in the  in the speech file , but , eh  when you have , eh  eh , two speakers together without enough silence between  between them , eh   I think eh  is better to use the acoustic change detector basically and I  I  I IX or , mmm , BIC criterion for consider all the frames in my opinion .\nMm - hmm . Yeah , the  you know , the reason that he , uh  just used silence  was not because he thought it was better , it was  it was  it was the place he was starting .\nYeah .\nYep .\nSo , he was trying to get something going ,\nYeah .\nand , uh e e you know , as  as   as is in your case , if you 're here for only a modest number of months you try to pick a realistic goal ,\nYeah , yeah , yeah , yeah . Yeah . Yeah , yeah , yeah , yeah .\nDo something .\nBut his  his goal was always to proceed from there to then allow broad category change also .\nUh - huh . But , eh  do  do you think that if you consider all the frames to apply  the  the , eh  the BIC criterion to detect the  the  the different acoustic change ,  eh  between speaker , without , uh  with , uh  silence or  with overlapping , uh , I think like  like , eh  eh a general , eh  eh  way of process the  the acoustic change .\nMm - hmm .\nIn a first step , I mean .\nMm - hmm .\nAn - and then , eh   eh  without considering the you  you  you , um  you can consider the energy  like a another parameter in the  in the feature vector , eh .\nRight . Absolutely .\nMm - hmm .\nThis  this is the idea . And if , if you do that , eh  eh , with a BIC uh criterion for example , or with another kind of , eh  of distance in a first step ,  and then you , eh  you get the , eh  the hypothesis to the  this change acoustic ,  eh   to po process\nRight .\nBecause , eh  eh , probably you  you can find the  the  eh  a small gap of silence between speaker  with eh  eh  a ga mmm ,   small duration Less than ,  eh  two hundred milliseconds for example\nMm - hmm .\nand apply another  another algorithm , another approach like , eh  eh  detector of ene , eh detector of bass - tone energy to  to consider that , eh  that , eh  zone . of s a small silence between speaker , or  another algorithm to  to process ,  eh  the  the segment between marks eh  founded by the  the  the BIC criterion and applied for  for each frame .\nMm - hmm . Mm - hmm .\nI think is , eh  nnn , it will be a an  an  a more general approach  the  if we compare  with use , eh  a neural net or another , eh  speech recognizer with a broad class or  or narrow class , because , in my opinion eh  it 's in my opinion ,  eh if you  if you change the condition of the speech , I mean , if you adjust to your algorithm with a mixed speech file and to , eh  to , eh   adapt the neural net , eh  used by Javier with a mixed file .\nMm - hmm . Mm - hmm .\nuh With a m mixed file ,\nWith the what file ?\n\" Mixed \" .\nwith a  the mix , mix .\n\" Mixed . \"\n\" Mixed ? \"\nMm - hmm .\nSorry . And  and then you  you , eh you try to  to apply that , eh , eh , eh , speech recognizer to that signal , to the PDA , eh  speech file ,  I  I think you will have problems , because the  the  the  the  condition  you  you will need t t I  I suppose that you will need to  to  to retrain it .\nWell , I  I\nOh , absolutely . This is  this is not what I was suggesting to do .\nu  Look , I  I think this is a  One  once  It 's a  I used to work , like , on voiced  on voice silence detection , you know , and this is this  kind of thing .\nReally ? Yeah .\nUm  If you  have somebody who has some experience with this sort of thing , and they work on it for a couple months ,  they can come up with something that gets most of the cases fairly easily . Then you say , \" OK , I don't just wanna get most of the cases I want it to be really accurate . \" Then it gets really hard no matter what you do . So , the p the problem is is that if you say , \" Well I  I have these other data over here ,  that I learn things from , either explicit training of neural nets or of Gaussian mixture models or whatever . \"\nYeah .\nUh  Suppose you don't use any of those things . You say you have looked for acoustic change . Well , what does that mean ? That  that means you set some thresholds somewhere or something ,\nYeah .\nright ? and  and so  where do you get your thresholds from ?\nYeah .\nFrom something that you looked at . So  you always have this problem , you 're going to new data um  H how are you going to adapt whatever you can very quickly learn about the new data ?  Uh , if it 's gonna be different from old data that you have ? And I think that 's a problem  with this .\nWell , also what I 'm doing right now is not intended to be an acoustic change detector for far - field mikes . What I 'm doing  is trying to use the close - talking mike  and just use   Can - and just generate candidate and just  try to get a first pass at something that sort of works .\nYeah !\nYou have candidates .\nActually  actually  actually\nthe candidate .\nI\nto make marking easier . Yeah .\nOr\nand I haven't spent a lot of time on it and I 'm not intending to spend a lot of time on it .\nOK . I  um , I , unfortunately , have to run ,\nSo .\nbut , um  I can imagine  uh building  a  um  model of speaker change  detection  that  takes into account  both the far - field and the  uh  actually , not just the close - talking mike for that speaker , but actually for all of th  for all of the speakers .\nYep . Everyone else .\nYeah .\num  If you model the   the  effect that  me speaking has on  your  microphone and everybody else 's microphone , as well as on that ,  and you build , um  basically I think you 'd  you would  build a   an HMM that has as a state space all of the possible speaker combinations\nAll the  Yep .\nYeah .\nand , um  you can control\nIt 's a little big .\nIt 's not that big actually , um\nTwo to the N . Two to the number of people in the meeting .\nBut  Actually , Andreas may maybe  maybe just something simpler but  but along the lines of what you 're saying ,\nAnyway .\nYeah .\nI was just realizing , I used to know this guy who used to build , uh  um , mike mixers  automatic mike mixers where , you know , t in order to able to turn up the gain , you know , uh  as much as you can , you  you  you lower the gain on  on the mikes of people who aren't talking ,\nMmm .\nYeah  Yeah .\nMmm . Mm - hmm .\nright ? And then he had some sort of  reasonable way of doing that ,\nMm - hmm .\nbut  uh , what if you were just looking at very simple measures like energy measures but you don't just compare it to some threshold  overall but you compare it to the  energy in the other microphones .\nI was thinking about doing that originally to find out  who 's the loudest , and that person is certainly talking .\nYeah .\nBut I also wanted to find threshold  uh , excuse me , mol overlap .\nYeah .\nSo , not just  just the loudest .\nBut , eh\nMm - hmm .\nI  I Sorry . I  I have found that when  when I I analyzed the  the speech files from the ,  eh  mike , eh  from the eh close eh  microphone , eh  I found zones with a  a different level of energy .\nSorry , I have to go .\nOK . Could you fill that out anyway ? Just ,  put your name in . Are y you want me to do it ? I 'll do it .\nBut he 's not gonna even read that . Oh .\nI know .\nincluding overlap zone . including . because , eh  eh  depend on the position of the  of the microph of the each speaker  to , eh , to get more o or less energy  i in the mixed sign in the signal . and then ,  if you consider energy to  to detect overlapping in  in , uh , and you process the  the  in  the  the  the speech file from the  the  the mixed signals . The mixed signals , eh . I  I think it 's  it 's difficult , um   only to en with energy to  to consider that in that zone We have eh , eh , overlapping zone Eh , if you process only the the energy of the , of each frame .\nWell , it 's probably harder , but I  I think what I was s nnn noting just when he  when Andreas raised that , was that there 's other information to be gained from looking at all  of the microphones and you may not need to look at very sophisticated things ,\nYeah .\nbecause if there 's   if most of the overlaps  you know , this doesn't cover , say , three , but if most of the overlaps , say , are two ,  if the distribution looks like there 's a couple high ones and  and  the rest of them are low ,\nYeah . Yeah . Yeah . Yeah .\nAnd everyone else is low , yeah .\nyou know , what I mean ,\nYeah .\nthere 's some information there about their distribution even with very simple measures .\nYeah . Yeah .\nUh , by the way , I had an idea with  while I was watching Chuck nodding at a lot of these things , is that we can all wear little bells on our heads ,  so that  then you 'd know that\nYeah .\nDing , ding , ding , ding .\nYeah .\n\" Ding \" . That 's cute !\nI think that 'd be really interesting too , with blindfolds . Then\nNodding with blindfolds ,\nYeah . The question is ,  like  whether\n\" what are you nodding about ? \"\nWell , trying with and   with and without , yeah .\n\" Sorry , I 'm just  I 'm just going to sleep . \"\nBut then there 's just one @ @ , like .\nYeah .\nActually , I saw a uh  a woman at the bus stop the other day who , um , was talking on her cell phone  speaking Japanese , and was bowing . you know , profusely .\nOh , yeah , that 's really common .\nYeah .\nYeah  Yeah .\nJust , kept\nYeah .\nAh .\nWow .\nIt 's very difficult if you try  while you 're trying , say , to convince somebody on the phone it 's difficult not to move your hands . Not  You know , if you watch people they 'll actually do these things .\nMm - hmm ?\nSo . I still think we should try a  a meeting or two with the blindfolds , at least of this meeting that we have lots of recordings of\nMm - hmm .\nUm , maybe for part of the meeting , we don't have to do it the whole meeting .\nYeah , I think th I think it 's a great idea .\nThat could be fun . It 'll be too hard to make barriers , I was thinking because they have to go all the way\nW Yeah .\nyou know , I can see Chuck even if you put a barrier here .\nWell , we could just turn out the lights .\nActually  well also  I  I can say I made barr barriers for  so that  the  stuff I was doing with Collin wha  which  just used , um  this  kind of foam board .\nY Yeah ?\nR really inexpensive . You can  you can masking tape it together , these are  you know , pretty l large partitions .\nYeah .\nBut then we also have these mikes , is the other thing I was thinking , so we need a barrier that doesn't disturb  the sound ,\nIt 's true , it would disturb the , um  the  the long - range\nThe acoustics .\num\nBlindfolds would be good .\nit would\nI think , blindfolds .\nI mean , it sounds weird but  but   you know it 's   it 's cheap and , uh Be interesting to have the camera going .\nProbably we should wait until after Adam 's set up the mikes , But .\nOK . I think we 're going to have to work on the , uh   on the human subjects  form .\nI 'll be peeking .\nYeah , that 's right , we didn't tell them we would be blindfolding .\nThat 's\n\" Do you mind being blindfolded while you 're interviewed ? \"", "topic_id": 3, "keywords": "thresholding, segmenting, talker, microphone, talking", "dialogue_id": 30}, {"text": "that 's  that 's  that 's the one that we videotape . So . Um , I  I wanna move this along . Uh  I did have this other agenda item which is , uh @ @  it 's uh a list which I sent to uh  a couple folks , but um I wanted to get broader input on it , So this is the things that I think we did  in the last three months obviously not everything we did but  but sort of highlights that I can   can  tell  s some outside person , you know , what  what were you  actually working on . Um  in no particular order  uh , one , uh , ten more hours of meeting r meetings recorded , something like that , you know from  from , uh  three months ago . Uh  XML formats and other transcription aspects sorted out  and uh  sent to IBM . Um , pilot data put together and sent to IBM for transcription , uh  next batch of recorded data put together on the CD - ROMs for shipment to IBM ,\nHasn't been sent yet , but  It 's getting ready .\nBut yeah , that 's why I phrased it that way , yeah OK . Um  human subjects approval on campus , uh  and release forms worked out so the meeting participants have a chance to request audio pixelization of selected parts of the spee their speech . Um  audio pixelization software written and tested . Um   preliminary analysis of overlaps in the pilot data we have transcribed , and exploratory analysis of long - distance inferences for topic coherence , that was  I was   wasn't  sure if those were the right way   that was the right way to describe that because of that little exercise that  that you  and  and Lokendra did .\nWhat was that called ?\nI  well , I I 'm probably saying this wrong , but what I said was exploratory analysis of long - distance inferences  for topic coherence .\nThe , uh  say again ?\nSomething like that . Um  so , uh  I    a lot of that was from , you know , what  what  what you two were doing so I  I sent it to you , and you know , please mail me , you know , the corrections or suggestions for changing\nMm - hmm .\nI  I don't want to make this twice it 's length but   but you know , just im improve it . Um Is there anything anybody\nI  I did a bunch of stuff for supporting of digits .\n\" Bunch of stuff for s \" OK , maybe  maybe send me a sentence that 's a little thought through about that .\nSo ,  OK , I 'll send you a sentence that doesn't just say \" a bunch of \" ?\n\" Bunch of stuff \" , yeah , \" stuff \" is probably bad too ,\nYep . \" Stuff \"  is not very technical .\nYeah , well .\nI 'll try to  phrase it in passive voice .\nYeah . Yeah , yeah ,\nTechnical stuff .\n\" range of things \" , yeah . Um  and  and you know , I sort of threw in what you did with what Jane did on  in  under the , uh  uh  preliminary analysis of overlaps . Uh  uh  Thilo , can you tell us about all the work you 've done on this project in the last , uh  last three months ?\nYeah .\nSo  what is  what  Um . Not really .\nThat 's\nIt 's too complicated .\nUm ,  I didn't get it . Wh - what is \" audio pixelization \" ?\nUh , audio pix wh he did it , so why don't you explain it quickly ?\nIt 's just , uh  beeping out parts that you don't want included in the meeting so , you know you can say things like , \" Well , this should probably not be on the record , but beep \"\nOK , OK . I got that .\nYeah . We  we  we spent a  a  a fair amount of time early on just talk dealing with this issue about op w e e  we realized , \" well , people are speaking in an impromptu way and they might say something that would embarrass them or others later \" , and , how do you get around that\nOK .\nso in the consent form it says , well you  we will look at the transcripts later and if there 's something that you 're  unhappy with , yeah .\nOK , and you can say  OK .\nBut you don't want to just totally excise it because um uh , well you have to be careful about excising it , how  how you excise it keeping the timing right and so forth so that at the moment tho th the idea we 're running with is  is h putting the beep over it .\nOK .\nYeah , you can either beep or it can be silence . I  I couldn't decide . which was the right way to do it .\nAh , yeah .\nBeep is good auditorily ,\nYeah .\nif someone is listening to it , there 's no mistake that it 's been beeped out ,\nYeah .\nbut for software it 's probably better for it to be silence .\nNo , no . You can  you know , you could make a m as long as you keep using the same beep , people could make a model of that beep ,\nHmm .\nand\nI like that idea .\nYep . And I use  it 's  it 's , uh  it 's an A below middle C beep ,\nI think the beep is a really good idea .\nYeah .\nIt 's very clear . Then you don't think it 's a long pause .\nAlso\nYeah , it 's more obvious that there was something there than if there 's just silence .\nso\nYeah .\nYeah .\nYeah , that  I mean , he 's  he 's removing the old  thing\nYeah\nand  and  and\nYep .\nYea - right . Right . But I mean if you just replaced it with silence ,  it 's not clear whether that 's really silence or\nYeah , it 's not\nYeah .\nYeah .\nYeah , I agree .\nYeah .\nYeah .\nYep .\nOne  one question . Do you do it on all channels ?\nOf course .\nInteresting . I like that .\nYeah .\nYeah , I like that .\nYeah you have to do it on all channels because it 's , uh  audible .\nVery clear . Very clear .\nUh , it 's  it 's potentially audible , you could potentially recover it .\nKe - keep a back door .\nWell , the other thing that  you know , I mean the  the alternative might be to s\nYeah . Well , I  I haven't thrown away any of the meetings that I beeped . Actually yours is the only one that I beeped and then , uh  the ar DARPA meeting .\nNotice how quiet I am .\nSorry , and then the DARPA meeting I just excised completely ,\nYeah .\nso it 's in a private directory .\nYou have some people who only have beeps as their speech in these meetings .\nThat 's great . Yeah .\nOK .\nThey 're easy to find , then .\nAlright , so , uh  I think we should , uh  uh , go on to the digits ?\nI have one concept a t I  I want to say , which is that I think it 's nice that you 're preserving the time relations ,\nOK .\ns so you 're  you 're not just cutting  you 're not doing scissor snips . You 're  you 're keeping the , uh  the time duration of a  de - deleted  deleted part .\nRight .\nYeah , definitely .\nYeah .\nOK , good , digits .\nYeah , since we wanna  possibly synchronize these things as well . Oh , I should have done that .\nIt 's great .\nShoot . Oh well .\nSo I guess if there 's an overlap ,  like , if I 'm saying something that 's  bleepable and somebody else overlaps during it they also get bleeped , too ?\nYeah . Oh\nYou 'll lose it . There 's no way around that .\nYeah . Um  I d I did  before we do the digits , I did also wanna remind people , uh   please do send me , you know , uh thoughts for an agenda ,\nAgenda ?\nyeah that  that would be that 'd be good .\nGood .\nEh So that , uh , people 's ideas don't get\nThursday crept up on me this week .\nyeah , well it does creep up , doesn't it ?\nAnd , I wanted to say , I think this is really interesting  analysis .\nOK .\nThank you .\nIt 's cool stuff , definitely .\nI meant to say that before I started off on the  Switchboard stuff .\nThank you .\nI was gonna say \" can you do that for the other meetings ,\nIt 's neat .\ncan you do it for them ? \"\nYeah .\nAnd , no actually , you can't .\nActually  actually I  I thought that 's what you were giving us was another meeting and I was like , \" Oh , OK ! \"\nDoes it take\nThank you . Yeah .\n\" Ooo , cool ! \"\nAw , thanks .\nHow long does it  take , just briefly , like  t to   OK .  to label the ,\nNo . I have the script now , so , I mean , it can work off the , uh  other thing ,\nIt 's  As soon as we get labels , yep .\nOK .\nBut it has to be hand - labeled first ?\nbut  Uh , well , yeah . Because , uh  well , I mean  once his  his algorithm is up and running then we can do it that way .\nIf it works well enough . Right now it 's not . Not quite to the point where it works .\nOK .\nBut  I  I just worked off of my\nIt 's really neat .\nOK , go ahead\nThanks . Appreciate that . I think  what I  what this has , uh , caused me  so this discussion caused me to wanna subdivide these further . I 'm gonna take a look at the , uh  backchannels , how much we have anal I hope to have that for next time .\nThat 'd be interesting .\nYeah , my  my algorithm worked great actually on these , but when you wear it like that or with the uh , lapel  or if you have it very far from your face , that 's when it starts  failing .\nMm - hmm . Oh .\nWell , I can wear it , I mean if you\nIt doesn't matter .\nOK .\nI mean , we want it to work ,\nIt 's too late now .\nright ? I  I don't want  to change the way we do the meeting .\nI feel like this troublemaker .\nIt 's uh   so , it was just a comment on the software , not a comment on  prescriptions on how you wear microphones .\nOK .\nOK , that 's  let 's  let 's  let 's do digits .\nGet the bolts , \" whh whh \"\nLet 's do it . OK .\nOK .\nI 'm sorry .\nOK , thank you .\nDo you want us to put a mark on the bottom of these when they 've actually been read , or do you just  i i the only one that wasn't read is  is known , so we don't do it . OK .", "topic_id": 4, "keywords": "transcripts, meetings, videotape, agenda, formats", "dialogue_id": 30}, {"text": "So I guess this is more or less now just to get you up to date , Johno . This is what , uh ,\nThis is a meeting for me .\num , Eva , Bhaskara , and I did .\nDid you add more stuff to it ?  later ?\nUm . Why ?\nUm . I don't know . There were , like , the  you know , @ @ and all that stuff . But . I thought you  you said you were adding stuff\nUh , no .\nbut  I don't know .\nThis is  Um , Ha ! Very nice . Um , so we thought that ,  We can write up uh , an element , and  for each of the situation nodes that we observed in the Bayes - net ? So . What 's the situation like at the entity that is mentioned ? if we know anything about it ? Is it under construction ? Or is it on fire or something  happening to it ? Or is it stable ? and so forth , going all the way um , f through Parking , Location , Hotel , Car , Restroom , @ @  Riots , Fairs , Strikes , or Disasters .\nSo is  This is  A situation are  is all the things which can be happening right now ? Or , what is the situation type ?\nThat 's basically  just specifying the  the input for the  w what 's\nOh , I see y Why are you specifying it in XML ?\nUm . Just because it forces us to be specific about the values  here ?\nOK .\nAnd , also , I mean , this is a  what the input is going to be . Right ? So , we will , uh  This is a schema . This is\nWell , yeah . I just don't know if this is th l what the  Does  This is what Java Bayes takes ? as a Bayes - net spec ?\nNo , because I mean if we  I mean we 're sure gonna interface to  We 're gonna get an XML document from somewhere . Right ? And that XML document will say \" We are able to  We were able to observe that w the element , um , @ @  of the Location that the car is near . \" So that 's gonna be    Um .\nSo this is the situational context , everything in it . Is that what Situation is short for , shi situational context ?\nYep .\nOK .\nSo this is just , again , a an XML schemata which defines a set of possible , uh , permissible XML structures , which we view as input into the Bayes - net . Right ?\nAnd then we can r  uh possibly run one of them uh transformations ? That put it into the format that the Bayes n or Java Bayes or whatever wants ?\nYea - Are you talking  are you talking about the  the structure ?\nWell it\nI mean when you observe a node .\nWhen you  when you say  the input to the  v Java Bayes ,  it takes a certain format ,\nUm - hmm .\nright ? Which I don't think is this . Although I don't know .\nNo , it 's certainly not this . Nuh .\nSo you could just  Couldn't you just run a\nXSL .  Yeah .\nYeah . To convert it into the Java Bayes for format ?\nYep .\nOK .\nThat 's  That 's no problem , but I even think that , um  I mean , once  Once you have this sort of as  running as a module  Right ? What you want is  You wanna say , \" OK , give me the posterior probabilities of the Go - there  node , when this is happening . \" Right ? When the person said this , the car is there , it 's raining , and this is happening . And with this you can specify the  what 's happening in the situation , and what 's happening with the user . So we get  After we are done , through the Situation we get the User Vector . So , this is a\nSo this is just a specification of all the possible inputs ?\nYep . And , all the possible outputs , too . So , we have , um , for example , the , uh , Go - there decision node\nOK .\nwhich has two elements , going - there and its posterior probability , and not - going - there and its posterior probability , because the output is always gonna be all the decision nodes and all the  the  a all the posterior probabilities for all the values .\nAnd then we would just look at the , eh , Struct that we wanna look at in terms of if  if we 're only asking about one of the  So like , if I 'm just interested in the going - there node , I would just pull that information out of the Struct that gets return that would  that Java Bayes would output ?\nUm , pretty much , yes , but I think it 's a little bit more complex . As , if I understand it correctly , it always gives you all the posterior probabilities for all the values of all decision nodes . So , when we input something , we always get the , uh , posterior probabilities for all of these . Right ?\nOK .\nSo there is no way of telling it t not to tell us about the EVA  values .\nYeah , wait I agree , that 's  yeah , use  oh , uh  Yeah , OK .\nSo  so we get this whole list of  of , um , things , and the question is what to do with it , what to hand on , how to interpret it , in a sense . So y you said if you  \" I 'm only interested in whether he wants to go there or not \" , then I just look at that node , look which one\nLook at that Struct in the output ,\nYep .\nright ?\nLook at that Struct in the  the output , even though I wouldn't call it a \" Struct \" . But .\nWell i well , it 's an XML Structure that 's being res returned ,\nOh . Mm - hmm .\nright ?\nSo every part of a structure is a \" Struct \" . Yeah .\nYeah , I just uh  I just was  abbreviated it to Struct in my head , and started going with that .\nThat element or object , I would say .\nNot a C Struct . That 's not what I was trying to k\nYeah .\nthough yeah .\nOK . And , um , the reason is  why I think it 's a little bit more complex or why  why we can even think about it as an interesting problem in and of itself is  Um . So . The , uh  Let 's look at an example .\nWell , w wouldn't we just take the structure that 's outputted and then run another transformation on it , that would just dump the one that we wanted out ?\nYeah . w We 'd need to prune . Right ? Throw things away .\nWell , actually , you don't even need to do that with XML .\nNo\nD Can't you just look at one specific\nYeah , exactly . The  @ @  Xerxes allows you to say , u \" Just give me the value of that , and that , and that . \" But , we don't really know what we 're interested in  before we look at the complete  at  at the overall result . So the person said , um , \" Where is X ? \" and so , we want to know , um , is  Does he want info ? o on this ? or know the location ? Or does he want to go there ? Let 's assume this is our  our question .\nSure .\nNuh ? So . Um . Do this in Perl . So we get  OK . Let 's assume this is the output . So . We should con be able to conclude from that that  I mean . It 's always gonna give us a value of how likely we think i it is that he wants to go there and doesn't want to go there , or how likely it is that he wants to get information . But , maybe w we should just reverse this to make it a little bit more delicate . So , does he wanna know where it is ? or does he wanna go there ?\nHe wants to know where it is .\nRight . I  I  I tend to agree . And if it 's  If\nWell now , y I mean , you could\nAnd i if there 's sort of a clear winner here , and , um  and this is pretty , uh  indifferent , then we  then we might conclude that he actually wants to just know where , uh t uh , he does want to go there .\nUh , out of curiosity , is there a reason why we wouldn't combine these three nodes ? into one smaller subnet ? that would just basically be  the question for  We have \" where is X ? \" is the question , right ? That would just be Info - on or Location ? Based upon\nOr Go - there . A lot of people ask that , if they actually just wanna go there . People come up to you on campus and say , \" Where 's the library ? \" You 're gonna say  y you 're gonna say , g \" Go down that way . \" You 're not gonna say \" It 's  It 's five hundred yards away from you \" or \" It 's north of you \" , or  \" it 's located  \"\nWell , I mean  But the  there 's  So you just have three decisions for the final node , that would link thes these three nodes in the net together .\nUm . I don't know whether I understand what you mean . But . Again , in this  Given this input , we , also in some situations , may wanna postulate an opinion whether that person wants to go there now the nicest way , use a cab , or so s wants to know it  wants to know where it is because he wants something fixed there , because he wants to visit t it or whatever . So , it  n I mean  a All I 'm saying is , whatever our input is , we 're always gonna get the full output . And some  some things will always be sort of too  not significant enough .\nWha Or i or i it 'll be tight . You won't  it 'll be hard to decide .\nYep .\nBut I mean , I guess  I guess the thing is , uh , this is another , smaller , case of reasoning in the case of an uncertainty , which makes me think Bayes - net should be the way to solve these things . So if you had  If for every construction ,\nOh !\nright ? you could say , \" Well , there  Here 's the Where - Is construction . \" And for the Where - Is construction , we know we need to l look at this node , that merges these three things together\nMm - hmm .\nas for th to decide the response . And since we have a finite number of constructions that we can deal with , we could have a finite number of nodes .\nOK . Mm - hmm .\nSay , if we had to y deal with arbitrary language , it wouldn't make any sense to do that , because there 'd be no way to generate the nodes for every possible sentence .\nMm - hmm .\nBut since we can only deal with a finite amount of stuff\nSo , basically , the idea is to f to feed the output of that belief - net into another belief - net .\nYeah , so basically take these three things and then put them into another belief - net .\nBut , why  why  why only those three ? Why not the whol\nWell , I mean , d For the Where - Is question . So we 'd have a node for the Where - Is question .\nYeah . But we believe that all the decision nodes are  can be relevant for the Where - Is , and the Where  How - do - I - get - to or the Tell - me - something - about .\nYou can come in if you want .\nYes , it is allowed .\nAs long as y you 're not wearing your h your h headphones . Well , I do I  See , I don't know if this is a  good idea or not . I 'm just throwing it out . But uh , it seems like we could have  I mea or uh we could put all of the all of the r information that could also be relevant  into the Where - Is node answer\nMm - hmm . Yep .\nnode thing stuff . And uh\nOK .\nI mean  Let 's not forget we 're gonna get some very strong  input from  these sub dis from these discourse things , right ? So . \" Tell me the location of X . \" Nuh ? Or \" Where is X located at ? \"\nWe u\nNuh ?\nYeah , I know , but the Bayes - net would be able to  The weights on the  on the nodes in the Bayes - net would be able to do all that ,", "topic_id": 0, "keywords": "bayes, situational, situations, observed, nodes", "dialogue_id": 31}, {"text": "Mm - hmm .\nwouldn't it ? Here 's a k Oh ! Oh , I 'll wait until you 're  plugged in . Oh , don't sit there . Sit here . You know how you don't like that one . It 's OK . That 's the weird one . That 's the one that 's painful . That hurts . It hurts so bad . I 'm h I 'm happy that they 're recording that . That headphone . The headphone  that you have to put on backwards , with the little  little thing  and the little  little foam block on it ? It 's a painful , painful microphone .\nI think it 's th called \" the Crown \" .\nThe crown ?\nWhat ?\nYeah , versus \" the Sony \" .\nThe Crown ? Is that the actual name ? OK .\nMm - hmm . The manufacturer .\nI don't see a manufacturer on it .\nYou w\nOh , wait , here it is . h This thingy . Yeah , it 's \" The Crown \" . The crown of pain !\nYes .\nYou 're on - line ?\nAre you  are your mike o Is your mike on ?\nIndeed .\nOK . So you 've been working with these guys ? You know what 's going on ?\nYes , I have . And , I do . Yeah , alright . s So where are we ?\nExcellent !\nWe 're discussing this .\nI don't think it can handle French , but anyway .\nSo . Assume we have something coming in . A person says , \" Where is X ? \" , and we get a certain  We have a Situation vector and a User vector and everything is fine ? An - an and  and our  and our\nDid you just sti Did you just stick the m the  the  the microphone actually in the tea ?\nNo .\nAnd , um ,\nI 'm not drinking tea . What are you talking about ?\nOh , yeah . Sorry .\nlet 's just assume our Bayes - net just has three decision nodes for the time being . These three , he wants to know something about it , he wants to know where it is , he wants to go there .\nIn terms of , these would be wha how we would answer the question Where - Is , right ? We u This is  i That 's what you s it seemed like , explained it to me earlier\nYeah , but , mmm .\nw We  we 're  we wanna know how to answer the question \" Where is X ? \"\nYeah . No , I can  I can do the Timing node in here , too , and say \" OK . \"\nWell , yeah , but in the s uh , let 's just deal with the s the simple case of we 're not worrying about timing or anything . We just want to know how we should answer \" Where is X ? \"\nOK . And , um , OK , and , Go - there has two values , right ? , Go - there and not - Go - there . Let 's assume those are the posterior probabilities of that .\nMm - hmm .\nInfo - on has True or False and Location . So , he wants to know something about it , and he wants to know something  he wants to know Where - it - is ,\nExcuse me .\nhas these values . And , um ,\nOh , I see why we can't do that .\nAnd , um , in this case we would probably all agree that he wants to go there . Our belief - net thinks he wants to go there ,\nYeah .\nright ?\nMm - hmm .\nIn the , uh , whatever , if we have something like this here , and this like that and maybe here also some\nYou should probably  make them out of  Yeah .\nsomething like that ,\nWell , it\nthen we would guess , \" Aha ! He , our belief - net ,  has s stronger beliefs that he wants to know where it is , than actually wants to go  there . \" Right ?\nThat it  Doesn't this assume , though , that they 're evenly weighted ?\nTrue .\nLike  I guess they are evenly weighted .\nThe different decision nodes , you mean ?\nYeah , the Go - there , the Info - on , and the Location ?\nWell , d yeah , this is making the assumption . Yes .\nLike\nWhat do you mean by \" differently weighted \" ? They don't feed into anything really anymore .\nBut I mean , why do we\nOr I jus\nIf we trusted the Go - there node more th much more than we trusted the other ones , then we would conclude , even in this situation , that he wanted to go there .\nLe\nSo , in that sense , we weight them equally right now .\nOK . Makes sense . Yeah . But\nSo the But I guess the k the question  that I was as er wondering or maybe Robert was proposing to me is  How do we d make the decision on  as to  which one to listen to ?\nYeah , so , the final d decision is the combination of these three . So again , it 's  it 's some kind of , uh\nBayes - net .\nYeah , sure .\nOK so , then , the question i So then my question is t to you then , would be  So is the only r reason we can make all these smaller Bayes - nets , because we know we can only deal with a finite set of constructions ? Cuz oth If we 're just taking arbitrary language in , we couldn't have a node for every possible question , you know ?\nA decision node for every possible question , you mean ?\nWell , I  like , in the case of  Yeah . In the ca Any piece of language , we wouldn't be able to answer it with this system , b if we just h Cuz we wouldn't have the correct node . Basically , w what you 're s proposing is a n Where - Is node , right ?\nYeah .\nAnd  and if we  And if someone  says , you know , uh , something in Mandarin to the system , we 'd - wouldn't know which node to look at to answer that question ,\nSo is  Yeah . Yeah .\nright ?\nMmm ?\nSo , but  but if we have a finite  What ?\nI don't see your point . What  what  what I am thinking , or what we 're about to propose here is we 're always gonna get the whole list of values and their posterior probabilities . And now we need an expert system or belief - net or something that interprets that , that looks at all the values and says , \" The winner is Timing . Now , go there . \" \" Uh , go there , Timing , now . \" Or , \" The winner is Info - on , Function - Off . \" So , he wants to know  something about it , and what it does . Nuh ? Uh , regardless of  of  of the input . Wh - Regardle\nYeah , but But how does the expert  but how does the expert system know  how who which one to declare the winner , if it doesn't know the question it is , and how that question should be answered ?\nBased on the k what the question was , so what the discourse , the ontology , the situation and the user model gave us , we came up with these values for these decisions .\nYeah I know . But how do we weight what we get out ? As , which one i Which ones are important ? So my i So , if we were to it with a Bayes - net , we 'd have to have a node  for every question that we knew how to deal with , that would take all of the inputs and weight them appropriately for that question .\nMm - hmm .\nDoes that make sense ? Yay , nay ?\nUm , I mean , are you saying that , what happens if you try to scale this up to the situation , or are we just dealing with arbitrary language ?\nWe\nIs that your point ?\nWell , no . I  I guess my question is , Is the reason that we can make a node f or  OK . So , lemme see if I 'm confused . Are we going to make a node for every question ? Does that make sense ?\nFor every question ?\nOr not .\nLike\nEvery construction .\nHmm . I don't  Not necessarily , I would think . I mean , it 's not based on constructions , it 's based on things like , uh , there 's gonna be a node for Go - there or not , and there 's gonna be a node for Enter , View , Approach .\nWel W OK . So , someone asked a question .\nYeah .\nHow do we decide how to answer it ?\nWell , look at  look  Face yourself with this pr question . You get this  You 'll have  y This is what you get . And now you have to make a decision . What do we think ? What does this tell us ? And not knowing what was asked , and what happened , and whether the person was a tourist or a local , because all of these factors have presumably already gone into making these posterior probabilities . What  what we need is a  just a mechanism that says , \" Aha ! There is  \"\nYeah . I just don't think a \" winner - take - all \" type of thing is the\nI mean , in general , like , we won't just have those three , right ? We 'll have , uh , like , many , many nodes . So we have to , like  So that it 's no longer possible to just look at the nodes themselves and figure out what the person is trying to say .\nYep . Because there are interdependencies , right ? The uh  Uh , no . So if  if for example , the Go - there posterior possibility is so high , um , uh , w if it 's  if it has reached  reached a certain height , then all of this becomes irrelevant . So . If  even if  if the function or the history or something is scoring pretty good on the true node , true value\nWel I don't know about that , cuz that would suggest that  I mean\nHe wants to go there and know something about it ?\nDo they have to be mutual Yeah . Do they have to be mutually exclusive ?\nI think to some extent they are . Or maybe they 're not .\nCuz I , uh  The way you describe what they meant , they weren't mutu uh , they didn't seem mutually exclusive to me .\nWell , if he doesn't want to go there , even if the Enter posterior proba So .\nWel\nGo - there is No . Enter is High , and Info - on is High .\nWell , yeah , just out of the other three , though , that you had in the\nHmm ?\nthose three nodes . The - d They didn't seem like they were mutually exclusive .\nNo , there 's  No . But  It 's through the\nSo th s so , yeah , but some  So , some things would drop out , and some things would still be important .\nMm - hmm .\nBut I guess what 's confusing me is , if we have a Bayes - net to deal w another Bayes - net to deal with this stuff ,\nMm - hmm .\nyou know , uh , is the only reason  OK , so , I guess , if we have a Ba - another Bayes - net to deal with this stuff , the only r reason  we can design it is cuz we know what each question is asking ?\nYeah . I think that 's true .\nAnd then , so , the only reason  way we would know what question he 's asking is based upon  Oh , so if  Let 's say I had a construction parser , and I plug this in , I would know what each construction  the communicative intent of the construction was\nMm - hmm .\nand so then I would know how to weight the nodes appropriately , in response . So no matter what they said , if I could map it onto a Where - Is construction , I could say , \" ah !\nGe Mm - hmm .\nwell the the intent , here , was Where - Is \" ,\nOK , right .\nand I could look at those .\nYeah . Yes , I mean . Sure . You do need to know  I mean , to have that kind of information .\nHmm . Yeah , I 'm also agreeing that  a simple pru  Take the ones where we have a clear winner . Forget about the ones where it 's all sort of middle ground . Prune those out and just hand over the ones where we have a winner . Yeah , because that would be the easiest way . We just compose as an output an XML mes  message that says . \" Go there  now . \" \" Enter historical information . \" And not care whether that 's consistent with anything . Right ? But in this case if we say , \" definitely he doesn't want to go there . He just wants to know where it is . \" or let 's call this  this \" Look - At - H \" He wants to know something about the history of . So he said , \" Tell me something about the history of that . \" Now , the e But for some reason the Endpoint - Approach gets a really high score ,  too . We can't expect this to be sort of at O point  three , three , three , O point , three , three , three , O point , three , three , three . Right ? Somebody needs to zap that . You know ? Or know  There needs to be some knowledge that\nWe  Yeah , but , the Bayes - net that would merge  I just realized that I had my hand in between my mouth and my micr er , my and my microphone . So then , the Bayes - net that would merge there , that would make the decision between Go - there , Info - on , and Location , would have a node to tell you which one of those three you wanted , and based upon that node , then you would look at the other stuff .\nYep . Yep .\nI mean , it i Does that make sense ?\nYep . It 's sort of one of those , that 's  It 's more like a decision tree , if  if you want . You first look o at the lowball ones ,\nYeah , i\nand then\nYeah , I didn't intend to say that every possible  OK . There was a confusion there , k I didn't intend to say every possible thing should go into the Bayes - net , because some of the things aren't relevant in the Bayes - net for a specific question . Like the Endpoint is not necessarily relevant in the Bayes - net for Where - Is until after you 've decided whether you wanna go there or not .\nMm - hmm .\nRight .\nShow us the way , Bhaskara .\nI guess the other thing is that um , yeah . I mean , when you 're asked a specific question and you don't even  Like , if you 're asked a Where - Is question , you may not even look  like , ask for the posterior probability of the , uh , EVA node , right ? Cuz , that 's what  I mean , in the Bayes - net you always ask for the posterior probability of a specific node . So , I mean , you may not even bother to compute things you don't need .\nUm . Aren't we always computing all ?\nNo . You can compute , uh , the posterior probability of one subset of the nodes , given some other nodes , but totally ignore some other nodes , also . Basically , things you ignore get marginalized over .\nYeah , but that 's  that 's just shifting the problem . Then you would have to make a decision ,\nYeah . So you have to make\n\" OK , if it 's a Where - Is question , which decision nodes do I query ? \"\nYeah . Yes . But I would think that 's what you want to do .\nThat 's un\nRight ?\nMmm .\nWell , eventually , you still have to pick out which ones you look at .\nYeah .\nSo it 's pretty much the same problem ,\nYeah  it 's  it 's  it 's apples and oranges .\nisn't it ?\nNuh ? I mean , maybe it does make a difference in terms of performance , computational time .\nMm - hmm .\nSo either you always have it compute all the posterior possibilities for all the values for all nodes , and then prune the ones you think that are irrelevant ,\nMmm .\nor you just make a p @ @  a priori estimate of what you think might be relevant and query those .\nYeah .\nSo basically , you 'd have a decision tree  query ,  Go - there . If k if that 's false , query this one . If that 's true , query that one . And just basically do a binary search through the  ?\nI don't know if it would necessarily be that , uh , complicated . But , uh  I mean , it w\nWell , in the case of Go - there , it would be . In the case  Cuz if you needed an If y If Go - there was true , you 'd wanna know what endpoint was . And if it was false , you 'd wanna d look at either Lo - Income Info - on or History .\nYeah . That 's true , I guess . Yeah ,  so , in a way you would have that .\nAlso , I 'm somewhat boggled by that Hugin software .\nOK , why 's that ?\nI can't figure out how to get the probabilities into it . Like , I 'd look at\nMm - hmm .", "topic_id": 1, "keywords": "microphone, headphone, crown, sony, recording", "dialogue_id": 31}, {"text": "It 's somewha It 's boggling me .\nOK . Alright . Well , hopefully it 's  fixable .\nJu\nIt 's  there 's a\nOh yeah , yeah . I d I just think I haven't figured out what  the terms in Hugin mean , versus what Java Bayes terms are .\nOK .\nUm , by the way , are  Do we know whether Jerry and Nancy are coming ?\nSo we can figure this out .\nOr  ?\nThey should come when they 're done their stuff , basically , whenever that is . So .\nWhat d what do they need to do left ?\nUm , I guess , Jerry needs to enter marks , but I don't know if he 's gonna do that now or later . But , uh , if he 's gonna enter marks , it 's gonna take him awhile , I guess , and he won't be here .\nAnd what 's Nancy doing ?\nNancy ? Um , she was sorta finishing up the , uh , calculation of marks and assigning of grades , but I don't know if she should be here . Well  or , she should be free after that , so  assuming she 's coming to this meeting . I don't know if she knows about it .\nShe 's on the email list , right ?\nIs she ? OK .\nMm - hmm . OK . Because basically , what  where we also have decided , prior to this meeting is that we would have a rerun of the three of us sitting together\nOK .\nsometime  this week  again\nOK .\nand finish up the , uh , values of this . So we have , uh  Believe it or not , we have all the bottom ones here .\nWell , I\nYou added a bunch of  nodes , for  ?\nYep . We  we  we have  Actually what we have is this line .\nOK .\nRight ?\nUh , what do the , uh , structures do ?\nHmm ?\nSo the  the  the  For instance , this Location node 's got two inputs ,\nFour inputs .\nHmm .\nthat one you\nFour .\nThose are  The bottom things are inputs , also .\nOh , I see .\nYeah .\nOK , that was OK . That makes a lot more sense to me now .\nYep .\nCuz I thought it was like , that one in Stuart 's book about , you know , the\nAlarm in the dog ?\nU Yeah .\nYeah .\nOr the earthquake and the alarm .\nSorry . Yeah , I 'm confusing two .\nYeah , there 's a dog one , too , but that 's in Java Bayes ,\nRight .\nisn't it ?\nMaybe .\nBut there 's something about bowel problems or something with the dog .\nYeah .\nAnd we have all the top ones , all the ones to which no arrows are pointing . What we 're missing are the  these , where arrows are pointing , where we 're combining top ones . So , we have to come up with values for this , and this , this , this , and so forth . And maybe just fiddle around with it a little bit more . And , um . And then it 's just , uh , edges , many of edges . And , um , we won't  meet next Monday . So .\nCuz of Memorial Day ?\nWe 'll meet next Tuesday , I guess .\nYep . Yeah .\nWhen 's Jerry leaving for  Italia ?\nOn  on Friday .\nWhich Friday ?\nThis  this Friday .\nOK .\nOh . This Friday ?\nUgh .\nThis Friday .\nAs in , four days ?\nYep .\nOr , three days ?\nIs he  How long is he gone for ?\nTwo weeks .\nItaly , huh ? What 's , uh  what 's there ?\nWell , it 's a country . Buildings . People .\nPasta .\nBut it 's not a conference or anything .\nHmm ?\nHe 's just visiting .\nRight . Just visiting .\nVacation .\nIt 's a pretty nice place , in my brief , uh , encounter with it .\nDo you guys  Oh , yeah . So . Part of what we actually want to do is sort of schedule out what we want to surprise him with when  when he comes back . Um , so\nOh , I think we should disappoint him .\nYeah ? You  or have a finished construction parser and a working belief - net , and uh\nThat wouldn't be disappointing . I think w we should do absolutely no work for the two weeks that he 's gone .\nWell , that 's actually what I had planned , personally . I had  I  I had sort of scheduled out in my mind that you guys do a lot of work , and I do nothing . And then , I sort of\nOh , yeah , that sounds good , too .\nsort of bask in  in your glory . But , uh , i do you guys have any vacation plans , because I myself am going to be , um , gone , but this is actually not really important . Just this weekend we 're going camping .\nYeah , I 'm wanna be this  gone this weekend , too .\nAh . But we 're all going to be here on Tuesday again ? Looks like it ?\nYeah .\nOK , then . Let 's meet  meet again next Tuesday . And , um , finish up this Bayes - net . And once we have finished it , I guess we can , um  and that 's going to be more just you and me , because Bhaskara is doing probabilistic , recursive , structured , object - oriented , uh ,\nKilling machines !\nreasoning machines .\nYes .\nAnd , um\nKilling , reasoning . What 's the difference ?\nWait . So you 're saying , next Tuesday , is it the whole group meeting , or just us three working on it , or  or  ?\nUh . The whole group . And we present our results , our final ,\nOK .\ndefinite\nSo , when you were saying we  need to do a re - run of , like\nh What ?\nWhat  Like , just working out the rest of the\nYeah . We should do this th the upcoming days .\nThis week ?\nSo , this week , yeah .\nWhen you say , \" the whole group \" , you mean  the four of us , and Keith ?\nOK .\nAnd , Ami might .\nAmi might be here , and it 's possible that Nancy 'll be here ?\nYep .\nSo , yeah .\nBecause , th you know , once we have the belief - net done\nYou 're just gonna have to explain it to me , then , on Tuesday , how it 's all gonna work out . You know .\nWe will . OK . Because then , once we have it sort of up and running , then we can start you know , defining the interfaces and then feed stuff into it and get stuff out of it , and then hook it up to some fake construction parser and\nThat you will have in about nine months or so .\nYeah .\nYeah .\nAnd , um ,\nThe first bad version 'll be done in nine months .", "topic_id": 2, "keywords": "bayes, nancy, java, jerry, meeting", "dialogue_id": 31}, {"text": "Yeah , I can worry about the ontology interface and you can  Keith can worry about the discourse . I mean , this is pretty  Um , I mean , I  I  I hope everybody uh knows that these are just going to be uh dummy values , right ?\nWhich\nwhere the\nWhich ones ?\nS so  so if the endpoint  if the Go - there is Yes and No , then Go - there - discourse will just be fifty - fifty . Right ?\nUm , what do you mean ? If the Go - there says No , then the Go - there is\nI don't get it .\nI don't u understand .\nUm .\nLike , the Go - there depends on all those four things .\nYep .\nYeah .\nBut , what are the values of the Go - there - discourse ?\nWell , it depends on the situation . If the discourse is strongly indicating that\nYeah , but , uh , we have no discourse input .\nOh , I see . The d See , uh , specifically in our situation , D and O are gonna be , uh  Yeah . Sure . So , whatever .\nSo , so far we have  Is that what the Keith node is ?\nYep .\nOK . And you 're taking it out ?  for now ?\nWell , this is D\nOr  ?\nOK , this , I can  I can get it in here .\nAll the D 's are\nI can get it in here , so th We have the , uh , um , sk let 's  let 's call it \" Keith - Johno\nJohno ?\nnode \" . There is an H  somewhere printed .\nThere you go .\nYeah . People have the same problem with my name .\nYeah .\nOops .\nAnd , um ,\nDoes th th does the H go b before the A or after the A ?\nOh , in my name ? Before the A .\nYeah . OK , good . Cuz you kn When you said people have the same problem , I thought  Cuz my H goes after the uh e e e the v\nPeople have the inverse problem with my name .\nOK . I always have to check , every time y I send you an email ,  a past email of yours ,  to make sure I 'm spelling your name correctly .\nYeah . That 's good .\nI worry about you .\nI appreciate that .\nBut , when you abbreviate yourself as the \" Basman \" , you don't use any H 's .\n\" Basman \" ? Yeah , it 's because of the chessplayer named Michael Basman , who is my hero .\nOK .\nYou 're a geek . It 's O K . I\nOK .\nHow do you pronou How do you pronounce your name ?\nEva .\nEva ?\nNot Eva ?\nYeah .\nWhat if I were  What if I were to call you Eva ?\nI 'd probably still respond to it . I 've had people call me Eva , but I don't know .\nNo , not just Eva , Eva . Like if I u take the V and s pronounce it like it was a German V ?\nWhich is F .\nYeah .\nUm , no idea then .\nVoiced .\nWhat ?\nIt sounds like an F .\nI\nThere 's also an F in German ,\nOK .\nWell , it 's just the difference between voiced and unvoiced .\nwhich is why I  Yeah .\nOK .\nAs long as that 's O K .\nUm .\nI mean , I might slip out and say it accidentally . That 's all I 'm saying .\nThat 's fine .", "topic_id": 3, "keywords": "discourse, ontology, interface, things, values", "dialogue_id": 31}, {"text": "Yeah . It doesn't matter what those nodes are , anyway , because we 'll just make the weights \" zero \" for now .\nYep . We 'll make them zero for now , because it  who  who knows what they come up with , what 's gonna come in there . OK . And , um , then should we start on Thursday ?\nOK .\nAnd not meet tomorrow ?\nSure .\nOK . I 'll send an email , make a time suggestion .\nWait , maybe it 's OK , so that  that  that we can  that we have one node per construction . Cuz even in people , like , they don't know what you 're talking about if you 're using some sort of strange construction .\nYeah , they would still c sort of get the closest , best fit .\nWell , yeah , but I mean , the  uh , I mean , that 's what the construction parser would do .\nMm - hmm .\nUh , I mean , if you said something completely arbitrary , it would f find the closest construction ,\nOK .\nright ? But if you said something that was completel er  h theoretically the construction parser would do that  But if you said something for which there was no construction whatsoever , n people wouldn't have any idea what you were talking about .\nMm - hmm .\nLike \" Bus dog fried egg . \" I mean . You know .\nOr , if even something Chinese , for example .\nOr , something in Mandarin , yeah . Or Cantonese , as the case may be . What do you think about that , Bhaskara ?\nI mean  Well  But how many constructions do  could we possibly have  nodes for ?\nIn this system , or in r\nNo , we . Like , when people do this kind of thing .\nOh , when p How many constructions do people have ?\nYeah .\nI have not  the slightest idea .\nIs it considered to be like in  are they considered to be like very , uh , sort of s abstract things ?\nEvery noun is a construction .\nOK , so it 's like in the  thousands .\nThe  Yeah . Any  any form - meaning pair , to my understanding , is a construction .\nOK .\nSo .\nAnd form u starts at the level of noun  Or actually , maybe even sounds .\nPhoneme . Yep .\nYeah . And goes upwards until you get the ditransitive construction .\nS\nAnd then , of course , the c I guess , maybe there can be the  Can there be combinations of the dit\nDiscourse - level  constructions .\nYeah . The \" giving a speech \" construction ,\nRhetorical constructions .\nYes .\nYeah . But , I mean , you know , you can probably count  count the ways . I mean .\nIt 's probab Yeah , I would s definitely say it 's finite .\nYeah .\nAnd at least in compilers , that 's all that really matters , as long as your analysis is finite .\nHow 's that ? {nonvocalsound} How it can be finite , again ?\nNah , I can't think of a way it would be infinite .\nWell , you can come up with new constructions .\nYeah .  If the  if your  if your brain was totally non - deterministic , then perhaps there 's a way to get , uh , infin an infinite number of constructions that you 'd have to worry about .\nBut , I mean , in the {nonvocalsound} practical sense , it 's impossible .\nRight . Cuz if we have a fixed number of neurons  ?\nYeah .\nSo the best - case scenario would be the number of constructions  or , the worst - case scenario is the number of constructions equals the number of neurons .\nWell , two to the power of the number of neurons .\nRight . But still finite .\nOK .\nNo , wait . Not necessarily , is it ? We can end the  meeting . I just  Can't you use different var different levels of activation ? across , uh  lots of different neurons , to specify different values ?\nMm - hmm .\nUm , yeah , but there 's , like , a certain level of\nThere 's a bandwidth issue ,\nBandw - Yeah , so you can't do better than something .\nright ? Yeah .\nTurn off the mikes . Otherwise it gets really tough for the tr", "topic_id": 4, "keywords": "constructions, nodes, construction, parser, node", "dialogue_id": 31}, {"text": "Yeah , we had a long discussion about how much w how easy we want to make it for people to bleep things out . So  Morgan wants to make it hard .\nIt  it doesn't\nDid  did  did it  ? I didn't even check yesterday whether it was moving .\nIt didn't move yesterday either when I started it .\nSo .\nSo I don't know if it doesn't like both of us\nChannel three ? Channel three ?\nYou know , I discovered something yesterday on these , um , wireless ones .\nChannel two .\nMm - hmm ?\nYou can tell if it 's picking up  breath noise and stuff .\nYeah , it has a little indicator on it  on the AF .\nMm - hmm . So if you  yeah , if you breathe under  breathe and then you see AF go off , then you know  it 's p picking up your mouth noise .\nOh , that 's good . Cuz we have a lot of breath noises .\nYep . Test .\nIn fact , if you listen to just the channels of people not talking , it 's like \" @ @ \" . It 's very disgust\nWhat ? Did you see Hannibal recently or something ?\nSorry . Exactly . It 's very disconcerting . OK . So , um ,\nI was gonna try to get out of here , like , in half an hour , um , cuz I really appreciate people coming , and  the main thing that I was gonna ask people to help with today is  to give input on what kinds of database format we should  use in starting to link up things like word transcripts and annotations of word transcripts , so anything that transcribers or discourse coders or whatever put in the signal ,  with time - marks for , like , words and phone boundaries and all the stuff we get out of the forced alignments and the recognizer . So , we have this , um  I think a starting point is clearly the  the channelized  output of Dave Gelbart 's program , which Don brought a copy of ,\nYeah . Yeah , I 'm  I 'm familiar with that . I mean , we  I sort of already have developed an XML format for this sort of stuff .\num , which\nCan I see it ?\nAnd so the only question  is it the sort of thing that you want to use or not ? Have you looked at that ? I mean , I had a web page up .\nRight . So ,\nSo\nI actually mostly need to be able to link up , or  I it 's  it 's a question both of what the representation is and\nYou mean , this  I guess I am gonna be standing up and drawing on the board .\nOK , yeah . So you should , definitely .\nUm , so  so it definitely had that as a concept . So tha it has a single time - line ,\nMm - hmm .\nand then you can have lots of different sections , each of which have I Ds attached to it , and then you can refer from other sections to those I Ds , if you want to . So that , um  so that you start with  with a time - line tag . \" Time - line \" . And then you have a bunch of times . I don't e I don't remember exactly what my notation was ,\nOh , I remember seeing an example of this .\nbut it\nRight , right .\nYeah .\nYeah , \" T equals one point three two \" , uh  And then I  I also had optional things like accuracy , and then \" ID equals T one , uh , one seven \" . And then , {nonvocalsound} I also wanted to  to be i to be able to not specify specifically what the time was and just have a stamp .\nRight .\nYeah , so these are arbitrary , assigned by a program , not  not by a user . So you have a whole bunch of those . And then somewhere la further down you might have something like an utterance tag which has \" start equals T - seventeen , end equals T - eighteen \" . So what that 's saying is , we know it starts at this particular time . We don't know when it ends .\nOK .\nRight ? But it ends at this T - eighteen , which may be somewhere else . We say there 's another utterance . We don't know what the t time actually is but we know that it 's the same time as this end time .\nMmm .\nYou know , thirty - eight , whatever you want .\nSo you 're essentially defining a lattice .\nOK . Yes , exactly .\nYeah .\nAnd then , uh  and then these also have I Ds . Right ? So you could  you could have some sort of other  other tag later in the file that would be something like , um , oh , I don't know ,  uh , {nonvocalsound} \" noise - type equals {nonvocalsound} door - slam \" . You know ? And then , uh , {nonvocalsound} you could either say \" time equals a particular time - mark \" or you could do other sorts of references . So  or  or you might have a prosody  \" Prosody \" right ? D ? T ? D ? T ? T ?\nIt 's an O instead of an I , but the D is good .\nYou like the D ? That 's a good D .\nYeah .\nUm , you know , so you could have some sort of type here , and then you could have , um  the utterance that it 's referring to could be U - seventeen or something like that .\nOK . So , I mean , that seems  that seems g great for all of the encoding of things with time and ,\nOh , well .\num  I  I guess my question is more , uh , what d what do you do with , say , a forced alignment ?\nHow - how\nI mean you 've got all these phone labels , and what do you do if you  just conceptually , if you get , um , transcriptions where the words are staying but the time boundaries are changing , cuz you 've got a new recognition output , or s sort of  what 's the , um , sequence of going from the waveforms that stay the same , the transcripts that may or may not change , and then the utterance which  where the time boundaries that may or may not change  ?\nOh , that 's  That 's actually very nicely handled here because you could  you could  all you 'd have to change is the ,  um , time - stamps in the time - line without  without , uh , changing the I Ds .\nUm . And you 'd be able to propagate all of the  the information ?\nRight . That 's , the who that 's why you do that extra level of indirection . So that you can just change the time - line .\nExcept the time - line is gonna be huge . If you say\nYes .\nYeah ,\nsuppose you have a phone - level alignment .\nyeah , especially at the phone - level .\nYou 'd have  you 'd have\nThe  we  we have phone - level backtraces .\nYeah , this  I don't think I would do this for phone - level . I think for phone - level you want to use some sort of binary representation\nUm\nbecause it 'll be too dense otherwise .\nOK . So , if you were doing that and you had this sort of companion , uh , thing that gets called up for phone - level , uh , what would that look like ?\nWhy\nI would use just an existing  an existing way of doing it .\nHow would you  ?\nMmm . But  but why not use it for phone - level ?\nH h\nIt 's just a matter of  it 's just a matter of it being bigger . But if you have  you know , barring memory limitations , or uh  I w I mean this is still the m\nIt 's parsing limitations . I don't want to have this text file that you have to read in the whole thing to do something very simple for .\nOh , no . You would use it only  for  purposes where you actually want the phone - level information , I 'd imagine .\nSo you could have some file that configures how much information you want in your  in your XML or something .\nRight . I mean , you 'd  y\nUm ,\nYou\nI  I am imagining you 'd have multiple versions of this depending on the information that you want .\ncuz th it does get very bush with  Right .\nUm , I 'm just  what I 'm wondering is whether  I think for word - level , this would be OK .\nYeah .\nFor word - level , it 's alright .\nYeah . Definitely .\nMm - hmm .\nFor lower than word - level , you 're talking about so much data that I just  I don't know . I don't know if that", "topic_id": 0, "keywords": "channel, channels, channelized, noise, noises", "dialogue_id": 32}, {"text": "I mean , we actually have  So , one thing that Don is doing , is we 're  we 're running  For every frame , you get a pitch value ,\nLattices are big , too .\nand not only one pitch value but different kinds of pitch values\nYeah , I mean , for something like that I would use P - file\ndepending on\nor  or any frame - level stuff I would use P - file .\nMeaning  ?\nUh , that 's a  well , or something like it . It 's ICS uh , ICSI has a format for frame - level representation of features . Um .\nOK . That you could call  that you would tie into this representation with like an ID .\nRight . Right . Or  or there 's a  there 's a particular way in XML to refer to external resources .\nAnd  OK .\nSo you would say \" refer to this external file \" . Um , so that external file wouldn't be in\nSo that might  that might work .\nBut what  what 's the advantage of doing that versus just putting it into this format ?\nMore compact , which I think is  is better .\nUh - huh .\nI mean , if you did it at this\nI mean these are long meetings and with  for every frame ,\nYou don't want to do it with that  Anything at frame - level you had better encode binary\num\nor it 's gonna be really painful .\nOr you just compre I mean , I like text formats . Um , b you can always , uh , G - zip them , and , um , you know , c decompress them on the fly if y if space is really a concern .\nYeah , I was thi I was thinking the advantage is that we can share this with other people .\nWell , but if you 're talking about one per frame , you 're talking about gigabyte - size files . You 're gonna actually run out of space in your filesystem for one file .\nThese are big files . These are really  I mean\nRight ? Because you have a two - gigabyte limit on most O Ss .\nRight , OK . I would say  OK , so frame - level is probably not a good idea . But for phone - level stuff it 's perfectly\nAnd th it 's\nLike phones , or syllables , or anything like that .\nPhones are every five frames though , so . Or something like that .\nBut  but  but most of the frames are actually not speech . So , you know , people don't  v Look at it , words times the average  The average number of phones in an English word is , I don't know ,  five maybe ?\nYeah , but we actually\nSo , look at it , t number of words times five . That 's not  that not\nOh , so you mean pause phones take up a lot of the  long pause phones .\nExactly .\nYep .\nYeah .\nYeah . OK . That 's true . But you do have to keep them in there . Y yeah .\nSo I think it  it 's debatable whether you want to do phone - level in the same thing .\nOK .\nBut I think , a anything at frame - level , even P - file , is too verbose .\nOK . So\nI would use something tighter than P - files .\nDo you  Are you familiar with it ?\nSo .\nI haven't seen this particular format ,\nI mean , I 've  I 've used them .\nbut\nI don't know what their structure is .\nOK .\nI 've forgot what the str\nBut , wait a minute , P - file for each frame is storing a vector of cepstral or PLP values ,\nIt 's whatever you want , actually .\nright ? Right .\nSo that  what 's nice about the P - file  It  i Built into it is the concept of  frames , utterances , sentences , that sort of thing , that structure . And then also attached to it is an arbitrary vector of values . And it can take different types .\nOh .\nSo it  th they don't all have to be floats . You know , you can have integers and you can have doubles , and all that sort of stuff .\nSo that  that sounds  that sounds about what I w\nUm . Right ? And it has a header  it has a header format that  describes it  to some extent . So , the only problem with it is it 's actually storing the  utterance numbers and the  frame numbers in the file , even though they 're always sequential . And so it does waste a lot of space .\nHmm .\nBut it 's still a lot tighter than  than ASCII . And we have a lot of tools already to deal with it .\nYou do ? OK . Is there some documentation on this somewhere ?\nYeah , there 's a ton of it . Man - pages and , uh , source code , and me .\nOK , great . So , I mean , that sounds good . I  I was just looking for something  I 'm not a database person , but something sort of standard enough that , you know , if we start using this we can give it out , other people can work on it ,\nYeah , it 's not standard .\nor   Is it  ?\nI mean , it 's something that we developed at ICSI . But , uh\nBut it 's  been used here\nBut it 's been used here\nand people 've\nand  and , you know , we have a  well - configured system that you can distribute for free , and\nI mean , it must be the equivalent of whatever you guys used to store feat your computed features in , right ?\nOK .\nYeah , th we have  Actually , we  we use a generalization of the  the Sphere format .\nMmm .\nUm , but  Yeah , so there is something like that but it 's , um , probably not as sophist\nWell , what does H T K do for features ?\nAnd I think there 's\nOr does it even have a concept of features ?\nThey ha it has its own  I mean , Entropic has their own feature format that 's called , like , S - SD or some so SF or something like that .\nYeah .\nI 'm just wondering , would it be worth while to use that instead ?\nYeah .\nHmm ?\nYeah . Th - this is exactly the kind of decision  It 's just whatever\nBut , I mean , people don't typically share this kind of stuff , right ?\nRight .\nThey generate their own .\nI mean  Yeah .\nActually , I  I just  you know , we  we 've done this stuff on prosodics and three or four places have asked for those prosodic files , and we just have an ASCII , uh , output of frame - by - frame .\nAh , right .\nWhich is fine , but it gets unwieldy to go in and  and query these files with really huge files .\nRight .\nI mean , we could do it . I was just thinking if there 's something that  where all the frame values are\nAnd a and again , if you have a  if you have a two - hour - long meeting , that 's gonna\nHmm ? They 're  they 're fair they 're quite large .\nYeah , I mean , they 'd be emo enormous .\nAnd these are for ten - minute Switchboard conversations ,\nRight .\nand  So it 's doable , it 's just that you can only store a feature vector at frame - by - frame and it doesn't have any kind of ,\nIs  is the sharing part of this a pretty important  consideration\num\nor does that just sort of , uh  a nice thing to have ?\nI  I don't know enough about what we 're gonna do with the data . But I thought it would be good to get something that we can  that other people can use or adopt for their own kinds of encoding . And just , I mean we have to use some we have to make some decision about what to do .\nYeah .\nAnd especially for the prosody work , what  what it ends up being is you get features from the signal , and of course those change every time your alignments change . So you re - run a recognizer , you want to recompute your features , um , and then keep the database up to date .\nRight .\nOr you change a word , or you change a  utterance boundary segment , which is gonna happen a lot . And so I wanted something where  all of this can be done in a elegant way and that if somebody wants to try something or compute something else , that it can be done flexibly . Um , it doesn't have to be pretty , it just has to be , you know , easy to use , and", "topic_id": 1, "keywords": "xml, formats, pitch, files, external", "dialogue_id": 32}, {"text": "Yeah , the other thing  We should look at ATLAS , the NIST thing ,\nOh .\nMmm .\nand see if they have anything at that level .\nUh\nI mean , I 'm not sure what to do about this with ATLAS , because they chose a different route . I chose something that  Th - there are sort of two choices . Your  your file format can know about  know that you 're talking about language  and speech , which is what I chose , and time , or your file format can just be a graph representation . And then the application has to impose the structure on top . So what it looked like ATLAS chose is , they chose the other way , which was their file format is just nodes and links , and you have to interpret what they mean yourself .\nAnd why did you not choose that type of approach ?\nUh , because I knew that we were doing speech , and I thought it was better if you 're looking at a raw file to be  t for the tags to say \" it 's an utterance \" , as opposed to the tag to say \" it 's a link \" .\nOK . OK .\nSo , but\nBut other than that , are they compatible ? I mean , you could sort of\nYeah , they 're reasonably compatible .\nI mean , you  you could\nYou could probably translate between them .\nYep .\nYeah , that 's w So ,\nSo , well , the other thing is if we choose to use ATLAS , which maybe we should just do , we should just throw this out before we invest a lot of time in it .\nOK . I don't  So this is what the meeting 's about ,\nYeah .\njust sort of how to  Um , cuz we need to come up with a database like this just to do our work . And I actually don't care , as long as it 's something useful to other people , what we choose .\nYeah .\nSo maybe it 's  maybe oth you know , if  if you have any idea of how to choose , cuz I don't .\nThe only thing  Yeah .\nDo they already have tools ?\nI mean , I  I chose this for a couple reasons . One of them is that it 's easy to parse . You don't need a full XML parser . It 's very easy to just write a Perl script  to parse it .\nAs long as uh each tag is on one line .\nExactly . Exactly . Which I always do .\nAnd you can have as much information in the tag as you want , right ?\nWell , I have it structured . Right ? So each type tag has only particular items that it can take .\nCan you  But you can add to those structures if you\nSure . If you have more information . So what  What NIST would say is that instead of doing this , you would say something like \" link {nonvocalsound} start equals , um , you know , some node ID ,\nYeah . So\nend equals some other node ID \" , and then \" type \" would be \" utterance \" .\nHmm .\nYou know , so it 's very similar .\nSo why would it be a  a waste to do it this way if it 's similar enough that we can always translate it ?\nIt probably wouldn't be a waste . It would mean that at some point if we wanted to switch , we 'd just have to translate everything .\nWrite a translator . But it se Since they are developing a big\nBut it  but that sounds\nBut that 's  I don't think that 's a big deal .\nAs long as it is\nthey 're developing a big infrastructure . And so it seems to me that if  if we want to use that , we might as well go directly to what they 're doing , rather than\nIf we want to  Do they already have something that 's  that would be useful for us in place ?\nYeah . See , that 's the question . I mean , how stable is their  Are they ready to go ,\nThe  I looked at it\nor  ?\nThe last time I looked at it was a while ago , probably a year ago , uh , when we first started talking about this .\nHmm .\nAnd at that time at least  it was still not very  complete . And so , specifically they didn't have any external format representation at that time . They just had the sort of conceptual  node  uh , annotated transcription graph , which I really liked . And that 's exactly what this stuff is based on . Since then , they 've developed their own external file format , which is , uh , you know , this sort of s this sort of thing . Um , and apparently they 've also developed a lot of tools , but I haven't looked at them . Maybe I should .\nWe should  we should find out .\nI mean , would the tools  would the tools run on something like this , if you can translate them anyway ?\nUm , th what would  would  would  what would worry me is that maybe we might miss a little detail\nIt 's a hassle\nI mean , that  I guess it 's a question that\nif\nuh , yeah .\nthat would make it very difficult to translate from one to the other .\nOK .\nI  I think if it 's conceptually close , and they already have or will have tools that everybody else will be using , I mean ,  it would be crazy to do something s you know , separate that\nOK .\nYeah , we might as well . Yep .\nYeah .\nSo I 'll  I 'll take a closer look at it .\nActually , so it 's  that  that would really be the question , is just what you would feel is in the long run the best thing .\nAnd  Right .\nCuz  once we start , sort of , doing this I don't  we don't actually have enough time to probably have to rehash it out again\nThe  Yep . The other thing  the other way that I sort of established this was as easy translation to and from the Transcriber format .\nand  s Right .\nUm ,\nRight .\nbut\nI mean , I like this . This is sort of intuitively easy to actually r read ,\nYep .\nas easy it could  as it could be . But , I suppose that  as long as they have a type here that specifies \" utt \" , um ,\nIt 's almost the same .\nit 's  yeah , close enough that\nThe  the  the  the point is  with this , though , is that you can't really add any supplementary information . Right ? So if you suddenly decide that you want\nYou have to make a different type .\nYeah . You 'd have to make a different type .\nSo  Well , if you look at it and  Um , I guess in my mind I don't know enough  Jane would know better ,  about the  types of annotations and  and  But I imagine that those are things that would  well , you guys mentioned this ,  that could span any  it could be in its own channel , it could span time boundaries of any type ,\nRight .\nit could be instantaneous , things like that . Um , and then from the recognition side we have backtraces at the phone - level .\nRight .\nIf  if it can handle that , it could handle states or whatever . And then at the prosody - level we have frame  sort of like cepstral feature files ,\nYep .\nuh , like these P - files or anything like that . And that 's sort of the world of things that I  And then we have the aligned channels , of course ,\nRight .\nIt seems to me you want to keep the frame - level stuff separate .\nand  Yeah .\nAnd then\nI  I definitely agree and I wanted to find actually a f a nicer format or a  maybe a more compact format than what we used before .\nRight .\nJust cuz you 've got  ten channels or whatever and two hours of a meeting . It 's  it 's a lot of\nHuge .\nNow  now how would you  how would you represent , um , multiple speakers in this framework ? Were  You would just represent them as\nUm ,\nYou would have like a speaker tag or something ?\nthere 's a spea speaker tag up at the top which identifies them and then each utt the way I had it is each turn or each utterance ,  I don't even remember now , had a speaker ID tag attached to it .\nMm - hmm . OK .\nAnd in this format you would have a different tag , which  which would , uh , be linked to the link . So  so somewhere else you would have another thing  that would be ,\nYeah .\num  Let 's see , would it be a node or a link ? Um  And so  so this one would have , um , an ID is link   link seventy - four or something like that .\nMm - hmm .\nAnd then somewhere up here you would have a link that  that , uh , you know , was referencing L - seventy - four and had speaker Adam .\nIs i ?\nYou know , or something like that .\nActually , it 's the channel , I think , that\nWell , channel or speaker or whatever .\nI mean , w yeah , channel is what the channelized output out\nIt doesn't\nThis isn't quite right .\nRight .\nI have to look at it again .\nYeah , but\nBut  but  so how in the NIST format do we express  a hierarchical relationship between , um , say , an utterance and the words within it ? So how do you  tell  that  these are the words that belong to that utterance ?\nUm , you would have another structure lower down than this that would be saying they 're all belonging to this ID .\nMm - hmm .\nSo each thing refers to the  utterance that it belongs to .\nRight . And then each utterance could refer to a turn ,\nSo it 's  it 's not hi it 's sort of bottom - up .\nand each turn could refer to something higher up .\nAnd what if you actually have  So right now what you have as utterance , um , the closest thing that comes out of the channelized is the stuff between the segment boundaries that the transcribers put in or that Thilo put in , which may or may not actually be , like , a s it 's usually not  um , the beginning and end of a sentence , say .\nWell , that 's why I didn't call it \" sentence \" .\nSo , right . Um , so it 's like a segment or something .\nYeah .\nSo , I mean , I assume this is possible , that if you have  someone annotates the punctuation or whatever when they transcribe , you can say , you know , from  for  from the c beginning of the sentence to the end of the sentence , from the annotations , this is a unit , even though it never actually  i It 's only a unit by virtue of the annotations  at the word - level .\nSure . I mean , so you would  you would have yet another tag .\nAnd then that would get a tag somehow .\nYou 'd have another tag which says this is of type \" sentence \" .\nOK . OK .\nAnd , what\nBut it 's just not overtly in the\nOK .\nUm , cuz this is exactly the kind of\nSo\nI think that should be  possible as long as the  But , uh , what I don't understand is where the  where in this type of file  that would be expressed .\nRight . You would have another tag somewhere . It 's  well , there 're two ways of doing it .\nS so it would just be floating before the sentence or floating after the sentence without a time - mark .\nYou could have some sort of link type  type equals \" sentence \" , and ID is \" S - whatever \" . And then lower down you could have an utterance . So the type is \" utterance \"  equals \" utt \" . And you could either say that  No . I don't know\nSo here 's the thing .\nI take that back .\nUm\nCan you  can you say that this is part of this ,\nSee , cuz it 's\nHhh .\nit 's\nYou would just have a r\nS\nor do you say this is part of this ? I think\nYou would refer up to the sentence .\nBut they 're\nWell , the thing\nthey 're actually overlapping each other , sort of .\nSo\nthe thing is that some something may be a part of one thing for one purpose and another thing of another purpose .\nRight .\nSo f\nYou have to have another type then , I guess .\ns Um , well , s let 's  let 's ta so let 's\nWell , I think I 'm  I think w I had better look at it again\nYeah .\nso\nbecause I  I 'm\nOK . OK .\ny So for instance @ @  sup\nThere 's one level  there 's one more level of indirection that I 'm forgetting .\nSuppose you have a word sequence and you have two different segmentations of that same word sequence . f Say , one segmentation is in terms of , um , you know , uh , sentences . And another segmentation is in terms of , um ,  I don't know ,  prosodic phrases . And let 's say that they don't  nest . So , you know , a prosodic phrase may cross two sentences or something .\nRight .\nI don't know if that 's true or not but  let 's as\nWell , it 's definitely true with the segment .\nRight .\nThat 's what I  exactly what I meant by the utterances versus the sentence could be sort of\nYeah . So , you want to be s you want to say this  this word is part of that sentence and this prosodic phrase .\nYeah .\nBut the phrase is not part of the sentence\nYeah .\nand neither is the sentence part of the phrase .\nRight .\nI I 'm pretty sure that you can do that , but I 'm forgetting the exact level of nesting .\nSo , you would have to have  two different pointers from the word up  one level up , one to the sent\nSo  so what you would end up having is a tag saying \" here 's a word , and it starts here and it ends here \" .\nRight .\nAnd then lower down you would say \" here 's a prosodic boundary and it has these words in it \" . And lower down you 'd have \" here 's a sentence ,\nRight .\nAn - Right .\nand it has these words in it \" .\nSo you would be able to go in and say , you know , \" give me all the words in the bound in the prosodic phrase\nYep .\nand give me all the words in the  \" Yeah .\nSo I think that 's  that would wor\nUm , OK .\nLet me look at it again .\nMm - hmm . The  the o the other issue that you had was , how do you actually efficiently extract , um  find and extract information in a structure of this type ?\nOK .\nSo .\nThat 's good .\nSo you gave some examples like\nWell , uh , and , I mean , you guys might  I don't know if this is premature because I suppose once you get the representation you can do this , but the kinds of things I was worried about is ,\nNo , that 's not clear .\nuh\nI mean , yeah , you c sure you can do it ,\nWell , OK . So i if it\nbut can you do it sort of l l you know , it\nI I mean , I can't do it , but I can  um ,\ny y you gotta  you gotta do this  you  you 're gonna want to do this very quickly\nWell\nor else you 'll spend all your time sort of searching through very  complex data structures\nRight . You 'd need a p sort of a paradigm for how to do it . But an example would be \" find all the cases in which Adam started to talk while Andreas was talking and his pitch was rising , Andreas 's pitch \" . That kind of thing .\nRight . I mean , that 's gonna be  Is the rising pitch a  feature , or is it gonna be in the same file ?\nWell , the rising pitch will never be  hand - annotated . So the  all the prosodic features are going to be automatically\nBut the  I mean , that 's gonna be hard regardless ,\nSo they 're gonna be in those\nright ? Because you 're gonna have to write a program that goes through your feature file and looks for rising pitches .\nYeah .\nSo  Right . So normally what we would do is we would say \" what do we wanna assign rising pitch to ? \" Are we gonna assign it to words ? Are we gonna just assign it to sort of  when it 's rising we have a begin - end rise representation ? But suppose we dump out this file and we say , uh , for every word we just classify it as , w you know , rise or fall or neither ?\nOK . Well , in that case you would add that to this  format\nOK .\nr\nSo we would basically be sort of , um , taking the format and enriching it with things that we wanna query in relation to the words that are already in the file ,\nRight .\nand then querying it .\nYou want sort of a grep that 's  that works at the structural  on the structural representation .\nOK .\nYou have that . There 's a  standard again in XML , specifically for searching XML documents  structured X - XML documents , where you can specify both the content and the structural position .\nYeah , but it 's  it 's not clear that that 's  That 's relative to the structure of the XML document ,\nIf\nnot to the structure of what you 're representing in the document .\nYou use it as a tool . You use it as a tool , not an end - user . It 's not an end - user thing .\nRight .\nIt 's  it 's  you would use that to build your tool to do that sort of search .\nRight . Be Because here you 're specifying a lattice .\nUh\nSo the underlying  that 's the underlying data structure . And you want to be able to search in that lattice .\nBut as long as the\nIt 's a graph , but\nThat 's different from searching through the text .\nBut it seems like as long as the features that\nWell , no , no , no . The whole point is that the text and the lattice are isomorphic . They  represent each other  completely .\nUm\nSo that  I mean th\nThat 's true if the features from your acoustics or whatever that are not explicitly in this are at the level of these types .\nHhh .\nThat  that if you can do that\nYeah , but that 's gonna be the trouble no matter what . Right ? No matter what format you choose , you 're gonna have the trou you 're gonna have the difficulty of relating the  the frame - level features\nThat 's right . That 's true . That 's why I was trying to figure out what 's the best format for this representation .\nYep .\nAnd it 's still gonna be\nHmm .\nit 's still gonna be , uh , not direct .\nRight .\nYou know , it  Or another example was , you know , uh , where in the language  where in the word sequence are people interrupting ? So , I guess that one 's actually easier .\nWhat about  what about , um , the idea of using a relational database to , uh , store the information from the XML ? So you would have  XML basically would  Uh , you  you could use the XML to put the data in , and then when you get data out , you put it back in XML . So use XML as sort of the  the transfer format ,\nTransfer .\nuh , but then you store the data in the database , which allows you to do all kinds of  good search things in there .\nThe , uh  One of the things that ATLAS is doing is they 're trying to define an API which is independent of the back store ,\nHuh .\nso that , uh , you could define a single API and the  the storage could be flat XML files or a database .\nMm - hmm .\nMy opinion on that is for the s sort of stuff that we 're doing ,  I suspect it 's overkill to do a full relational database , that , um , just a flat file and , uh , search tools I bet will be enough .\nBut\nBut that 's the advantage of ATLAS , is that if we actually take  decide to go that route completely and we program to their API , then if we wanted to add a database later it would be pretty easy .\nMm - hmm . Mm - hmm .\nIt seems like the kind of thing you 'd do if  I don't know , if people start adding all kinds of s bells and whistles to the data . And so that might be  I mean , it 'd be good for us to know  to use a format where we know we can easily , um , input that to some database if other people are using it .", "topic_id": 2, "keywords": "atlas, structured, files, file, parser", "dialogue_id": 32}, {"text": "Yep .\nSomething like that .\nI guess I 'm just a little hesitant to try to go whole hog on sort of the  the whole framework that  that NIST is talking about , with ATLAS and a database and all that sort of stuff ,\nSo\ncuz it 's a big learning curve , just to get going .\nHmm .\nHmm .\nWhereas if we just do a flat file format , sure , it may not be as efficient but everyone can program in Perl and  and use it .\nOK .\nRight ?\nBut this is\nSo , as opposed to\nI  I 'm still , um ,  not convinced that you can do much at all on the text  on the flat file that  that  you know , the text representation . e Because the text representation is gonna be , uh , not reflecting the structure of  of your words and annotations . It 's just  it 's\nWell , if it 's not representing it , then how do you recover it ? Of course it 's representing it .\nNo . You  you have to  what you have to do is you have to basically\nThat 's the whole point .\nY yeah . You can use Perl to read it in and construct a internal representation that is essentially a lattice . But , the  and then\nOK .\nYeah .\nWell , that was a different point .\nRight .\nRight ? So what I was saying is that\nBut that 's what you 'll have to do . Bec - be\nFor Perl  if you want to just do Perl . If you wanted to use the structured XML query language , that 's a different thing . And it 's a set of tools  that let you specify given the D - DDT  DTD of the document , um , what sorts of structural searches you want to do . So you want to say that , you know , you 're looking for , um , a tag within a tag within a particular tag that has this particular text in it , um , and , uh , refers to a particular value . And so the point isn't that an end - user , who is looking for a query like you specified , wouldn't program it in this language . What you would do is , someone would build a tool that used that as a library . So that they  so that you wouldn't have to construct the internal representations yourself .\nIs a  See , I think the kinds of questions , at least in the next  to the end of this year , are  there may be a lot of different ones , but they 'll all have a similar nature . They 'll be looking at either a word - level prosodic , uh , an  a value ,\nMm - hmm .\nlike a continuous value , like the slope of something . But you know , we 'll do something where we  some kind of data reduction where the prosodic features are sort o uh , either at the word - level or at the segment - level ,\nRight .\nor  or something like that . They 're not gonna be at the phone - level and they 're no not gonna be at the frame - level when we get done with sort of giving them simpler shapes and things . And so the main thing is just being able  Well , I guess , the two goals . Um , one that Chuck mentioned is starting out with something that we don't have to start over , that we don't have to throw away if other people want to extend it for other kinds of questions ,\nRight .\nand being able to at least get enough , uh , information out on  where we condition the location of features on information that 's in the kind of file that you  put up there . And that would  that would do it ,\nYeah . I think that there are quick and dirty solutions ,\nI mean , for me .\nand then there are long - term , big - infrastructure solutions . And so  we want to try to pick something that lets us do a little bit of both .\nIn the between , right . And especially that the representation doesn't have to be thrown away ,\nUm  Right .\neven if your tools change .\nAnd so it seems to me that  I mean , I have to look at it again to see whether it can really do what we want , but if we use the ATLAS external file representation , um , it seems like it 's rich enough that you could do quick tools just as I said in Perl , and then later on if we choose to go up the learning curve , we can use the whole ATLAS inter infrastructure ,\nYeah . I mean , that sounds good to me .\nwhich has all that built in .\nI  I don't  So if  if you would l look at that and let us know what you think .\nSure .\nI mean , I think we 're sort of guinea pigs , cuz I  I want to get the prosody work done but I don't want to waste time , you know , getting the\nOh , maybe\nYeah ?\num\nWell , I wouldn't wait for the formats , because anything you pick we 'll be able to translate to another form .\nWell  Ma well , maybe you should actually look at it yourself too to get a sense of what it is you 'll  you 'll be dealing with ,\nOK .\nbecause , um , you know , Adam might have one opinion but you might have another , so\nYeah .\nYeah , definitely .\nI think the more eyes look at this the better .\nEspecially if there 's , e um  you know , if someone can help with at least the  the setup of the right\nHi , Jane .\nOh , hi .\nMmm .\nthe right representation , then , i you know , I hope it won't  We don't actually need the whole full - blown thing to be ready ,\nCan you  Oh , well .\nso . Um , so maybe if you guys can look at it and sort of see what ,\nYeah .\nSure .\num  I think we 're  we 're   we 're actually just\nWe 're about done .\nyeah ,\nHmm .\nwrapping up , but , um  Yeah , sorry , it 's a uh short meeting , but , um  Well , I don't know . Is there anything else , like  I mean that helps me a lot ,\nWell , I think the other thing we might want to look at is alternatives to P - file .\nbut\nI mean , th the reason I like P - file is I 'm already familiar with it , we have expertise here , and so if we pick something else , there 's the learning - curve problem . But , I mean , it is just something we developed at ICSI .\nIs there an  is there an IP - API ?\nAnd so  Yeah .\nOK .\nThere 's an API for it . And , uh ,\nThere used to be a problem that they get too large ,\na bunch of libraries , P - file utilities .\nand so  basically the  uh the filesystem wouldn't\nWell , that 's gonna be a problem no matter what . You have the two - gigabyte limit on the filesystem size . And we definitely hit that with Broadcast News .\nMaybe you could extend the API to , uh , support , uh , like splitting up , you know , conceptually one file into smaller files on disk so that you can essentially , you know , have arbitrarily long f\nYep . Most of the tools can handle that .\nYeah .\nSo that we didn't do it at the API - level . We did it at the t tool - level . That  that  most  many of them can s you can specify several P - files and they 'll just be done sequentially .\nOK .\nSo .\nSo , I guess , yeah , if  if you and Don can  if you can show him the P - file stuff and see .\nSure .\nSo this would be like for the F - zero\nTrue .\nI mean , if you do \" man P - file \" or \" apropos P - file \" , you 'll see a lot .\nI 've used the P - file , I think . I 've looked at it at least , briefly , I think when we were doing s something .\nWhat does the P stand for anyway ?\nI have no idea .\nOh , in there .\nI didn't de I didn't develop it . You know , it was  I think it was Dave Johnson . So it 's all part of the Quicknet library . It has all the utilities for it .\nNo , P - files were around way before Quicknet . P - files were  were around when  w with , um ,  RAP .\nOh , were they ?\nMm - hmm .\nRight ?\nIt 's like the history of ICSI .\nYou worked with P - files .\nMm - hmm .\nLike\nNo .\nI worked with P - files .\nYeah ?\nI don't remember what the \" P \" is , though .\nNo .\nBut there are ni they 're  The  Quicknet library has a bunch of things in it to handle P - files ,\nYeah .\nso it works pretty well .\nAnd that isn't really , I guess , as important as the  the main  I don't know what you call it , the  the main sort of word - level\nNeither do I .\nProbably stands for \" Phil \" . Phil Kohn .\nIt 's a Phil file ?\nYeah . That 's my guess .\nHuh . OK . Well , that 's really useful . I mean , this is exactly the kind of thing that I wanted to settle . Um , so\nYeah , I 've been meaning to look at the ATLAS stuff again anyway .\nGreat .\nSo , just keep\nYeah . I guess it 's also sort of a political deci I mean , if  if you feel like that 's a community that would be good to tie into anyway , then it 's  sounds like it 's worth doing .\nYeah , I think it  it w\nj I think there 's\nAnd , w uh , as I said , I  what I did with this stuff  I based it on theirs . It 's just they hadn't actually come up with an external format yet . So now that they have come up with a format , it doesn't  it seems pretty reasonable to use it .\nMmm .\nBut let me look at it again .\nOK , great .\nAs I said , that\nCuz we actually can start\nThere 's one level  there 's one more level of indirection and I 'm just blanking on exactly how it works . I gotta look at it again .\nI mean , we can start with , um , I guess , this input from Dave 's , which you had printed out , the channelized input . Cuz he has all of the channels , you know , with the channels in the tag and stuff like that .\nYeah , I 've seen it .\nSo that would be i directly ,\nYep . Easy  easy to map .", "topic_id": 3, "keywords": "annotations, perl, formats, structured, text", "dialogue_id": 32}, {"text": "um  Yeah . And so then it would just be a matter of getting  making sure to handle the annotations that are , you know , not at the word - level and , um , t to import the\nWhere are those annotations coming from ?\nWell , right now , I g Jane would   would\nMm - hmm .\nYeah .\nAre you talking about the overlap a annotations ?\nYeah , any kind of annotation  that , like , isn't already there . Uh , you know , anything you can envision .\nYeah . So what I was imagining was  um , so Dave says we can have unlimited numbers of green ribbons . And so put , uh , a  a green ribbon on for an overlap code . And since we w we  I  I think it 's important to remain flexible regarding the time bins for now . And so it 's nice to have  However , you know , you want to have it , uh , time time uh , located in the discourse . So , um , if we  if we tie the overlap code to the first word in the overlap , then you 'll have a time - marking . It won't  it 'll be independent of the time bins , however these e evolve , shrink , or whatever , increase , or  Also , you could have different time bins for different purposes . And having it tied to the first word in an overlap segment is unique , uh , you know , anchored , clear . And it would just end up on a separate ribbon .\nRight .\nSo the overlap coding is gonna be easy with respect to that . You look puzzled .\nI  I just  I don't quite understand what these things are .\nOK .\nUh .\nWhat , the codes themselves ?\nWell , th overlap codes .\nOr the  ?\nI 'm not sure what that @ @\nWell , I mean , is that\nIt probably doesn't matter .\nWell , we don't have to go into the codes .\nI mean , it doesn't .\nNo , I d\nWe don't have to go into the codes .\nI mean , that  not for the topic of this meeting .\nBut let me just  No . W the idea is just to have a separate green ribbon , you know , and  and  and let 's say that this is a time bin . There 's a word here . This is the first word of an overlapping segment of any length , overlapping with any other , uh , word  uh , i segment of any length . And , um , then you can indicate that this here was perhaps a ch a backchannel , or you can say that it was , um , a usurping of the turn , or you can  you know , any  any number of categories . But the fact is , you have it time - tagged in a way that 's independent of the , uh , sp particular time bin that the word ends up in . If it 's a large unit or a small unit , or\nMm - hmm .\nwe sh change the boundaries of the units , it 's still unique and  and , uh , fits with the format ,\nRight .\nflexible , all that .\nUm , it would be nice  um , eh , gr this is sort of r regarding  uh , uh it 's related but not directly germane to the topic of discussion , but , when it comes to annotations , um , you often find yourself in the situation where you have  different annotations  of the same , say , word sequence . OK ?\nYeah .\nAnd sometimes the word sequences even differ slightly because they were edited s at one place but not the other .\nYeah .\nSo , once this data gets out there , some people might start annotating this for , I don't know , dialogue acts or , um , you know , topics or what the heck . You know , there 's a zillion things that people might annotate this for . And the only thing that is really sort of common among all the versi the various versions of this data is the word sequence , or approximately .\nYep .\nOr the time .\nOr the times . But , see , if you 'd annotate dialogue acts , you don't necessarily want to  or topics  you don't really want to be dealing with time - marks .\nI guess .\nYou 'd  it 's much more efficient for them to just see the word sequence , right ?\nMm - hmm .\nI mean , most people aren't as sophisticated as  as we are here with , you know , uh , time alignments and stuff . So  So the  the  the point is\nShould  should we mention some names on the people who are n ?\nRight . So , um , the p my point is that  you 're gonna end up with , uh , word sequences that are differently annotated . And  you want some tool , uh , that is able to sort of merge these different annotations back into a single , uh , version . OK ? Um , and we had this problem very massively , uh , at SRI when we worked , uh , a while back on ,  uh  well , on dialogue acts as well as , uh , you know , um , what was it ? uh ,\nWell , all the Switchboard in it .\nutterance types . There 's , uh , automatic , uh , punctuation and stuff like that .\nYeah .\nBecause we had one set of  annotations that were based on , uh , one version of the transcripts with a particular segmentation , and then we had another version that was based on , uh , a different s slightly edited version of the transcripts with a different segmentation . So ,  we had these two different versions which were  you know , you could tell they were from the same source but they weren't identical . So it was extremely hard  to reliably merge these two back together to correlate the information from the different annotations .\nYep . I  I don't see any way that file formats are gonna help us with that .\nNo .\nIt 's  it 's all a question of semantic .\nNo . But once you have a file format , I can imagine writing  not personally , but someone writing a tool that is essentially an alignment tool , um , that mediates between various versions ,\nMm - hmm .\nYeah .\nand  uh , sort of like th uh , you know , you have this thing in UNIX where you have , uh , diff .\nDiff .\nW - diff or diff .\nThere 's the , uh , diff that actually tries to reconcile different  two diffs f  based on the same original .\nYeah .\nIs it S - diff ?\nYep .\nMmm .\nSomething like that , um , but operating on these lattices that are really what 's behind this  uh , this annotation format .\nYep .\nSo\nThere 's actually a diff library you can use  to do things like that that  so you have different formats .\nYou could definitely do that with the\nSo somewhere in the API you would like to have like a merge or some  some function that merges two  two versions .\nYeah , I think it 's gonna be very hard . Any sort of structured anything when you try to merge is really , really hard\nRight .\nbecause you ha i The hard part isn't the file format . The hard part is specifying what you mean by \" merge \" .\nIs  Exactly .\nAnd that 's very difficult .\nBut the one thing that would work here actually for i that is more reliable than the utterances is the  the speaker ons and offs . So if you have a good ,\nBut this is exactly what I mean , is that  that the problem i\num  Yeah . You just have to know wha what to tie it to .\nYeah , exactly . The problem is saying \" what are the semantics ,\nAnd\nwhat do you mean by \" merge \" ? \"\nRight , right .\nRight . So  so just to let you know what we  where we kluged it by , uh , doing  uh , by doing  Hhh .\nSo .\nBoth were based on words , so , bo we have two versions of the same words intersp you know , sprinkled with  with different tags for annotations .\nAnd then you did diff .\nAnd we did diff . Exactly !\nYeah , that 's just what I thought .\nAnd that 's how\nThat 's just wh how I would have done it .\nYeah . But , you know , it had lots of errors and things would end up in the wrong order , and so forth . Uh , so , um , if you had a more\nYep .\nUh , it  it was a kluge because it was basically reducing everything to  uh , to  uh , uh , to textual alignment .\nA textual\nUm , so\nBut , d isn't that something where whoever  if   if the people who are making changes , say in the transcripts , cuz this all happened when the transcripts were different  ye um , if they tie it to something , like if they tied it to the acoustic segment  if they  You know what I mean ? Then  Or if they tied it to an acoustic segment and we had the time - marks , that would help .\nYep .\nBut the problem is exactly as Adam said , that you get , you know , y you don't have that information or it 's lost in the merge somehow ,\nWell , can I ask one question ?\nso\nIt  it seems to me that , um , we will have o an official version of the corpus , which will be only one  one version in terms of the words  where the words are concerned . We 'd still have the  the merging issue maybe if coding were done independently of the\nAnd you 're gonna get that\nBut  but\nbecause if the data gets out , people will do all kinds of things to it . And , uh , s you know , several years from now you might want to look into , um , the prosody of referring expressions . And someone at the university of who knows where has annotated the referring expressions . So you want to get that annotation and bring it back in line with your data .\nRight .\nOK ?\nBut unfortunately they 've also hand - edited it .\nOK , then\nBut they 've also  Exactly . And so that 's exactly what we should  somehow when you distribute the data , say that  you know , that  have some way of knowing how to merge it back in and asking people to try to do that .\nYeah .\nYep .\nRight .\nWell , then the\nWhat 's  what 's wrong with  doing times ? I\nI agree . That was what I was wondering .\nUh , yeah , time is the\nWell ,\nTime is unique . You were saying that you didn't think we should\nTime is passing !\nTime  time  times are ephemeral .\nAndreas was saying  Yeah .\nwhat if they haven't notated with them , times ?\nYeah . He  he 's a language modeling person , though .\nUm\nSo  so imagine  I think his  his example is a good one . Imagine that this person who developed the corpus of the referring expressions didn't include time .\nMm - hmm . Yeah .\nHe included references to words .\nAch !\nYeah .\nHe said that at this word is when  when it happened .\nWell , then\nOr she .\nOr she .\nBut then couldn't you just indirectly figure out the time  tied to the word ?\nBut still they  Exactly .\nSure . But what if  what if they change the words ?\nYeah .\nNot  Well , but you 'd have some anchoring point . He couldn't have changed all the words .\nBut can they change the words without changing the time of the word ?\nSure . But they could have changed it a little . The  the point is , that  that they may have annotated it off a word transcript that isn't the same as our word transcript , so how do you merge it back in ? I understand what you 're saying .\nMmm . Mm - hmm .\nAnd I  I guess the answer is , um , it 's gonna be different every time . It 's j it 's just gonna be\nYeah .\nYeah .\nI it 's exactly what I said before ,\nYou only know the boundaries of the\nwhich is that \" what do you mean by \" merge \" ? \" So in this case where you have the words and you don't have the times , well , what do you mean by \" merge \" ? If you tell me what you mean , I can write a program to do it .\nRight . Right . You can merge at the level of the representation that the other person preserved and that 's it .\nRight . And that 's about all you can do .\nAnd beyond that , all you know is  is relative ordering and sometimes even that is wrong .\nSo  so in  so in this one you would have to do a best match between the word sequences ,\nSo .\nMm - hmm .\nextract the times f from the best match of theirs to yours , and use that .\nAnd then infer that their time - marks are somewhere in between .\nRight .\nYeah , exactly .\nBut it could be that they just  uh , I mean , it could be that they chunked  they  they lost certain utterances and all that stuff ,\nRight , exactly . So it could get very , very ugly .\nor\nDefinitely .\nYeah .\nDefinitely . Alright .\nThat 's interesting .\nWell , I guess , w I  I didn't want to keep people too long and Adam wanted t people  I 'll read the digits . If anyone else offers to , that 'd be great . And\nAh , well .\nYeah .\nif not , I guess\nFor th for the  {nonvocalsound} for the benefit of science we 'll read the digits .", "topic_id": 4, "keywords": "annotations, annotating, annotation, annotate, annotated", "dialogue_id": 32}, {"text": "More digits , the better . OK , this is\nThanks  thanks a lot . It 's really helpful . I mean , Adam and Don {nonvocalsound} will sort of meet and I think that 's great . Very useful . Go next .\nScratch that .\nO three\nOh , right .", "topic_id": 5, "keywords": "digits, adam, meet, scratch, sort", "dialogue_id": 32}, {"text": "Alright , so I 'm - I should read all of these numbers ?\nOK .\nPiece of paper ? I could borrow ?\nOh yeah .\nOK , so uh i um I don't know whether Ami 's coming or not um but I think we oughta just get started .\nNancy is uh currently in Berkeley but not here ?\nNancy 's still stick ?\nDon't know . Anyway\nOK .\nOh , so there you go . Anyway , so my idea f for today and we can uh decide that that isn't the right thing to do was to at  spend at least part of the time trying to eh build the influence links , you know which sets of things are uh relevant to which decisions and actually I had uh specific s suggestion to start first with the path ones . The database ones being in some sense less interesting to us although probably have to be done and so to do that so there 's  and the idea was we were gonna do two things\nIs your mike on ?\nAh . Oh right , well . Yeah . We were gonna do two things one of which is just lay out the influence structure of what we think influences what\nThat 's funny .\nand then as a uh separate but related task uh particularly Bhaskara and I were going to try to decide what kinds of belief nodes are needed in order to um do what we  what we need to do . Once so but du we should sort of have all of the uh basic design of what influences what done before we decide exactly how to compute it . So I didn't  did you get a chance to look at all  yet ?\nYeah , I looked at some of that stuff .\nGreat . OK so let 's start with the uh belief - nets , the general influence stuff and then we 'll  then we 'll also at some point break and talk about the techy stuff .\nWell I think one could go there 's I think we can di discuss everything . First of all this I added , I knew from sort of basically this has to be there right ? Um\nOh are you gonna go there or not ? Yeah , so one i\nGiven  given uh uh not transverse the castle , the decision is does the person want to go there or is it just\nRight , true . Does have to be there . And I 'm sure we 'll find more as we go that\nAnd Hmm ? So Go - there in the first place or not is definitely uh one of the basic ones . We can start with that . Interesting effect . Um Is this basically true or false or maybe we 'll get\nWell\nWhich one ?\nwhat ?\n\" Go there \" .\nm right .\nso there is this question about\nHere we we actually get just probabilities ,\nYeah .\nright for each down here .\nWhen we 're  yeah when we 're done . So  so\nHmm .\nthe  the reason it might not be true or false is that we did have this idea of when so it 's , you know uh current @ @ and so forth and so on or not at all ,\nMm - hmm .\nright ? And so that a decision would be do we want that so you could  two different things you could do , you could have all those values for Go - there or you could have Go - there be binary and given that you 're going there when .\nWhen . How .\nYeah and so forth .\nWhy ,\nSo I 'll let\nyeah .\nwe 'll see .\nHmm ?\nI mean it seems that you could um uh it seems that those things would be logically independent like you would wanna have them separate or binary , Go - there and then the  the possibilities of how to go there because\nOK , that 's  let 's start that way .\nbecause , you know it might be easy to figure out that this person is going to need more film eventually from their utterance but it 's much more complex to query when would be the most appropriate time .\nHmm . Hmm . OK . And so I 've tried to come up with some initial things one could observe so who is the user ? Everything that has user comes from the user model everything that has situation comes from the situation model - A . We should be be clear . But when it comes to sort of writing down when you  when you do these things is it here ? You sort of have to a write the values this can take .\nRight .\nAnd here I was really uh in some s sometimes I was really sort of standing in front of a wall feeling very stupid because um  this case it 's pretty simple , but as we will see the other ones um for example if it 's a running budget so what are the discrete values of a running budget ? So maybe my understanding there is too impoverished .\nHmm .\nNo uh\nHow can I write here that this is something , a number that cr keeps on changing ? But OK . Thus is understandable ?\nThink so .\nYes .\nSo here for example .\nYou 've s have you seen this before at all Keith , these belief - net things ?\nUh , no , but I think I 'm following it . So far .\nSo here is the  the  we had that the user 's budget may influence the outcome of decisions .\nYeah .\nHmm .\nThere we wanted to keep sort of a running total of things .\nIs this like a number that represents how much money they have left to spend ? OK , h well I mean how is it different from user finance ?\nUm the finance is sort of here thought of as  as the financial policy a person carries out in his life , he  is he cheap , average , or spendy ?\nAlright .\nAnd um I didn't come uh maybe a user I don't know , I didn't want to write greediness , but\nYeah . Hmm .\nOr cheapness .\nWelcome .\nUser thrift .\nWelcome .\nThrift , that 's good .\nYeah .\nGreat .\nThere it is .\nYeah . So Keith w what 's behind this is actually a program that will once you fill all this in actually s solve your belief - nets for you and stuff .\nMm - hmm .\nSo this is not just a display , this is actually a GUI to a simulator that will if we tell it all the right things we 'll wind up with a functioning belief - net at the other end .\nOK . OK .\nAnd it 's so simple even I can use it .\nWow , that is simple .\nOK , so here was OK , I can think of uh people being cheap , average , or spendy or we can even have a  a finer scale moderately cheap ,\nDoesn't matter .\ndoesn't matter . Agree there but here um I wasn't sure what to write in .", "topic_id": 0, "keywords": "suggestion, things, task, influences, idea", "dialogue_id": 33}, {"text": "Let 's  go ahead .\nWell , I mean you 've written in  you 've written in what uh seems to be required like what else is  is do you want ?\nIf that 's permissible then I 'm happy .\nWell yeah . So here 's  here 's what 's permissible is that you can arrange so that the um the value of that is gonna have to be updated and n it 's not a belief update , right ? It 's  you took some actions , you spent money and stuff , so the update of that is gonna have to be essentially external to the belief - net . Right ?\nYeah .\nAnd then what you 're going to need is uh for the things that it influences . Well let 's  first of all let 's see if it does influence anything . And if it does influence anything then you 're gonna need something that converts from the  the number here to something that 's relevant to the decision there . So it could be ra they create different ranges that are relevant for different decisions or whatever  but for the moment this is just a node that is conditioned externally and might influence various things .\nHmm . Yeah  this is where um OK anyways let 's forget it .\nWell that 's fine . Well anyway , go ahead .\nOK , and so this , oh that\nThe other thing is that um every time that 's updated beliefs will have to be propagated but then the question is do you  do we wanna propagate beliefs every single time it 's updated or only when we need to ?\nYeah , that 's a good question . And uh does it have a lazy mode ? I don't remember .\nUh Well , I mean , in Srini 's thing there was this thing  there was this um option like proper inferences which suggests that uh doesn't happen , automatically .\nOh right . Yeah . S probably does . Yeah someone has to track that down , but I  but uh And  and  and I think  actually uh\nI just accidentally Oops .\none of the we w items for the uh user home base uh should be uh essentially non - local . I they 're only there for the day and they don't have a place that they 're staying .\nWell\nOh just uh accidentally erased this , I  I just had values here such as uh um is he s we had in our list we had \" Is he staying in our hotel ? \" , \" Is he staying with friends ? \" , and so forth\nYeah .\nuh so we 're OK .\nSo it 's clear where w w w where we are right now . So my suggestion is we just pick uh\nSomething down here ?\none , you know one uh particular one of the uh well let 's do the first  first one let 's do the one that we sort of already think we did so w that was the  of the endpoint ?\nMm - hmm . And um Oops .\nIs hmm\nAh ,\nSo it 's true or false ?\nNo , that 's  that 's a\nOK . No no no , EVA .\nSo\nMissed that one .\nWhat 's the difference between mode and endpoint ?\nI thought mode , yeah .\nalthough that\nUm mode was um\nWell , that 's\nMode of transportation ?\nYeah .\nOK . Also true or false .\nMm - hmm .\nNo , he has he hasn't filled them in yet , is what 's true .\nYeah , OK .\nDid I or didn't I ? Ah . Probably nothing done yet , oh I just did it on the upper ones , OK . Makes sense . OK , so this was EVA . Maybe we can think of more things , cross\nYeah .\nClimb , rob .\nOK .\nclimb , emerge\nNo no no , these are ju that 's just a point ,\nUh\nWell some of those are subsumed by approach .\nthis is ju\nWould it be an endpoint if you were crossing over it ?\nThe Charles Bridge , you know .\nYeah , would be a f for a given segment . You know , you  y you go  first go the town square\nWell I eh\nNo , I mean , if you go to re you know if you go to Prague or whatever one of your  your key points that you have to do is cross the Charles Bridge and doesn't really matter which way you cross which  where you end up at the end but the part  the good part is walking over it , so .\nThat 's subtle , but true . Anyway so let 's just leave it three  with three for now\nMm - hmm , mmm . Yeah .\nand let 's see if we can get it linked up just to get ourselves started .\nOK , we\nYou 'll see it  you 'll see something comes up immediately , that the reason I wanna do this .\nw well the uh user was uh definitely more likely to enter if he 's a local\nRight . Right .\nmore likely to view if he 's a tourist um and then of course we had the fact that given the fact that he 's thrifty and there will be admission then we get all these cross um\nWe did , but the three things w that  that it contributed to this in fact , the other two aren't up there . so one was the ontology\nWe 'll d what type of building is it ?\nYeah .\nYeah .\nAnd the  and the third thing we talked about was something from the discourse .\nWhat he has mentioned before .\nOK , so this is w Right , so what w I  what we seem to need here , this is why it starts getting into the technical stuff\nmm - hmm\nthe way we had been designing this , there were three intermediate nodes uh which were the endpoint decision as seen from the uh user model as seen from the ontology and as seen from the discourse . So each of those the way we had it designed , now we can change the design , but the design we had was there was a decision with the same three outcomes uh based on the th those three separate considerations\nmm - hmm\nso if we wanted to do that would have to put in uh three intermediate nodes\nUh we can load it up it you know very simple .\nSo\nand then what you and I have to talk about is , OK if we 're doing that and they get combined somehow uh how do they get combined ? But the  they 're  they 're undoubtedly gonna be more things to worry about .\nSo this was adjusted for this one mode thing .\nOh yes .\nYeah .\nSo that 's w w in our uh in  in Johno 's sort of pictogram everything that could contribute to whether a person wants to enter , view , or approach something .\nOh , it was called mode , so this  this is m mode here means the same as endpoint .\nIs now this endpoint .\nRight .\nOK , why don't we ch can we change that ?\nWe can just rename that , yeah .\nAlright . You know , but that was actually , yeah unfortunately that was a um kind of an intermediate versio that 's I don't think what we would currently do .\nCan I ask about \" slurred \" and \" angry \" as inputs to this ?\nThat 's a\nWhat  why ?\nLike they 're either true or false\nThe prosody ?\nOK .\nand they uh oh I see .\nIf the  if the person talking is angry or slurs their speech they might be tired or , you know\nMm - hmm . OK . Drunk .\nTherefore\nAnd , you know , possibly uh\nLess likely to enter .\nsome ,\nHmm .\nyeah .\nuh I was thinking less likely to view\nYeah . But that 's - that seems to , yeah . So  so my advice to do is  is get this down to what we think is actually likely to  to be a  a strong influence .\nOK .\nBut yeah , that was what he had in mind .\nRight .\nSo let 's think about this  this question of how do we wanna handle  so there 're two separate things . One is  uh at least two . One is how do we want to handle the notion of the ontology now what we talked about , and this is another technical thing Bhaskara , is uh can we arrange so that I think we can so that the belief - net itself has properties and the properties are filled in uh from on ontology items . So the  let 's take the case of the uh this endpoint thing , the notion was that if you had a few key properties like is this a tourist site , you know some kind of landmark is it a place of business uh is it something you physically could enter\nMm - hmm .\nOK , et cetera . So that there 'd be certain properties that would fit into the decision node and then again as part of the ou outer controlling conditioning of this thing those would be set , so that some somehow someone would find this word , look it up in the ontology , pull out these properties , put it into the belief - net , and then the decision would flow .\nMm - hmm .\nNow\nSeems to me that we 've sort of e em embedded a lot , em embedded a lot of these uh things we had in there previously in  in  in some of the other final decisions done here , for example if we would know that this thing is exhibiting something um\nRight . Right .\nif it 's exhibiting itself it is a landmark ,\nYeah .\nmeaning more likely to be viewed\nYep .\nif it is exhibiting pictures or sculptures and stuff like this , then it 's more likely to be entered .\nI uh that 's  I think that 's completely right and um I think that 's good , right ? So what  what that says is that we might be able to uh take and in particular so  so the ones we talked about were uh exhibiting and selling\nAccessibility .\nno , accessibility meant\nIf it 's closed one probably won't enter . Or if it 's not accessible to a tourist ever the likelihood of that person actually wanting to enter it ,\nOK .\ngiven that he knows it , of course .\nAlright . So let me suggest this . Uh w could you move those up about halfway . Uh The ones that you th And selling I guess .\nYeah , all  all of these if it 's fixing things selling things , or servicing things\nRight . So here  here 's what it looks like to me . is that you want an intermediate structure which i uh is essentially the or of uh for this purpose of  of uh selling , f fixing , or servicing . So that it uh that is , for certain purposes , it becomes important but for this kind of purpose uh one of these places is quite like the other . Does that seem right ? So we di\nBasic you 're basically just merging those for just the sake of endpoint decision ?\nif we Yes .\nYeah .\nMm - hmm .\nSo if  well it may be more than endpoint decisions , so the idea would be that you might wanna merge those three\nThese three ?\nYeah . Eh ser s uh selling , fixing , and servicing .\nYeah .\nWhat ex um and so either those is true f or false ?\nUh Uh well it  it  i here 's where it gets a little tricky .\nSo\nUh from the belief - net point of view it is from another point of view of course it 's interest it 's  it 's important to know what it 's selling or servicing and so forth .\nYeah .\nSo for this decision it 's just uh true or false\nOK . Yeah .\nand in th this is a case where the or seems just what you want .\nOK .\nThat  that if any of those things is true then it 's the kind of place that you uh\nUm more likely to enter .\nare more likely to enter .\nSo you just wanna have them all pointing to a summary thing ?\nYou could , yeah . Yeah , so let 's do that . No no , no eh to  to an inter no , an intermediate node .\nT\nOh , OK .\nThat 's the p part of the idea , is\nUm is  is that the object type node ?\nI d\nSo are they the  is it the kind of object that sells , fixes , or services things ?\nWell , o open up object type and let 's see what its values are .\nOh I just created it , it has none so far .\nOh , well OK first of all it 's not objects , we called them entities , right ?\nYeah . And then we have sort of the um\nLet 's say I put commercial .\nYeah , I w I was just gonna commercial action inside where people p\nWell couldn't I do  let 's do commercial uh landmark and\nAnd where was the accessible , yeah .\nWell accessible I think is different cuz that 's tempor that  that varies temporally ,\nYeah .\nwhereas this is a\nMm - hmm .\nWhat would a hotel fall under ?\nI would call that a service , but  but I don't know .\nWell I mean in terms of entity type ?\nSay w w well it 's co I would s a a again for this purpose I think it 's commercial . Someplace you want to go in to do some kind of business .\nOK .\nUm what does the underscore - T at the end of each of those things signify ?\nUm things . So places that service things sell things or fix things and pe places that e exhibit things .\nUh - huh . OK . OK . That also points to entity type I guess .\nSo we 're deriving um this  the  this feature of whether the  the main action at this place happens inside or outside or what we 're deriving that from what kind of activity is done there ? Couldn't you have it as just a primitive feature of the entity ?\nWell you could , that 's a  that 's a choice .\nOK .\nSo uh\nI mean it seems like that 's much more reliable cuz you could have outdoor places that sell things and you know indoor places that do something else\nYeah , the problem with it is that it sort of putting in a feature just for one decision ,\nand Hmm .\nnow w we may wind up having to do that this i anyway , this i\nOK .\nat a mental level that 's what we we 're gonna have to sort out .\nOK .\nSo , you know what does this look like , what are  what are uh intermediate things that are worth computing , what are the features we need in order to make all these decisions\nMm - hmm .\nand what 's the best way to organize this so that um it 's clean and  and consistent and all that sort of stuff .\nOK . I 'm just thinking about how people , human beings who know about places and places to go and so on would store this and it would probably  you wouldn't just sort of remember that they sell stuff and then deduce from that that it must be going on inside or something .\nWell I think an entity maybe should be regard as a vector of several possible things , it can either em do s do sell things , fix things , service things , exhibit things , it can be a landmark at the same time as doing these things ,\nMm - hmm .\nit 's not either or mmm certainly a place can be a hotel and a famous site .\nMm - hmm .\nMany come to mind . Things can be generally um a landmark and be accessible . IE a  a castle or can be a landmark a or not accessible , some statue\nMm - hmm .\nyou know can go inside .", "topic_id": 1, "keywords": "belief, beliefs, inferences, nodes, influence", "dialogue_id": 33}, {"text": "OK . Anyway so let me suggest you do something else . Uh which is to get rid  get rid of that l long link between who  the user and the endpoint .\nCould we just move it like this ?\nNo no , I don't want the link there at all .\nOh , OK .\nBecause what we 're gonna want is an intermediate thing which is uh the endpoint decisi the endpoint decision based o on the user models , so what we  we  what we talked about is three separate endpoint decisions , so let 's make a new node\nYeah . Yeah .\nJust as a suggestion maybe you could \" save as \" to keep your old one nice and clean and so you can mess with this one .\nMmm . The old one was not that not that important , I think but\nOK , well , not a big deal then .\nLet 's do it then .\nWell the  Isn't there a \" save as \" inside of java base ?\nBut I can just take this\nOK .\ncopy it somewhere else . This was user something\nWell this was\nor\nuh let 's p put it this  let 's do endpoint underbar - U .\nend point ?\ni endpoint , e end poi this is sa\nAh .\nit 's the endpoint\nGotcha , yeah .\nlet 's say underbar - U , so that 's the endpoint decision uh as seen through the\nAs related from the user model .\nRight . So let 's  let 's actually yeah so lin you can link that up to the\nShould I rename this  too ?\nuh yeah , so that , I guess that 's endpoint uh\nIt 's underscore - E .\nunderscore - E for entity , and we may change all this , but . Right . And\nOK , shouldn't I be able to move them all ? No . Or  ? Can I ? Where ? What ?\nOh I d eh I don't know . Actually , I guess the easiest thing would move  mo move the endpoint , well , go ahead . Just do whatever .\nWasn't this possible ?\nWell .\nYeah .\nI think you have to be in move mode before\nUh - huh . OK .\nGood . Right .\nSo now we 're looking for user related things that um\nYeah . And uh maybe th maybe it 's just one who is the user , I don't know , maybe  maybe there 's more .\nHuh .\nWell if he 's usi if he 's in a car right now what was that people with Harry drove the car into the cafe\nNever mind . Uh anyway , this is crude . Now but the  now so  so  but then the question is uh so  and  and we assume that some of these properties would come indirectly through an ontology , but then we had this third idea of input from the discourse .\nWell let 's  should we finish this ,\nSure ,\nI mean but surely the user interests\nOK .\nThe user thrift , the user budget .\nyeah , yeah\nWell , maybe , I again , I d well , OK , put em in but what we 're gonna wanna do is actually uh\nWell is\nHere this was one of my problems we have the user interest is a  is a vector of five hundred values , so um That 's from the user model ,\nOh you mean level of interest ?\nmm - hmm , no not levels of interest but things you can be interested in .\nWell\nsomebody else has built this user model .\nOh I see ,\nGothic churches versus Baroque townhouses versus\nright . So why is it oh it , so it 's like a vector of five hundred one 's or zero 's ?\nYea - n is that\nLike for each thing are we  are you interested in it or not ?\nyeah uh I  I think\nI see .\nHmm .\nOK . So uh you cou and so here let me give you two ways to handle that . Alright ? One is um you could ignore it . But the other thing you could do is have an  and this will give you the flavor of the  of what you could have a node that 's  that was a measure of the match between the object 's feature , you know , the match between the object the entity , I 'm sorry and the user .\nMm - hmm . Uh .\nSo you could have a k a \" fit \" node and again that would have to be computed by someone else\nMm - hmm .\nbut uh so that uh\nJust as a mental note uh\nYeah , that 's all .\nMm - hmm . And  and should we say that this interests eh affects the likelihood of  of entering ?\nYeah . I mean , we could .\nYeah . And also if it 's an expensive place to enter , this may also\nOK .\nBudget .\nUser schedule . \" Do I have time to go in and climb all the way to the top of the Koelner Dome  or do I just have to  \" \" time to take a picture of the outside ? \"\nSchedule ?\nRight .\nIt seems like everything in a user model a affects\nWell that 's what we don't wanna do , see that  se cuz then we get into huge combinatorics and stuff like that\nYeah .\nMm - hmm .\nan\nCuz if the , I mean , and if the user is tired , the user state ,\nWell\nright , it would affect stuff , but I can't see why e anything w everything in the model wouldn't be\nWell , but\nRight .\nWell , that  that 's  we can't do that , so we we 're gonna have to\nYeah .\nbut this is a good discussion , we 're gonna have to somehow figure out uh some way to encapsulate that uh so if there 's some general notion of for example the uh relation to the time to do this to the amount of time the guy has or something like that is  is the uh compatibility with his current state , so that 's what you 'd have to do , you 'd have to get it down to something which uh was itself relatively compact , so it could be compatibility with his current state which would include his money and his time and  and his energy\nYeah , just seems like it 'd push the problem back a level .\nRight .\nIt does .\nMm - hmm .\nYeah , but\nNo but , it 's more than that , like the  the more sort of you break it up like because if you have everything pointing to one node it 's like exponential whereas if you like keep breaking it up more and more it 's not exponential anymore .\nSo it yeah , there are two advantages . That 's tha there 's one technical one\nSh - sh yeah ,\nand the other is it  it gets used\nS so we 'd basically be doing subgrouping ? Subgrouping , basically into mo\nYeah .\nso basically make it more tree like going backwards ?\nRight .\nYeah .\nRight . But it  there 's two advantages , one is the technical one that you don't wind up with such big exponential uh CBT 's ,\nBhaskara ?\nthe other is it can be  it presumably can be used for multiple decisions .\nMm - hmm .\nSo that if you have this idea of the compatibility with the requirements of an action to the state of the user one could well imagine that that was u\nRight .\nnot only is it sim is it cleaner to compute it separately but it could be that it 's used in multiple places . Anyway th so in general this is the design , this is really design problem .\nYeah .\nOK , you 've got a signal , a d set of decisions um how do we do this ?\nWhat do I have under user state anyhow cuz I named that already something . Oh that 's tired , fresh , yeah . Maybe should be renamed into physical state .\nOr fat user fatigue even .\nHmm .\nThat 's with a \" G \" ?\nMm - hmm .\nWhatever .\nThen we can make a user state .\nWhat 's th what we 're talking about is compatibility . Uh or something , I don't know , but .\nI guess the  the question uh is It 's hard for me to imagine how everything wouldn't just contribute to user state again . Or user compatibility .\nOh but the thing is that we uh uh we had some things that uh\nThat don't .\nthat don't\nThe user interests and the user who  who  who the user is are completely apart from the fact whether he is tired broke\nSure , but other  I thought though the node we 're creating right now is user compatibility to the current action , right ?\nthe right\nSeems like everything in the user model would contribute to whether or not the user was compatible with something .\nUh maybe not . I mean the  that 's the  the issue is um would Even if it was true in some abstract general sense it might not be true in terms of the information we actually had and can make use of . And anyway we 're gonna have to find some way to cl uh get this sufficiently simple to make it feasible .\nMaybe um if we look at the  if we split it up again into sort of um if we look at the uh the endpoint again we  we said that for each of these things there are certain preconditions so you can only enter a place if you are not too tired to do so and also eh have the money to do so if it costs something so if you can afford it and perform it is preconditions . Viewing usually is cheap or free .\nMm - hmm .\nIs that always true ? I don't know .\nWell , with the way we 're defining it I think yeah .\nW w but that eh viewing it without ent yeah view w with our definition of view it 's free cuz you\nAnd so is approaching .\nYeah .\nWell what about the Grand Canyon , right ? No , never mind . I mean are there  are there large things that you would have to pay to get up close to like , I mean never mind , not in the current\nNo we have to enter the park .\nOK .\nEh almost by definition um paying involves entering ,\nYeah .\nge going through some\nOK . Right , sure .\nRight . Uh So let me suggest we switch to another one , I mean clearly there 's more work to be done on this\nMm - hmm .\nbut I think it 's gonna be more instructive to  to think about uh other decisions that we need to make in path land . And what they 're gonna look like .\nSo you can save this one as and open up the old one , right and  and then everything would be clean . You could do it again .\nWhy , I think it 's worth saving this one but I think I 'd  I 'd like to keep this one\nYeah .\ncuz I wanna see if  if we 're gonna reuse any of this stuff .\nMm - hmm .\nUm so this might be What next ?\nWell you tell me , so in terms of the uh planner what 's  what 's a good one to do ?\nWell let 's  th this go there or not I think is a good one .\nUh\nIs a very basic one . So what makes things more likely that\nWell the fir see the first thing is , getting back to thing we left out of the other is the actual discourse .\nSo\nSo Keith this is gonna get into your world because uh we 're gonna want to know you know , which constructions indicate various of these properties\nMm - hmm . Mm - hmm .\ns and so I  I don't yet know how to do this , I guess we 're gonna wind up pulling out uh discourse properties like we have object properties and we don't know what they are yet .\nMm - hmm .\nSo that  that the Go - there decision will have a node from uh discourse , and I guess why don't we just stick a discourse thing up there to be as a placeholder for\nWe  we also had discourse features of course for the endpoint .\nOf  of course .\nIdentified that\nYeah .\nand so again re that 's completely correct , we have the user model , the situation model here , we don't have the discourse model here yet . Much the same way as we didn't  we don't have the ontology here .\nWell the ontology we sort of said we would pull these various kinds of properties from the ontology like exhibiting , selling , and so forth .\nReally .\nSo in some sense it 's  it 's there .\nMm - hmm .\nBut the discourse we don't have it represented at all yet .\nYeah . Um This be specific for second year ? Um And  and we probably will have uh something like a discourse for endpoint .\nBut if we do it 'll have the three values .\nHmm ?\nIt 'll have the EVA values if  if we have it .\nYeah . Yeah . OK just for starters and here discourse um\nFor Go - there , probably is true and false , let 's say . That 's what we talked about .\num well , I think um we 're looking at the  the little data that we have , so people say how do I get to the castle and this usually means they wanna go there .\nMm - hmm .\nSo this should sort of push it in one direction\nRight .\nhowever people also sometimes say how do I get there in order to find out how to get there without wanting to go there .\nMm - hmm .\nAnd sometimes um people say where is it\nMm - hmm .\nbecause they wanna know where it is but in most cases they probably\nYeah , but that doesn't change the fact that you 're  you want these two values .\nOh yeah , true . So this is sort of some external thing that takes all the discourse stuff and then says here it 's either  yep , yay , A , or nay . Yeah . OK ?\nAnd they 'll be a y uh , a user Go - there and maybe that 's all , I don't know .\nSituation Go - there , I mean , because it 's  whether it 's open or not .\nMm - hmm .\nOK , good .\nThat definitely interes\nYep .\nBut that now that kind of um what 's the word\nHmm .\num the  that interacts with the uh EVA thing if they just wanna view it then it 's fine to go there when it 's closed whereas if they want to um\nRight .\nso\nRight , so that 's  that 's where it starts getting to be uh uh essentially more interesting , so what uh Bhaskara says which is completely right is if you know that they 're only going to view it then it doesn't matter whether it 's closed or not\nMm - hmm .\nin terms of uh uh you know , whether  whether you wanna go there .\nThe time of day ,\nMm - hmm .\nright I  well , right .\nIt does matter though if there 's like a strike or riot or something .\nAbsolutely there are other situational things that do matter .\nRight . So yeah , that 's what I said just having one situational node may not be enough because this  that node by itself wouldn't distinguish\nWell i i it can have di various values . Yeah , but we eh you  you 're right it might not be enough .\nYeah , I mean , see I 'm  I 'm thinking that any node that begins with \" Go - there \" is either gonna be true or false .\nWell , what  Whoops .\nYeah .\nRight .\nAh . I see that could be .\nAlso , that node , I mean the Go - there s S node would just be fed by separate ones for\nMm - hmm .\nyou know , there 's different things , the strikes and the\nCould be . Yeah . N\nLike situation traffic and so on .\nYeah , the time of day .\nYeah . Yeah . So  so now the other thing that Bhaskara eh pointed out is what this says is that uh there sh should be a link , and this is where things are gonna get very messy from the endpoint uh decision\nI guess the final\nmaybe the t they 're final re and , I guess the very bottom endpoint decision uh to the Go - there node . And I  don't worry about layout ,\nYeah .\nI mean then we 'll go  we 'll go nuts but\nMmm .\nMm - hmm .\nMaybe we could um have intermediate node that just the Endpoint and the Go - there S node sort of fed into ?\nCould be , yeah .\nRight . Because that 's what we , I mean that 's why this situation comes up .\nYeah . Well the Go - there , actually the Endpoint node could feed  feed into the Go - there S That 's right ,\nYeah , right .\nso the Endpoint node ,\nMm - hmm .\nmake that up t t to the Go - there then\nYeah .\nand again we 'll have to do layout at some point , but something like that . Now it 's gonna be important not to have loops by the way . Uh really important in  in the belief worl net world not to have loops\nI was just gonna\nuh\nYes .\nHow long does it take you to  to compute uh\nNo it 's much worse than that . It  if i loo it  it  it  it  it 's not def i it 's not well defined if you 're there are loops ,\nIt  things don't converge , yeah .\nuh R recursive action ?\nyou just you have to there are all sorts of ways of breaking it up so that there isn't uh OK .\nUh but this isn't , this is  this line is just coming from over here .\nYeah .\nYeah , no it 's not a loop yet , I 'm just saying we  we , in no , in\nYeah . Well , but the good thing is we  we could have loopy belief propagation which  we all love .\nMmm .", "topic_id": 2, "keywords": "endpoint, java, reuse, node, saving", "dialogue_id": 33}, {"text": "Right . OK , so anyway , so that 's another decision . Uh what 's  what 's another decision you like ?\nOK , these have no parents yet , but I guess that sort of doesn't matter . Right ?\nWell , the idea is that you go there , you go comes from something about the user from something about the situation and the uh the discourse is  is a mystery .\nI mean this is sort of This comes from traffic and so forth , yeah . Sh - Should we just make some\nSure , if you want .\num if there 's parking maybe Mmm Oh who cares . OK . And if he has seen it already or not and so forth ,\nRight .\nOK . Um and discourse is something that sort of should we make a Keith note here ?\nSure .\nThat sort of comes from Keith .\nMm - hmm .\nJust sort of so we don't forget . Oops . Have to get used to this . OK , whoops .\nUm actually\nAnd then also the discourse endpoint , I  I guess endpoint sub - D is  if you wanna make it consistent .\nWh - ah .\nMm - hmm .\nUm actually is this the  the right way to have it where um go there from the user and go there from the situation just sort of don't know about each other but they both feed the go there decision because isn't the , I mean\nI think so . S\nuh , hmm OK . But that still allows for the possibility of the  of the user model affecting our decision about whether a strike is the sort of thing which is going to keep this user away from\nMaybe not , a Right .\nThat  all that  that kind of decision making happens at the Go - there node .\nUh y you  yeah you  i you  if you needed to do that .\nUh . If you needed it to do that .\nYeah .\nBut uh OK I was just thinking I guess maybe I 'm conflating that user node with possible  possible asking of the user\nYeah .\nyou know hey there 's a strike on , uh does that affect whether or not you wanna go or something\nAh . Good point , I don't  I don't know how we 're going to  t uh\nor Yeah , so that might not come out of a user model but , you know , directly out of interaction .\nRight . Uh I gu yes my curr you know , don't yeah yeah yeah that 's enough .\nYeah .\nUh My current idea on that would be that each of these decision nodes has questions associated with it .\nMm - hmm .\nAnd the question wouldn't itself be one of these conditional things\nOK .\nyou know , given that you know there 's a strike do you still wanna go ?\nYeah .\nBut uh if you told him a bunch of stuff , then you would ask him do you wanna go ?\nMm - hmm . OK .\nBut I think trying to formulate the conditional question , that sounds too much .\nRight , right . Yeah . Right , sure , OK .\nTo me .\nMm - hmm .\nAlright , but let me  let  let 's stay with this a minute\nBut\nbecause I want to do a little bit of organization . Before we get more into details . The organization is going to be that uh the flavor of what 's going on is going to be that uh as we s e sort of going to this detail indeed Keith is going to  to worry about the various constructions that people might use\nMm - hmm .\nand Johno has committed himself to being the parser wizard ,\nAlright .\nso what 's going to happen is that eventually like by the time he graduates , OK uh they 'll be some sort of system which is able to take the discourse in context and have outputs that can feed the rest of belief - net . I j wa I  I assume everybody knows that , I just wanna you know , get closure that that 'll be the game then ,\nMm - hmm .\nso the semantics that you 'll get out of the discourse will be of values that go into the various discourse - based decision nodes . And now some of those will get fancier like mode of transportation and stuff so it isn't by any means uh necessarily a simple thing that you want out . So uh if there is an and there is mode of transportation\nAnd it there 's a sort of also a split if you loo if you blow this up and look at it in more detail there 's something that comes from the discourse in terms of what was actually just said what 's the utterance go giving us\nYeah .\nand then what 's the discourse history give us .\nYeah , well that , well , we 'll have to decide uh how much of th where that goes .\nMm - hmm .\nThat 's uh two things then .\nMm - hmm .\nMmm .\nan and it 's not clear yet . I mean it could be those are two separate things , it could be that the discourse gadget itself integrates em as  which would be my guess that you 'd have to do see in order to do reference and stuff like that um you 've gotta have both the current discourse and the context to say I wanna go back there ,\nMm - hmm .\nwow , what does that mean and uh\nMm - hmm\nNow . Mm - hmm .\nAlright . So\nBut is th is this picture that 's emerging here just my wish that you have noticed already for symmetry or is it that we get for each  each decision on the very bottom we sort of get the sub - E , sub - D , sub - U and maybe a sub - O  \" O \" for \" ontology \" um meta node\nI don't know .\nbut it might just\nIt could be .\ncould be\nThis is  this is getting into the thing I wanna talk about next ,\nso this\nwhich is s if that 's true uh how do we wanna combine those ? O or when it 's true ?\nbut this eh w wou wou would be nice though that , you know , we only have at most four at the moment um arrows going f to each of the uh bottom decisions .\nYeah .\nYeah .\nAnd four you  we can handle .\nNo .\nYeah .\nIt 's too much ?\nWell i i it see i if it 's fou if it 's four things and each of them has four values it turns out to be a big CPT , it 's not s completely impossi I mean it 's  it 's not beyond what the system could solve but it 's probably beyond what we could actually uh write down . or learn .\nRight , true .\nUh but , you know it 's four to the fourth . It 's pretty big . Uh .\nTwo fifty - six ,\nYeah .\nis that what that\nYeah , I mean it 's and I don't think it 's gonna g e I don't think it 'll get worse than that by the way , so le that 's a  that 's a good\nMmm yeah .\nBut  but four  didn't we decide that all of these had true or false ? So is  it 's four\nUh for go there , but not f but not for  the other one 's three values for endpoint already .\nYeah .\nYeah , I mean you need actually three to the five because uh well I mean if  if it has four inputs and then it itself has three values\nRight .\nso I mean it can get big fast .\nUm for endpoint ? No it 's  it 's sh\nEV - it 's the EVA .\nyeah , down here , but this one only has two .\nNo .\nNo it still has three ,\nSince ta they will still have three .\nEVA .\nEach  so you 're uh uh from each point of view you 're making the same decision .\nMm - hmm . Mm - hmm .\nSo from the point of view of the ob of the entity\nWant to view that , yeah yeah . C sl\nYeah .\nyeah\nThis  and also , I mean , the other places where , like for example consider endpoint view , it has inputs coming from user budget , user thrift\nRight .\nso even\nThose are not necessarily binary . S so we 're  we 're gonna have to use some t care in the knowledge engineering to not have this explode . And in fact I think it doesn't in the sense that um Read it , you know actually with the underlying semantics and stuff I think it isn't like you have two hundred and fifty - six different uh ways of  of thinking about whether this user wants to go to some place . Alright . So we  we just have to figure out what the regularities are and and code them . But um What I was gonna suggest next is maybe we wanna work on this a little longer but I do want to also talk about the thing that we started into now of uh well it 's all fine to say all these arrows come into the si same place what rule of combination is used there .\nMm - hmm .\nSo th yes they  so these things all affect it ,\nRight .\nhow do they affect it ? And belief - nets have their own beliefs about uh what are good ways to do that . So is it  it 's  it 's clearer n clear enough what the issue is ,\nRight .\nright ? So do we wanna switch that now or we wanna do some more of this ?\nR basically w we just need to sort of in order to get some closure on this figure out how we 're gonna get this picture sort of uh completely messy .\nWell , here  he here 's one of the things that  that I th you sh you  no , I don't know how easy it is to do this in the interface but you  it would be great if you could actually just display at a given time uh all the things that you pick up , you click on \" endpoint \" , OK and everything else fades\nMm - hmm .\nand you just see the links that are relevant to that . And I does anybody remember the GUI on this ?\nUh d I would almost say the other way to do that would be to open u or make you know N - many belief - nets and then open them every time you wanted to look at a different one\nMm - hmm .\nvers cuz uh\nIt 's probably pretty easy do it  to do it in HTML , just\nYeah , but\nUh\nHTML ?\nYeah I have each of these thing each of the end belief - nets be  be a page and then you click on the thing and then li consider that it 's respective ,\nYeah the  well the b\nOK .\nbut\nanyway so uh it clear that even with this if we put in all the arrows nobody is gonna be able to read the diagram .\nYeah .\nAlright , so e we have to figure out some eh eh uh basically display hack or something to do this because anyway I  I  let me consi suggest that 's a s not a first - order consideration , we have two first - order considerations which is what are the uh influences A , A , and B how do they get combined mathematically , how do we display them is an issue , but um\nI don't , yeah I just don't think this has been designed to support something like that .\nYeah . Yeah , I  I mean , it might soon , if this is gonna be used in a serious way like java base then it might soon be necessary to uh start modifying it for our purposes .\nRight . Yeah , and Um I  that seems like a perfectly feasible thing to get into , but um we have to know what we want first . OK , so why don't you tell us a little bit about decision nodes and what  what the choices might be for these ?\nSo Ah , sorry . I guess that 's\nYou can technically wear that as you 're talking .\nYeah , it 's right , I guess I can do that .\nDarn .\nPut it in your , yeah .\nI guess this board works fine . So um recall the basic problem which is that um you have a belief - net and you have like a lot of different nodes all contributing to one node . Right ? So as we discussed specifying this kind of thing is a big pain and it 's so will take a long time to write down because for example if these S have three possibilities each and this has three possibilities then you know you have two hundred and forty - three possibilities which is already a lot of numbers to write down . So what um helps us in our situation is that these all have values in the same set , right ? These are all like saying EV or A , right ? So it 's not just a generalized situation like I mean basically we wanna just take a combination of  we wanna view each of these as experts ea who are each of them is making a decision based on some factors and we wanna sort of combine their decisions and create you know , um sorta weighted combination .\nHmm . ROVER , the ROVER decision .\nThe what decision ?\nROVER . All of their outputs combined to make a decision .\nHmm .\nYeah . Yeah . So the problem is to specify the uh so the conditional property of this given all those , right ? That 's the way belief - nets are defined , like each node given its parents , right ? So um that 's what we want , we want for example P of um let 's call this guy Y and let 's call these X - one , X - two XN , right . So we want probability that Y equals , you know , for example um E given that these guys are I 'll just refer to this as like X um hat or something , uh the co like all of them ? Given that for example the data says you know , A , V , A , E , or something right ?\nYep .\nSo we would like to do this kind of combination .\nAlright , so um Is that uh I  yeah , I just wanna make sure everybody is with us before he goes on .\nI think so , yeah .\nIt 's  it 's cl e is  is it clear what he wants to compute ?\nMm - hmm .\nRight . So , right . So Basically um  what we don't wanna do is to for every single combination of E and V and A and every single letter E , s give a number\nMm - hmm .\nbecause that 's obviously not desirable . What we wanna do is find some principled way of um saying what each of these is and we want it to be a valid probability distribution , so we want it to um add up to one , right ?\nHmm .\nSo those are the two things that we uh need . So what uh I guess , what Jerry suggested earlier was basically that we , you know view these guys as voting and we just take the uh we essentially take um averages , right ? So for example here two people have voted for A , one has voted for V , and one has voted for E , so we could say that the probabilities are , you know , probability of being E is one over four , because one person voted for E out of four and similarly , probability of so this is probability of E s and then probability of A given all that is um two out of four and probability of V is one out of four . Right ? So that 's step  that 's the uh yeah that 's the  that 's the basic uh thing . Now\nUm Yeah .\nIs that all OK ?\nAnd that one outcome , that 's\nWhat ?\nit 's X  X - one voted for A X - two voted for V\nMm - hmm .\nand so forth ?\nY right . Yep .\nYeah .\nYeah .\nS so this assumes symmetry and equal weights and all this sort of things , which may or may not be a good assumption ,\nThat 's the outcome .\nMm - hmm . Right .\nso that\nYeah . Yeah . So step two is um right . So we 've assumed equal weights whereas it might turn out that you know , some w be that for example , what the um the actual the uh verbal content of what the person said , like what uh what might be uh somehow more uh important than the uh\nX - one matters more i than X - two or\nRight . Sure , so we don't wanna like give them all equal weight so currently we 've been giving them all weight one fourth so we could replace this by uh W - one , W - two , W - three , and W - four\nHmm .\nright ? And in order for this to be a valid probability distribution for each um X - hat , we just need that the W 's sum to one . So they can be for example , you know you  you could have point one , point three , point two , and point four , say .\nThat 's one .\nAnd that 'd be one . So that um also seems to work fine . And uh\nSo I jus just to make sure I understand this , so in this case um we would still compute the average ?\nYou 'd compute the weighted average , so the probability of E would be uh\nOK , so  so it 'd be so in this case the probability that Y equals A would be uh  W one times\nPoint three .\nor A or  let 's see , one full quarter times point one\nNot one quarter ,\nNo .\nso these numbers have been replaced with point one , point three , point two , and point four . So you can view these as gone .\nOK .\nProbability of\nOK .\nYeah . Yeah . OK . So , alright . So this is uh step two . So the next possibility is that um we 've given just a single weight to each expert , right , whereas it might be the case that um in certain situations one of the experts is more uh reliable and in certain situations the other expert is more reliable . So the way this is handled is by what 's called a mixture of experts , so what you can have is you augment these diagrams like this so you have a new thing called \" H \" , OK ? This is a hidden variable . And what this is is it gets its input from X - one , X - two , X - three , and X - four , and what it does is it decides which of the experts is to be trusted in this particular situation . Right ? And then these guys all come here . OK . So this is sightly uh more complicated . So what 's going on is that um this H node looks at these four values of those guys and it decides in given these values which of these isn't likely to be more reliable or most reliable . So H produces some you know , it produces a number , either one , two , three , or four , in our situation , right ? Now this guy he looks at the value of H say it 's two , and then he just selects the uh thing . That 's all there is to say , I guess about it . Right , so you can have a mixture that\nMm - hmm .\nRight .\nSo  so the function of the thing that comes out of H is very different from the function of the other inputs . It 's driving how the other four are interpreted . OK .\nYeah . Yeah .\nSo H passes a vector on to the next node ?\nIt could .\nIt could ? A vector of the weights as the se\nYeah , it could\noh .\nSorry ?\nWell a vector with three zero 's and one one , right ?\nOh it 's basically to tell the bottom node which one of the situations that it 's in or which one of the weighting systems\nRight , so I mean the way you desc\nW I was just , if you wanted to pay attention to more than one you could pass a w a weighting s system though too , couldn't you ? OK .\nUm Does H have to have another input to tell it alpha , beta , whatever , or is the  that 's determined by what the experts are saying , like the type of situ OK . Hmm . OK . OK . I mean It  it just seems that like without that  that outside input that you 've got a situation where , you know , like if  if uh X - one says no , you know , a low value coming out of X - on or i if X - one says no then ignore X - one , you know , I mean that seems like that 'd be weird ,\nYeah , well could be things like if X - two and X - three say yes then i ignore X - one also .\nright ? Oh , OK . OK . Alright , right .\nOh The situations that H has , are they built into the net or OK , so they  they could either be hand coded or learned or OK .\nYeah .\nBased on training data , OK .\nYeah . Yes .\nSo you specify one of these things for every one of those possi possible situations . Oh yeah .", "topic_id": 3, "keywords": "discourse, utterance, talking, talk, semantics", "dialogue_id": 33}, {"text": "Yeah . Um Well , I mean to learn them we need data , where are we gonna get data ? Well I mean we need data with people intentions , right ?\nRight , right .\nWhich is slightly tricky . Right .\nUh - huh .\nMm - hmm . But what 's the data about like , are we able to get these nodes from the data ?\nLike how thrifty the user is , or do we have access to that ? Mm - hmm . Oh right . Oh good . OK .\nYeah .\nMm - hmm . Mm - hmm . OK .\nYeah , but that 's my question , like how do we  I mean , how do we have data about something like um um endpoint sub - E , or endpoint sub uh  you know s S ?\nWell , basically you would say , based on  in this dialogue that we have which one of the things that they said eh whether it was the entity relations or whatever was the thing that determined what mode it was ,\nMmm . Mmm .\nright ?\nSo this is what we wanna learn . Yep . Right . Hmm . Yeah . I don't think , well you have a  can you bring up the function thing ? Um w where is the thing that allows you to sort of\nThat 's on the added variable , isn't it ?\nOh function properties , is that it ? Hmm , I guess not . Yeah , that 's\nNo .\nRight . OK . And um it so e either it 'll allow us to do everything which I think is unlikely , I think more likely it 'll allow us to do very few of these things and in that case we 'll have to um just write up little things that allow you to um create such CPU 's on your own in the java base format . Yeah . Yeah . Yeah , I was assuming that 's what we 'd always do because yeah I was assuming that 's what we 'd always do , it 's Right . Yeah .\nAh . Well in terms of java base I think it 's basically what you see is what you get in I don't yeah , I would be surprised if it supports anything more than what we have right here .\nSo Yeah . Yeah . By the way um uh just talking about uh about that general end of things uh is there gonna be data soon from what people say when they 're interacting with the system and so on ? Like , I mean , what kind of questions are being given  being asked ? Cuz  OK . Yeah yeah . OK . OK . Fey , you mean . OK . OK . O OK . OK . I 'm just wondering , because in terms of , you know , I mean uh w the figure  I was thinking about this figure that we talked about , fifty constructions or whatever that 's uh that 's a whole lot of constructions and um you know , I mean one might be f fairly pleased with getting a really good analysis of five maybe ten in a summer so , I mean I know we 're going for sort of a rough and ready . Mm - hmm . Mm - hmm . OK . OK . I mean , I  I  I  I was  uh I was talking about the , you know , if you wanted to do it really in detail and we don't really need all the detail for what we 're doing right now but anyway in terms of just narrowing that task you know which fifty do I do , I wanna see what people are using , so Well , it will inspire me . Right , sure sure . Right . Yeah , sure . Sure . Yeah . OK . Touche . Good enough .", "topic_id": 4, "keywords": "data, endpoint, entity, nodes, constructions", "dialogue_id": 33}, {"text": "OK .\nAdam , what is the mike that , uh , Jeremy 's wearing ?\nIt 's the ear - plug mike .\nEar - plug .\nThat 's good .\nIs that a wireless , or  ? Oh .\nNo .\nIt 's wired .\nOh !\nIs that  Does that mean you can't hear anything during the meeting ?\nIt 's old - school .\nHuh ? What ? Huh ?\nShould we , uh , close the door , maybe ?\nIt  it 's a fairly good mike , actually .\nSo it 's  Yeah . Huh .\nWell , I shouldn't say it 's a good mike . All I really know is that the signal level is OK . I don't know if it 's a  the quality .\nWell , that 's a\nUgh ! So I didn't send out agenda items because until five minutes ago we only had one agenda item and now we have two . So .  And , uh .\nOK . So , just to repeat the thing bef that we said last week , it was there 's this suggestion of alternating weeks on  more , uh , automatic speech recognition related or not ? Was that sort of  the division ?\nRight .\nSo which week are we in ?\nWell  We haven't really started , but I thought we more  we more or less did Meeting Recorder stuff last week , so I thought we could do , uh\nI thought we had a thing about speech recognition last week too .\nYeah .\nBut I figure also if they 're short agenda items , we could also do a little bit of each .\nYeah .\nSo . I seem to be having difficulty getting this adjusted . Here we go .\nOK .\nSo , uh , as most of you should know , I did send out the consent form thingies and , uh , so far no one has made any  Ach !   any comments on them . So , no on no one has bleeped out anything .\nUm . Yeah .\nSo . I don't expect anyone to . But .\nUm .  So , w what follows ? At some point y you go around and get people to sign something ?\nNo . We had spoken w about this before\nYeah , but I 've forgotten .\nand we had decided that they have  they only needed to sign once . And the agreement that they already signed simply said that we would give them an opportunity . So as long as we do that , we 're covered .\nAnd how long of an opportunity did you tell them ?\nUh , July fifteenth .\nJuly fifteenth . Oh , so they have a plenty of time , and y\nYep .\nGiven that it 's that long , um , um  Why was that date chosen ? You just felt you wanted to  ?\nJane told me July fifteenth . So , that 's what I set it .\nOh . I just meant that that was  the release date that you had on the  data .\nOh , OK .\nOh . I  I didn't understand that there was something specific .\nI , uh  I thought\nYou  y you had\nI don't\nI had heard July fifteenth , so that 's what I put .\nMm - hmm .\nNo , the only  th the only  mention I recall about that was just that July fifteenth or so is when  this meeting starts .\nSo .\nThat 's right . That 's why .\nOh , I see .\nYou said you wanted it to be available then .\nOK .\nI didn't mean it to be the hard deadline .\nRight .\nIt 's fine with me if it is , or we cou But I thought it might be good to remind people two weeks prior to that\nw\nin case , uh  you know , \" by the way  this is your last  \"\nRight .\nUh . Yeah .\nWe probably should have talked about it , cuz i because if we wanna be able to give it to people July fifteenth , if somebody 's gonna come back and say \" OK , I don't want this and this and this used \" , uh , clearly we need some time to respond to that . Right ?\nYeah . As I said , we  I just got one date\nYeah .\nDamn !\nand that 's the one I used .\nYeah .\nSo . But I can send a follow - up . I mean , it 's almost all us . I mean the people who are in the meeti this meeting was , uh , these  the meetings that  in  are in set one .\nWas my  was my response OK ?\nThat 's right .\nI just wrote you  replied to the email saying they 're all fine .\nRight . I mean , that 's fine .\nOK , good .\nI  we don't  My understanding of what we  had agreed upon when we had spoken about this months ago was that , uh , we don't actually need a reply .\nThat makes it easy .\nWe just need to tell them that they can do it if they want .\nOK . I just didn't remember , but\nAnd so no reply is no changes .\nAnd he 's got it so that the default thing you see when you look at the page is \" OK \" .\nOK .\nSo that 's very clear all the way down the page , \" OK \" . And they have two options they can change it to . One of them is  \" censor \" , and the other one is \" incorrect \" . Is it  is  your word is \" incorrect \" ?\nRight .\nWhich means also we get feedback on  if  um , there 's something that they w that needs to be  adjusted , because , I mean , these are very highly technical things . I mean , it 's an added , uh , level of checking on the accuracy of the transcription , as I see it . But in any case , people can agree to things that are wrong .\nWell\nSo .\nYeah . The reason I did that it was just so that people would not censor  not ask to have stuff removed because it was transcribed incorrectly ,\nAnd the reason I liked it was because\nas opposed to , uh\nwas because it , um  it gives them the option of , uh , being able to correct it .\nRight .\nApprove it and correct it . And  um . So , you have  it nicely set up so they email you and , uh\nWhen they submit the form , it gets processed and emailed to me .\nMm - hmm . Mm - hmm . And I wanted to say the meetings that are involved in that set are Robustness and Meeting Recorder .\nSo .\nThe German ones will be ready for next week . Those are three  three of those . A different set of people . And we can impose\nThe German ones ?\nUh , well .\nYeah . Those  uh\nNSA .\nOK . I spoke loosely . The  the German , French  Sorry , the German ,  Dutch , and Spanish ones .\nSpanish . Yeah .\nMm - hmm .\nOh , those are the NSA meetings ?\nThe non - native\nThose are\nYeah . Uh - huh .\nGerman , Dutch , Swiss and Spanish .\nOh , oh ! OK .\nThe all non - native\nThat 's  that 's  that 's r\nMm - hmm .\nUh - huh .\nOK . I 'd  I d\nYeah .  It 's the other group .\nI It was the network  network services group .\nOK .\nUh - huh . Yeah , exactly . Yeah .\nYeah .\nI didn't mean to  isolate them .\nOtherwise known as the German , Dutch , and Spanish .\nYeah . Sorry . It was  it was not the best characterization .\nMm - hmm .\nBut what   what I meant to say was that it 's the other group that 's not  n no m no overlap with our present members . And then maybe it 'd be good to set an explicit deadline , something like  a week  before that , uh , J July fifteenth date , or two weeks before .\nI mean , I would suggest we discuss  I mean , if we 're going to have a policy on it , that we discuss the length of time that we want to give people ,\nMm - hmm .\nso that we have a uniform thing . So , tha that 's a month , which is fine . I mean , it seems\nTwelve hours .\nWell , the only thing I said in the email is that  the data is going to be released on the fifteenth . I didn't give any other deadline .\nMm - hmm .\nSo my feeling is if someone after the fifteenth says , \" wow I suddenly found something \" , we 'll delete it from our record . We just won't delete it from whatever 's already been released .\nHmm . That 's a little bit difficult .\nWhat else can we do ?\nYeah .\nIf someone says \" hey , look , I  found something in this meeting and  it 's libelous and I want it removed \" . What can we do ?\nWell .  That 's true .\nWe have to remove it .\nI  I agree with that part , but I think that it would  it , uh  we need to have , uh , a  a  a message to them very clearly that  beyond this date , you can't make additional changes .\nI mean , um , I  I   i I think that somebody might  request something even though we say that . But I think it 's good to at least start some place like that .\nMm - hmm . Good .\nSo if we agreed ,  OK , how long is a reasonable amount of time for people to have  if we say two weeks , or if we say a month , I think we should just say that  say that , you know , i a as  um ,  \" per the  the  the , uh , page you signed , you have the ability to look over this stuff \" and so forth \" and , uh , because we w \" these , uh  I would  I would imagine some sort of generic thing that would say \" because we , uh , will continually be making these things available  to other researchers , uh , this can't be open - ended and so , uh , uh , please give us back your response within this am you know , within this amount of time \" , whatever time we agree upon .\nWell , did you read the email and look at the pages I sent ?\nDid I ? No , I haven't yet . No , just\nNo . OK , well why don't you do that and then make comments on what you want me to change ?\nNo , no . I 'm not saying that you should change anything . I I 'm  what I 'm  what I 'm   I 'm trying to spark a discussion hopefully among people who have read it so that  that you can   you can , uh , decide on something .\nMm - hmm .\nSo I 'm not telling you what to decide .\nMm - hmm .\nI 'm just saying you should decide something ,\nOK .\nand then\nI already did decide something , and that 's what 's in the email .\nYeah , yeah . OK , so\nAnd if you disagree with it , why don't you read it and give me comments on it ?\nYeah . Well  I  I think that there 's one missing line .\nWell , the one thing that I did read and that you just repeated to me  was that you gave the specific date of July fifteenth .\nMm - hmm .\nAnd you also just said that the reason you said that was because someone said it to you . So what I 'm telling you  is that what you should do is come up with a length of time that you guys think is enough\nRight .\nand you should use that rather than  this date that you just got from somewhere . That 's all I 'm saying .\nOK .\nOK ?\nI ha I have one question . This is in the summer period and presumably people may be out of town . But we can make the assumption , can't we ? that , um , they will be receiving email , uh , most of the month . Right ? Because if someone\nIt  well , it  well , you 're right . Sometimes somebody will be  away and , uh , you know , there 's , uh  for any length of time that you  uh , choose  there is some person sometime who will not  end up reading it .\nOK .\nThat 's  it 's , you know , just a certain risk to take .\nS so maybe when  Am I on , by the way ?\nI don't know . You should be .\nOh . Hello ? Hello ?\nYou should be channel B .\nOh , OK . Alright . So . The , um  Maybe we should say in  w you know , when the whole thing starts , when they sign the   the agreement  that  you know , specify exactly uh , what , you know , how  how they will be contacted and they can , you know  they can be asked to give a phone number and an email address , or both . And , um , then\nWe did that , I  I believe .\nRight .\nYeah .\nSo .  A And , then , you know , say very clearly that if they don't  if we don't hear from them , you know , as Morgan suggested , by a certain time or after a certain  period after we contact them  that is implicitly giving their agreement .\nWell , they 've already signed a form .\nAnd the form says\nAnd nobody  nobody really reads it anyway .\nRight .\nSo . And the s and the form was approved by Human Subjects ,\nSays that . Right .\nUh , the f\nWell , if that 's i tha if that 's already  if\nso , eh , that 's gonna be a little hard to modify .\nWell , the form  Well , the form doesn't say , if  uh , you know , \" if you don't respond by X number of days or X number of weeks  \"\nI see . Uh  Oh , OK . So what does it say about the  the  the process of  of , uh   y the review process ?\nIt doesn't have a time limit . That you 'll be provided access to the transcripts and then , uh , allowed to  remove things that you 'd like to remove , before it goes to the general  uh , larger audience .\nOh , OK . Hmm . Right .\nHere .\nThere you go .\nYou can read what you already signed .\nOh .\nI guess when I  read it , um\nOK .\nI 'm not as diligent as Chuck , but I had the feeling I should probably respond and tell Adam , like , \" I got this and I will do it by this date , and if you don't hear from me by then  \" You know , in other words responding to your email  once , right away , saying \" as soon as you get this could you please respond . \"\nRight .\nAnd then if you  if the person thinks they 'll need more time because they 're out of town or whatever , they can tell you at that point ? Because\nOh , I just  I didn't wanna do that , because I don't wanna have a discussion with every person  if I can avoid it .\nWell , it 's\nSo what I wanted to do was just send it out and say \" on the fifteenth , the data is released ,\nMm - hmm .\nif you wanna do something about it , do something about it , but that 's it \" .\nI  I kind of like this .\nWell\nYeah .\nOK . So , we 're assuming that\nWell , that 's  that would be great if  but you should probably have a  legal person look at this and  make sure it 's OK . Because if you  if you , uh , do this  and you  then there 's a dispute later and , uh , some   you know , someone who understands these matters concludes that they didn't have , uh , you know , enough opportunity to actually  exercise their  their right\nOr they  they might never have gotten the email , because although they signed this , they don't know by which date to expect your email . And so  someone whose machine is down or whatever  I mean , we have no\nMm - hmm .\nin internally we know that people are there ,\nWell , OK . l Let me  Let me reverse this .\nbut we have no confirmation that they got the mail .\nSo let 's say someone  I send this out , and someone doesn't respond . Do we delete every meeting that they were in ?\nWell , then\nI don't think so .\nIt  we 're hoping that doesn't happen ,\nNo .\nbut that 's why there 's such a thing as registered mail\nThat will happen .\nor\nThat will happen .\nRight .\nThat will absolutely happen . Because people don't read their email , or they 'll read and say \" I don't care about that , I 'm not gonna delete anything \" and they don just won't reply to it .\nMaybe  uh , do we have mailing addresses for these people ?\nNo . We have what they put on the speaker form ,\nNo .\nWell    Most\nwhich was just generic contact information .\nOh .\nBut the ones that we 're dealing with now are all local ,\nWell , then\nexcept the ones who  I mean , we  we 're totally in contact with all the ones in those two groups .\nMmm . OK .\nSo maybe , uh , I  you know , that 's not that many people and if I  if , uh  i i there is an advantage to having them admit  and if I can help with  with processing that , I will . It 's  it 's  there is an advantage to having them be on record as having received the mail and indicating\nYeah . I mean I thought we had discussed this , like , a year ago .\nYes , we did .\nAnd so it seems like this is a little odd for it to be coming up yet again .\nYou 're right . Well , I  you know . But sometimes\nWell , we  we haven't experienced it before .\nSo .\nThat 's right .\nRight ? So\nYou 'll either wonder  at the beginning or you 'll wonder at the end .\nNeed to get it right .\nI mean , there 's no way to get around  I It 's pretty much the same am amount of work except for an additional email just saying they got the email .\nYeah .\nAnd maybe it 's better legally to wonder before  you know , a little bit earlier than\nWell\nIt 's much easier to explain  this way .\nOK . Well , why don't you talk  t\nT t to have it on record .\nMorgan , can you talk to our lawyer about it , and find out what the status is on this ? Cuz I don't wanna do something that we don't need to .\nYeah , but w Mmm .\nBecause what  I 'm telling you , people won't respond to the email . No matter what you do , you there 're gonna be people who  you 're gonna have to make a lot of effort to get in contact with .\nWell , then we make the effort .\nI mean , i it 's k\nAnd do we want to spend that effort ?\nHmm .\nWe make the effort .\nIt 's kind of like signing up for a mailing list . They have opt in and opt out . And there are two different ways . I mean , and either way works probably , I mean .\nExcept I really think in this case  I  I 'm agr I agree with Liz , that we need to be  in the clear and not have to after the fact say \" oh , but I assumed \" , and \" oh , I 'm sorry that your email address was just accumulating mail without notifying you \" , you know .\nIf this is a purely administrative task , we can actually have administration do it .\nOh , excellent .\nBut the thing is that , you know , I  I  I think , without going through a whole expensive thing with our lawyers ,  from my previous conversations with them , my  my sense very  much is that we would want something on record  as indicating that they actually were aware of this .\nYes .\nWell , we had talked about this before\nMm - hmm .\nand I thought that we had even gone by the lawyers asking about that and they said you have to s they 've already signed away the f with that form  that they 've already signed once .\nI don't remember that this issue of  the time period allowed for response was ever covered .\nYeah .\nYeah . We never really talked about that .\nOK .\nOr the date at which they would be receiving the email from you .\nOr  or how they would indicate\nYeah .\nThey probably forgot all about it .\nWe certainly didn't talk , uh , about  with them at all about , uh , the manner of them being   made the , uh , uh , materials available .\nYeah .\nWe do it like with these\nThat was something that was sort of just within our implementation .\nOK .\nWe can use it  we can use a  a ploy like they use to , um  you know , that when they serve , like  uh , uh , uh   uh , you know , like dead - beat dads , they  they  they make it look like they won something in the lottery and then they open the envelope\nAnd they 're served .\nand that  Right ? Because  and then the  the  the  the thing is served . So you just make it , you know , \" oh , you won  you know , go to this web site and you 've , uh  you 're  \"\nThat 's why you never open these things that come in the mail .\nThat one .\nYeah .\nWell , it 's just , we 've gone from one extreme to the other , where at one point , a few months ago , Morgan was  you were saying let 's not do anything ,\nRight .  Right . No , it I  it might\nWell , it doesn't matter .\ni i it  it might well be the case\nand now we 're  we 're saying we have to follow up each person and get a signature ?\nit might  Right .\nI mean , what are we gonna doing here ?\nIt might well be the case that  that this is perfectly  you know , this is enough to give us a basis t to just , eh , assume their consent if they don't reply .\nWell .\nMm - hmm .\nBut , I 'm not  you know , me not being a lawyer , I wouldn't just wanna do that without  having the  the expert , uh , opinion on that .\nAnd how many people ? Al - altogether we 've got twenty people . These people are people who read their email almost all the time .\nThen I think we had better find out , so that we can find a\nYeah .\nLet me look at this again .\nRight .\nI  I really don't see that it 's a problem . I  I think that it 's a common courtesy to ask them  uh , to expect for them to , uh , be able to have @ @  us try to contact them ,\nFor  for th\nu just in case they hadn't gotten their email . I think they 'd appreciate it .\nYeah . My  Adam , my  my view before was about  the nature of what was  of the presentation ,\nMm - hmm .\nof  of how  my  my  the things that we 're questioning were along the lines of how easy  uh , h how m how much implication would there be that it 's likely you 're going to be changing something , as opposed to\nMm - hmm .\nThat was the kind of dispute I was making before .\nMm - hmm . I remember that .\nBut , um , the attorneys , I  uh , I can guarantee you , the attorneys will always come back with  and we have to decide how stringent we want to be in these things , but they will always come back with saying  that , um , you need to  you want to have someth some paper trail or  which includes electronic trail   that they have , uh , in fact  O K 'd it .\nMm - hmm .\nSo , um , I think that if you f i if  we send the email as you have and if there 's half the people , say , who don't respond  at all by , you know , some period of time ,  we can just make a list of these people and hand it to , uh  you know , just give it to me and I 'll hand it to administrative staff or whatever ,\nRight .\nand they 'll just call them up and say , you know , \" have you  Is  is this OK ? And would you please mail  you know , mail Adam that it is , if i if it , you know , is or not . \" So , you know , we can  we can do that .\nThe other thing that there 's a psychological effect that  at least for most people , that if they 've responded to your email saying \" yes , I will do it \" or \" yes , I got your email \" , they 're more likely to actually do it   later  than to just ignore it .\nMm - hmm .\nAnd of course we don't want them to bleep things out , but it  it 's a little bit better if we 're getting the  their , uh , final response , once they 've answered you once than if they never answer you 'd  at al at all . That 's how these mailing houses work . So , I mean , it 's not completely lost work because it might benefit us in terms of getting  responses .\nMm - hmm .\nYou know , an official OK from somebody  is better than no answer , even if they responded that they got your email . And they 're probably more likely to do that once they 've responded that they got the email .\nI also think they 'd just simply appreciate it . I think it 's a good  a good way of  of fostering goodwill among our subjects . Well , our participants .\nI think the main thing is  I mean , what lawyers do is they always look at worst cases .\nSending lots of spam .\nSo they s so  so  Tha - that 's what they 're paid to do .\nYep .\nAnd so ,  it is certainly possible that , uh , somebody 's server would be down or something and they wouldn't actually hear from us , and then they find this thing is in there and we 've already distributed it to someone . So ,  what it says in there , in fact , is that they will be given an opportunity to blah - blah - blah ,\nMm - hmm .\nbut if in fact  if we sent them something or we thought we sent them something but they didn't actually receive it for some reason ,  um , then we haven't given them that .\nWell , so how far do we have to go ? Do we need to get someone 's signature ? Or , is email enough ?\nI i i em email is enough .\nDo we have to have it notarized ? I mean  OK .\nYeah . I mean , I 've been through this  I mean , I 'm not a lawyer , but I 've been through these things a f things f like this a few times with lawyers now\nMm - hmm .\nso I  I  I I 'm pretty comfortable with that .\nDo you track , um , when people log in to look at the  ?\nUh . If they submit the form , I get it .\nUh - huh .\nIf they don't submit the form , it goes in the general web log . But that 's not sufficient .\nHmm .\nRight ? Cuz if someone just visits the web site that doesn't  imply anything in particular .\nExcept that you know they got the mail .\nMm - hmm . That 's right .\nRight .\nI  I could get you on the notify list if you want me to .\nI 'm already on it .\nFor that directory ? OK , great .\nMm - hmm .\nSo again , hopefully , um , this shouldn't be quite as odious a problem either way , uh , in any of the extremes we 've talked about because  uh , we 're talking a pretty small  number of people .\nW For this set , I 'm not worried , because  we basically know everyone on it .\nMm - hmm .\nHmm .\nMm - hmm .\nYou know , they 're all more or less here or it 's  it 's Eric and Dan and so on . But for some of the others , you 're talking about visitors who are  gone from ICSI , whose email addresses may or may not work ,\nMm - hmm .\nOh .\nMm - hmm .\nand  So what are we gonna do when we run into someone that we can't get in touch with ?\nI don't think , uh  They 're so recent , these visitors .\nMm - hmm .\nI  and  and I  they 're also so\nMm - hmm .\nThey 're prominent enough that they 're easy to find through  I  I mean , I  I w I 'll be able to  if you have any trouble finding them , I really think I could find them .\nOther methods ? OK .\nYeah . Cuz it  what it  what it really does promise here is that we will ask their permission . Um , and I think , you know , if you go into a room and close the door and  and ask their permission  and they 're not there , it doesn't seem  that that 's the intent of , uh , meaning here . So .\nWell , the qu the question is just whether  how active it has to be . I mean , because they  they filled out a contact information and that 's where I 'm sending the information .\nRight .\nAnd so far everyone has done email . There isn't anyone who did , uh , any other contact method .\nWell , the way ICSI goes , people , uh , who , uh , were here ten years ago still have acc  have forwards to other accounts and so on .\nYeah .\nSo it 's unusual that  that they , uh\nSo my original impression was that that was sufficient , that if they give us contact information and that contact information isn't accurate that  we fulfilled our burden .\nYeah .\nThen they just come back .\nAll my files were still here .\nSame as us .\nI just\nSo if we get to a boundary case like that then maybe I will call the attorney about it .\nYeah .\nOK .\nBut , you know , hopefully we won't need to .\nI d I just don't think we will . For all the reasons that we 've discussed .\nAlright .\nSo we 'll  we 'll see if we do or not .\nYep . And we 'll see how many people respond to that email .\nYeah .\nSo far , two people have .\nYeah . I think very few people will\nSo .\nand  and  and , you know , people  people see long emails about things that they don't think  is gonna be high priority , they typically , uh , don't  don't read it , or half read it .\nRight .\nCuz people are swamped .\nAnd actually ,\nBut\num , I  I  didn't anticipate this so I  that 's why I didn't give this comment , and it  I  this discussion has made me think it might be nice to have a follow - up email within the next couple of days saying \" by the way , you know , we wanna hear back from you by X date and please  \" , and then add what Liz said  \" please , uh , respond to  please indicate you received this mail . \"\nUh , or e well , maybe even additionally , uh , um , \" Even if you 've decided you have no changes you 'd like to make , if you could tell us that \" .\nRespond to the email .  Yep .\nMm - hmm . It is the first time through the cycle .\nYeah .\nRight . That would  that would definitely work on me . You know , it makes you feel m like , um , if you were gonna p if you 're predicting that you might not answer , you have a chance now to say that . Whereas , I  I mean , I would be much more likely myself ,\nAnd the other th\ngiven all my email , t to respond at that point , saying \" you know what , I 'm probably not gonna get to it \" or whatever , rather than just having seen the email , thinking I might get to it , and never really ,  uh , pushing myself to actually do it until it 's too late .\nYeah . I was  I was thinking that it also  lets them know that they don't have to go to the page to  accept this .\nRight . R Right . That 's true .\nRight .\nI mean , I  I  Yeah . So that way they could  they can see from that email that if they just write back and say \" I got it , no changes \" , they 're off the hook .\nYeah .\nThey don't have to go to the web page\nI mean , the other thing I 've learned from dealing with  dealing with people sending in reviews and so forth , uh , is , um ,  if you say \" you 've got three months to do this review \" ,  um , people do it , you know ,  two and seven eighths months from now .\nand\nYeah . That 's true .\nIf you say \" you 've got three weeks to do this review \" , they do  do it , you know , two and seven eighths weeks from now   they do the review .\nRight .\nAnd , um  So , if we make it  a little less time , I don't think it 'll be that much\nWell , and also if we want it ready by the fifteenth , that means we better give them deadline of the first , if we have any prayer of actually getting everyone to respond in time .\nThere 's the responding part and there 's also what if , uh , I mean , I hope this doesn't happen , what if there are a bunch of deletions that have to get put in and changes ?\nRight .\nThen  we actually have to deal with that\nMm - hmm . Some lead time .\nif we want it to\nUgh ! Disk space ,\nBy the way , has  has Jeremy signed the form ?\noh my god ! I hadn't thought about that .\nOK .\nThat for every meeting  any meeting which has any bleeps in it we need yet another copy of .\nOh .\nJust that channel .\nCan't you just do that channel ?\nOh , no . We have to do\nNo , of course not .\nYeah . You have to do all of them ,\nYou need all the channels .\nOh .\nDo you have to do the other close - talking ?\nas well as all of these .\nYeah .\nYou have to do all  You could just do it in that time period , though ,\nYes . Absolutely . There 's a lot of cross - talk .\nWow .\nWell\nbut I guess it 's a pain .\nWell , but you have to copy the whole file .\nYeah .\nRight ? Because we 're gonna be releasing the whole file .\nYeah . You 're right .\nWell   I  you know , I think at a certain point , that copy that has the deletions will become the master copy .\nYeah . It 's just I hate deleting any data . So I  I don't want  I really would rather make a copy of it , rather than bleep it out\nAre you del are you bleeping it by adding ?\nand then  Overlapping . So , it 's  it 's exactly a censor bleep . So what I really think is \" bleep \"\nI I I I understand , but is  is it summing signals\nand then I want to\nor do you  delete the old one and put the new one in ?\nI delete the old one , put the new one in .\nOh , OK . Cuz\nThere 's nothing left of the original signal .\nOh . Cuz if you were summing , you could  No . But anyway\nYeah . It would be qui quite easy to get it back again .\nBut   And then w I was gonna say also that the they don't have to stay on the system , as you know ,\nYeah .\nThen someday we can sell the  unedited versions .\ncuz  cuz the  the ones\nSay again ?\nOnce it 's been successfully bleeped , can't you rely on the  ?\nOr  we 'll tell people the frequency of the beep\nEncrypt it .\nand then they could subtract the beep out .\nYou can hide it . Yeah .\nCan't you rely on the archiving to preserve the older version ?\nOh , yeah .\nIt wouldn't be that hard to hide it .\nRight . Exactly . I see .\nYeah , that 's true . Yeah . Yep , that 's true .\nSee , this is good . I wanted to create some  side conversations in these meetings .\nOK .\nYeah . You could encrypt it , you know , with a  with a two hundred bit   thousand bit , uh\nYou can use spread spectrum .\nUh - huh .\nHide it .\nSo\nHere we go .\nYeah . Yeah .\nYeah , there you go .\nCuz we don't have enough asides .\nI have an idea . You reverse the signal ,\nThere you go .\nso it  it lets people say what they said backwards .\nBackwards .\nThen you have , like , subliminal , uh , messages ,\nBut , ha you 've seen the  this  the speech recognition system that reversed very short segments .\nYeah .\nlike .\nDid you read that paper ? It wouldn't work .\nNo .\nThe speech recognizer still works .\nYeah . And if you do it backward then\nYeah .\nThat 's cuz they use forward - backward .\nH - good old HMM .\nForward but backward . That 's right .\nNo , it 's backward - forward .\nGood point . A point . Well , I 'm sorry if I sound a little peeved about this whole thing . It 's just we 've had meeting after meeting after meeting a on this and it seems like we 've never gotten it resolved .\nHmm .\nWell , but we never also  we 've also never done it .\nUh .\nSo .\nThis is the first cycle .\nIf it makes\nYeah .\nThere 're bound to be some glitches the first time through .\nSo .  And , uh  and I 'm sorry responding without , uh , having much knowledge , but the thing is , uh , I am , like , one of these people who gets a gazillion mails and  and stuff comes in as\nWell , and that 's exactly why I did it the way I did it , which is the default is if you do nothing we 're gonna release it .\nYeah .\nBecause , you know , I have my  stack of emails of to d to be done , that , you know , fifty or sixty long , and the ones at the top I 'm never gonna get to .\nRight .\nAnd , uh  So  so\nMove them to the bottom .\nSo  so the only thing we 're missing is  is some way to respond to easily to say , uh , \" OK , go ahead \" or something .\nYeah , right . So , i this is gonna mean\nJust re - mail them to yourself and then they 're at the bottom .\nYeah .\nYeah .\nYeah .\nYeah . That 's actually definitely a good point . The m email doesn't specify that you can just reply to the email , as op as opposed to going to the form\nMm - hmm .\nIn\nAnd it also doesn't give a  a specific  I didn't think of it .\nRight .\nand\nS I think it 's a good idea  an ex explicit time by which this will be considered definite .\nYeah , release .\nAnd  and it has to be a time earlier than that endpoint .\nYeah . It 's converging .\nYeah . That 's right .\nThis  um , I 've seen this recently . Uh , I got email , and it  i if I use a MIME - capable mail reader , it actually says , you know , click on this button to confirm receipt  of the  of the mail .\nOh , that 's interesting .\nHmm .\nSo\nYou  you can\nIt 's like certified mail .\nA lot of mailers support return receipt .\nCould do that .\nRight .\nBut it doesn't confirm that they 've read it .\nNo , no , no . This is different . This is not  So , I  I know , you can tell , you know , the , uh , mail delivery agent to  to confirm that the mail was delivered to your mailbox .\nMmm .\nRight .\nBut  but , no . This was different . Ins - in the mail , there was a\nOh , just a button .\nuh , th there was a button that when you clicked on it , it would send , uh , you know , a actual acknowledgement to the sender that you had actually looked at the mail .\nOh , yeah . Yeah . Unfor - Yeah , we could do that . But I hate that .\nBut it o but it only works for , you know , MIME - capable  you know , if you use Netscape or something like that for your n\nYeah .\nAnd\nYou might as well just respond to the mail .\nAnd we actually need a third thing .\nI mean\nRight .\nIt 's not that you 've looked at it , it 's that you 've looked at it and  and  and agree with one of the possible actions .\nNo , no . You can do that .\nRight ?\nYou know , you can put this button anywhere you want ,\nOh ? Oh , I see .\nand you can put it the bottom of the message and say \" here , by  you know , by clicking on this , I  I agree   uh , you know , I acknowledge  \"\nThat i i my first - born children are yours , and  Yeah . Yeah .\nQuick question . Are , um\nWell , I could put a URL in there without any difficulty and  even pretty simple MIME readers can do that . So .\nBut why shouldn't they just  email back ? I don't see there 's a problem .\nYeah .\nYeah . Reply .\nRight .\nIt 's very nice . I  I like the high - tech aspect of it ,\nYeah .\nbut I think\nNo , no , no .  I actually don't .\nI appreciate it .\nI 'm just saying that\nWell , I  cuz I use a text mail reader .\nif ev but I 'm\nDon't you use VI for your mai ?\nYeah .\nWow . That 's  that 's my guy . Alright .\nYou  you read email  in VI ?\nYeah .\nYeah .  I like VI .\nSo  I  i There 's these logos  that you can put at the bottom of your web page , like \" powered by VI \" .\nYeah .\nWow .\nI see .\nAnyway , quick question .\nYou could put wed bugs in the email .\nHow m\nYeah .\nLike , there were three meetings this time , or so\nSix .\nor how many ? Six ? But , no of different people . So I guess if you 're in both these types of meetings , you 'd have a lot . But   How  I mean , it also depends on how many  Like , if we release  this time it 's a fairly small number of meetings , but what if we release , like , twenty - five meetings to people ? In th\nWell , what my s expectation is , is that we 'll send out one of these emails  every time a meeting has been checked and is ready .\nI don't know . Oh . Oh , OK . So this time was just the first chunk . OK .\nSo . Tha - that was my intention . It 's just  yeah  that we just happened to have a bunch all at once .\nWell , that 's a good idea .\nI mean , maybe  Is that  the way it 's gonna be , you think , Jane ?", "topic_id": 0, "keywords": "conversations, meetings, mike, talking, meeting", "dialogue_id": 34}, {"text": "I agree with you . It 's  we could do it , uh  I I could  I 'd be happy with either way , batch - wise  What I was thinking  Uh , so this one  That was exactly right , that we had a  uh , uh  I  I had wanted to get the entire set of twelve hours ready . Don't have it . But , uh , this was the biggest clump I could do by a time where I thought it was reasonable .\nMm - hmm .\nPeople would be able to check it and still have it ready by then . My , um  I was thinking that with the  NSA meetings , I 'd like  there are three of them , and they 're  uh , I  I will have them done by Monday . Uh , unfortunately the time is later and I don't know how that 's gonna work out , but I thought it 'd be good to have that released as a clump , too , because then ,  you know , they 're  they  they have a  it it 's in a category , it 's not quite so distracting to them , is what I was thinking , and it 's all in one chu But after that , when we 're caught up a bit on this process , then , um , I could imagine sending them out periodically as they become available .\nOK .\nI could do it either way . I mean , it 's a question of how distracting it is to the people who have to do the checking .\nWe heard anything from IBM ? at all ?\nUh . Let 's see . We  Yeah , right . So we got the transcript back from that one meeting . Everything seemed fine . Adam  had a script that will  put everything back together and there was  Well , there was one small problem but it was a simple thing to fix . And then , um ,  we , uh  I sent him a pointer to three more . And so he 's  off and  working on those .\nYeah . Now we haven't actually had anyone go through that meeting , to see whether the transcript is correct and to see how much was missed and all that sort of stuff .\nThat 's on my list .\nSo at some point we need to do that .\nYeah .\nWell , that 's on my list .\nYeah . It 's gonna have to go through our regular process .\nI mean , the one thing I noticed is it did miss a lot of backchannels . There are a fair number of \" yeahs \" and \" uh - huhs \" that  it 's just  that aren't in there . So .\nHmm .\nBut I think  Yeah . Like you said , I mean , that 's  that 's gonna be our standard proc that 's what the transcribers are gonna be spending most of their time doing , I would imagine ,\nMm - hmm . Mm - hmm , mm - hmm .\nonce  once we\nYes , absolutely . Yeah .\nOne question about the backchannels .\nIt 's gonna\nDo you suppose that was because they weren't caught by the pre - segmenter ?\nYes , absolutely . Absolutely .\nOh , interesting . Oh , interesting . OK .\nYeah . They 're  they 're not in the segmented .\nOK .\nIt 's not that the  IBM people didn't do it .\nOK .\nJust they didn't get marked .\nOK . So maybe when the detector for that gets better or something  I w I  There 's another issue which is this  we 've been , uh , contacted by University of Washington now , of course , to , um  We sent them the transcripts that correspond to those  six meetings and they 're downloading the audio files . So they 'll be doing that . Chuck 's  Chuck 's , uh , put that in .\nMm - hmm . Yeah , I pointed them to the set that Andreas put , uh , on the  web so th if they want to compare directly with his results they can . And , um , then once , uh , th we can also point them at the , um , uh , the original meetings and they can grab those , too , with SCP .\nWait . So you put the reference files  ?\nNo , no . They d they wanted the audio .\nOr the  ?\nJane sent them the , uh , transcripts .\nNo , I mean of the transcripts . Um . Well , we can talk about it off - line .\nMm - hmm .\nThere 's another meeting in here , what , at four ? Right ? Yeah , so we have to finish by three forty - five .\nD d So , does Washi - does  does UW wanna u do this  wanna use this data for recognition or for something else ?\nUh , for recognition .\nI think they 're doing w\nOh .\ndidn't they want to do language modeling on , you know , recognition - compatible transcripts\nOh . I see .\nThis is to show you , uh , some of the things that turn up during the checking procedure .\nYeah .\nor  ?\nUm @ @  So , this is from one of the NSA meetings and , uh , i if you 're familiar with the diff format , the arrow to the left is what it was , and the arrow to the right is  what it was changed to . So , um .  And now the first one . \" OK . So , then we started a weekly meeting . The last time , uh  \" And the transcriber thought \" little too much \" But ,  uh , really , um , it was \" we learned too much \" , which makes more sense syntactically as well .\nAnd these  the parentheses were f from\nThen  Oh , this  that 's the convention for indicating uncertain .\nU uncertains .\nSo the transcriber was right .\nS\nYou know , she was uncertain about that .\nOK .\nSo she 's right to be uncertain . And it 's also a g a good indication of the  of that .\nOh .  OK .\nThe next one . This was about , uh , Claudia and  she 'd been really b busy with stuff , such as waivers . Uh , OK . Um , next one . Um .  This was  an interesting one . So the original was \" So that 's not  so Claudia 's not the bad master here \" , and then he laughs , but it really \" web master \" .\nWeb master .\nOh .  Uh - oh .\nAnd then you see another type of uncertainty which is , you know , they just didn't know what to make out of that . So instead of \" split upon unknown \" ,  it 's \" split in principle \" .\nYep .\nJane , these are from IBM ?\nSpit upon ?\nThe top lines ?\nNo , no . These are  these are our local transcriptions of the NSA meetings .\nNo , these are  ours .\nThe transcribers  transcriber 's version ver versus the checked version .\nOh . Oh , I see .\nMy  my checked version , after I go through it .\nOK .\nUm , then you get down here . Um . Sometimes some speakers will insert foreign language terms . That 's the next example , the next one . The , uh , version beyond this is  So instead of saying \" or \" , especially those words , \" also \" and \" oder \" and some other ones . Those sneak in . Um , the next one\nThat 's cool .\nDiscourse markers .\nS\nDiscourse markers .\nSorry , what ? Discourse markers ? Sure . Sure , sure , sure .\nDiscourse markers .\nAnd it 's  and it makes sense\nYeah . Yeah .\ncuz it 's , like , below this  it 's a little subliminal there .\nYeah . Yeah , yeah .\nUm . OK , the next one , uh ,  this is a term . The problem with terminology . Description with th the transcriber has \" X as an advance \" . But really it 's \" QS in advance \" . I mean , I  I 've benefited from some of these , uh , cross - group meetings . OK , then you got , um ,  uh , instead of \" from something - or - other cards \" ,  it 's \" for multicast \" . And instead of \" ANN system related \" , it 's \" end system related \" . This was changed to an acronym initially and it should shouldn't have been . And then , you can see here \" GPS \" was misinterpreted . It 's just totally understanda This is  this is a lot of jargon . Um , and the final one , the transcriber had th \" in the core network itself or the exit unknown , not the internet unknown \" . And it  it comes through as \" in the core network itself of the access provider , not the internet backbone core \" . Now this is a lot of  terminology . And they 're generally extremely good ,\nMmm .\nbut , you know in this  this area it really does pay to , um  to double check and I 'm hoping that when the checked versions are run through the recognizer that you 'll see s substantial improvements in performance cuz the  you know , there 're a lot of these in there .\nYeah . So how often  ?\nYeah , but I bet  I bet they 're acoustically challenging parts anyway , though .\nNo , actually no .\nMmm .\nHuh - uh .\nOh , really ? Uh , it 's  Oh , so it 's just jargon .\nIt 's jargon . Yeah . I mean this is  cuz , you know you don't realize in daily life how much you have top - down influences in what you 're hearing .\nWell , but\nAnd it 's jar it 's jargon coupled with a foreign accent .\nBut  but  But we don't  I mean , our language model right now doesn't know about these words anyhow . So ,\nYeah .\nyou know , un until you actually  get a decent language model , @ @  Adam 's right .\nIt probably won't do any better .\nYou probably won't notice a difference . But it 's  I mean , it 's definitely good that these are fixed . I mean ,  obviously .\nWell , also from the standpoint of getting people 's approval ,\nYeah .\ncuz if someone sees a page full of uh , um , barely decipherable w you know , sentences , and then is asked to approve of it or not ,  it 's , uh , uh\nDid I say that ?\nYeah .\nOK .\nYeah . That would be a shame if people said \" well , I don't approve it because  the  it 's not what I said \" .\nWell , that 's exactly why I put the extra option in ,\nYeah .\nExactly . That 's why we discussed that .\nYeah .\nis that I was afraid people would say , \" let 's censor that because it 's wrong \" ,\nYeah .\nand I don't want them to do that .", "topic_id": 1, "keywords": "nsa, busy, meetings, clump, meeting", "dialogue_id": 34}, {"text": "And then I also  the final thing I have for transcription is that I made a purchase of some other headphones\nC\nbecause of the problem of low gain in the originals . And  and they very much appro they mu much prefer the new ones , and actually I  I mean , I  I think that there will be fewer things to correct because of the  the choice . We 'd originally chosen , uh , very expensive head headsets\nYeah . Ugh !\nbut , um , they 're just not as good as these , um , in this  with this respect to this particular task .\nWell , return the old ones .\nIt 's probably impedance matching problems .\nI don't know exactly ,\nBut\nbut we chose them because that 's what 's been used here by prominent projects in transcription .\nCould be .\nSo it i we had every reason to think they would work .\nMm - hmm .\nSo you have spare headsets ?\nSorry , what ?\nYou have spare headsets ?\nThey 're just earphones . They 're not headsets . They 're not microphones .\nRight .\nNo , no . I mean , just earphones ? Um , because I , uh , I could use one on my workstation , just to t because sometimes I have to listen to audio files and I don't have to b go borrow it from someone and\nWe have actua actually I have  W Well , the thing is , that if we have four people come to work  for a day , I was  I was hanging on to the others for , eh  for spares ,\nOh , OK .\nbut I can tell you what I recommend .\nNo , but you 'd  If you  Yeah , w we should get it .\nSure . No problem .\nBut if you need it , just get it .\nI just\nCome on .\nRight .\nYeah . If you need it .\nYeah .\nYeah .\nIt 'd just have to be a s a separate order  an added order .\nYeah , I still  I still need to get a pair , too .\nThey 're  they 're  they 're  they 're pretty inexpensive .\nYeah , that  We should order a cou uh , t two or three or four , actually .\nYeah .\nI 'm using one of these . Yeah .\nWe have\nI think I have a pair that I brought from home , but it 's f just for music listening\nNo . Just  just  just  just buy them .\nSh - Just get the model number\nand it 's not  Nnn . Yeah .\nJust buy them .\nand  Where do you buy these from ?\nYeah .\nCambridge SoundWorks , just down the street .\nLike  ? You just b go and b\nYeah . They always have them in stock .\nOh .\nYeah .\nThat 'd be a good idea .\nAnyway .\nYeah .\nW uh , could you email out the brand ?\nOh , sure . Yeah . OK .\nCuz I think  sounds like people are interested .\nYeah .\nYeah .\nDefinitely .\nSo .\nIt 's made a difference in  in how easy . Yeah .\nI realized something I should talk about . So what 's the other thing on the agenda actually ?\nUh , the only one was Don wanted to , uh , talk about disk space yet again .\nYeah . u It 's short . I mean , if you wanna go , we can just throw it in at the end .\nNo , no . Why don't you  why don't you go ahead since it 's short .\nUm , well , uh .\nOh , I thought you meant the disk space . Yeah , we know disk space is short .\nThe disk space was short . Yeah . That 's what I thought too .\nThat 's a great ambiguity .\nYeah .\nIt 's one of these  it 's  it 's social\nIt 's  I i i it i\nand , uh , discourse level\nYeah .\nand\nYeah , it 's great . Yeah ,\nSorry .\ndouble  double\nYeah , it was really goo\nSee , if I had that little  scratch - pad , I would have made an X there .\nThank you , thank you .\nUh , well , we 'll give you one then .\nYeah .\nUm .  So , um , without thinking about it , when I offered up my hard drive last week\nOh , no .\nUm , this is always a suspect phrase .\nIt was while I was out of town .\nBut , um , no . I , uh  I realized that we 're going to be doing a lot of experiments , um ,  o for this , uh , paper we 're writing , so we 're probably gonna need a lot more  We 're probably gonna need  that disk space that we had on that eighteen gig hard drive . But , um , we also have someone else coming in that 's gonna help us out with some stuff .\nWe 've just ordered a hundred gigabytes .\nSo  OK . We just need to\nI think we need , like , another eighteen gig disk  to be safe .\nWell , we 're getting three thirty  thirty - sixes .\nSo .\nRight ?\nOK .\nThat are going into the main f file server .\nOK .\nSo .\nMarkham 's ordering and they should be coming in soon .\nW Well . So  so\nSoon ?\nYeah . I mean , I guess the thing is is , all I need is to hang it off , like ,  the person who 's coming in , Sonali 's , computer .\nOh , so  so , you mean the d the internal  the disks on the machines that we just got ?\nWhew . Or we can move them .\nNo .\nThese are gonna go onto Abbott .\nNe - new disks .\nOr extra disk ?\nOnto Abbott , the file server .\nSo are we gonna move the stuff off of my hard drive onto that when those come in ?\nOn\nOh , oh . OK .\nYeah .\nUh , i\nOnce they come in . Sure .\nOK . That 's fine .\nDo  when  when is this planned for  roughly ?\nThey should be  I  I imagine next week or something .\nOK .\nOK . So\nIf you 're  if you 're desperate , I have some space on my drive .\nI think if I 'm\nBut I  I vacillate between no space free and  a few gig free .\nYeah . I think I can find something if I 'm desperate\nYeah .\nSo .\nand , um , in the meantime I 'll just hold out .\nOK .\nThat was the only thing I wanted to bring up .\nIt should be soon . We  we should\nOK .\nSo there 's another hundred gig . So .\nAlright . Great .\nMm - hmm .\nOK . It 's great to be able to do it ,\nThat 's it .\njust say \" oh yeah , a hundred gig ,\nGood .\nno big deal \" .\nYeah .\nYeah . A hundred gig here , a hundred gig there .\nWell , each meeting is like a gig or something ,\nIt 's eventually real disk space .\nYeah .\nso it 's really", "topic_id": 2, "keywords": "headsets, headphones, earphones, transcription, microphones", "dialogue_id": 34}, {"text": "Yeah . Um . Yeah . I was just going to comment that I I 'm going to , uh , be on the phone with Mari tomorrow , late afternoon .\nOh , yeah .\nWe 're supposed to  get together and talk about , uh , where we are on things . Uh , there 's this meeting coming up , uh , and there 's also an annual report . Now , I never actually  I  I was asking about this . I don't really quite understand this . She was re she was referring to it as  I think this actually  didn't just come from her , but this is  what , uh , DARPA had asked for . Um , she 's referring to it as the an annual report for the fiscal year . But of course the fiscal year starts in October , so I don't quite understand w w why we do an annual report that we 're writing in July .\nShe 's either really late or really early .\nHuh . Or she 's getting a good early start .\nUh , I think basically it it 's none of those . It 's that the meeting is in July so they  so DARPA just said do an annual report . So . So . So anyway , I 'll be putting together stuff . I 'll do it , uh , you know , as much as I can without bothering people , just by looking at  at papers and status reports . I mean , the status reports you do are very helpful .\nHmm .\nUh , so I can grab stuff there . And if , uh  if I have some questions I 'll\nWhen we remember to fill them out .\nYeah . If  people could do it as soon as  as you can , if you haven't done one si recently . Uh .  Uh , but , you know , I 'm  I 'm sure before  it 's all done , I 'll end up bugging people for  for more clarification about stuff . Um .  But , um , I don't know , I guess  I guess I know pretty much what people have been doing . We have these meetings and  and there 's the status reports . Uh . But , um . Um . Yeah . So that wasn't a long one . Just to tell you that . And if something  hasn't , uh  I 'll be talking to her late tomorrow afternoon , and if something hasn't been in a status report and you think it 's important thing to mention on  this kind of thing , uh , uh , just pop me a one - liner and  and  and I 'll  I 'll have it in front of me for the phone conversation .\nOK .\nUh . I guess , uh , you you 're still pecking away at the  demos and all that , probably .\nYep . And Don is  gonna be helping out with that .\nOh , that 's right .\nSo .\nOK .\nDid you wanna talk about that this afternoon ?\nUm .\nNot here , but later today ?\nWe should probably talk off - line about when we 're gonna talk off - line .\nOK . OK .\nOK . Yeah , I might want to get updated about it in about a week cuz , um , I 'm actually gonna have a   a few days off the following week , a after the  after the picnic . So .\nOh , OK .\nThat 's all I had .\nSo we were gonna do sort of status of speech transcription  automatic transcription , but we 're kind of running late . So .\nHow long does it take you to save the data ?\nFifteen minutes .\nYeah .\nSo . If you wanna do a quick\nYeah .\nten minute\nGuess we should stop , like , twenty of at the latest .\nUh\nWe  we have another meeting coming in that they wanna record .\nAnd there 's the digits to do .\nSo .\nSo maybe  may maybe  maybe\nYeah . Well , we can skip the digits .\nWe could . Fi - five minute report or something .\nIt 's up to you . I don't\nYeah , yeah .\nWhatever you want .\nWell , I would love to hear about it ,\nWhat do you have to say ?\nespecially since\nI 'm interested , so\nYeah . Well , I 'm gonna be on the phone tomorrow , so this is just a  good example of  the sort of thing I 'd like to  hear about .\nWait . Why is everybody looking at me ?\nI don't know .\nSorry .\nCuz he looked at you\nWhat ?\nand says you 're sketching .\nUh . I 'm not sure what you were referring to .\nI  I  I  I 'm not  actually , I 'm not sure what  ? Are we supposed to have done something ?\nNo . We were just talking before about alternating the subject of the meeting .\nOh .\nUh - huh .\nAnd this week we were gonna try to do  t automatic transcription  status .\nAlternating .\nI wasn't here last week . Sorry .\nOh !\nOh .\nBut we sort of failed .\nWe did that last week . Right ?\nHhh .\nNo .\nI thought we did .\nDid we ? OK .\nYeah . We did .\nOK . So now  now we have the schedule . So next week we 'll do automatic transcription status , plus anything that 's real timely .\nOK .\nOh . OK .\nOK .\nOK . Whew !\nGood update .\nWhew !\nThat was\nDodged that bullet .\nYeah . Nicely done , Liz .\nA woman of few words .\nBut  but lots of prosody . OK .  OK .\nTh\nUh , I mean , we  we really haven't done anything .\nExcuse me ?\nSorry .\nWell , since last week .\nYeah , we 're\nI mean , the  the next thing on our agenda is to go back and look at the , um   the automatic alignments because , uh , I got some  I  I  I learned from Thilo what data we can use as a benchmark to see how well we 're doing on automatic alignments of the background speech  or , of the foreground speech with background speech .\nYeah .\nSo .\nAnd then , uh , I guess , the new data that Don will start to process\nBut , we haven't actually\nthe , um  when he can get these  You know , before we were working with these segments that were all synchronous and that caused a lot of problems\nMmm .\nbecause you have timed sp at  on either side .\nOh . Right , right . Mm - hmm .\nAnd so that 's sort of a stage - two of trying the same kinds of alignments with the tighter boundaries with them is really the next step .\nRight .\nI 'll be interested .\nWe did get our , um  I guess , good news . We got our abstract accepted for this conference , um  workshop , ISCA workshop , in , um , uh , New Jersey . And we sent in a very poor abstract , but they  very poor , very quick . Um , but we 're hoping to have a paper for that as well , which should be an interesting\nWhen 's it due ?\nThe t paper isn't due until August . The abstracts were already due . So it 's that kind of workshop .\nMm - hmm .\nBut , I mean , the good news is that that will have sort of the European experts in prosody  sort of a different crowd , and I think we 're the only people working on prosody in meetings so far , so that should be interesting .\nWhat 's the name of the meeting ?\nUh , it 's ISCA Workshop on Prosody in Speech Recognition and Understanding , or something like that\nIt 's called Prosody to\nMm - hmm .\nGood .\nsome generic  Uh , so it 's focused on using prosody in automatic systems and there 's a  um , a web page for it .\nY you going to , uh , Eurospeech ? Yeah .\nI don't have a paper\nYeah .\nbut I 'd kinda like to go , if I could . Is that alright ?\nWe 'll discuss it .\nOK .  I guess that 's \" no \" .\nMy  my  my car  my car needs a good wash , by the way .\nOK . Well , that th Hey , if that 's what it takes , that 's fine with me .\nUm .\nI 'll pick up your dry - cleaning , too . Should we do digits ?\nYeah .\nUh .\nCan I go next ? Because I have to leave , actually .\nYep . Go for it . Hmm ! Thanks . Thank you .\nSo you get to be the one who has all the paper rustling . Right ?", "topic_id": 3, "keywords": "fiscal, reports, annual, meeting, meetings", "dialogue_id": 34}, {"text": "OK So uh today we 're looking at a number of uh things we 're trying and uh fortunately for listeners to this uh we lost some of it 's visual but um got tables in front of us . Um what is  what does combo mean ?\nSo combo is um a system where we have these features that go through a network and then this same string of features but low - pass filtered with the low - pass filter used in the MSG features . And so these low - pass filtered goes through M eh  another MLP and then the linear output of these two MLP 's are combined just by adding the values and then there is this KLT . Um the output is used as uh features as well .\nUm so let me try to restate this and see if I have it right . There is uh  there is the features uh there 's the OGI features and then um those features um go through a contextual  uh l l let 's take this bottom arr one pointed to by the bottom arrow . Um those features go through a contextualized KLT . Then these features also uh get um low - pass filtered\nYeah . Yeah so yeah I could perhaps draw this on the blackboard\nSure . Yeah . Yeah .\nYeah .\nThe graph , yeah another one .\nYeah , that 's good .\nSo\nSo we have these features from OGI that goes through the three paths .\nYeah . Three , OK .\nThe first is a KLT using several frames of the features .\nYeah . Yeah .\nThe second path is uh MLP also using nine frames  several frames of features\nYeah . Uh - huh .\nThe third path is this low - pass filter .\nUh - huh .\nUh , MLP\nAha ! aha !\nAdding the outputs just like in the second propose the  the proposal from  for the first evaluation .\nYeah ? Yeah . Yeah .\nAnd then the KLT and then the two together again .\nNo , the KLT . And those two together . That 's it .\nTwo HTK .\nOK so that 's  that 's this bottom one .\nUm . So this is  yeah\nAnd so uh and then the  the  the one at the top  and I presume these things that uh are in yellow are in yellow because overall they 're the best ?\nYeah that 's the reason , yeah .\nOh let 's focus on them then so what 's the block diagram for the one above it ?\nFor the f the f first yellow line you mean ?\nYeah .\nYeah so it 's uh basically s the same except that we don't have this uh low - pass filtering so we have only two streams .\nStep .\nWell . There 's  there 's no low  low - pass processing used as additional feature stream .\nMm - hmm . Mm - hmm .\nUm\nDo you e um they mentioned  made some  uh when I was on the phone with Sunil they  they mentioned some weighting scheme that was used to evaluate all of these numbers .\nYeah . Uh actually the way things seems to um well it 's uh forty percent for TI - digit , sixty for all the SpeechDat - Cars , well all these languages . Ehm the well match is forty , medium thirty five and high mismatch twenty - five . Yeah .\nUm and we don't have the TI - digits part yet ?\nUh , no .\nOK .\nBut yeah . Generally what you observe with TI - digits is that the result are very close whatever the  the system .\nOK . And so have you put all these numbers together into a single number representing that ?\nYeah .\nI mean not\nUh not yet .\nOK so that should be pretty easy to do and that would be good\nNo . Mmm yeah , yeah .\nthen we could compare the two and say what was better .\nMmm . Yeah .\nUm and how does this compare to the numbers  oh so OGI two is just the top  top row ?\nYeah .\nSo yeah to  actually OGI two is the  the baseline with the OGI features but this is not exactly the result that they have because they 've  they 're still made some changes in the features\nOK .\nand  well but uh actually our results are better than their results . Um I don't know by how much because they did not send us the new results\nOK .\nUh\nUh OK so the one  one place where it looks like we 're messing things up a bit is in the highly mismatched Italian .\nYeah . Yeah .\nAn\nYeah there is something funny happening here because  yeah .\nYeah .\nBut there are thirty - six and then sometimes we are  we are  we are around forty - two and\nNow up\nbut\nUh so one of the ideas that you had mentioned last time was having a  a second um silence detection .\nYeah . So there are some results here\nFor the Italian .\nuh so the third and the fifth line of the table\nFor this one .\nSo filt is what that is ?\nFilt , yeah\nYeah .\nUm yeah so it seems f for the  the well match and mismatched condition it 's uh it brings something . Uh but uh actually apparently there are  there 's no room left for any silence detector at the server side because of the delay . Uh well\nOh we can't do it . Oh OK .\nNo .\nFor that  for that we\nOh .\nUh\nToo bad . Good idea , but can't do it .\nYeah .\nOK .\nExcept I don't know because they  I think they are still working well .\nUh - huh .\nUh t two days ago they were still working on this trying to reduce the delay of the silence detector so but yeah if we had time perhaps we could try to find uh some kind of compromise between the delay that 's on the handset and on the server side . Perhaps try to reduce the delay on the handset and  but well hmm For the moment they have this large delay on the  the feature computation and so we don't\nOK . So Alright so for now at least that 's not there you have some results with low - pass filter cepstrum doesn't have a huge effect but it  but it looks like it you know maybe could help in a couple places .\nI th\nUh little bit .\nYeah .\nUm and um um Yeah and uh let 's see What else did we have in there ? Uh I guess it makes a l um at this point this is I  I guess I should probably look at these others a little bit uh And you  you yellowed these out uh but uh uh Oh I see yeah that  that one you can't use because of the delay . Those look pretty good . Um let 's see that one Well even the  just the  the second row doesn't look that bad right ? That 's just uh yeah ?\nYep .\nAnd  and that looks like an interesting one too .\nMmm yeah .\nUh\nActually the  yeah the second line is uh pretty much like the first line in yellow except that we don't have this KLT on the first  on the left part of the diagram . We just have the features as they are .\nMm - hmm .\nUm\nYeah . Yeah so when we do this weighted measure we should compare the two cuz it might even come out better . And it 's  it 's  it 's a little  slightly simpler .\nMm - hmm . Yeah .\nSo  so there 's  so I  I would put that one also as a  as a maybe . Uh and it  yeah and it 's actually  does  does significantly better on the uh uh highly mismatched Italian , so s and little worse on the mis on the MM case , but uh Well yeah it 's worse than a few things\nMm - hmm .\nso uh let 's see how that c that c c see how that comes out on their  their measure and  are  are we running this uh for TI - digits or uh\nYeah .\nNow is TI di  is is that part of the result that they get for the uh development  th the results that they 're supposed to get at the end of  end of the month , the TI - digits are there also ?\nYeah . Yeah . It 's included , yeah .\nOh OK . OK . And see what else there is here . Um Oh I see  the one  I was looking down here at the  the o the row below the lower yellowed one . Uh that 's uh that 's with the reduced uh KLT size  reduced dimensionality .\nMm - hmm ? Yeah . Yeah .", "topic_id": 0, "keywords": "combo, visual, features, feature, mlp", "dialogue_id": 35}, {"text": "What happens there is it 's around the same and so you could reduce the dimension as you were saying before a bit perhaps .\nYeah , it 's  it 's significantly worse well but  Mm - hmm .\nIt 's significantly worse  it 's  it 's uh it 's  it 's mostly worse .\nExc - except for the HM\nFor many a mismatch it 's worse .\nbut\nYeah . But it is little . I mean not  not by a huge amount , I don't know . What are  what are the sizes of any of these sets , I  I 'm  I 'm sure you told me before , but I 've forgotten . So  you know how many words are in uh one of these test sets ?\nUh\nI don't remember .\nAbout ?\nUm it 's  it depends  well  the well matched is generally larger than the other sets and I think it 's around two thousand or three thousand words perhaps , at least .\nYe But words  well word  I don't know .\nHmm ? The words , yeah . S sentences .\nSentences .\nSome sets have five hundred sentences , so .\nYeah .\nSo the  so the sets  so the test sets are between five hundred and two thousand sentences , let 's say\nMmm .\nand each sentence on the average has four or five digits or is it  most of them longer or\nYeah .\nYeah for the Italian even seven digits y more or less\nIt  it d Seven digits .\nbut sometime the sentence have only one digit and sometime uh like uh the number of uh credit cards , something like that .\nMm - hmm . Right , so between one and sixteen . See the  I mean the reason I 'm asking is  is  is we have all these small differences and I don't know how seriously to take them , right ?\nMm - hmm ?\nSo uh i if  if you had uh just you know  to give an example , if you had uh um if you had a thousand words then uh a  a tenth of a percent would just be one word ,\nYeah .\nright ? So  so it wouldn't mean anything .\nYeah .\nOh\nYeah .\num so um yeah it be kind of  I 'd kind of like to know what the sizes of these test sets were actually .\nYeah .\nThe size that we have ?\nWe could  we could run  run some kind of significance tests\nYeah since these  well also just to know the numbers ,\nor\nYeah .\nright . So these  these are word error rates\nYeah .\nso this is on how many words .\nYep .\nYeah we have the result that the output of the HTK\nYeah .\nThe number of  of sentences , no it 's the number isn't .\nYeah sure  sure . Yeah sure .\nYeah so anyway if you could just mail out what those numbers are and then  then  that  that be great .\nYeah .\nYeah .\nUm  what else is there here ? Um see the second  second from the bottom it says SIL , but this is some different kind of silence or thing or  what was that ?\nUh\nIt the  the output silence of the MLP .\nOh yeah I see .\nIt 's only one small experiment to know what happened . To apply also to in include also the  the silence of the MLP we have the fifty - six form and the silence to pick up the silence and we include those .\nYes . Uh - huh , uh - huh . The silence plus the KLT output ? Oh so you 're only using the silence .\nYeah .\nYeah , because when we apply the KLT\nNo they 're  I think there is this silence in addition to the um KLT outputs\nNo .\nin addition , yes .\nit is because we  we  we just keep uh we don't keep all the dimensions after the KLT\nIn addition t\nand  yeah .\nand we not s we are not sure if we pick  we have the silence .\nSo we try to add the silence also in addition to the  these twenty - eight dimensions .\nI see . OK . And what  and what 's OGI forty - five ? The bottom one there ?\nUh it 's o it 's OGI two , it 's  so the  th it 's the features from the first line\nIt 's in fact OGI two .\nS\nand  yeah .\nRight , but I mean what 's the  what does the last row mean ?\nSo it 's uh basically this but without the KLT on the  from the left path .\nI thought that was the one  I thought that was the second row . So what 's the difference between the second\nUh the second line you don't have this combo stuff so you just\nOh .\nuh\nSo this is like the second line but with  with the combo stuff .\nYeah . Yeah .\nAnd with the  all the output of the combo .\nOK . Yeah .\nYeah .\nUh\nOK , so  alright so it looks to me  I guess the same  given that we have to take the filt ones out of the  the running because of this delay problem  so it looks to me like the ones you said I agree are  are the ones to look at\nMm - hmm .\nbut I just would add the  the  the second row one\nYeah .\nand then um if we can um\nMmm .\noh yeah also when  when they 're using this weighting scheme of forty , thirty - five , twenty - five is that on the percentages or on the raw errors ? I guess it 's probably on the percentages right ?\nUh  I guess , yeah .\nYeah OK .\nI guess , yeah . Mmm .\nAlright .\nIt 's not clear here .\nOK . Maybe  maybe they 'll argue about it . Um OK so if we can know what  how many words are in each and then um Dave uh Dave promised to get us something tomorrow which will be there as far as they 've gotten  Friday\nMm - hmm .\nand then we 'll operate with that\nYeah .\nand uh how long did it I guess if we 're not doing all these things  if we 're only doing um um I guess since this is development data it 's legitimate to do more than one , right ? I mean ordinarily if  in final test data you don't want to do several and  and take the best\nYeah . Mmm .\nthat 's  that 's  that 's not proper but if this is development data we could still look at a couple .", "topic_id": 1, "keywords": "tests, sets, sentences, test, words", "dialogue_id": 35}, {"text": "Yeah . We can  yeah . Sure . But we have to decide  I mean we have to fix the system on this d on this data , to choose the best\nYeah . I Right .\nand these\nBut the question is when  when do we fix the system ,\nBut we could\ndo we fix the system uh tomorrow or do we fix the system on Tuesday ?\nit d\nI  Yeah , OK except that we do have to write it up .\nI think we fixed on Tuesday , yeah . Yeah . Mm - hmm . Mm - hmm .\nAlso , so\nYeah . Yeah .\nUm\nUh yeah well . Well basically it 's this with perhaps some kind of printing and some  some other @ @ .\nRight so maybe what we do is we  we  we uh as soon as we get the data from them we start the training and so forth\nYeah but Mm - hmm .\nbut we start the write - up right away because as you say there  there 's only minor differences between these .\nI think you  we could  we could start soon , yeah .\nYeah .\nWrite up something .\nYeah , and  and I  I would  you know , I would  I 'd kind of like to see it\nUm yeah . Mm - hmm .\nmaybe I can  I can edit it a bit uh sure . The  my  what in this si i in this situation is my forte which is English .\nYeah .\nUh so\nMmm .\nuh H yeah . Have y have you seen alt d do they have a format for how they want the system descriptions or anything ?\nUh not really .\nOK .\nUm There is the format of the table which is  quite impressive .\nYeah ? Uh I see . Yes , for those who are listening to this and not looking at it uh it 's not really that impressive , it 's just tiny . It 's all these little categories set a , set b , set c , multi - condition , clean . Uh No mitigation . Wow . Do you know what no  what no mitigation means here ?\nUm it should be the the problem with the error  channel error\nOh that 's probably the\nor\nthis is probably channel error stuff\nwell , you\nhuh ? Oh this is i right , it says right above here channel  channel error resilience ,\nYeah . Yeah .\nyeah . So recognition performance is just the top part , actually . Uh and they have  yes , split between seen databases and non - seen so basically between development and  and evaluation .\nYeah .\nAnd  so  right , it 's presumed there 's all sorts of tuning that 's gone on on the see what they call seen databases and there won't be tuning for the uh unseen . Multi - condition  multi - condition . So they have  looks like they have uh uh\nMm - hmm .\nso they splitting up between the TI - digits and everything else , I see . So the everything else is the SpeechDat - Car , that 's the multi multilingual\nYeah , so it 's not divided between languages you mean or\nWell , it is .\nit just\nIt is , but there 's also  there 's these tables over here for the  for the TI - digits and these tables over here for the car data which is  which is I guess all the multilingual stuff\nOh yeah .\nand then uh there 's  they also split up between multi - condition and clean only .\nYeah . For TI - digits .\nYes .\nYeah , actually yeah . For the TI - digits they want to train on clean and on noisy\nYeah .\nand  yeah .\nSo we 're doing that also , I guess .\nUh yeah . But uh we actually  do we have the features ? Yeah . For the clean TI - digits but we did not test it yet . Uh the clean training stuff .\nOK .\nMmm .\nWell anyway , sounds like there 'll be a lot to do just to  work with our partners to fill out the tables  over the next uh next few days\nMm - hmm .\nYes .\nI guess they have to send it out  let 's see the thirty - first is uh uh Wednesday and I think the  it has to be there by some hour uh European time on Wednesday\nHmm - hmm .\nso  I think basically\nWe lost time uh Wednesday maybe because  that the difference in the time may be  is a long different of the time .\nE excuse me ?\nMaybe the Thursday the twelfth of the night of the Thurs - thirty - one is  is not valid in Europe .\nYeah .\nWe don't know is happening .\nYes , so I mean  I think we have to actually get it done Tuesday\nTuesday .\nright because I  I think\nYeah , well .\nuh Uh\nExcept if  if it 's the thirty - one at midnight or I don't know  we can  still do some work on Wednesday morning .\nyeah well . W i is but is  is it midni I thought it was actually something like five PM on\nYeah , well . Yeah .\nYeah .\nMm - hmm .\nwas like  I thought it was five PM or something , I didn't think it was midnight . I thought they said they wanted everything by\nYeah , five PM .\nwell , so five PM their time is  is  if\nNot five PM , three PM .\nthree PM .\nThree PM .\nAlright , that 's six in the morning here .\nIt 's d no .\nUh no three  three A - three PM ?\nNo , we are wondering about the  the  the hour that we have to eh I don't know if it 's three PM  it 's\nOh yeah , yeah , yeah , yeah . Three PM here is in Europe midnight .\nYeah , it 's  it 's midnight but\nYes , yes , but I didn't think it was midnight that it was due , I thought it was due at some hour during the day like five PM or something .\nOh OK . Mm - hmm . Mm - hmm ,\nIn which case\nmaybe .\nso I  I  uh well we should look but my assumption is that we basically have to be done Tuesday . Um so then next Thursday we can sort of have a little aftermath\nYeah .\nbut then  then we 'll actually have the new data which is the German and the Danish\nYeah .\nbut that really will be much less work because uh the system will be fixed\nYeah .\nso all we 'll do is take whatever  they have and  and uh and run it through the process .\nYeah .\nUh we won't be changing the training on anything\nMm - hmm .\nso there 'll be no new training , there 'll just be new HTK runs , so that 's means in some sense we can kind of relax from this after  after Tuesday and  and uh maybe next meeting we can start talking a little bit about where we want to go from here uh in terms of uh the research .\nMm - hmm .\nUm you know what things uh did you think of when you were uh doing this process that uh you just didn't really have time to adequately work on uh uh so\nMm - hmm . Yeah .\nWhat ?\nOh , Stephane always has these great ideas and  oh , but uh we don't have time .\nSure .\nYeah .\nYeah .\nYeah .\nI 'm not sure these are great ideas .\nBut they 're ideas . Yeah ? Oh , that was good .\nYeah .\nYeah .\nAnd  and uh also it 's still true that uh I think it 's true that  that we  we at least got fairly consistent i improved results by running uh the uh neural net transformation in parallel with the features\nBut\nrather than uh in sequence which was  was your suggestion and that  that  that seems to have been borne out .\nMm - hmm . Mm - hmm .\nThe fact that none of these are  are  you know , enormous is  is  is not too surprising  most improvements aren't enormous and  uh\nYeah .\nsome of them are but uh I mean you have something really really wrong  and you fix it  you can get big and really enormous improvements\nMm - hmm .\nbut  uh  um Cuz our best improvements over the years that we 've gotten from finding bugs , but Anyway OK well I  I think  I see where we are and everybody knows what they 're doing and is there  is there anything else we should talk about or  or  are we done ?\nMm - hmm . I think it 's OK um . We so basically we will  I think we 'll try to  to focus on these three architectures and  and perhaps I was thinking also a fourth one with just  just a single KLT because we did not really test that\nUh - huh .\nremoving all these KLT 's and putting one single KLT at the end .\nYeah , I mean that would be pretty low maintenance to try it .\nYeah .\nUh if you can fit it in .\nMm - hmm .\nOh I have  yeah I do have one other piece of information which uh I should tell people outside of this group too uh I don't know if we 're gonna need it uh but uh Jeff up at the uh University of Washington has uh gotten a hold of a uh uh some kind of server farm of uh of ten uh uh multiprocessor uh IBM machines RS six thousands\nMm - hmm .\nand  and uh so I think each one is four processors or something or  I don't know , eight hundred megahertz or something and there 's four processors in a box and there 's ten boxes and there 's some kind of ti so if  you know he 's got a lot of processing power and um we 'd have to schedule it but if we have some big jobs and we wanna  wanna  wanna run them he 's  he 's offering it .\nMm - hmm .\nSo . It 's uh when he was here eh uh he  he used i not only every machine here but every machine on campus as far as I could tell , so  so in some ways he just got his payback , but uh again I  I don't know if we 'll end up with  if we 're gonna be CPU limited on anything that we 're doing in this group\nMm - hmm .\nbut  but if  if we are that 's an offer . OK well uh you guys doing great stuff so that 's  that  that 's really neat and uh we 'll uh uh g don't think we need to uh um Oh well the other thing I guess that I will say is that uh the digits that we 're gonna record momentarily is starting to get  are starting to get into a pretty good size collection and um in addition to the SpeechDat stuff we will have those to work with really pretty soon now so that 's  that 's another source of data . Um which is s under somewhat better control and that we can  we can make measurements of the room the  uh that  you know if we feel there 's other measurements we don't have that we 'd like to have we can make them and uh Dave and I were just talking about that a little while ago so uh that 's another  another possibility for this  this kind of work .\nMm - hmm .\nK , uh if nobody has anything else maybe we should go around do  do our digits  do our digits duty . OK . OK I 'll start . Uh , let me say that again . OK . I guess we 're done .", "topic_id": 2, "keywords": "processing, write, momentarily, let, improvements", "dialogue_id": 35}, {"text": "OK , we 're on .\nOK , what are we talking about today ?\nI don't know . Do you have news from the conference talk ? Uh , that was programmed for yesterday  I guess .\nUh\nYesterday\nUh\nYesterday morning on video conference .\nUh ,\nWell\noh , I 'm sorry .\nOh . Conference call .\nI know  now I know what you 're talking about . No , nobody 's told me anything .\nAlright .\nOh , this was the , uh , talk where they were supposed to try to decide\nTo  to decide what to do ,\nAh , right .\nyeah .\nYeah .\nYeah . No , that would have been a good thing to find out before this meeting , that 's . No , I have no  I have no idea . Um , Uh , so I mean , let 's  let 's assume for right now that we 're just kind of plugging on ahead ,\nYeah .\nbecause even if they tell us that , uh , the rules are different , uh , we 're still interested in doing what we 're doing . So what are you doing ?\nMm - hmm . Uh , well , we 've  a little bit worked on trying to see , uh , what were the bugs and the problem with the latencies .\nTo improve\nSo , We took  first we took the LDA filters and ,  uh , we designed new filters , using uh recursive filters actually .\nSo when you say \" we \" , is that something Sunil is doing or is that  ?\nI 'm sorry ?\nWho is doing that ?\nUh , us . Yeah .\nOh , oh . Oh , OK .\nSo we took the filters  the FIR filters  and we  designed , uh , IIR filters that have the same frequency response .\nBut\nMm - hmm .\nWell , similar , but that have shorter delays .\nMm - hmm .\nSo they had two filters , one for the low frequency bands and another for the high frequency bands . And so we redesigned two filters . And the low frequency band has sixty - four milliseconds of delay , and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the IIR filters . But it 's not yet test . So we have the filters but we still have to implement a routine that does recursive filtering\nOK .\nand\nYou  you had a discussion with Sunil about this though ?\nNo . No .\nUh - huh . Yeah , you should talk with him .\nYeah , yeah .\nYeah . No , I mean , because the  the  the  the whole problem that happened before was coordination ,\nMm - hmm .\nright ? So  so you need to discuss with him what we 're doing ,\nYeah .\nuh , cuz they could be doing the same thing and  or something .\nMm - hmm . Uh , I  yeah , I don't know if th that 's what they were trying to  They were trying to do something different like taking , uh  well , using filter that takes only a past\nRight .\nand this is just a little bit different . But I will I will send him an email and tell him exactly what we are doing , so .\nYeah , yeah . Um ,\nUm ,\nI mean  We just  we just have to be in contact more . I think that  the  the fact that we  we did that with  had that thing with the latencies was indicative of the fact that there wasn't enough communication .\nMm - hmm .\nSo .\nAlright .\nOK .\nUm , Yeah . Well , there is w one , um , remark about these filters , that they don't have a linear phase . So ,\nRight .\nWell , I don't know , perhaps it  perhaps it doesn't hurt because the phase is almost linear but . Um , and so , yeah , for the delay I gave you here , it 's  it 's , uh , computed on the five hertz modulation frequency , which is the  mmm , well , the most important for speech so . Uh , this is the first thing .\nSo that would be , uh , a reduction of a hundred and thirty - six milliseconds ,\nThe low f f\nYeah .\nwhich , uh  What was the total we ended up with through the whole system ?\nThree hundred and thirty .\nSo that would be within  ?\nYeah , but there are other points actually , uh , which will perhaps add some more delay . Is that some other  other stuff in the process were perhaps not very  um perf well , not very correct , like the downsampling which w was simply dropping frames .\nYeah .\nUm , so we will try also to add a nice downsampling having a filter that  that\nUh - huh .\nwell , a low - pass filter at  at twenty - five hertz . Uh , because wh when  when we look at the LDA filters , well , they are basically low - pass but they leave a lot of what 's above twenty - five hertz .\nYeah .\nUm , and so , yeah , this will be another filter which would add ten milliseconds again .\nYeah .\nUm , yeah , and then there 's a third thing , is that , um , basically the way on - line normalization was done uh , is just using this recursion on  on the um , um , on the feature stream ,\nYeah .\nand  but this is a filter , so it has also a delay . Uh , and when we look at this filter actually it has a delay of eighty - five milliseconds . So if we\nEighty - five .\nYeah . If we want to be very correct , so if we want to  the estimation of the mean t t to  to be  well , the right estimation of the mean , we have to t to take eighty - five milliseconds in the future . Mmm .\nHmm ! That 's a little bit of a problem .\nYeah . Um , But , well , when we add up everything it 's  it will be alright . We would be at six so , sixty - five , plus ten , plus  for the downsampling , plus eighty - five for the on - line normalization . So it 's\nUh ,\nplus  plus eighty for the neural net and PCA .\nyeah , but then there 's  Oh .\nSo it would be around two hundred and forty  so , well ,\nJust  just barely in there .\nplus  plus the frames , but it 's OK .\nWhat 's the allowable ?\nTwo - fifty , unless they changed the rules .\nHmm .\nWhich there is  there 's some discussion of .\nWhat were they thinking of changing it to ?\nBut\nYeah .\nUh , well the people who had very low latency want it to be low  uh , very   very very narrow , uh , latency bound . And the people who have longer latency don't . So .\nHuh .\nSo , yeah .\nUnfortunately we 're the main ones with long latency , but\nAh !\nBut , uh ,\nYeah , and basically the best proposal had something like thirty or forty milliseconds of latency .\nyou know , it 's  Yeah .\nSo . Well .\nYeah , so they were basically  I mean , they were more or less trading computation for performance and we were , uh , trading latency for performance . And they were dealing with noise explicitly and we weren't , and so I think of it as complementary , that if we can put the\nThink of it as what ?\nComplementary .\nHmm .\nI think the best systems  so , uh , everything that we did in in a way it was  it was just adamantly insisting on going in with a brain damaged system , which is something  actually , we 've done a lot over the last thirteen years . Uh ,  which is we say , well this is the way we should do it . And then we do it . And then someone else does something that 's straight forward . So , w th w this was a test that largely had additive noise and we did  we adde did absolutely nothing explicitly to handle ad additive noise .\nRight .\nWe just , uh , you know , trained up systems to be more discriminant . And , uh , we did this , uh , RASTA - like filtering which was done in the log domain and was tending to handle convolutional noise . We did  we actually did nothing about additive noise . So , um , the , uh , spectral sub subtraction schemes a couple places did seem to seem to do a nice job . And so , uh , we 're talking about putting  putting some of that in while still keeping some of our stuff . I think you should be able to end up with a system that 's better than both but clearly the way that we 're operating for this other stuff does involved some latency to  to get rid of most of that latency . To get down to forty or fifty milliseconds we 'd have to throw out most of what we 're doing . And  and , uh , I don't think there 's any good reason for it in the application actually . I mean , you 're  you 're  you 're speaking to a recognizer on a remote server and , uh , having a  a  a quarter second for some processing to clean it up . It doesn't seem like it 's that big a deal .\nMm - hmm .\nThese aren't large vocabulary things so the decoder shouldn't take a really long time , and .\nAnd I don't think anybody 's gonna notice the difference between a quarter of a second of latency and thirty milliseconds of latency .\nSo . No . What  what does  wa was your experience when you were doing this stuff with , uh , the  the  the surgical , uh , uh , microscopes and so forth . Um , how long was it from when somebody , uh , finished an utterance to when , uh , something started happening ?\nUm , we had a silence detector , so we would look for the end of an utterance based on the silence detector .\nMm - hmm .\nAnd I  I can't remember now off the top of my head how many frames of silence we had to detect before we would declare it to be the end of an utterance .\nMm - hmm . Mm - hmm .\nUm , but it was , uh , I would say it was probably around the order of two hundred and fifty milliseconds .\nYeah , and that 's when you 'd start doing things .\nYeah , we did the back trace at that point to get the answer .\nYeah . Of course that didn't take too long at that point .\nNo , no it was pretty quick .\nYeah .\nSo\nYeah , so you  you  so you had a\nthis w\nso you had a  a quarter second delay before , uh , plus some little processing time ,\nRight .\nand then the  the microscope would start moving or something .\nRight .\nYeah .\nRight .\nAnd there 's physical inertia there , so probably the  the motion itself was all\nAnd it felt to , uh , the users that it was instantaneous . I mean , as fast as talking to a person . It  th I don't think anybody ever complained about the delay .\nYeah , so you would think as long as it 's under half a second or something .\nYeah .\nUh , I 'm not an expert on that\nYeah .\nbut .\nI don't remember the exact numbers but it was something like that .\nYeah .\nI don't think you can really tell . A person  I don't think a person can tell the difference between , uh , you know , a quarter of a second and a hundred milliseconds , and  I 'm not even sure if we can tell the difference between a quarter of a second and half a second .\nYeah .\nI mean it just  it feels so quick .\nYeah . I mean , basically if you  yeah , if you said , uh , um , \" what 's the , uh , uh  what 's the shortest route to the opera ? \" and it took half a second to get back to you ,\nYeah .\nI mean ,  it would be f I mean , it might even be too abrupt . You might have to put in a s a s  a delay .\nYeah . I mean , it may feel different than talking to a person\nYeah .\nbecause when we talk to each other we tend to step on each other 's utterances . So like if I 'm asking you a question , you may start answering before I 'm even done .\nYeah .\nSo it  it would probably feel different\nRight .\nbut I don't think it would feel slow .\nRight . Well , anyway , I mean , I think  we could cut  we know what else , we could cut down on the neural net time by  by , uh , playing around a little bit , going more into the past , or something like that . We t we talked about that .\nSo is the latency from the neural net caused by how far ahead you 're looking ?\nMm - hmm .\nMm - hmm .\nAnd there 's also  well , there 's the neural net and there 's also this , uh , uh , multi - frame , uh , uh , KLT .\nWasn't there  Was it in the , uh , recurrent neural nets where they weren't looking ahead at all ?\nThey weren't looking ahead much . They p they looked ahead a little bit .\nA little bit . OK .\nYeah . Yeah , I mean , you could do this with a recurrent net . And  and then  But you also could just , um , I mean , we haven't experimented with this but I imagine you could , um , uh , predict a , uh  um , a label , uh , from more in the past than in  than  than in the future . I mean , we 've d we 've done some stuff with that before . I think it  it works OK .\nMm - hmm .\nWe 've always had  usually we used the symmetric windows\nSo .\nbut I don't think\nYeah , but we 've  but we played a little bit with  with asymmetric , guys .\nYeah .\nYou can do it . So . So , that 's what  that 's what you 're busy with , s messing around with this ,\nUh , yeah .\nyeah . And , uh ,", "topic_id": 0, "keywords": "talking, meeting, conference, talk, communication", "dialogue_id": 36}, {"text": "Also we were thinking to  to , uh , apply the eh , spectral subtraction from Ericsson\nYeah .\nUh - huh .\nand to  to change the contextual KLT for LDA .\nChange the what ?\nThe contextual KLT .\nI 'm missing that last word . Context\nK  KLT .\nKLT .\nKLT\nOh . KLT .\nOh , KLT .\nMm - hmm .\nUh - huh .\nKLT , I 'm sorry . Uh , to change and use LDA discriminative .\nYeah .\nUh - huh .\nBut  I don't know .\nUh ,\nWhat is the advantage of that ?\nUh\nWell , it 's that by the for the moment we have , uh , something that 's discriminant and nonlinear . And the other is linear but it 's not discriminant at all . Well , it 's it 's a linear transformation , that  Uh\nSo at least just to understand maybe what the difference was between how much you were getting from just putting the frames together and how much you 're getting from the discriminative , what the nonlinearity does for you or doesn't do for you . Just to understand it a little better I guess .\nMmm . Well  uh  yeah . Actually what we want to do , perhaps it 's to replace  to  to have something that 's discriminant but linear , also . And to see if it  if it improves ov over  over the non - discriminant linear transformation .\nHmm .\nAnd if the neural net is better than this or , well . So .\nYeah , well , that 's what I meant , is to see whether  whether it  having the neural net really buys you anything .\nYe Mmm .\nUh , I mean , it doe did look like it buys you something over just the KLT .\nYeah .\nBut maybe it 's just the discrimination and  and maybe  yeah , maybe the nonlinear discrimination isn't necessary .\nS maybe .\nYeah . Mm - hmm .\nCould be .\nMaybe .\nGood  good to know . But the other part you were saying was the spectral subtraction , so you just kind of , uh\nYeah .\nAt what stage do you do that ? Do you  you 're doing that , um  ?\nSo it would be on the um  on  on the mel frequency bands ,\nWe was think\nso . Yeah , be before everything .\nOK ,\nYeah ,\nso just do that on the mel f\nwe  no  nnn We  we was thinking to do before after VAD or\nYeah ,\nOh ,  we don't know exactly when it 's better .\num\nBefore after VAD or\nSo  so you know that  that  that the way that they 're\nand then\nUm .\nuh , one thing that would be no  good to find out about from this conference call is that what they were talking about , what they 're proposing doing , was having a third party , um , run a good VAD , and  and determine boundaries .\nYeah .\nAnd then given those boundaries , then have everybody do the recognition .\nBegin to work .\nThe reason for that was that , um , uh  if some one p one group put in the VAD and another didn't , uh , or one had a better VAD than the other since that  they 're not viewing that as being part of the  the task , and that any  any manufacturer would put a bunch of effort into having some s kind of good speech - silence detection . It still wouldn't be perfect but I mean , e the argument was \" let 's not have that be part of this test . \" \" Let 's  let 's separate that out . \" And so , uh , I guess they argued about that yesterday and , yeah , I 'm sorry , I don't  don't know the answer but we should find out . I 'm sure we 'll find out soon what they , uh  what they decided . So , uh  Yeah , so there 's the question of the VAD but otherwise it 's  it 's on the  the , uh  the mel fil filter bank , uh , energies I guess ?\nMm - hmm .\nMmm , yeah .\nYou do  doing the  ?\nMm - hmm .\nAnd you 're  you 're subtracting in the  in the  in the  I guess it 's power  power domain , uh , or  or magnitude domain . Probably power domain , right ?\nI guess it 's power domain , yeah .\nwhy\nI don't remember exactly .\nYeah ,\nI don't remember .\nBut  yeah , so it 's before everything else ,\nyep .\nand\nI mean , if you look at the theory , it 's  it should be in the power domain but  but , uh , I 've seen implementations where people do it in the magnitude domain\nYeah .\nand\nMmm .\nI have asked people why and they shrug their shoulders and say , \" oh , it works . \" So .\nYeah .\nUh , and there 's this  I guess there 's this mysterious  I mean people who do this a lot I guess have developed little tricks of the trade . I mean , there 's  there 's this , um  you don't just subtract the  the estimate of the noise spectrum . You subtract th that times\nA little bit more and  Yeah .\nOr  or less , or\nReally ?\nYeah .\nHuh !\nYeah .\nAnd generated this  this ,\nUh .\num , so you have the estimation of the power spectra of the noise , and you multiply this by a factor which is depend dependent on the SNR . So . Well .\nHmm , maybe .\nHmm !\nWhen the speech lev when the signal level is more important , compared to this noise level , the coefficient is small , and around one . But when the power le the s signal level is uh small compared to the noise level , the coefficient is more important . And this reduce actually the music musical noise ,\nOh !\nuh which is more important during silence portions ,\nUh - huh .\nwhen the s the energy 's small .\nHmm !\nSo there are tricks like this but , mmm .\nHmm !\nYeah .\nYeah .\nSo .\nIs the estimate of the noise spectrum a running estimate ? Or\nYeah .\nYeah .\nYeah .\nWell , that 's  I mean , that 's what differs from different  different tasks and different s uh , spectral subtraction methods .\nHmm !\nI mean , if  if you have , uh , fair assurance that , uh , the noise is  is quite stationary , then the smartest thing to do is use as much data as possible to estimate the noise , get a much better estimate , and subtract it off .\nMm - hmm .\nBut if it 's varying at all , which is gonna be the case for almost any real situation , you have to do it on - line , uh , with some forgetting factor or something .\nSo do you  is there some long window that extends into the past over which you calculate the average ?\nWell , there 's a lot of different ways of computing the noise spectrum . So one of the things that , uh , Hans - Guenter Hirsch did , uh  and pas and other people  actually , he 's  he wasn't the only one I guess , was to , uh , take some period of  of  of speech and in each band , uh , develop a histogram . So , to get a decent histogram of these energies takes at least a few seconds really . But , uh  I mean you can do it with a smaller amount but it 's pretty rough . And , um , in fact I think the NIST standard method of determining signal - to - noise ratio is based on this .\nA couple seconds ?\nSo  No , no , it 's based on this kind of method ,\nHmm .\nthis histogram method . So you have a histogram . Now , if you have signal and you have noise , you basically have these two bumps in the histogram , which you could approximate as two Gaussians .\nBut wh don't they overlap sometimes ?\nOh , yeah .\nOK .\nSo you have a mixture of two Gaussians .\nYeah .\nRight ? And you can use EM to figure out what it is . You know .\nYeah .\nSo  so basically now you have this mixture of two Gaussians , you  you n know what they are , and , uh  I mean , sorry , you estimate what they are , and , uh , so this gives you what the signal is and what the noise e energy is in that band in the spectrum . And then you look over the whole thing and now you have a noise spectrum . So , uh , Hans - Guenter Hirsch and others have used that kind of method . And the other thing to do is  which is sort of more trivial and obvious   is to , uh , uh , determine through magical means that  that , uh , there 's no speech in some period , and then see what the spectrum is .\nMm - hmm .\nUh , but , you know , it 's  that  that  that 's tricky to do . It has mistakes . Uh , and if you 've got enough time , uh , this other method appears to be somewhat more reliable . Uh , a variant on that for just determining signal - to - noise ratio is to just , uh  you can do a w a uh  an iterative thing , EM - like thing , to determine means only . I guess it is EM still , but just  just determine the means only . Don't worry about the variances .\nMm - hmm .\nAnd then you just use those mean values as being the  the , uh uh signal - to - noise ratio in that band .\nBut what is the  it seems like this kind of thing could add to the latency . I mean , depending on where the window was that you used to calculate  the signal - to - noise ratio .\nYeah , sure . But  Mmm .\nNot necessarily . Cuz if you don't look into the future , right ?\nOK , well that  I guess that was my question ,\nif you just  yeah\nyeah .\nI mean , if you just  if you  you , uh  a at the beginning you have some\nGuess .\nesti some guess and  and , uh , uh\nYeah , but it\nIt 's an interesting question . I wonder how they did do it ?\nActually , it 's a mmm  If - if you want to have a good estimation on non - stationary noise you have to look in the  in the future . I mean , if you take your window and build your histogram in this window , um , what you can expect is to have an estimation of th of the noise in  in the middle of the window , not at the end . So\nWell , yeah ,\nthe  but  but people\nbut what does  what  what  what does Alcatel do ?\nMm - hmm .\nAnd  and France Telecom .\nThe They just look in the past . I guess it works because the noise are , uh pret uh , almost stationary\nPretty stationary .\nPretty stationary ,\nbut , um\nWell , the thing , e e e e\nyeah .\nYeah , y I mean , you 're talking about non - stationary noise but I think that spectral subtraction is rarely  is  is not gonna work really well for  for non - stationary noise ,\nWell , if y if you have a good estimation of the noise ,\nyou know ?\nyeah , because well it it has to work .\nBut it 's hard to\ni\nbut that 's hard to do .\nYeah , that 's hard to do . Yeah .\nYeah . So  so I think that  that what  what is  wh what 's more common is that you 're going to be helped with r slowly varying or stationary noise .\nBut  Mm - hmm .\nThat 's what spectral subtraction will help with , practically speaking .\nMm - hmm . Mm - hmm .\nIf it varies a lot , to get a If  if  to get a good estimate you need a few seconds of speech , even if it 's centered , right ?\nMm - hmm .\nif you need a few seconds to get a decent estimate but it 's changed a lot in a few seconds , then it , you know , i it 's kind of a problem .\nYeah .\nI mean , imagine e five hertz is the middle of the  of the speech modulation spectrum ,\nMmm .\nright ? So imagine a jack hammer going at five hertz .\nYeah , that 's\nI mean , good  good luck . So ,\nSo in this case , yeah , sure , you cannot\nYeah .\nBut I think y um , Hirsch does experiment with windows of like between five hundred milliseconds and one second . And well , five hundred wa was not so bad . I mean and he worked on non - stationary noises , like noise modulated with well , wi with amplitude modulations and things like that ,\nWere his , uh , windows centered around the\nand  But  Um , yeah . Well , I think  Yeah . Well , in  in the paper he showed that actually the estimation of the noise is  is delayed . Well , it 's  there is  you  you have to center the window , yeah .\nYeah .\nMmm .\nNo , I understand it 's better to do but I just think that  that , uh , for real noises wh what  what 's most likely to happen is that there 'll be some things that are relatively stationary\nMmm .\nwhere you can use one or another spectral subtraction thing\nYeah .\nand other things where it 's not so stationary and  I mean , you can always pick something that  that falls between your methods ,\nHmm .\nuh , uh , but I don't know if , you know , if sinusoidally , uh , modul amplitude modulated noise is  is sort of a big problem in  in in  practice .\nYeah .\nI think that  it 's uh\nWe could probably get a really good estimate of the noise if we just went to the noise files , and built the averages from them .\nYeah . Well .\nWhat  What do you mean ?\nJust cheat  You 're saying , cheat .\nBut if the  if the noise is stationary perhaps you don't even need some kind of noise estimation algorithm .\nYeah . Yeah .\nWe just take th th th the beginning of the utterance and\nOh , yeah , sure .\nI I know p I don't know if people tried this for Aurora .\nIt 's the same .\nWell , everybody seems to use some kind of adaptive , well , scheme\nBut  but\nYeah .\nbut ,\nA dictionary .\nis it very useful", "topic_id": 1, "keywords": "discriminative, spectral, lda, discriminant, spectrum", "dialogue_id": 36}, {"text": "you know , stationary\nVery slow adaptation .\nand is the c\nth\nRight , the word \" stationary \" is  has a very precise statistical meaning . But , you know , in  in signal - processing really what we 're talking about I think is things that change slowly , uh , compared with our  our processing techniques .\nMm - hmm .\nSo if you 're driving along in a car I  I would think that most of the time the nature of the noise is going to change relatively slowly . It 's not gonna stay absolute the same . If you  if you check it out , uh , five minutes later you may be in a different part of the road\nMm - hmm .\nor whatever . But it 's  it 's  i i i using the local characteristics in time , is probably going to work pretty well .\nMm - hmm .\nBut you could get hurt a lot if you just took some something from the beginning of all the speech , of , you know , an hour of speech and then later\nYeah .\nUh , so they may be  you know , may be overly , uh , complicated for  for this test but  but  but , uh , I don't know . But what you 're saying , you know , makes sense , though . I mean , if possible you shouldn't  you should  you should make it , uh , the center of the  center of the window . But  uh , we 're already having problems with these delay , uh   delay issues .\nYeah , so .\nSo , uh , we 'll have to figure ways without it . Um ,\nIf they 're going to provide a , uh , voice activity detector that will tell you the boundaries of the speech , then , couldn't you just go outside those boundaries and do your estimate there ?\nOh , yeah . You bet . Yeah . So I  I imagine that 's what they 're doing , right ? Is they 're  they 're probably looking in nonspeech sections and getting some , uh\nYeah , they have some kind of threshold on  on the previous estimate , and  So . Yeah . I think . Yeah , I think Ericsson used this kind of threshold . Yeah , so , they h they have an estimate of the noise level and they put a threshold like six or ten DB above , and what 's under this threshold is used to update the estimate . Is  is that right\nYeah .\nor  ?\nI think so .\nSo it 's  it 's\nI have not here the proposal .\nYeah . It 's like saying what 's under the threshold is silence ,\nDoes France Telecom do this\nand\nHmm .\nDoes France Telecom do th do the same thing ? More or less ?\nI d I  Y you know , perhaps ?\nNo . I do I have not here the proposal .\nOK . Um , OK , if we 're  we 're done  done with that , uh , let 's see . Uh , maybe we can talk about a couple other things briefly , just , uh , things that  that we 've been chatting about but haven't made it into these meetings yet . So you 're coming up with your quals proposal , and , uh  Wanna just give a two three minute summary of what you 're planning on doing ?\nOh , um , two , three , it can be shorter than that .\nYeah .\nUm . Well , I 've  I 've talked to some of you already . Um , but I 'm , uh , looking into extending the work done by Larry Saul and John Allen and uh Mazin Rahim . Um , they  they have a system that 's , uh , a multi - band , um , system but their multi - band is  is a little different than the way that we 've been doing multi - band in the past , where um  Where we 've been @ @  uh taking  um   sub - band features and i training up these neural nets and  on  on phonetic targets , and then combining them some somehow down the line , um , they 're  they 're taking sub - band features and , um , training up a detector that detects for , um , these phonetic features for example , um , he presents um , uh , a detector to detect sonorance . And so what  what it basically is  is , um  it 's  there 's  at the lowest level , there  it 's  it 's an OR ga I mean , it 's an AND gate . So , uh , on each sub - band you have several independent tests , to test whether um , there 's the existence of sonorance in a sub - band . And then , um , it c it 's combined by a soft AND gate . And at the  at the higher level , for every  if , um  The higher level there 's a soft OR gate . Uh , so if  if this detector detects um , the presence of  of sonorance in any of the sub - bands , then the detect uh , the OR gate at the top says , \" OK , well this frame has evidence of sonorance . \"\nWhat are  what are some of the low level detectors that they use ?\nAnd these are all  Oh , OK . Well , the low level detectors are logistic regressions . Um , and the , uh\nSo that , by the way , basically is a  is one of the units in our  in our  our neural network .\nthe one o\nSo that 's all it is . It 's a sig it 's a sigmoid ,\nYeah .\nuh , with weighted sum at the input ,\nHmm .\nwhich you train by gradient  descent .\nRight . Yeah , so he uses , um , an EM algorithm to  to um train up these um parameters for the logistic regression .\nWell , actually , yeah ,\nThe\nso I was using EM to get the targets . So  so you have this  this  this AND gate  what we were calling an AND gate , but it 's a product  product rule thing at the output . And then he uses , uh , i u and then feeding into that are  I 'm sorry , there 's  it 's an OR at the output , isn't it ? Yeah ,\nMm - hmm .\nso that 's the product . And then , um , then he has each of these AND things . And , um , but  so they 're little neural  neural units . Um , and , um , they have to have targets . And so the targets come from EM .\nAnd so are each of these , low level detectors   are they , uh  are these something that you decide ahead of time , like \" I 'm going to look for this particular feature or I 'm going to look at this frequency , \" or  What  what  what are they looking at ?\nUm\nWhat are their inputs ?\nUh Right , so the  OK , so at each for each sub - band  there are basically , uh , several measures of SNR and  and correlation .\nAh , OK , OK .\nUm , um and he said there 's like twenty of these per  per sub - band . Um , and for  for every s every sub - band , e you  you just pick ahead of time , um , \" I 'm going to have like five  i independent logistic tests . \"\nMm - hmm .\nAnd you initialize these parameters , um , in some  some way and use EM to come up with your training targets for a  for the  the low - level detectors .\nMm - hmm .\nAnd then , once you get that done , you  you  you train the whole  whole thing on maximum likelihood . Um , and h he shows that using this  this method to detect sonorance is it 's very robust compared to , um   to typical , uh , full - band Gaussian mixtures um estimations of  of sonorance .\nMm - hmm . Mm - hmm .\nAnd , uh so  so that 's just  that 's just one detector . So you can imagine building many of these detectors on different features . You get enough of these detectors together , um , then you have enough information to do , um , higher level discrimination , for example , discriminating between phones\nMm - hmm .\nand then you keep working your way up until you  you build a full recognizer .\nMm - hmm .\nSo , um , that 's  that 's the direction which I 'm  I 'm thinking about going in my quals .\nCool .\nYou know , it has a number of properties that I really liked . I mean , one is the going towards , um , using narrow band information for , uh , ph phonetic features of some sort rather than just , uh , immediately going for the  the typical sound units .\nRight .\nAnother thing I like about it is that you t this thing is going to be trained  explicitly trained for a product of errors rule , which is what , uh , Allen keeps pointing out that Fletcher observed in the twenties ,\nMm - hmm .\nuh , for people listening to narrow band stuff . That 's Friday 's talk , by the way . And then , um , Uh , the third thing I like about it is , uh , and we 've played around with this in a different kind of way a little bit but it hasn't been our dominant way of  of operating anything , um , this issue of where the targets come from . So in our case when we 've been training it multi - band things , the way we get the targets for the individual bands is , uh , that we get the phonetic label  for the sound there\nMm - hmm .\nand we say , \" OK , we train every  \" What this is saying is , OK , that 's maybe what our ultimate goal is  or not ultimate but penultimate  goal is getting these  these small sound units . But  but , um , along the way how much should we , uh  uh , what should we be training these intermediate things for ? I mean , because , uh , we don't know uh , that this is a particularly good feature . I mean , there 's no way , uh  someone in the audience yesterday was asking , \" well couldn't you have people go through and mark the individual bands and say where the  where it was sonorant or not ? \"\nMm - hmm .\nBut , you know , I think having a bunch of people listening to critical band wide ,  uh , chunks of speech trying to determine whether   I think it 'd be impossible .\nOuch .", "topic_id": 2, "keywords": "stationary, phonetic, noise, tests, speech", "dialogue_id": 36}, {"text": "It 's all gonna sound like  like sine waves to you , more or less .\nMm - hmm .\nI mean  Well not I mean , it 's g all g narrow band uh , i I m I think it 's very hard for someone to  to  a person to make that determination . So , um , um , we don't really know how those should be labeled . It could sh be that you should , um , not be paying that much attention to , uh , certain bands for certain sounds , uh , in order to get the best result .\nMm - hmm .\nSo , um , what we have been doing there , just sort of mixing it all together , is certainly much  much cruder than that . We trained these things up on the  on the , uh the final label . Now we have I guess done experiments  you 've probably done stuff where you have , um , done separate , uh , Viterbis on the different\nYeah . Forced alignment on the sub - band labels ?\nYeah .\nYeah .\nYou 've done that . Did  did that help at all ?\nUm , it helps for one or t one iteration but um , anything after that it doesn't help .\nSo  so that may or may t it  that aspect of what he 's doing may or may not be helpful because in a sense that 's the same sort of thing . You 're taking global information and determining what you  how you should  But this is  this is , uh , I th I think a little more direct .\nHow did they measure the performance of their detector ?\nAnd  Well , he 's look he 's just actually looking at , uh , the confusions between sonorant and non - sonorant .\nMm - hmm .\nSo he hasn't applied it to recognition or if he did he didn't talk about it . It 's  it 's just  And one of the concerns in the audience , actually , was that  that , um , the , uh , uh  he  he did a comparison to , uh , you know , our old foil , the  the nasty old standard recognizer with  mel  mel filter bank at the front , and H M Ms , and  and so forth . And , um , it didn't do nearly as well , especially in  in noise . But the  one of the good questions in the audience was , well , yeah , but that wasn't trained for that . I mean , this use of a very smooth , uh , spectral envelope is something that , you know , has evolved as being generally a good thing for speech recognition but if you knew that what you were gonna do is detect sonorants or not  So sonorants and non - sonorants is  is  is almost like voiced - unvoiced , except I guess that the voiced stops are  are also called \" obstruents \" . Uh , so it 's  it 's  uh , but with the exception of the stops I guess it 's pretty much the same as voiced - unvoiced ,\nMm - hmm .\nright ? So  so  Um . So , um , if you knew you were doing that , if you were doing something say for a  a , uh  a  a Vocoder , you wouldn't use the same kind of features . You would use something that was sensitive to the periodicity and  and not just the envelope . Uh , and so in that sense it was an unfair test . Um , so I think that the questioner was right . It  it was in that sense an unfair test . Nonetheless , it was one that was interesting because , uh , this is what we are actually using for speech recognition , these smooth envelopes . And this says that perhaps even , you know , trying to use them in the best way that we can , that  that  that we ordinarily do , with , you know , Gaussian mixtures and H M Ms  and so forth , you  you don't , uh , actually do that well on determining whether something is sonorant or not .\nDidn't they\nWhich means you 're gonna make errors between similar sounds that are son sonorant or obstruent .\nDidn't they also do some kind of an oracle experiment where they said \" if we  could detect the sonorants perfectly  and then show how it would improve speech recognition ? I thought I remember hearing about an experiment like that .\nThe - these same people ?\nMm - hmm .\nI don't remember that .\nHmm .\nThat would  that 's  you 're right , that 's exactly the question to follow up this discussion , is suppose you did that , uh , got that right . Um , Yeah .\nHmm .\nWhat could be the other low level detectors , I mean , for   Other kind of features , or  ? in addition to detecting sonorants or  ? Th - that 's what you want to  to  to go for also\nUm\nor  ?\nWhat t Oh , build other  other detectors on different  phonetic features ?\nOther low level detectors ? Yeah .\nUm , uh Let 's see , um , Yeah , I d I don't know . e Um , um , I mean , w easiest thing would be to go  go do some voicing stuff but that 's very similar to sonorance .\nMm - hmm .\nUm ,\nWhen we  when we talked with John Ohala the other day we made a list of some of the things that w\nYeah .\nlike frication ,\nOh ! OK .\nabrupt closure ,\nMm - hmm . Mm - hmm .\nR - coloring , nasality , voicing  Uh .\nYeah , so there 's a half dozen like that that are\nYeah , nasality .\nNow this was coming at it from a different angle but maybe it 's a good way to start . Uh , these are things which , uh , John felt that a  a , uh  a human annotator would be able to reliably mark . So the sort of things he felt would be difficult for a human annotator to reliably mark would be tongue position kinds of things .\nOh , OK . Placing stuff ,\nMm - hmm .\nYeah .\nyeah .\nThere 's also things like stress .\nUh\nYou can look at stress .\nBut stress doesn't , uh , fit in this thing of coming up with features that will distinguish words from one another ,\nMm - hmm .\nright ? It 's a  it 's a good thing to mark and will probably help us ultimate with recognition\nYeah , there 's a few cases where it can like permit  and permit .\nbut\nBut  that 's not very common in English . In other languages it 's more uh , important .\nWell , yeah , but i either case you 'd write PERMIT , right ? So you 'd get the word right .\nNo , I 'm saying , i i e I thought you were saying that stress doesn't help you distinguish between words .\nUm ,\nOh , I see what you 're saying . As long as you get  The sequence ,\nWe 're g if we 're doing  if we 're talking about transcription as opposed to something else\nright ? Yeah . Yeah , yeah , yeah . Yeah . Right .\nYeah .\nSo where it could help is maybe at a higher level . Yeah .\nRight .\nLike a understanding application .\nUnderstanding , yeah . Exactly .\nYeah .\nYeah .\nBut that 's this afternoon 's meeting . Yeah . We don't understand anything in this meeting . Yeah , so that 's  yeah , that 's , you know , a neat  neat thing and  and , uh  So .\nS so , um , Ohala 's going to help do these , uh  transcriptions of the meeting data ?\nUh , well I don't know . We d we sort of didn't get that far . Um , we just talked about some possible features that could be marked by humans and , um ,\nHmm .\nbecause of having maybe some extra transcriber time we thought we could go through and mark some portion of the data for that . And , uh\nYeah ,\nHmm .\nI mean , that 's not an immediate problem , that we don't immediately have a lot of extra transcriber time .\nYeah , right .\nBut  but , uh , in the long term I guess Chuck is gonna continue the dialogue with John and  and , uh , and , we 'll  we 'll end up doing some I think .\nI 'm definitely interested in this area , too , f uh , acoustic feature stuff .\nUh - huh .\nOK .\nSo .\nYeah , I think it 's an interesting  interesting way to go .\nCool .\nUm , I say it like \" said - int \" . I think it has a number of good things . Um , so , uh , y you want to talk maybe a c two or three minutes about what we 've been talking about today and other days ?\nRi Yeah , OK , so , um , we 're interested in , um , methods for far mike speech recognition , um ,  mainly , uh , methods that deal with the reverberation  in the far mike signal . So , um , one approach would be , um , say MSG and PLP , like was used in Aurora one and , um , there are other approaches which actually attempt to  remove the reverberation , instead of being robust to it like MSG . And so we 're interested in , um , comparing the performance of  um , a robust approach like MSG with these , um , speech enhancement or de - reverber de - reverberation approaches .\nMm - hmm .\nAnd , um ,  it looks like we 're gonna use the Meeting Recorder digits data for that .\nAnd the de - reverberation algorithm , do you have  can you give some more details on this or  ? Does it use one microphone ?\no o\nSeveral microphones ? Does it  ?\nOK , well , um , there was something that was done by , um , a guy named Carlos , I forget his last name ,  who worked with Hynek , who , um ,\nAvendano .\nOK .\nYeah .\nWho , um ,\nMm - hmm .\num , it was like RASTA in the sense that of it was , um , de - convolution by filtering um , except he used a longer time window ,\nMm - hmm .\nlike a second maybe . And the reason for that is RASTA 's time window is too short to , um include the whole , um , reverberation  um , I don't know what you call it the reverberation response . I if you see wh if you see what I mean . The reverberation filter from my mouth to that mike is like  it 's t got it 's too long in the  in the time domain for the um  for the RASTA filtering to take care of it . And , um , then there are a couple of other speech enhancement approaches which haven't been tried for speech recognition yet but have just been tried for enhancement , which , um , have the assumption that um , you can do LPC um analysis of th of the signal you get at the far microphone and the , um , all pole filter that you get out of that should be good . It 's just the , um , excitation signal  that is going to be distorted by the reverberation and so you can try and reconstruct a better excitation signal and , um , feed that through the i um , all pole filter and get enhanced speech with reverberation reduced .\nMm - hmm . Mm - hmm .\nThere 's also this , uh , um , uh , echo cancellation stuff that we 've sort of been chasing , so , uh we have , uh  and when we 're saying these digits now we do have a close microphone signal and then there 's the distant microphone signal . And you could as a kind of baseline say , \" OK , given that we have both of these , uh , we should be able to do , uh , a cancellation . \" So that , uh , um , we  we , uh , essentially identify the system in between  the linear time invariant system between the microphones and  and  and  and re and invert it , uh , or  or cancel it out to  to some  some reasonable approximation\nMm - hmm .\nthrough one method or another . Uh , that 's not a practical thing , uh , if you have a distant mike , you don't have a close mike ordinarily , but we thought that might make  also might make a good baseline . Uh , it still won't be perfect because there 's noise . Uh , but  And then there are s uh , there are single microphone methods that I think people have done for , uh  for this kind of de - reverberation . Do y do you know any references to any ? Cuz I  I w I was  w w I  I lead him down a  a bad path on that .\nUh , I g I guess  I guess when people are working with single microphones , they are more trying to do\nBut .\nwell , not  not very  Well , there is the Avendano work ,\nRight .\nbut also trying to mmm , uh  trying to f t find the de - convolution filter but in the um  not in the time domain but in the uh the stream of features uh I guess . Well , @ @  there  there 's someone working on this on i in Mons\nYeah , OK .\nSo perhaps , yeah , we should try t to  He 's working on this , on trying to\nYeah .\non re reverberation , um\nThe first paper on this is gonna have great references , I can tell already .\nMm - hmm .\nIt 's always good to have references , especially when reviewers read it or  or one of the authors and ,  feel they 'll \" You 're OK , you 've r You cited me . \"\nSo , yeah . Well , he did echo cancellation and he did some fancier things like , uh ,   uh , training different network on different reverberation conditions and then trying to find the best one , but . Well .\nYeah .\nYeah .", "topic_id": 3, "keywords": "bands, mixing, experiments, labels, band", "dialogue_id": 36}, {"text": "The oth the other thing , uh , that Dave was talking about earlier was , uh , uh , multiple mike things , uh , where they 're all distant . So , um , I mean , there 's  there 's all this work on arrays , but the other thing is , uh ,  what can we do that 's cleverer that can take some advantage of only two mikes , uh , particularly if there 's an obstruction between them , as we  as we have over there .\nIf there is  ?\nAn obstruction between them .\nAh , yeah .\nIt creates a shadow which is  is helpful . It 's part of why you have such good directionality with ,  with two ears\nMm - hmm .\neven though they 're not several feet apart . For most  for most people 's heads .\nThat could help though .\nSo that  Yeah , the  the head , in the way , is really  that 's what it 's for . It 's basically ,\nThat 's what the head 's for ? To separate the ears ?\nYeah , it 's to separate the ears . That 's right , yeah . Yeah . Uh , so . Anyway , O K . Uh , I think that 's  that 's all we have this week .\nOh .\nAnd , uh , I think it 's digit time .\nActually the , um  For some reason the digit forms are blank .\nYeah ?\nUh , I think th that may be due to the fact that  Adam ran out of digits ,  uh , and didn't have time to regenerate any .\nOh ! Oh ! I guess it 's  Well there 's no real reason to write our names on here then ,\nYeah , if you want to put your credit card numbers and , uh\nis there ?\nOh , no  ?\nOr do  did any  do we need the names for the other stuff ,\nUh , yeah , I do need your names and  and the time , and all that ,\nor  ? Oh , OK .\ncuz we put that into the \" key \" files .\nOh , OK .\nUm . But w\nOK .\nThat 's why we have the forms , uh , even if there are no digits .\nOK , yeah , I didn't notice this . I 'm sitting here and I was  I was about to read them too . It 's a , uh , blank sheet of paper .\nSo I guess we 're  we 're done .\nYeah , yeah , I 'll do my credit card number later . OK .", "topic_id": 4, "keywords": "mikes, directionality, mike, ears, heads", "dialogue_id": 36}, {"text": "Hmm . Testing channel two .\nTwo , two .\nTwo .\nTwo . Oh .\nHello ?\nHmm ? Yeah Thank You . OK Well , so Ralf and Tilman are here .\nOK . Great . Great .\nMade it safely .\nSo the  what w we h have been doing i they would like us all to read these digits . But we don't all read them but a couple people read them .\nOK .\nUh , wanna give them all with German accents today or  ?\nSure .\nOK .\nOK and the way you do it is you just read the numbers not as uh each single , so just like I do it .\nMm - hmm .\nOK . First you read the transcript number . Turn .\nOK , uh  What 's\nOK . Let 's be done with this .\nOK .\nOK . this is Ami , who  And this is Tilman and Ralf .\nHi . Uh - huh . Nice to meet you .\nHi .\nHi . OK . So we 're gonna try to finish by five so people who want to can go hear Nancy Chang 's talk , uh downstairs .\nHmm .\nAnd you guys are g giving talks on tomorrow and Wednesday lunch times ,\nYes .\nMmm .\nright ? That 's great . OK so , do y do you know what we 're gonna do ?\nI thought two things uh we 'll introduce ourselves and what we do . And um we already talked with Andreas , Thilo and David and some lines of code were already written today and almost tested and just gonna say we have um again the recognizer to parser thing where we 're working on and that should be no problem and then that can be sort of developed uh as needed when we get  enter the tourism domain . em we have talked this morning with the  with Tilman about the generator .\nS\nand um There one of our diligent workers has to sort of volunteer to look over Tilman 's shoulder while he is changing the grammars to English\nMm - hmm .\nbecause w we have  we face two ways . Either we do a syllable concatenating um grammar for the English generation which is sort of starting from scratch and doing it the easy way , or we simply adopt the ah um more in - depth um style that is implemented in the German system and um are then able not only to produce strings but also the syntactic parse uh not parse not the syntactic tree that is underneath in the syntactic structure which is the way we decided we were gonna go because A , it 's easier in the beginning\nMm - hmm .\nand um it does require some  some knowledge of  of those grammars and  and  and some ling linguistic background . But um it shouldn't be a problem for anyone .\nOK So That sounds good . Johno , are you gonna have some time t to do that uh w with these guys ?\nSure .\ncuz y you 're the grammar maven .\nOK .\nI mean it makes sense ,\nYeah .\ndoesn't it ? Yeah Good . OK . So , I think that 's probably the  the right way to do that . And an Yeah , so I  I actually wanna f to find out about it too , but I may not have time to get in .\nthe  the ultimate goal is that before they leave we  we can run through the entire system input through output on at least one or two sample things . And um and by virtue of doing that then in this case Johno will have acquired the knowledge of how to extend it . Ad infinitum . When needed , if needed , when wanted and so forth .\nOK that sounds great .\nAnd um also um Ralf has hooked up with David and you 're gonna continue either all through tonight or tomorrow on whatever to get the er parser interface working .\nMmm .\nThey are thinning out and thickening out lattices and doing this kind of stuff to see what works best .\nMmm , yep .\nGreat . So , you guys enjoy your weekend ?\nYes , very much so .\nYeah , very much\nOK , before  before you got put to work ?\nYeah\nGreat . OK , so that 's  Sort of one branch is to get us caught up on what 's going on . Also of course it would be really nice to know what the plans are , in addition to what 's sort of already in code .\nYes .\nand we can d I dunno w w was there uh a time when we were set up to do that ? It probably will work better if we do it later in the week , after  we actually understand uh better what 's going on .\nYes .\nHmm .\nYeah .\nSo when do you guys leave ?\nUm we 're here through Sunday ,\nOh\nso All through Friday would be fine .\nOh , OK , so  OK , So  so anyt we 'll find a time later in the week to uh get together and talk about  your understanding of what SmartKom plans are .\nMm - hmm .\nand how we can change them .\nYes . Sure .\nUh ,\nShould we already set a date for that ? Might be beneficial while we 're all here .\nOK ? um What  what does not work for me is Thursday afternoon . I can do earlier in the day on Thursday , or  um  most of the time on Friday , not all .\nThursday morning sounds fine ?\nWha - but , Johno ,\nMm - hmm .\nwhat are your constraints ?\num Thursday afternoon doesn't work for me , but\nNeither does Thursday morning , no ?\nUh Thursday morning should be fine .\nOK .\nEleven ? Eleven on Thursday ?\nI was just thinking I w I will  have  leavened by eleven .\nRight . Right . This is then out of deference to our non - morning people .\nMm - hmm . OK . So at eleven ?\nHmm .\nThursday around eleven ? OK .\nYeah . And actually we can invite um Andreas as well .\nUh he will be in Washington , though .\nOh that 's true . He 's off  off on his trip already .\nbut um David is here and he 's actually knows everything about the SmartKom recognizer .\nThilo . OK well yeah maybe we 'll see if David could make it . That would be good .\nOK so facing to  to what we 've sort of been doing here um well for one thing we 're also using this room to collect data .\nYeah obviously .\num um Not this type of data ,\nOh , OK .\nno not meeting data but sort of  sort ah our version of a wizard experiment such not like the ones in Munich but pretty close to it .\nMm - hmm .\nThe major difference to the Munich ones is that we do it via the telephone\nOK .\neven though all the recording is done here and so it 's a  sort of a computer call system that gives you tourist information\nMm - hmm .\ntells you how to get places . And it breaks halfway through the experiment and a human operator comes on . and part of that is sort of trying to find out whether people change their linguistic verbal behavior when first thinking they speak to a machine and then to a human .\nYeah .\nand we 're setting it up so that we can  we hope to implant certain intentions in people . For example um we have first looked at a simple sentence that \" How do I get to the Powder - Tower ? \" OK so you have the  castle of Heidelberg\nOK .\nand there is a tower and it 's called Powder - Tower .\nOh , OK . Yeah .\nand um so What will you parse out of that sentence ? Probably something that we specified in M - three - L , that is @ @  \" action go to whatever domain , object whatever Powder - Tower \" .\nMmm .\nAnd maybe some model will tell us , some GPS module , in the mobile scenario where the person is at the moment . And um we 've sort of gone through that once before in the Deep Mail project and we noticed that first of all what are  I should 've brought some slides , but what our  So here 's the tower . Think of this as a two - dimensional representation of the tower . And our system led people here , to a point where they were facing a wall in front of the tower . There is no entrance there , but it just happens to be the closest point of the road network to the geometric center Because that 's how the algorithm works . So we took out that part of the road network as a hack and then it found actually the way to the entrance . which was now the closest point of the road network to\nYeah .\nOK , geometric center . But what we actually observed in Heidelberg is that most people when they want to go there they actually don't want to enter , because it 's not really interesting . They wanna go to a completely different point where they can look at it and take a picture .\nOh , OK .\nHmm .\nYeah .\nAnd so what uh uh a s you s let 's say a simple parse from a s from an utterance won't really give us is what the person actually wants . Does he wanna go there to see it ? Does he wanna go there now ? Later ? How does the person wanna go there ? Is that person more likely to want to walk there ? Walk a scenic route ? and so forth . There are all kinds of decisions that we have identified in terms of getting to places and in terms of finding information about things . And we are constructing  and then we 've identified more or less the extra - linguistic parameters that may f play a role . Information related to the user and information related to the situation . And we also want to look closely on the linguistic information that what we can get from the utterance . That 's part of why we implant these intentions in the data collection to see whether people actually phrase things differently whether they want to enter in order to buy something or whether they just wanna go there to look at it . And um so the idea is to construct uh um suitable interfaces and a belief - net for a module that actually tries to guess what the underlying intention  was . And then enrich or augment the M - three - L structures with what it thought what more it sort of got out of that utterance . So if it can make a good suggestion , \" Hey ! \" you know , \" that person doesn't wanna enter . That person just wants to take a picture , \" cuz he just bought film , or \" that person wants to enter because he discussed the admission fee before \" . Or \" that person wants to enter because he wants to buy something and that you usually do inside of buildings \" and so forth . These ah these types of uh these bits of additional information are going to be embedded into the M - three - L structure in an  sort of subfield that we have reserved . And if the action planner does something with it , great . If not you know , then that 's also something um that we can't really  at least we  want to offer the extra information . We don't really  um we 're not too worried .\nMm - hmm .\nHmm .\nI mean  t s Ultimately if you have  if you can offer that information , somebody 's gonna s do something with it sooner or later . That 's sort of part of our belief .\nWhat was he saying ?\nUm , for example , right now I know the GIS from email is not able to calculate these viewpoints . So that 's a functionality that doesn't exist yet to do that dynamically ,\nMm - hmm .", "topic_id": 0, "keywords": "channel, accents, talks, transcript, speak", "dialogue_id": 37}, {"text": "but if we can offer it that distinction , maybe somebody will go ahead and implement it . Surely nobody 's gonna go ahead and implement it if it 's never gonna be used , so . What have I forgotten about ? Oh yeah , how we do it ,\nWell th uh\nyeah that 's the\nNo no . It 's a good time to pause . I s I see  questions on peoples ' faces , so why don't\nOh\nlet 's  let 's  Let 's hear\nWell the obvious one would be if  if you envision this as a module within SmartKom , where exactly would that Sit ? That 's the d\num  so far I 've thought of it as sort of adding it onto the modeler knowledge module .\nOK , yeah .\nSo this is one that already adds additional information to the\nHmm .\nMakes perfect sense . Yes .\nHmm , ah .\nbut it could sit anywhere in the attention - recognition I mean basically this is what attention - recognition literally sort of can\nWell it 's supposed to do . Yeah\nMmm .\nThat 's what it should do .\nYeah .\nRight ,\nYeah .\nyeah .\nHuh .\nYeah .\nWell f from my understanding of what the people at Phillips were originally trying to do doesn't seem to quite fit into SmartKom currently so what they 're really doing right now is only selecting among the alternatives , the hypotheses that they 're given enriched by the domain knowledge and the um discourse modeler and so on .\nYeah .\nSo if  if this is additional information that could be merged in by them .\nYeah .\nAnd then it would be available to action planning and  and others .\nYeah . the\nlet 's  let 's That w OK that was one question . Is there other  other things that cuz  we wanna not Pa - pass over any  you know , questions or concerns that you have .\nWell there 're  there 're two levels of  of giving an answer and I guess on both levels I don't have any um further questions .\nMmm . Mmm .\nuh the  the two levels will be as far as I 'm concerned as  uh standing here for the generation module\nMmm .\nand the other is  is my understanding of what SmartKom uh is supposed to be\nRight .\nand I  I think that fits in perfectly\nSo  well , let me  Let me s  expand on that a little bit from the point of view of the generation .\nHmm .\nYeah .\nSo the idea is that we 've actually got this all laid out an and we could show it to you ig um Robert didn't bring it today but there 's a  a belief - net which is  There 's a first cut at a belief - net that  that doesn't  it  isn't fully uh instantiated , and in particular some of the  the combination rules and ways of getting the  the conditional probabilities aren't there . But we believe that we have laid out the fundamental decisions in this little space\nMm - hmm .\nand the things that influence them . So one of the decisions is what we call this AVE thing . Do you want to um access , view or enter a thing .\nHmm .\nSo that 's a a discrete decision .\nMm - hmm .\nThere are only three possibilities and the uh  what one would like is for this uh , knowledge modeling module to add which of those it is and give it to the planner .\nMm - hmm .\nBut , uh th the current design suggests that if it seems to be an important decision and if the belief - net is equivocal so that it doesn't say that one of these is much more probable than the other , then an option is to go back and ask for the information you want .\nMm - hmm .\nAlright ? Now there are two ways one can go  a imagine doing that . For the debugging we 'll probably just have a  a drop - down menu and the  while you 're debugging you will just  OK . But for a full system , then one might very well formulate a query ,\nMm - hmm .\ngive it to the dialogue planner and say this , you know ar are you know you  are you planning to enter ? Or whatever it  whatever that might be . So that 's  under that model then , There would be a  uh  um a loop in which this thing would formulate a query ,\nYes .\npresumably give it to you . That would get expressed and then hopefully you know , you 'd get an answer  back .\nYep .\nAnd that would of course  the answer would have to be parsed .\nMmm . Yep .\nright and\nYes .\nOK so ,  th  that uh , We probably won't do this early on , because the current focus is more on the decision making and stuff like that .\nYep .\nBut While we 're on the subject I just wanted to give you a sort of head 's up that it could be that some months from now we said \" OK we 're now ready to try to close that loop \" in terms of querying about some of these decisions .\nMm - hmm . Mm - hmm .\nHmm .\nYep . So  my suggestion then is that you um look into the currently ongoing discussion about how the action plans are supposed to look like . And they 're currently um Agreeing or  or in the process of agreeing on an X M L - ification of um something like a state - transition network of how dialogues would proceed . and  The  these um transition networks uh will be what the action planner interprets in a sense .\nHmm . D did you know this Robert ?\nuh Michael is doing that , right ?\nWell uh Marcus Lerkult is actually implementing that stuff and Marcus and Michael together are um leading the discussion there , yeah .\nOK .\nSo we ha we have to get in on that .\nYep .\nMm - hmm .\nMmm .\nbecause um partly those are like X - schemas .\nDefinitely .\nthe transition diagrams .\nHmm .\nAnd it may be that  that um we should early on make sure that they have the flexibility that we need .\nHmm . But they uh Have I understood this right ? They  they govern more or less the  the dialogue behavior or the action\nMm - hmm .\nIt 's not really what you do with the content of the dialogue but it 's So , I mean there is this  this  this nice interf\nuh , No , it 's  it 's also a quantrant uh uh\ni Is it\nSo there 's ac so there  th the word \" action \" , OK , is  is what 's ambiguous here .\nI think . Hmm .\nYes .\nSo , um one thing is there 's an actual planner that tells the person in the tourist domain now ,\nOK .\nper tells the person how to go , \" First go here ,\nMm - hmm .\nfirst go there uh , you know , take a bus \" , whatever it is . So that 's that form of planning , and action , and a route planner and GIS , all sort of stuff . uh But I think that isn't what you mean .\nNo . No , in SmartKom terminology that 's um called a function that 's modeled by a function modeler . And it 's th that 's completely um encapsulated from th the dialogue system . That 's simply a functionality that you give data as in a query and then you get back from that mmm , a functioning model um which might be a planner or a VCR or whatever . um some result and that 's then  then used .\nWell , OK , so that 's what I thought . So action he action here means dia uh speech ac uh you know dialogue act .\nYeah , yeah . Yeah , in that  in that sense\nMmm .\nyes , dialogue act ,\nYeah .\nyeah .\nUm , I think tha I think it 's not going to  I think that 's not going to be good enough . I I don what uh  what I meant by that . So I think the idea of having a , you know , transition diagram for the grammar of conversations is a good idea .\nMm - hmm .\nOK ? And I think that we do hav definitely have to get in on it and find out  OK . But I think that um when  so , when you get to the tourist domain it 's not just an information retrieval system .\nMm - hmm . Clearly . Yes .\nRight ? So this i this is where I think this  people are gonna have to think this through a bit more carefully .\nMm - hmm .\nSo , if it 's only like in  in the  in the film and T V thing , OK , you can do this . And you just get information and give it to people . But what happens when you actually get them moving and so forth and so on\nYep .\nUh , y y your  I d I think the notion of this as a self contained uh module you know th the functional module that  that interacts with  with where the tourism g stuff is going  probably is too restrictive .\nYep .\nNow I dunno how much people have thought ahead to the tourist domain in this\nProbably not enough , I mean an  another uh more basic point there is that the current um tasks and therefore th the concepts in this ac what 's called the action plan and what 's really the dialogue manager .\nYeah\num is based on slots that have to be filled and the um kind of values in these slots would be fixed things like the a time or a movie title or something like this\nMm - hmm . Right .\nwhereas in the a um tourist domain it might be an entire route . Set - based , or even very complex structured information in these slots\nIndeed . Right .\nand I 'm not sure if  if complex slots of that type are really um being taken into consideration .\nOK .\nSo that 's  that 's really something we\nCould you  could you put a message into the right place to see if we can at least ask that question ?\nMm - hmm .\nYep .\nI mean nothing 's being completely settled there\nrea yep\nso this is really an ongoing discussion\nMm - hmm\nand that 's\nyeah and um it might actually OK ah also  because um again in in Deep Map we have faced and implemented those problems once already\nMm - hmm .\nmaybe we can even shuffle some know how from there to to Markus and Michael .\nYes .\nMmm .\nYep .\nAnd um mmm You don't know  OK th I 'll  I 'll talk to Michael it 's what I do anyway . Who  How far is the uh the  the M - three - L specification for  for the la natural language input gone on the  the uh I haven't seen anything for the uh tourist path domain .\nYeah , it 's  it 's not defined yet .\nAnd um you are probably also involved in that ,\nUm  Yeah .\nright ? uh together with the usual gang , um Petra and Jan\nMmm . Yeah , there 's a meeting next next week I think\nOK because That 's  Those are the  I think the  the true key issues is how does the whatever comes out of the language input pipeline look like and then what the action planner does with it  and how that is uh specified . I didn't think of the internal working of the uh the action planner and the language  uh the function model as sort of relevant . Because what  what they take is sort of this  this fixed representation of a  of an intention .\nMm - hmm .\nAnd that can be as detailed or as crude as you want it to be . But um the internal workings of of the  whether you know there 're dialogue  action planners that work with belief - nets that are action planners that work with you know state automata . So that shouldn't really matter too much . I mean it does matter because it does have to keep track of you  we are on part six of r a route that consists of eight steps and so forth\nRight .\nYeah , th there  there  I think there are a lot of reasons why it matters . OK , so that uh , for example , the i it 's the action planner is going to take some spec and s make some suggestions about what the user should do . What the user says after that is going to be very much caught up with what the action planner told it .\nYes .\nIf the  If the parser and the language end doesn't know what the person 's been told OK th it 's you 're making your life much more difficult than it has to be .\nYeah .\nRight ? So if someone says the best t to uh go there is by taxi , let 's say . Now the planner comes out and says you wanna get there fast , take a taxi . OK . And the language end doesn't know that . OK , there 's all sorts of dialogues that won't make any sense which would be just fine .\nhmm\nYeah .\nuh\nThat would b but that  I think that  that uh point has been realized and it 's  it 's not really um been defined yet but there 's gonna be some kind of feedback and input from uh the action planner into all the analysis modules , telling them what to expect and what the current state of the discourse is .\nMmm .\nBeyond what 's currently being implemented which is just word lists .\nYeah , but this is not the st this is not just the state of the discourse .\nMm - hmm .\nOf  of special interest .\nThis is actually the state of the plan . That 's why\nYes , Yes , Mm - hmm yeah .\nMm - hmm .\nOK so it  z and s uh , It 's great if people are already taking that into account . But One would have t have to see  see the details .\nThe specifics aren't really there yet . Yes . So , there 's work to do there .\nYeah . So anyway , Robert , that 's why I was thinking that\nMm - hmm .\num I think you 're gonna need  We talked about this several times that  that  the  the input end is gonna need a fair amount of feedback from the planning end .\nhmm\nIn  in one of these things which are  are much more continuous than the  just the dialogue over movies and stuff .\nYeah .\nMmm .\nAnd even on  on a more basic level the  the action planner actually needs to be able to have um an expressive power that can deal with these structures . And not just um say um  um the dialogue um will consist of ten possible states and th these states really are fixed in  in a certain sense .\nHmm ?\nYou have to\nWould there be any chance of getting the terminology changed so that the dialogue planner was called a \" dialogue planner \" ? Because there 's this other thing The o There 's this other thing in  in the tourist domain which is gonna be a route planner\nThat 'd be nice .\nor  It 's really gonna be an action planner . And  i it\nIt oughta be called a  a dialogue manager . cuz that 's what everybody else calls it .\nI would think ,\nMmm .\nyeah .\nYeah .\nHuh ? So , s So what would happen if we sent a note saying \" Gee we 've talked about this and couldn't we change this uh th the whole word ? \" I have no idea how complicated these things are .\nProbably close to impossible .\nDepends on who you talk to how . We 'll see . I 'll go check , cause I completely agree . Yeah ,\nMmm .\nand I think this is just for historical reasons within uh , the preparation phase of the project and not because somebody actually believes it ought to be action planner . So if there is resistance against changing it , that 's just because \" Oh , We don't want to change things . \" That  that not deep reason\nOK , anyway . I if  if that c in persists then we 're gonna need another term . for the thing that actually does the planning of the uh routes and whatever we are doing for the tourist .\nThat 's external services .\nYeah , but that 's not g eh tha That ha has all the wrong connotations . it 's  it sounds like it 's you know stand alone . It doesn't interact , it doesn't That 's why I 'm saying . I think you can't  it 's fine for looking up when T you know when the show 's on TV . You go to th but I  I  I  I think it 's really  really wrong headed for something that you  that has a lot of state , it 's gonna interact co in a complicated way with the uh understanding parts .\nYeah . Yeah I think just the  the spatial planner and the route planner I showed you once the interac action between them among them in the deep map system\nRight .\nso  a printout of the communication between those two fills up I don't know how many pages\nHmm\nand that 's just part of how do I get to one place . It 's really insane . and uh but um so this is um definitely a good point to get uh Michael into the discussion . Or to enter his discussion , actually .\nYeah , Marcus .\nThat 's the way around . Markus\nWh - where 's ?\nIs he new in the  in the ?\nYeah , he 's  he started um I think January .\nYeah .\nAnd he 's gonna be responsible for the implementation of this action planner . Dialogue manager .\nIs he gonna continue with the old  uh  thing ?\nNo , no he 's completely gonna rewrite everything . In Java .\nOK .\nOK so that 's interesting .\nYes I was just  that 's my next question\nhmm\nwhether we 're  we 're gonna stick to Prolog or not .\nNo . No , that 's gonna be phased out .\nYeah .\nOK But I do think the  the function modeling concept has a certain  makes sense in a  in a certain light\nYeah .\nbecause the action planner should not be  or the dialogue manager in that case should not um w have to worry about whether it 's interfacing with um something that does route planning in this way or that way\nMm - hmm .\nI I totally agree .\nhuh ,\nSure .\nit j\nYeah I  I agree . There is  there 's a logic to dialogue which  which is  is separable . I Yeah .\nand it  cant  sort of formulate its what it wants in a  in a rather a abstract uh way , you know f \" Find me a good route for this . \"\nMm - hmm .\nIt doesn't really have to worry ab how route planner A or how route planner B actually wants it . So this is  seemed like a good idea . In the beginning .\nIt 's tricky . It 's tricky because one could well imagine  I think it will turn out to be the case that uh , this thing we 're talking about , th the extended n uh knowledge modeler will fill in some parameters about what the person wants . One could well imagine that the next thing that 's trying to fill out the detailed uh , route planning , let 's say , will also have questions that it would like to ask the user . You could well imagine you get to a point where it 's got a  a choice to make and it just doesn't know something .\nMm - hmm .\nAnd so y you would like it t also be able to uh formulate a query . And to run that back through uh . the dialogue manager and to the output module and back around .\nhmm\nAnd a I a a good design would  would allow that to happen .\na lot of , yeah\nMmm .\nIf  if you know if  if you can't make it happen then you  you do your best .\nYeah but that doesn't necessarily contradict um an architecture where there really is a pers a def well - defined interface . and  and\nI totally agree . But  but what it nee but th what the point is the in that case the dialogue manager is sort of event driven . So the dialogue manager may think it 's in a dialogue state of one sort ,\nMm - hmm .\nand this  one of these planning modules comes along and says \" hey , right now we need to ask a question \" . So that forces the dialogue manager to change state .\nYes\nOK .\nSure ,\nIt could be y\nye yeah I  I think that 's  that 's the um concept that people have ,\nYeah , yeah it  it\nyep .\nOK .\nAnd  and the  the underlying idea of course is that there is something like kernel modules with kernel functionality that you can plug uh certain applications like tourist information or um the home scenario with uh controlling a VCR and so on . And then extend it to an arbitrary number of applications eventually . So  wouldn't That 's an additional reason to have this well - defined interface and keep these things like uh tourist information external .\nOh , yeah , yeah .\nAnd then call it external services .\nHmm .\nBut of course the  the more complex\nYeah , there is another philosophical issue that I think you know you can  evade\nyep .\nbut , at at least it makes sense to me that sooner or later uh  a service is gonna come and describe itself to you . and that 's sort of what Srini is working on in  in  in the DAML uh project where um you  you find a GIS about  that gives you information on Berkeley ,\nYeah .\nand it 's  it 's gonna be there and tell you what it can do and how it wants to do things . and so you can actually interface to such a system without ever having met it before and the function modeler and a self - description of the um external service haggle it out\nHmm .\nand you can use the same language core , understanding core to interface with planner - A , planner - B , planner - C and so forth .\nHmm .\nMmm .\nWhich is , you know , uh  uh  utopian  completely utopian at the moment , but slowly , you know , getting into the realm of the uh contingent .\nHmm .\nBut we are facing of course much more um realistic problems . And language input for example , is of course uh crucial you know also when you do the sort of deep understanding analysis that we envision . um Then of course , the uh um , you know what is it  poverty of the stimulus , yet the m uh the less we get of that the better . and um so we  we 're thinking , for example how much syntactic analysis actually happens already in the parser . and whether one could interface to that potentially\nHmm . Yeah , are there currently is uh no syntactic analysis but in the next release there will be some .\nHmm .\nunless\nHow 's it\nand it 's um uh you can access this\nS so uh y we  we looked at the e current pattern matching thing .\nHmm .\nAnd as you say it 's just a surface pattern matcher . Uh , So what are  what are the plans roughly ?\num it 's to  to integrate and syntactic analysis . and um add some more features like segmentation . So then an utter more than one utterance is  There um there 's often uh pause between it and a segmentation occurs . um\nSo , the um  So the idea is to uh  have a pa y y a particular\nyeah\nDo you have a particular parser in mind ? Is it uh  partic d I mean have you thought through  ? Is it an HPSG parser ? Is it a whatever ?\nNo  no it 's  uh I think it 's it 's totally complicated for it 's just one  one person\nOK .\nand so I have to keep the\nOh , you have to do it . You have to do it ,\nYeah ,\nyeah .\nah and so  things must be simpler\nI see ,\nbut uh , Miel syntactic analysis with um finite state transducers .\nso But the people at D F Yeah . People at DFKI have written a fair number of parsers . Other  you know , people over the years . uh have written various parsers at DFKI . None of them are suitable ? I  I  I d I 'm asking . I don't know .\nYeah , uh the problem is th that it has to be very fast because um if you want to for more than one path anywhere\nOK .\nwhat 's in the latches from the speech recognizer\nMm - hmm .\nso it 's speed is crucial . uh And they are not fast enough .\nMm - hmm .\nAnd they also have to be very robust . cuz of um speech recognition errors and\nOK . So , um  So there was a chunk parser in Verbmobil , that was one of the uh branchers . You know they  d th I c There were these various uh , competing uh syntax modules . And I know one of them was a chunk parser and I don't remember  who did that .\nA Alan ?\nI think it 's that might , at Tuebingen I thought .\nYeah I d I don't remember .\nwas  Do you know something about that ?", "topic_id": 1, "keywords": "smartkom, attention, concept, concepts, recognizer", "dialogue_id": 37}, {"text": "Tubingen was at least involved in putting the chunks together\nIn Tub - at\nI  can't quite recall whether they actually produced the chunks in the first place .\noh\nUh . I see . Yeah , that 's right .\nOr wh\nOh from  from Stuttgart ,\nThere w That 's right . They w They had  There were  This was done with a two phase thing , where  the chunk parser itself was pretty stupid\nyeah , also\nand then there was a kind of trying to fit them together that h used more context .\nRight . Yeah\nRight ?\nWell you s and  and especially you did some  some um , l um was a learning - based approach which learned from a big corpus of  of trees .\nMm - hmm .\nRight .\nAnd yes the  it  the chunk parser was a finite - state machine that um Mark Light originally w worked on in  while he was in Tuebingen\nRight .\nand then somebody else in Tuebingen picked that up . So it was done in Tuebingen , yeah . Definitely .\nBut is that the kind of thing y It sounds like the kind of thing that you were thinking of .\nYeah I guess it 's similar .\nyeah . yeah that 's In this direction , yes\nWhat ?\nYeah , it 's in  in this direction .\nThe\nHmm .\nFrom Michael Strube , I 've heard very good stuff about the chunk parser that is done by FORWISS , uh , which is in embassy doing the parsing .\nMm - hmm .\nSo this is sort of  came as a surprise to me that you know , embassy s  is featuring a nice parser but it 's  what I hear . One could also look at that and see whether there is some synergy possible .\nMm - hmm , yeah , it would be very interesting , Mm - hmm . Mmm , yeah .\nAnd they 're doing chunk parsing and it 's uh  I  I can give you the names of the people who do it there . But um . Then there is of course more ways of parsing things .\nOf course . But  But uh given th the constraints , that you want it to be small and fast and so forth , my guess is you 're probably into some kind of chunk parsing . And uh I 'm not a big believer in this um statistical you know , cleaning up uh It  That seems to me kind of a last resort if uh you can't do it any other way . uh but I dunno .\nHmm .\nIt may  i i may be that 's what you guys finally decide do . Uh . And have you looked  uh just  again for context\nMm - hmm .\nThere is this  this one that they did at SRI some years ago  Fastus ?\num\na\nyeah , I 've  I 've looked at it but  but it 's no  not much uh information available . I found ,\nah !\nbut it 's also finite - state transducers , I thought .\nIt is . Yeah . I mean  it 's  it was pretty ambitious .\nand\nAnd of course it was English oriented ,\nYeah , and  and Purely finite - state transducers are not so good for German since there 's um\num w Right .\nThe word order is  is uh not fixed\nYeah , I guess that 's the point is  is all the morphology and stuff . And English is all th all word order . And it makes a lot more sense .\nYeah .\nAnd  e Yeah , OK . Good point . So in  in  in German you 've got uh most of this done with\nMm - hmm . Also it 's uh  it 's um  Yes , uh the um choice between uh this processing and that processing and my template matcher .\nRight . Right .\nSo what about Um Did y like Morfix ? a a e y you 've got stemmers ? Or is that something that\nUm , yeah but it 's all in the  in the lexicon . So it 's\nBut did you have that ?\nYeah th the information is available .\nOK . I see . So , but\nSo\nSo y you just connect to the lexicon\nYeah\nand uh at least for German you have all  all of the  uh the stemming information .\nYeah , we can , oh yeah . We have knowledge bases from  from Verbmobil system we can use\nYep .\nand so .\nRight . But it  it  it doesn't look like i you 're using it . I didn't n see it being used in the current template uh parser . I  I didn't see any Uh  of course we l actually only looked at the English .\nIt  um\nDid we look at the German ? I don't remember .\nYeah , but  but it 's used for  for stem forms .\nSo w wha\nn Well I think  I think there 's some misunderstanding here\ni\nit 's  Morphix is not used on - line .\nOh , OK .\ns so the lexicon might be derived by Morphix\nWhat ?\nbut What  what 's happening on - line is just um um a  a retrieval from the lexicon which would give all the stemming information\nRight .\nHmm .\nRight .\nso it would be a full foreign lexicon .\nAnd that 's what you have .\nYep .\nYeah\nOK .\nWe threw out all the forms .\nWhat  uh I didn't reme\nWe threw out all the forms\nHuh ?\nbecause , you know , English , well\nOh OK , so it  yeah , s s I thought I 'd\nMm - hmm .\nSo in German then you actually do case matching and things like in the  in the pattern matcher or not ?\num Not yet but it 's planned to do that .\nOK . Cuz I r I didn't reme I didn't think I saw it .\nYeah\nHave we looked at the German ? Oh , I haven yeah that 's  getting it from the lexicon is just fine .\nSure , right .\nOh yes .\nYeah , yeah , yeah . No problem with that . um Yeah and here 's the case where the English and the German might really be significantly different . In terms of if you 're trying to build some fast parser and so forth and  You really might wanna do it in a significantly different way . I don't know . So you 've  you guys have looked at this ? also ? in terms of You know , w if you 're doing this for English as well as German Um Do you think now that it would be this  doing it similarly ?\num Yeah , it 's um I think it 's um yes , it 's  it 's um possible to  to do list processing . and Maybe this is um more adequate for English and in German um set processing is used .\nSet .\nMaybe yeah . Some extensions uh have to be made . For  for a English version\nMmm . OK . Interesting . Not easy .\nWell there 's m I 'm sure there 's gonna be more discussion on that after your talk .\nMm - hmm ,\nWe 're just gonna foreshadow what we saw that\nyeah .\nRight . Right .\nand um\nNow actually , um Are you guys free at five ? Or  Do you have to go somewhere at five o ' clock tonight ? W in ten minutes ?\nAh\nuh  uh  I think we 're expect\nmmm . No . Oder there was an  talk ?\nYeah , there  there 's the um practice talk .\nuh Mmm , yeah .\nGreat . So you 're going to that .\nYeah , that  that 's what we were planning to do .\nThat 's good , because that will uh tell you a fair amount about The form of semantic construction grammar that we 're using .\nYeah . Mm - hmm .\nso  So I th I think that probably as good an introduction as you 'll get .\nAh .\nUh to the form of  of uh  conceptual grammar that  that w we have in mind for this .\nMmm , ah .\nIt won't talk particularly about how that relates to what uh Robert was saying at the beginning . But let me give you a very short version of this . So we talked about the fact that There 're going to be a certain number of decisions That you want the knowledge modeler to make , that will be then fed to the function module , that does uh , route planning . It 's called the \" route planner \" or something .\nMm - hmm .\nSo there are these decisions . And then one half of this we talked about at little bit is how if you had the right information , if you knew something about what was said and about th the something about was the agent a tourist or a native or a business person or uh young or old , whatever . That information , and also about the Uh , what we 're calling \" the entity \" , Is it a castle , is it a bank ? Is it a s town square , is it a statue ? Whatever . So all that kind of information could be combined into decision networks and give you decisions . But the other half of the problem is How would you get that kind of information from the parsed input ? So , um So what you might try to do is just build more templates , saying uh we 're trying to build a templ you know build a template that w uh somehow would capture the fact that he wants to take a picture .\nMmm .\nOK ? And  and we could  you could do this . And it 's a small enough domain that probably you , you know\nMmm .\nOK . You could do this . But uh from our point of view this is also a research project and there are a couple of people not here for various reasons who are doing doctoral dissertations on this ,\nMm - hmm .\nand the idea that we 're really after is a very deep semantics based on cognitive linguistics and the notion that there are a relatively small number of primitive conceptual schemas that characterize a lot of activity . So a typical one in this formulation is a container . So this is a static thing . And the notion is that all sorts of physical situations are characterized in terms of containers . Going in and out the portals and con\nMmm .\nOK . But also , importantly for Lakoff and these guys is all sorts of metaphorical things are also characterized this way . You get in trouble and you know et cetera\nMmm .\nand so  s So , what we 're really trying to do is to map from the discourse to the conceptual semantics level . And from there to the appropriate decisions .\nMm - hmm .\nSo another one of these primitive , what are called \" image schemas \" , is uh goal seeking . So this a notion of a source , path , goal , trajector , possibly obstacles .\nMm - hmm .\nAnd the idea is this is another conceptual primitive .\nMm - hmm .\nAnd that all sorts of things , particularly in the tourist domain , can be represented in terms of uh source , path and goal . So the idea would be could we build an analyser that would take an utterance and say \" Aha ! th this utterance is talking about an attempt to reach a goal . The goal is this , the pers the , uh traveller is that , uh the sor w where we are at now is is this , they 've mentioned possible obstacles , et cetera . \" So th the  and this is an  again attempt to get very wide coverage . So if you can do this , then the notion would be that across a very large range of domains , you could use this deep conceptual basis as the interface .\nMm - hmm . Mm - hmm .\nAnd then , uh The processing of that , both on the input end , recognizing that certain words in a language talk about containers or goals , et cetera , and on the output end , given this kind of information , you can then uh make decisions about what actions to take . Provides , they claim , a very powerful , general notion of deep semantics . So that 's what we 're really doing .\nMm - hmm .\nAnd Nancy is going to  Her talk is going to be not about using this in applications , but about modeling how children might learn this kind of uh deep semantic grammar .\nMm - hmm . Yep , yep . And how do you envision um the  the um this deep semantic to be worked with . Would it be highly ambiguous if and then there would be another module that takes that um highly underspecified deep semantic construction and map it onto the current context to find out what the person really was talking about in that context . or  or a\nWell that 's  that 's  that 's where the belief - net comes in . So th the idea is , let 's take this business about going to the Powder - Tower .\nMm - hmm .\nSo part of what you 'll get out of this will be the fact tha w if it works right , OK , that this is an agent that wants to go to this place and that 's their goal\nMm - hmm .\nand there will be additional situational information .\nOh , OK .\nUh , OK ,\nth\npart of it comes from the ontology . The tower is this kind of object .\nMm - hmm . Yeah , OK .\nPart of it comes from the user model .\nMm - hmm .\nAnd the idea of the belief - net is it combines the information from the dialogue which comes across in this general way ,\nMm - hmm .\nyou know this is a  this is a goal seeking behavior , along with specific information from the ontology about the kinds of objects involved\nYeah OK , Yeah , yep yep yep yep\nand about the situation about \" Is it raining ? \" I don't know . Whatever it is . And so that 's the belief - net that we 've laid out .\nMm - hmm .\nAnd so th the coupling to the situation comes in this model from , at th at th at the belief - net , combining evidence from the dialogue with the ontology with the situation .\nYeah .\nHmm .\nBut Nancy isn't gonna talk about that ,\nYeah , oh yeah , I see ,\njust about the um\nyeah yeah , really .\nFirst steps .\nRight . The  the construction grammar .\nAnd she 's gonna start in a minute .\nIn a minute .\nAh , OK .\nOK .\nIs it i in , then , your place , in five  five - A ?\nAlright .", "topic_id": 2, "keywords": "tubingen, tub, chunks, chunk, linguistics", "dialogue_id": 37}, {"text": "As usual .\nYes . Whew ! I almost forgot  about the meeting . I woke up twenty minutes ago , thinking , what did I forget ?\nIt 's great how the br brain sort of does that .\nSomething 's not right here .\nInternal alarms .\nOK . So the news for me is A , my forthcoming travel plans\nYes .\nin two weeks from today ? Yeah ? More or less ? I 'll be off to Sicily and Germany for a couple , three days .\nNow what are y what are you doing there ? I forgot ?\nOK , I 'm flying to Sicily basically to drop off Simon there with his grandparents . And then I 'm flying to Germany t to go to a MOKU - Treffen which is the meeting of all the module - responsible people in SmartKom ,\nMmm .\nand , represent ICI and myself I guess there . And um . That 's the mmm actual reason . And then I 'm also going up to EML for a day , and then I 'm going to  meet the very big boss , Wolfgang Walster , in Saarbruecken and the System system integration people in Kaiserslautern and then I 'm flying back via Sicily pick up my son come back here on the fourth of July . And uh .\nWhat a great time to be coming back to the\nGod bless America .\nYou 'll see maybe  see the fireworks from your plane coming in .\nAnd I 'm sure all the  the people at the airport will be happy to work on that day .\nYeah . You 'll get even better service than usual .\nWait , aren't you flying on Lufthansa though ?\nMm - hmm . Alitalia .\nOh . Well then the  you know , it 's not a big deal . Once you get to the United States it 'll be a problem , but\nYeah . And um , that 's that bit of news , and the other bit of news is we had  you know , uh , I was visited by my German project manager who A , did like what we did  what we 're doing here , and B , is planning to come here either three weeks in July or three weeks in August , to actually work .\nOn  ?\nWith us .\nOh .\nAnd we sat around and we talked and he came up  we came up  with a pretty strange idea . And that 's what I 'm gonna lay on you now . And um , maybe it might be ultimately the most interesting thing for Eva because she has been known to complain about the fact that the stuff we do here is not weird enough .\nOK .\nSo this is so weird it should even make you happy .\nUh .  OK .\nOh great .\nImagine if you will ,  that we have a system that does all that understanding that we want it to do based on utterances .\nMm - hmm .\nIt should be possible to make that system produce questions . So if you have the knowledge of how to interpret \" where is X ? \" under given conditions , situational , user , discourse and ontological  conditions , you should also be able to make that same system ask \" where is X ? \"\nMm - hmm .\nin a sper certain way , based on certain intentions . So in instead of just being able to observe phenomenon , um , and , guess the intention we might be able just to sort of give it an intention , and make it produce an utterance .\nHmm .\nWell , like in AI they generally do the take in , and then they also do the generation phase , like Nancy 's thing . Or uh , you remember , in the  the hand thing in one - eighty - two , like not only was it able to recognize but it was also to generate based upon situations . You mean that sort of thing ?\nAbsolutely .\nOK .\nAnd once you 've done that what we can do is have the system ask itself . And answer , understand the answer , ask something else , and enter a dialogue with itself . So the  the ba basic  the same idea as having two chess computers play against each other .\nExcept this smacks a little bit more of a schizophrenic computer than AI .\nYeah you c if you want , you can have two parallel  machines um , asking each other . What would that give us ? Would A be something completely weird and strange , and B , i if you look at all the factors , we will never observe people let 's say , in wheelchairs under  you know , in  under all conditions ,\nThat 's good .\nyou know , when they say \" X \" , and there is a ride at the goal , and the parking is good , we can never collect enough data . It 's  it 's  it 's not possible .\nMm - hmm . Right , right .\nBut maybe one could do some learning . If you get the system to speak to itself , you may find n break downs and errors and you may be able to learn . And make it more robust , maybe learn new things . And um , so there 's no  no end of potential things one could get out of it , if that works . And he would like to actually work on that with us .\nWell then , he probably should be coming back a year  from now .\nSo Yeah , I w See the  the generation bit , making the system generate  generate something ,  is  shouldn't be too hard .\nWell , once the system understands things .\nYeah . No problem .\nI just don't think  I think we 're probably a year away from getting the system to understand things .\nYeah . Well , if we can get it to understand one thing , like our \" where is \" run through we can also , maybe , e make it say , or ask \" where is X ? \" Or not .\nMmm , I don't know . e I 'm sort of  have the impression that getting it to say the right thing in the right circumstances is much more difficult than getting it to understand something given the circumstances and so on , you know , I mean just cuz it 's sort of harder to learn to speak correctly in a foreign language , rather than learning to understand it . Right ? I mean\njust the fact that we 'll get  The point is that getting it to understand one construction doesn't mean that it will n always know exactly when it 's correct to use that construction . Right ?\nIt 's  it 's uh  Well , I 've  I 've done generation and language production research for fo four  four and a half years . And so it 's  it 's  you 're right , it 's not the same as the understanding . It 's in some ways easier and some ways harder . nuh ?\nYeah .\nBut , um , I think it 'd be fun to look at it , or into that question .\nNnn , yeah .\nIt 's a pretty strange idea . And so that 's  that 's  But\nThe basic idea I guess would be to give  allow the system to have intentions , basically ? Cuz that 's basically what needs to be added to the system for it .\nWell , look at th eee , I think even  think even  What it  would be the  the prior intention . So let 's uh  uh , let 's say we have this\nWell we 'd have to seed that , I mean .\nNo . Let 's  we have to  we have some  some top - down processing , given certain setting . OK , now we change nothing , and just say ask something . Right ?\nWhat would it ask ?\nIt wouldn't know what to ask . I mean .\nIt shur\nUnless it was in a situation . We 'd have to set up a situation where , it didn't know where something was and it wanted to go there .\nYeah !\nMm - hmm .\nYeah .\nWhich means that we 'd need to set up an intention inside of the system . Right ? Which is basically , \" I don't know where something is and I need to go there \" .\nEh , n\nYeah .\nOoh , do we really need to do that ? Because ,\nWell , no I guess not . Excel\ns It 's  i I know it 's  it 's strange , but look at it  look at our Bayes - net . If we don't have  Let 's assume we don't have any input from the language . Right ? So there 's also nothing we could query the ontology , but we have a certain user setting . If you just ask , what is the likelihood of that person wanting to enter some  something , it 'll give you an answer .\nSure .\nRight ? That 's just how they are . And so , @ @ whatever that is , it 's the generic default intention . That it would find out . Which is , wanting to know where something is , maybe nnn  and wanting  I don't know what it 's gonna be , but there 's gonna be something that\nWell you 're not gonna  are you gonna get a variety of intentions out of that then ? I mean , you 're just talking about like given this user , what 's the th what is it  what is that user most likely to want to do ?\nWell you can observe some user and context stuff and ask , what 's the posterior probabilities of all of our decision nodes .\nAnd , have it talk about  OK .\nYou could even say , \" let 's take all the priors , let 's observe nothing \" , and query all the posterior probabilities . It - it 's gonna tell us something . Right ?\nWell , it will d r assign values to all the nodes . Yes .\nAnd  Yes . And come up with posterior probabilities for all the values of the decision nodes . Which , if we have an algorithm that filters out whatever the  the best or the most consistent answer out of that , will give us the intention ex nihilo . And that is exactly what would happen if we ask it to produce an utterance , it would be b based on that extension , ex nihilo , which we don't know what it is , but it 's there . So we wouldn't even have to  t to kick start it by giving it a certain intention or observing anything on the decision node . And whatever that  maybe that would lead to \" what is the castle ? \" ,\nI 'm just\nor \" what is that whatever \" .\nI guess what I 'm afraid of is if we don't , you know , set up a  situation ,  we 'll just get a bunch of garbage out , like you know , everything 's exactly thirty percent .\nNo\nMmm .\nYeah . So what we actually then need to do is  is write a little script that changes all the settings , you know , go goes through all the permutations , which is  we did a  didn't we calculate that once ?\nWell that was  that was absurdly low , in the last meeting ,\nIt 's a\nUh ,\ncuz I went and looked at it cuz I was thinking , that could not be right , and it would  it was on the order of twenty output nodes and something like twenty\nAnd like thirty input nodes\nthirty input nodes .\nor some\nSo to test every output node , uh , would at least  Let 's see , so it would be two to the thirty for every output node ? Which is very th very large .\nOh ! That 's n\nOh .\nthat 's  that 's nothing for those neural guys . I mean , they train for millions and millions of epochs .\nWell , I 'm talking about\nSo .\nOh , I was gonna take a drink of my water . I 'm talking about billions and billions and billions and a number  two to the thirty is like a Bhaskara said , we had calculated out and Bhaskara believes that it 's larger than the number of particles in the universe . And if i\nI don't know if that 's right or not . Th - that 's big . That 's just  That 's uh  It 's a billion , right ?\nTwo to the thirty ? Well , two to the thirty is a billion , but if we have to do it two to the twenty times , then that 's a very very large number .\nRight . Argh . Oh , OK . Yeah . Yeah , that 's big .\nCuz you have to query the node , for every a uh , or query the net two to the twenty times .\nSure . Alright .\nOr not two to th excuse me , twenty times .\nOK . So , is it t comes to twenty billion or something ?\nYes . As far as\nThat 's pretty big , though .\nThat 's @ @  That 's big . Actually  Oh ! We calculated a different number before . How did we do that ?\nHmm .\nI remember there being some other one floating around . But anyway , uh .\nI don't really know .\nYeah , it 's g Anyway , the point is that given all of these different factors , it 's uh e it 's  it 's still going to be impossible to run through all of the possible situations or whatever .\nOoo , it 's just big .\nBut I mean , this 'll get us a bit closer at least , right ? I mean .\nIf it takes us a second to do , for each one , and let 's say it 's twenty billion ,  then that 's twenty billion seconds , which is\nYeah .\nEva , do the math .\nCan't .\nLong !\nHours and hours and hours and hours . But we can do randomized testing .\nTah - dah !\nWhich probabilistically will be good enough .\nMm - hmm . Yeah . So , it be it it 's an idea that one could n for  for example run  run past , um , what 's that guy 's name ? You know ? He - he 's usually here . Tsk . J J Jer - Jerj\nHere in the group ? Jerry Feldman .\nOh , yeah . That 's the guy . We  we  we  we g\nWait , who ?\nYeah , i that would the g the bald guy .\nOh ! My advisor !\nAnd um . so this is just an idea that 's floating around and we 'll see what happens . And um , hmm , what other news do I have ? Well we fixed some more things from the SmartKom system , but that 's not really of general interest , Um , Oh ! Questions , yeah . I 'll ask Eva about the E Bayes and she 's working on that . How is the generation XML thing ?\nI 'm gonna work on that today and tomorrow .\nOK . No need to do it today or tomorrow even . Do it next week or\nI 'm gonna finish it today , uh hopefully .\nOK .\nI wanna do one of those things where I stay here . Cuz uh , if I go home , I can't finish it . I 've tried about five times so far , where I work for a while and then I 'm like , I 'm hungry . So I go home , and then I think\nI 'm not going back .\nYeah . Either that or I think to myself , I can work at home . And then I try to work at home , but I fail miserably .\nYeah .\nLike I ended up at Blakes last night .\nNon - conducive .\nNo . I almost got into a brawl . But I did not finish the uh , But I 've been looking into it . I th @ @ It 's not like it 's a blank slate . I found everything that I need and stu and uh ,\nBut st\nAt the b uh furthermore , I told Jerry that I was gonna finish it before he got back . So .\nOK .\nThat 's approaching . He 's coming back when ? Uh next\nWell , I think  we think we 'll see him definitely on Tuesday for the next  Or , no , wait . The meetings are on Thursday .\nMaybe .\nMaybe .\nWho knows .\nOK .\nWell , we 'll see him next week .\nAlright .\nThat 's good . Yeah . The paper .\nHmm .", "topic_id": 0, "keywords": "meeting, sicily, meetings, plans, meet", "dialogue_id": 38}, {"text": "I was thinking about that .\nHmm .\nI think I will try to work on the SmartKom stuff and I 'll  if I can finish it today , I 'll help you with that tomorrow , if you work on it ? I don't have a problem with us working on it though ? So .\nOK .\nAnd it\nSo you would say it 's funky cool .\nI mean we just  I mean it wouldn't hurt to write up a paper , cuz then , I mean , yeah  I was talking with Nancy and Nancy said , you don't know whether you have a paper to  write up until you write it up . So .\nYeah .\nWell\nAnd since Jerry 's coming back , we can run it by him too . So .\nYep . Um , what 's your input ?\nWell , um , I don't have much experience with uh , conference papers for compu in the computer science realm , and so when I looked at what you had , which was apparently a complete submission , I just sort of said what  just  I  I didn't really know what to do with it , like , this is the sort of the basic outline of the system or whatever , or  or \" here 's an idea \" , right ? That 's what that paper was , \" here 's  here 's one possible thing you could do \" ,\nMm - hmm .\nshort , eight pages , and I just don't know what you have in mind for expanding . Like I 'd  I  what I didn't do is go to the web site of the conference and look at what they 're looking for or whatever .\nMm - hmm . Well , it seems to me that um\nWait , is this a computer science conference or is it a\nUm , well it 's more  It 's both , right ? It 's  it 's sort of t cognitive , neural , psycho , linguistic , but all for the sake of doing computer science . So it 's sort of cognitive , psycho , neural , plausibly motivated , architectures of natural language processing . So it seems pretty interdisciplinary , and I mean , w w the keynote speaker is Tomasello and blah - blah - blah ,\nRight . Oh , yeah .\nso , W the  the question is what could we actually do and  and  and keep a straight face while doing it .\nWell , I really can't keep a straight face doing anything .\nAnd i My idea is ,\nSetting that aside .\nwell , you can say we have done a little bit and that 's this , and uh sort of the rest is position paper , \" we wanna also do that \" . Which is not too good . Might be more interesting to do something like let 's assume um , we 're right , we have as Jerry calls it , a delusion of adequacy , and take a \" where is X \" sentence ,\nMm - hmm .\nand say , \" we will just talk about this , and how we cognitively , neurally , psycho - linguistically , construction grammar - ally , motivated , envision uh , understanding that \" .\nMmm .\nSo we can actually show how we parse it . That should be able to  we should be able to come up with , you know , a sort of a  a parse .\nRight .\nIt 's on , just  just put it on .\nI 'm OK .\nDid Ben harass you ?\nYes .\nGood .\nWas he supposed to harass me ?\nYes .\nWell , he just told me that you came looking for me .\nYou don\nOh .\nfigure this out .\nYou will suffer in hell , you know that .\nBackwards . There 's a s diagram somewhere which tells you how to put that\nI know , I didn't understand that either !\nNo wait . You have to put it on exactly like that ,\nThis is it . Yeah .\nso put that  those things over your ears like that .\nOK .\nSee the p how the plastic things ar arch out like that ? There we go .\nOK . It hurts .\nIt hurts . It hurts real bad .\nIt does ! I 'm sorry I didn't mean to\nBut that 's what you get for coming late to the meeting .\nI 'm sorry . I 'm sorry , oh these are all the same . OK ! th this is not very  on target .\nIs your mike on ?\nAn\nShoot .\nYeah , it is .\nOK .\nAlright , you guys can continue talking about whatever you were talking about before .\nUm ,\nWe 're talking about this um , alleged paper that we may , just , sort of w\nOh ! Which Johno mentioned to me . Uh - huh .\nYeah . And I just sort of brought forth the idea that we take a sentence , \" Where is the Powder - Tower \" ,\nMm - hmm .\nand we  we p pretend to parse it , we pretend to understand it , and we write about it .\nHmm . About how  all of these things\nWhat 's the part that 's not pretend ? The writing ?\nOK , then we pretend to write about .\nThe submitting to a major international conference .   Yeah .\nTha -  Which conference is it for ?\nIt 's the whatever , architectures , eh you know , where  There is this conference , it 's the seventh already international conference , on neu neurally , cognitively , motivated , architectures of natural language processing .\nOh . Wow . Interesting .\nAnd the keynote speakers are Tomasello , MacWhinney ?\nWhinney .  MacWhinney. Uh - huh .\nWe - MacWhinney , I think .\nSo , interesting , both , like , child language people .\nYeah . Yep .\nOK .\nSo maybe you wanna write something too .\nYeah , maybe I wanna go . Um , why are they speaking at it if it\nMmm .  Mmm .\nis  is it normally like  like , dialogue systems , or , you know , other NLP - ish things ?\nNo no no no no no no no . It 's  it 's like a\nOh , it 's cognitive . OK .\nYeah . Yeah . Even neuro .\nAnd uh , both learning and like , comprehension , production , that kinda stuff .\nPsycho . You could look at the web site .\nOK .\nI 'll\nOK . I don't know about it .\nAnd the ad and  and the deadline is the fifteenth of June .\nYeah that 's pretty soon .\nMmm .\nHey . Plenty of time .\nWhy , we 've got over a week !\nIt would be nice to go write two papers actually . Yeah . And one  one from your perspective , and one from our peve per per\nMm - hmm . I mean , th that 's the kinda thing that maybe like , um , the general uh con sort of like NTL - ish like , whatever , the previous simulation based pers  maybe you 're talking about the same kind of thing . A general paper about the approach here would probably be appropriate . And good to do at some point anyway .\nYeah . Yeah .\nUm .\nWell , I  I also think that if we sort of write about what we have done in the past six months , we  we  we could sort of craft a nice little paper that  if it gets rejected , which could happen , doesn't hurt\nMm - hmm .\nbecause it 's something we eh\nHaving it is still a good thing .\nhaving it is a good  good thing .\nYeah .\nIt 's a nice exercise , it 's  I usually enjoy writing papers . It 's not  I don't re regard it as a painful thing .\nMm - hmm . It 's fun .\nAnd um , we should all do more for our publication lists . And . It just never hurts . And Keith and - or Johno will go , probably .\nWill I ?\nWhen is it and where ?\nIn case of\nHmm !\nIt 's on the twenty second of September , in Saarbruecken Germany .\nAh , it 's in Germany . Ah , OK . I s I see . Tomasello 's already in Germany anyway , so makes sense . OK .\nJust\nUm . OK . So , is the  What  Are you just talking about you know , the details of how to do it , or whether to do it , or what it would be ?\nWhat would one possibly put in such a paper ?\nWhat to write about .\nOr what to write about ?\nWhat is our  what 's our take home message . What  what do we actually  Because I mean , it  I don't like papers where you just talk about what you plan to do . I mean , it 's obvious that we can't do any kind of evaluation , and have no  you know , we can't write an ACL type paper where we say , \" OK , we 've done this\nMm - hmm .\nand now we 're whatever percentage better than everybody else \" . You know .\nMm - hmm .\nIt 's far too early for that . But uh , we  we can tell them what we think . I mean that 's  never hurts to try . And um , maybe even  That 's maybe the time to introduce the  the new formalism that you guys have cooked up .\nMm - hmm .\nBut that\nAre in the process of\nHow many pages ?\ndon't they need to finish the formalism ?\nIt 's just like four pages .\nFour pages ?\nI mean it 's  it 's not even a h\nYeah .\nOK , so it 's a little thing .\nMm - hmm .\nOh .\nWell , you said it was four thousand lines ?\nOh .\nIs that what you s\nOK . Four pages is , like , really not very much space .\nI don't know w Did you look at it ? Yeah , it depends on the format .\nOh my gosh . Oh , I thought you were  I thought we were talking about something which was much more like ten or something .\nNo that 's  I mean that 's actually a problem . It 's difficu it 's more difficult to write on four pages than on eight .\nIt 's  Yeah .\nYeah .\nAnd it 's also difficult to  even if you had a lot of substance , it 's hard to demonstrate that in four pages , basically .\nYeah .\nUm .\nThat would be hard .\nI mean it 's still  it 's still\nWell I uh maybe it 's just four thousand lines . I do I don't  They don't want any  They don't have a TeX f style @ @ guide .\nUh - huh , uh - huh .\nThey just want ASCII . Pure ASCII lines ,\nOK .\nwhatever . Why , for whatever reason ,\nNot including figures and such ?\nI don't know . I don't know . Very unspecific unfortunately .\nOK . Well ,\nWe 'll just uh\nI would say that 's closer to six pages actually . Four thousand lines of ASCII ?\nOK then . It 's\nFour thousand lines . I mean . Isn't a isn't it about fifty s fifty five , sixty lines to a page ?\nI d don't quote me on this . This is numbers I  I have from looking o\nHow many characters are on a line ?\nOK .\nASCII ?\nLet 's  let 's  wh wh what should we  should  should we uh , um , discuss this over tea and all of us look at the web ? Oh , I can't . I 'm wizarding today .\nOK , look at the web page ?\nUm .\nWha - w\nLook at the web page and let 's talk about it maybe tomorrow afternoon ?\nMore cues for us to find it are like , neural cons\nJohno will send you a link .\nOh , you have a link . OK . OK .\nI got an email .\nOK .\nBy the way , Keith is comfortable with us calling him \" cool Keith \" .\nOh . Cool . Keith .\nHe  he decided  I 'm chilling in the five - one - O .\nCool , \" cool Keith \" .\nYeah .\nExcellent .\nOK .\nThat 's a very cool T - shirt .\nThank you .\nAnd I 'm also flying\nI got this from the two one two .\nNew York ? Excellent .\nYeah .\nSorry . Yes ?\nI 'm flying to Sicily next  in a w two weeks from now ,\nOh , lucky you .\nw and a week of business in Germany . I should mention that for you . And otherwise you haven't missed much , except for a really weird idea , but you 'll hear about that soon enough .\nThe idea that you and I already know about ? That you already told me ? Not that  OK .\nNo , no , no . Yeah , that is something for the rest of the gang to  to g\nThe thing with the goats and the helicopters ?\nChange the watchband . It 's time to walk the sheep .\nlike\nOK .\nUm . Did you catch that allusion ? It 's time to walk the sheep ?\nNo .\nIt 's a a uh presumably one of the Watergate codes they uh\nOh .\nAnyways , th um , um , don't make any plans for spring break next year . That 's\nOh , shoot .\nThat 's the other thing . We 're gonna do an int EDU internal workshop in Sicily .\nThat 's what  That 's what he says .\nI 've already got the funding .\nI kn That 's great !\nSo , I mean .\nDoes that mean  Does that mean you 'll get  you 'll fly us there ?\nWe 'll see .\nNo , that 's  Yeah , that 's what it means .\nHhh ! OK , cool . Uh - a a\nAnd he 'll put us up , too .\nHuh .\nI know  I know about that part . I know about the  the almond trees and stuff . Not joking .\nOK .\nName a vegetable , OK .  Oh , um , kiwi ?\nYeah .\nMmm , too easy .\nCoconut .\nKi\nPineapple . See ? Mango ? OK . OK . Too easy ?\nToo easy . Yeah , mangos go everywhere .\nReally ?\nSo do kiwi .\nOh . OK , but I was trying to find something that he didn't grow on his farm .\nBut coconut anana pineapple , that 's  that 's tricky , yeah .\nSorry . Anyway . Cantaloupe .\nSo , but we have to decide what , like , sort of the general idea of\nPotatoes . So . Sorry !\nUm , I mean , we 're gonna have an example case um , right ? I m the  the point is to  like this \" where is \" case , or something .\nYeah , maybe you have  It would be kind of  The paper ha would have , in my vision , a nice flow if we could say , well here is th the  th here is parsing if you wanna do it c right , here is understanding if you wanna do it right , and you know  without going into technical\nMm - hmm .\nBut then in the end we 're not doing like those things right yet , right ? Would that be clear in the paper or not ?\nThat would be clear , we would\nOK .\nI  I mailed around a little paper that I have\nIt would be like , this is the idea . Oh , I didn't get that ,\nw we could sort of say , this is\ndid I ? Oops . Did I ?\nNo ,\nOops .  Sorry .\nNo , y I don't think you got it .\nSee this , if you if you 're not around , and don't partake in the discussions , and you don't get any email ,\nI 'm sorry . I 'm sorry , I 'm sorry . Sorry .\nand\nOK , go on . So parsing done right  is like chicken done right .\nSu So we could  we could say this is what  what 's sort of state of the art today . Nuh ?\nOK .\nAnd say , this is bad . Nuh ?\nYeah .\nAnd then we can say , uh well what we do is this .\nOK .\nYeah .\nParsing done right , interpretation done right , example .\nMm - hmm . Yeah . And\nAnd how much to get into the cognitive neural part ?\nThat 's the only  That 's the question mark .\nWe\nDon't you need to reduce it if it 's a  or reduce it , if it 's a cognitive neuro\nWell , you don't have t I mean the conference may be cognitive neural , doesn't mean that every paper has to be both . Like , NLP cognitive neural .\nYeah , and you can  you can just point to the  to the literature ,\nMmm .\nyou can say that construction - based You know\nSo i so this paper wouldn't particularly deal with that side although it could reference the NTL - ish sort of , like , um , approach .\nMm - hmm .\nYeah .\nYeah .\nThe fact that the methods here are all compatible with or designed to be compatible with whatever , neurological  neuro neuro - biol su stuff .\nMm - hmm .\nYeah , I guess four pages you could  I mean you could definitely  it 's definitely possible to do it . It 's just  It 'd just be small . Like introducing the formalism might be not really possible in detail , but you can use an example of it .\nWell , l looking at  yeah , looking at that paper that  that you had , I mean you know , like , you didn't really explain in detail what was going on in the XML cases or whatever you just sorta said well , you know , here 's the general idea , some stuff gets put in there . You know , hopefully you can  you can say something like constituents tells you what the construction is made out of , you know , without going into this intense detail .\nYeah , yeah . So it be like using the formalism rather than you know , introducing it per se .\nYeah .\nSo .\nGive them the one paragraph whirlwind tour of w w what this is for ,\nYeah .\nand  Yeah .", "topic_id": 1, "keywords": "paper, cognitive, smartkom, writing, papers", "dialogue_id": 38}, {"text": "Mm - hmm .\nAnd people will sort of figure out or ask about the bits that are implicit .\nYeah . So this will be sort of documenting what we think , and documenting what we have in terms of the Bayes - net stuff .\nMm - hmm .\nAnd since there 's never a bad idea to document things , no ?\nThat 's th that 's definitely a good idea .\nThat would be my , uh  We  we should sketch out the details maybe tomorrow afternoon - ish , if everyone is around . I don't know . You probably wouldn't be part of it .\nI think so .\nMaybe you want ? Think about it . Um , You may  may ruin your career forever , if you appear .\nYeah , you might get blacklisted .\nAnd um , the uh , other thing , yeah we actually  Have we made any progress on what we decided , uh , last week ? I 'm sure you read the transcript of last week 's meeting in red so sh so you 're up to dated  caught up .\nNo . Sorry .\nWe decided t that we 're gonna take a \" where is something \" question , and pretend we have parsed it , and see what we could possibly hope to observe on the discourse side .\nRemember I came in and I started asking you about how we were sor going to sort out the uh , decision nodes ?\nYes ! What 'd you say ?\nI remember you talking to me , just not what you said .\nI do remember you talking to me . Um , a few more bits .\nWell , there was like we needed to  or uh , in my opinion we need to design a Bayes  another sub - Bayes - net  You know , it was whether  it was whether we would have a Bayes - net on the output and on the input ,\nOh .\nor whether the construction was gonna be in the Bayes - net ,\nOh , yeah . OK .\na and outside of it ,\nOK .\nand\nSo that was  was that the question ? Was that what\nWell that was related to what we were talking about .\nShould I introduce it as SUDO - square ?\nYeah sure .\nWe have to put this in the paper . If we write it . This is  this is my only constraint . The  th So . The SUDO - square {nonvocalsound} is ,  \" Situation \" , \" User \" , \" Discourse \" , right ? \" Ontology \" .\nOh I saw the diagram in the office ,\nOh my god , that 's amazing !\nMmm . Yeah . Whatever .\nNo way .\nWay !\nIs it ?\nSomeone 's gonna start making Phil Collins jokes .\nYeah . Hmm ?\nSorry .\nWhat ?\nOh , god , I hope not .\nYou guys are too young .\nYou know like \" Sussudio \" ,\nYeah , come on .\nthat horrible , horrible song that should never have been created .\nOh , oh , oh , oh .\nI know , that was horrible . Sussudio .\nI 've blocked every aspect of Phil Collins out of my mind .\nWhat ?\nI 'm sorry , I haven't . Not on purpose .\nin here\nOh   Well , also he 's talking about suicide , and that 's  that 's not a notion I wanna have evoked .\nNo , he 's not . Really ?\nHe is .\nOops .  I didn't really listen to it ,\nThe\nI was too young .\nHmm .\nAnyway .\nIt sounds too rocking for that .\nYeah .\nAnyway . So , what 's going on here ? So what are  what\nSo ,\nWas wollte der Kuenstler uns damit sagen ?\nStop excluding me .\nOK , so we have tons of little things here ,\nI can't believe that that 's never been thought of before .\nand we 've\nWait , what are the dots ? I don't remember what the dots were .\nThose are little bugs .\nCool Keith .\nOK .\nYou know , these are our , whatever , belief - net decision nodes , and they all contribute to these  {nonvocalsound} things down here .\nOh , oh .\nWait , wait , what 's the middle thing ?\nThat 's EDU .\nThat 's a c\ne e Our e e e\nBut wh I mean\nThat 's\nYou . We . Us .\nBut what is it ?\nWell , in the moment it 's a Bayes - net . And it has sort of fifty not - yet - specified interfaces . OK . Eh  I have taken care that we actually can build little interfaces , {nonvocalsound} to other modules that will tell us whether the user likes these things and , n the  or these things , and he  whether he 's in a wheelchair or not ,\nOK . Is that supposed to be the international sign for interface ?\nI think so , yeah .\nMmm . OK .\nI 'd  I 'd never seen it before either .\nOK . Just t Cool .\nMmm . So .\nYeah .\nCuz things fit onto that , see ?\nCool .\nIn a vaguely obscene fashion .\nNo , this is a RME core by agent design , I don't know .\nThat 's so great .\nThere 's maybe a different\nSo wait , what a what are these letters again , Situr -  Situation , User , Discourse and\nSituation , user , d ontology .\nUser ?\nOntology .\nWhat about the utterance ?\nDiscourse .\nThat 's here .\nIt 's\nOh , discourse . So that 's not like context , OK .\nYeah .\nDiscourse is all things linguistic , yeah .\nSo this  this includes the  the current utterance plus all the previous utterances .\nInteresting , uh - huh . User .\nAnd for example w i s I Irena Gurevich is going to be here eh , end of July .\nUser .\nShe 's a new linguist working for EML . And what she would like to do for example is great for us . She would like to take the ent ontolog\nOuch .\nSo , we have discussed in terms of the EVA\nGrateful for us ?\nuh\nDid you just say grateful for us ? OK , sorry . Anyway .\nThink of  back at the EVA vector , and Johno coming up with the idea that if the person discussed the  discussed the admission fee , in  eh previously , that might be a good indication that , \" how do I get to the castle ? \" , actually he wants to enter .\nMm - hmm .\nOr , you know , \" how do I get to X ? \" discussing the admission fee in the previous utterance , is a good indication .\nMm - hmm .\nSo we don't want a hard code , a set of lexemes , or things , that person 's you know , sort of filter , or uh search the discourse history .\nMm - hmm .\nSo what would be kind of cool is that if we encounter concepts that are castle , tower , bank , hotel , we run it through the ontology , and the ontology tells us it has um , admission , opening times , it has admission fees , it has this , it has that , and then we  we  we make a thesaurus lexicon , look up , and then search dynamically through the uh , discourse history for  occurrences of these things in a given window of utterances .\nMm - hmm .\nAnd that might , you know , give us additional input to belief A versus B . Or E versus A .\nSo it 's not just a particular word 's  OK , so the  you 're looking for a few keys that you know are cues to  sorry , a few specific cues to some intention .\nYou can dynamically look up keys , yeah .\nYeah .\nOK .\nUh , so , wait  so um , since this  since this sort of technical stuff is going over my head ,\nAnd then grep , basically .\nthe  the point is that you uh  that when someone 's talking about a castle , you know that it 's the sort of thing that people are likely to wanna go into ? Or , is it the fact that if there 's an admission fee , then one of the things we know about admission fees is that you pay them in order to go in ? And then the idea of entering is active in the discourse or something ? And then\nWell\nblah - blah - blah ?\nthe  the idea is even more general .\nI mean .\nThe idea is to say , we encounter a certain entity in a  in a in a utterance . So le let 's look up everything we  the ontology gives us about that entity , what stuff it does , what roles it has , what parts , whatever it has . Functions . And , then we look in the discourse , whether any of that , or any surface structure corresponding to these roles , functions aaa  has ever occurred .\nOh , OK .\nAnd then , the discourse history can t tell us , \" yeah \" , or \" no \" .\nOK .\nAnd then it 's up for us to decide what to do with it . t So i\nOK . So  No , go ahead .\nSo , we may think that if you say um ,   \" where is the theater \" , um , whether or not he has talked about tickets before , then we  he 's probably wanna go there to see something .\nMm - hmm .\nOr \" where is the opera in Par - Paris ? ,\nOK .\nyeah ? Lots of people go to the opera to take pictures of it and to look at it ,\nMm - hmm . OK .\nand lots of people go to attend a performance .\nMm - hmm .\nAnd , the discourse can maybe tell us w what 's more likely if we know what to look for in previous statements . And so we can hard code \" for opera , look for tickets , look for this , look for that ,\nOK . OK .\nor look for Mozart , look for thi \" but the smarter way is to go via the ontology and dynamically , then look up u stuff .\nOK . But you 're still doing look up so that when the person  So the point is that when the person says , \" where is it ? \" then you sort of say , let 's go back and look at other things and then decide , rather than the other possibility which is that  all through discourse as they talk about different things  You know like w prior to the \" where is it \" question they say , you know , \" how much does it cost to get in , you know , to  to see a movie around here \" , um ,  \" where is the closest theater \"  The  the  the point is that by mentioning admission fees , that just sort of stays active now .\nYeah .\nYou know . That becomes part of like , their sort of current ongoing active conceptual structure .\nMm - hmm .\nAnd then , um , over in your Bayes - net or whatever , when  when the person says \" where is it \" , you 've already got , you know since they were talking about admission , and that evokes the idea of entering , um , then when they go and ask \" where is it \" , then you 're Enter node is already active\nMm - hmm .\nbecause that 's what the person is thinking about .\nYeah .\nI mean that 's the sort of cognitive linguistic - y way ,\nYeah , e ultimately that 's also what we wanna get at .\nand probably not practical .\nI think that 's  that 's the correct way . So , of course we have to keep memory of what was the last intention , and how does it fit to this , and what does it tell us , in terms of  of the  the  what we 're examining .\nMm - hmm . Mmm , yeah .\nAnd furthermore , I mean we can idealize that , you know , people don't change topics ,\nMm - hmm .\nbut they do . But , even th for that , there is a student of ours who 's doing a dialogue act um , recognition module .\nRight . Mm - hmm .\nSo , maybe , we 're even in a position where we can take your approach , which is of course much better , as to say how  how do these pieces\nMmm . And much harder to r program .\nHmm ?\nAnd much harder to p to program .\nYeah . How  how do these pieces fit together ? Uh - huh . And um . But , OK , nevertheless . So these are issues but we  what we actually decided last week , is to , and this is , again , for your benefit  is to um , pretend we have observed and parsed an utterance such as \" where is the Powder - Tower \" , or \" where is the zoo \" , and specify um , what  what we think the  the output uh , observe , out  i input nodes for our Bayes - nets for the sub sub - D , for the discourse bit , should be . So that  And I will  I will then   come up with the ontology side uh , bits and pieces , so that we can say , OK we  we always just look at this utterance . That 's the only utterance we can do , it 's hard coded , like Srini , sort of hand parsed , hand crafted , but this is what we hope to be able to observe in general from utterances , and from ontologies , and then we can sort of fiddle with these things to see what it actually produces , in terms of output .\nUh\nSo we need to find out what the \" where is X \" construction will give us in terms of semantics and  Simspec type things .\nJust  OK . Just \" where is X \" ?\nMm - hmm .\nOr any variants of that .\nYeah . No ! Um , look at it this way , i Yeah . What did we decide . We decided sort of the  the prototypical \" where is X \" , where you know , we don't really know , does he wanna go there , or just wanna know where it is .\nWell we were\nSo the difference of \" where is the railway station \" , versus where  where  \" where is Greenland \" . Nuh ?\nMm - hmm .\nUh s I was just dancing , sorry .\nWe 're not videotaping any of this . So .\nUh  ah\nSo , um , we 're supposed to  I mean we 're talking about sort of anything that has the semantics of request for location , right ? actually ? Or , I mean , anyway , the node in the uh  the ultimate , uh , in  in the Bayes - net thing when you 're done , the  the node that we 're talking about um , is one that says \" request for location , true \" , or something like that , right ? Um , and  and exactly how that gets activated , you know , like whether we want the sentence \" how do I get there ? \" to activate that node or not , you know , that 's  that 's sort of the issue that sort of the linguistic - y side has to deal with , right ?\nYeah , but it  Yea - Nnn Well actually more  m more the other way around . We wanted something that represents uncertainty uh we in terms of going there or just wanting to know where it is , for example . Some generic information .\nOK .\nAnd so this is prototypically @ @ found in the \" where is something \" question , surface structure ,\nOK .\nWe\nwhich can be p you know , should be maps to something that activates both . I mean the idea is to\nI don't\nAlright , OK .\nHhh . I guess . I don't\nlet 's have it fit nicely with the paper .\nI don't see unde how we would be able to distinguish between the two intentions just from the g utterance , though .\nThe\nI mean , uh bef or , before we don't  before we cranked it through the Bayes - net . I mean .\nYeah , we  we wouldn't . That 's exactly what we want .\nWe would ?\nWe want to get  No . We wouldn't .\nOK , but then so basically it 's just a  for every construction we have a node in the net , right ? And we turn on that node .\nYeah . What  what is this gonna\nOy .\nExactly . What is the uh  Well\nAnd then given that we know that  the construction  has these two things , we can set up probabilities  we can s basically define all the tables for ev for those\nYeah , it should be  So we have um , i let 's assume we  we call something like a loc - X node and a path - X node . And what we actually get if we just look at the discourse , \" where is X \" should activate or should\nMmm .\nHmm . Should be both , whereas maybe \" where is X located \" , we find from the data , is always just asked when the person wants to know where it is , and \" how do I get to \" is always asked when the person just wants to know how to get there . Right ? So we want to sort of come up with what gets uh , input , and how inter in case of a \" where is \" question . So what  what would the outcome of  of your parser look like ? And , what other discourse information from the discourse history could we hope to get , squeeze out of that utterance ? So define the  the input into the Bayes - net  based on what the utterance , \" where is X \" , gives us . So definitely have an Entity node here which is activated via the ontology ,\ns\nso \" where is X \" produces something that is s stands for X , whether it 's castle , bank , restroom , toilet , whatever . And then the ontology will tell us\nThat it has a location or something like that ?  or th the ontology will tell us where actually it is located ?\nNo . Not at all .\nOK .\nWhere it is located , we have , a user proximity node here somewhere ,\nOK . OK .\ne which tells us how far the user  how far away the user is in respect to that uh entity .\nOK . So you 're talking about , for instance , the construction obviously involves this entity or refers  refers to this entity ,\nMm - hmm .\nand from the construction also you know that it is a location  is  or a thing  thing that can be located . Right ? Ontology says this thing has a location slot . Sh - and that 's the thing that is being  that is the content of the question that 's being queried by one interpretation of \" where is X \" . And another one is , um , path from current  user current location to  that location .\nMm - hmm .\nSo . So is the question  I mean it 's just that I 'm not sure what the  Is the question , for this particular construction how we specify that that 's the information it provides ? Or  or asked for ? b Both sides , right ?\nYeah , you don't need to even do that . It 's just sort of what  what would be @ @  observed in uh  in that case .\nObserved when you heard the speaker say \" where is X \" , or when  when that 's been parsed ?\nMm - hmm .\nSo these little circles you have by the D ? Is that  ? OK . OK .\nThat 's exactly what we 're looking for .\nI d I just  I don't like having  characterizing the constructions with location and path , or li characterizing them like that . Cuz you don't  It seems like in the general case you wouldn't know how  how to characterize them .\nYou wouldn't .\nI mean  or , for when . There could be an interpretation that we don't have a node for in the  I mean it just seems like @ @ has to have uh  a node for the construction and then let the chips fall where they may . Versus uh , saying , this construction either can mean location or path . And , in this cas and since  since it can mean either of those things , it would light both of those up .\nIt 's the same .\nThoughts ? Questions ?\nI 'm thinking about it .\nIt will be the same .\nUm\nSo I think r in here we have \" I 'll go there \" , right ?\nAnswers ?\nAnd we have our Info - on . So in my c my case , this would sort of make this  happy , and this would make the Go - there happy . What you 're saying is we have a Where - X question , Where - X node , that makes both happy . Right ? That 's what you 're proposing , which is , in my mind just as fine . So w if we have a construction  node , \" where is X \" , it 's gonna both get the po posterior probability that  it 's Info - on up ,\nMmm , yeah .\nInfo - on is True - up , and that Go - there is True - up , as well . Which would be exactly analogous to what I 'm proposing is , this makes  uh makes something here true , and this makes something  also something here true , and this makes this True - up , and this makes this True - up as well .\nI kinda like it better without that extra level of indirection too . You know with  with this points to this points to that , and so on because  I don't know , it\nIs - uh ,\nYeah , because we get  we get tons of constructions I think . Because , you know , mmm people have many ways of asking for the same thing ,\nYeah .\nYeah , sure .\nYeah .\nand\nSo un\nI change I changed my mind actually .\nSo I agree with that .\nOK .\nI have a different kinda question , might be related , which is , OK so implicitly everything in EDU , we 're always inferring the speaker intent , right ? Like , what they want either , the information that they want , or  It 's always information that they want probably , of some kind . Right ? Or I  I don't know , or what 's something that they\nThe system doesn't massage you , no . No .\nI  I  I don't  OK . So , um , let 's see . So I don't know if the  I mean i if th just there 's more s here that 's not shown that you  it 's already like part of the system whatever , but , \" where is X \" , like , the fact that it is , you know , a speech - act , whatever , it is a question . It 's a question that , um , queries on some particular thing X , and X is that location . There 's , like , a lot of structure in representing that .\nYep . Yeah .\nSo that seems different from just having the node \" location - X \" and that goes into EDU , right ?\nYeah .  Precisely . That 's  that 's\nSo tha is that what you 're t talking about ?\nSo , w Exactly . We have su we have specified two .\nwh what kinds of structure we want .\nOK , the next one would be here , just for mood .\nMm - hmm .\nMm - hmm .\nThe next one would be what we can squeeze out of the uh I don't know , maybe we wanna observe the uh , um ,   uh the length of  of the words used , and , or the prosody\nMmm .\nand g a and t make conclusions about the user 's intelligence .\nOK . So in some ways\nI don't know ,\num , so in some ways in the other sort of parallel set of mo more linguistic meetings we 've been talking about possible semantics of some construction .\nyeah .\nMm - hmm .\nRight ? Where it was the simulation that 's , according to it  you know , that  that corresponds to it , and as well the  as discourse , whatever , conte infor in discourse information ,\nMm - hmm .\nsuch as the mood , and , you know , other stuff . So , are we looking for a sort of abbreviation of that , that 's tailored to this problem ? Cuz that  that has , you know , basically , you know , s it 's in progress still it 's in development still , but it definitely has various feature slots , attributes , um , bindings between things\nMm - hmm . Yeah . U that 's exactly r um , why I 'm proposing  It 's too early to have  to think of them  of all of these discourse things that one could possibly observe ,\nUh - huh . Mm - hmm .\nso let 's just assume\nFor the subset of\nhuman beings are not allowed to ask anything but \" where is X \" .\nOK .\nThis is the only utterance in the world . What could we observe from that ?\nOK . That exactly \" where is X \" ,\nIn ter\nnot the  the choices of \" where is X \" or \" how do I get to X \" . Just \" where is X \" .\nJust  just \" where is X \" .\nYeah .\nOK .\nAnd , but you know , do it  do it in such a way that we know that people can also say , \" is the town hall in front of the bank \" , so that we need something like a w WH focus . Nuh ? Should be  should be there , that , you know , this  the  whatever we get from the\nWait , so do , or do not take other kinds of constructions into account ?\nWell , if you  if you can , oh definitely do ,\nOK . Where possible . OK .\nwhere possible . Right ? If i if  if it 's not at all triggered by our thing , then it 's irrelevant ,\nMm - hmm .\nand it doesn't hurt to leave it out for the moment . Um , but\nOK . Um , it seems like for instance , \" where is X \" , the fact that it might mean um , \" tell me how to get to X \" , like  Do y So , would you wanna say that those two are both , like  Those are the two interpretations , right ? the  the ones that are location or path . So , you could say that the s construction is a question asking about this location , and then you can additionally infer , if they 're asking about the location , it 's because they wanna go to that place , in which case , the  you 're jumping a step  step and saying , \" oh , I know where it is\nMm - hmm .\nYeah .\nbut I also know how to get  they wanna seem  they seem to wanna get there so I 'm gonna tell them \" . So there 's like structure\nRight , th this  it 's not  it 's not that this is sort of like semantically ambiguous between these two .\ni do you kn sort of uh , that\nMm - hmm .\nIt 's really about this but why would you care about this ? Well , it 's because you also want to know this , or something like that right ?\nSo it 's like you infer the speaker intent ,\nMm - hmm .\nand then infer a plan , a larger plan from that , for which you have the additional information ,\nYeah .\nMm - hmm .\nyou 're just being extra helpful .\nYep .\nUm .\nThink  Uh , well this is just a mental exercise .\nYeah .\nIf you think about , focus on this question , how would you design  that ?\nMm - hmm .\nIs it  do you feel confident about saying this is part of the language already to  to detect those plans , and why would anyone care about location , if not , you know and so forth .\nMmm .\nOr do you actually , I mean this is perfectly legitimate , and I  I would not have any problems with erasing this and say , that 's all we can activate , based on the utterance out of context .\nMm - hmm . And just by an additional link  Oh .\nWhat ?\nRight ,\nRight .\nlike ,\nAnd then the  the  the miracle that we get out the intention , Go - there , happens , based on what we know about that entity , about the user , about his various beliefs , goals , desires , blah - blah - blah .\nwith context and enough user information , yeah .\nYeah .\nAbsolutely fine . But this is the sort of thing , I  I propose that we think about ,\nOK .\nso that we actually end up with um , um , nodes for the discourse and ontology so that we can put them into our Bayes - net , never change them , so we  all there is is \" where is X \" , and , Eva can play around with the observed things , and we can run our better JavaBayes , and have it produce some output . And for the first time in th in  in the world , we look at our output , and um  and see uh whether it  it 's any good .\nOK .\nYou know ? I mean ,\nHere 's hoping .\nHmm ?\nHere 's hoping . Right ? Now cross your fingers .\nYeah , I  I mean , for me this is just a ba matter of curiosity , I wanna  would like to look at uh , what this ad - hoc process of designing a belief - net would actually produce .\nYeah .  Yeah .\nMmm .\nIf  if we ask it where is something . And , maybe it also h enables you to think about certain things more specifically , um , come up with interesting questions , to which you can find interesting answers . And , additionally it might fit in really nicely with the paper . Because if  if  if we want an example for the paper , I suggest there it is .\nUm - hmm . Yeah .\nSo th this might be a nice opening paragraph for the paper as saying , \" you know people look at kinds of   at ambiguities \" , and um , in the literature there 's \" bank \" and whatever kinds of garden path phenomenon .\nMm - hmm .\nAnd we can say , well , that 's all nonsense . A , A , uh these things are never really ambiguous in discourse , B , B , don't ever occur really in discourse , but normal statements that seem completely unambiguous , such as \" where is the blah - blah \" , actually are terribly complex , and completely ambiguous .\nMm - hmm . Mm - hmm .\nAnd so , what every everybody else has been doing so far in  in  in  you know , has been completely nonsensical , and can all go into the wastepaper bin , and the only\nThat 's always a good way to begin . Yeah . Yeah .\nYeah . And the  the  the only\nI am great .\nYeah .\nAll others are useless .\nYeah .\nThat 's good .\nNice overture , but , you know , just not really  OK , I 'm eja exaggerating , but that might be , you know , saying \" hey \" , you know , some stuff is  is actually complex , if you look at it in  in  in the vacuum\nMm - hmm .\nand  and ceases to be complex in reality . And some stuff that 's as  that 's absolutely straightforward in the vacuum , is actually terribly complex in reality . Would be nice sort of , uh , also , nice , um bottom - up linguistics , um , type message .\nMm - hmm . True .\nVersus the old top - down school . I 'm running out of time . OK .\nWhen do you need to start wizarding ?\nAt four ten . OK , this is the other bit of news . The subjects today know Fey , so she can't be here , and do the wizarding . So I 'm gonna do the wizarding\nHuh .\nand Thilo 's gonna do the instructing .\nMmm .\nAlso we 're getting a  a person who just got fired uh , from her job . Uh a person from Oakland who is interested in maybe continuing the wizard bit once Fey leaves in August . And um , she 's gonna look at it today . Which is good news in the sense that if we want to continue , after the thir thir after July , we can . We could . And , um  and that 's also maybe interesting for Keith and whoever , if you wanna get some more stuff into the data collection . Remember this , we can completely change the set - up any time we want .\nMm - hmm . OK .\nLook at the results we 've gotten so far for the first , whatever , fifty some subjects ?\nFifty ? You 've had fifty so far , or  ?\nNo , we 're approaching twenty now .\nOK .\nBut , until Fey is leaving , we surely will hit the  some of the higher numbers .\nYeah . Hmm .\nAnd um , so that 's cool . Can a do more funky stuff .\nSure . Yeah , I 'll have to look more into that data . Is that around ? Like , cuz that 's pretty much getting posted or something right away when you get it ?\nUm .\nOr  ? I guess it has to be transcribed , huh ?\nWe have uh , eh found someone here who 's hand st hand transcribing the first twelve .\nOK .\nFirst dozen subjects\nUh - huh .\njust so we can build a  a language model for the recognizer .\nOK .\nBut , um  So those should be available soon .\nOK .\nThe first twelve . And I can ch ch st e\nYou know  I mean you know that I  that I looked at the first  the first one and got enough data to keep me going for , you know , probably most of July . So .  But , um . Yeah , a probably not the right way to do it actually .\nBut you can listen to  a y y y You can listen to all of them from your Solaris box .\nOK .\nIf you want .\nRight .\nIt 's always fun .", "topic_id": 2, "keywords": "documenting, discussing, bayes, inferring, instructing", "dialogue_id": 38}, {"text": "OK ,\nThat 's looks strange .\nnow we 're on and it seems to be working .\nOh there we go .\nOne two three four five six\nThat is weird .\nThis looks good .\nIt 's like when it 's been sitting for a long time or something .\nSo , I mean  I don't know what it is . But all  all I know is that it seems like every time I am up here after a meeting , and I start it , it works fine . And if I 'm up here and I start it and we 're all sitting here waiting to have a meeting , it gives me that error message and I have not yet sat down with  been able to get that error message in a point where I can sit down and find out where it 's occurring in the code .\nNext time you get it maybe we should write it down .\nYep , we will . One of these days .\nYeah .\nWas it a pause , or  ? OK . Was it on \" pause \" or something ?\nNo .\nOK . Don't know .\nSo uh  so the uh , the new procedural change that just got suggested , which I think is a good idea is that um , we do the digit recordings at the end . And that way , if we 're recording somebody else 's uh meeting , and a number of the participants have to run off to some other meeting and don't have the time , uh , then they can run off . It 'll mean we 'll get somewhat fewer uh , sets of digits , but um , I think that way we 'll cut into people 's time , um , if someone 's on strict time uh , less . So , I th I think  I think we should start doing that . Um , so , uh , let 's see , we were having a discussion the other day , maybe we should bring that up , about uh , the nature of the data that we are collecting . uh @ @ that uh , we should have a fair amount of data that is um , collected for the same meeting , so that we can , uh  I don't know . Wh - what  what were some of the points again about that ? Is it\nUh , well , OK , I 'll back up .\nYeah .\nUm , at the previous  at last week 's meeting , this meeting I was griping  about wanting to get more data and I  I talked about this with Jane and Adam , um , and was thinking of this mostly just so that we could do research on this data um , since we 'll have a new  this new student di does wanna work with us ,\nWell , great .\nth the guy that was at the last meeting .\nGreat .\nAnd he 's already funded part - time , so we 'll only be paying him for sort of for half of the normal part - time ,\nWhat a deal .\nuh  Yeah .\nAnd what 's he interested in , specifically ?\nSo he 's  comes from a signal - processing background , but I liked him a lot cuz he 's very interested in higher level things , like language , and disfluencies and all kinds of eb maybe prosody ,\nMm - hmm . Great .\nso he 's just getting his feet wet in that . Anyway , I thought OK , maybe we should have enough data so that if he starts  he 'd be starting in January , next semester that we 'd have , you know , enough data to work with .\nRight .\nBut , um , Jane and Adam brought up a lot of good points that just posting a note to Berkeley people to have them come down here has some problems in that you m you need to make sure that the speakers are who you want and that the meeting type is what you want , and so forth . So , I thought about that and I think it 's still possible , um , but I 'd rather try to get more regular meetings of types that we know about , and hear , then sort of a mish - mosh of a bunch of one  one - time\nOne offs ?\nYeah , just because it would be very hard to process the data in all senses , both to get the , um  to figure out what type of meeting it is and to do any kind of higher level work on it , like well , I was talking to Morgan about things like summarization , or what 's this meeting about . I mean it 's very different if you have a group that 's just giving a report on what they did that week , versus coming to a decision and so forth . So . Then I was um , talking to Morgan about some  new proposed work in this area , sort of a separate issue from what the student would be working on where I was thinking of doing some kind of summarization of meetings or trying to find cues in both the utterances and in the utterance patterns , like in numbers of overlaps and amount of speech , sort of raw cues from the interaction that can be measured from the signals and from the diff different microphones that point to sort of hot spots in the meeting , or things where stuff is going on that might be important for someone who didn't attend to  listen to . And in that uh , regard , I thought we definitely w will need  it 'd b it 'd be nice for us to have a bunch of data from a few different domains , or a few different kinds of meetings . So this  this meeting is one of them , although I 'm not sure I can participate if I  You know , I would feel very strange being part of a meeting that you were then analysing later for things like summarization .\nMm - hmm .\nUm , and then there are some others that menti that Morgan mentioned , like the front - end meeting  and maybe a networking  group meeting .\nRight . Yep . Yeah , we 're  we 're hoping that they 'll let us start recording regularly .\nSo  So if that were the case then I think we 'd have enough .\nSo . Mm - hmm .\nBut basically , for anything where you 're trying to get a summarization of some kind of meeting    meaning out of the meeting , um , it would be too hard to have fifty different kinds of meetings where we didn't really have a good grasp on what does it mean to summarize ,\nYeah .\nbut  rather we should have different meetings by the same group but hopefully that have different summaries . And then we need a couple that  of   We don't wanna just have one group because that might be specific to that particular group , but @ @ three or four different kinds .\nYeah , we have a lot of overlap between this meeting and the morning meeting .\nS So\nYeah .\nSee , I 've never listened to the data for the front - end  meeting .\nYeah , we  we 've only had three .\nYeah .\nSo .\nOK . But maybe that 's enough . So , in general , I was thinking more data but also data where we hold some parameters constant or fairly similar ,\nMm - hmm .\nlike a meeting about of people doing a certain kind of work where at least half the participants each time are the same .\nUm\nNow , let  l l let me just give you the other side to that cuz I ca because I  I don't disagree with that , but I think there is a complimentary piece to it too . Uh , for other kinds of research , particularly the acoustic oriented research , I actually feel the opposite need . I 'd like to have lots of different people .\nRight . Right .\nAs many people here a a and talking about the kind of thing that you were just talking about it would have uh too few people from my point of view . I 'd like to have many different speakers . So , um I think I would also very much like us to have a fair amount of really random scattered meetings , of somebody coming down from campus , and  and uh ,\nMm - hmm .\nI mean , sure , if we can get more from them , fine ,\nMm - hmm .\nRight .\nbut if we only get one or two from each group , that still could be useful acoustically just because we 'd have close and distant microphones with different people .\nYeah , I definitely agree with that .\nYeah .\nMm - hmm .\nDefinitely .\nYeah .\nCan I  can I say about that  that the  the issues that I think Adam and I raised were more a matter of advertising so that you get more native speakers . Because I think if you just say  an And in particular , my suggestion was to advertise to linguistics grad students because there you 'd have so people who 'd have proficiency enough in English that  that uh , it would be useful for  for purposes  You know .\nMm - hmm .\nBut you know , I think I 've been  I 've I  I 've gathered data from undergrads at  on campus and if you just post randomly to undergrads I think you 'd get such a mixed bag that it would be hard to know how much conversation you 'd have at all . And  and the English you 'd have  The language models would be really hard to build\nWell , you want to i\nbecause it would not really be  it would be an interlanguage rather than  than a\nWell , OK , uh , first place , I  I  I don't think we 'd just want to have random people come down and talk to one another , I think there should be a meeting that has some goal and point cuz I  I think that 's what we 're investigating ,\nOK .\nIt has to be a  a pre - existing meeting ,  like a meeting that would otherwise happen anyway .\nso\nRight .\nYeah , yeah .\nOK .\nYep .\nSo I was  I was thinking more in terms of talking to professors uh , and  and  and uh , senior uh , uh , d and uh , doctoral students who are leading projects and offering to them that they have their  hold their meeting down here .\nThat 's I think what we  and I agree with .\nOh , interesting !\nYeah .\nOh , I see . Oh , interesting !\nUh , that 's the first point . The second point is um I think that for some time now , going back through BeRP I think that we have had speakers that we 've worked with who had non - native accents and I th I think that\nOh , oh . I 'm not saying accents . u The accent 's not the problem .\nOh , OK .\nNo , it 's more a matter of uh , proficiency , e e just simply fluency .\nYeah .\nI mean , I deal with people on  on campus who  I think sometimes people , undergraduates um in computer science uh , have language skills that make , you know  that their  their fluency and writing skills are not so strong .\nOh ! You 're not talking about foreign language at all .\nYeah . Yeah , just talking about .\nYou 're just talking about\nWell , e I just think ,\nWe all had the same thought .\nbut you know , it 's like when you get into the graduate level , uh , no problem . I mean , I 'm not saying accents .\nUh - huh .\nYeah , then we 're completely gone .\nI 'm say I 'm saying fluency .\nMm - hmm .\nIt 's   The  the habits are already burnt in .\nWell , yeah . I 'm just saying fluency .\nBut\nWell , I think that , um  I think that the only thing we should say in the advertisement is that the meeting should be held in English . And  and I think if it 's a pre - existing meeting and it 's held in English ,  I  I think it 's probably OK if a few of the people don't have uh , g particularly good English skills .\nYeah .\nOK , now can I  can I say the other aspect of this from my perspective which is that um , there 's  there 's this  this issue , you have a corpus out there , it should be used for  for multiple things cuz it 's so expensive to put together .\nRight .\nRight .\nAnd if people want to approach  Um , i so I know  e e  You know this  The idea of computational linguistics and probabilistic grammars and all may not be the focus of this group ,\nUh - huh .\nbut the idea of language models , which are fund you know generally speaking uh , you know , t t terms of like the amount of benefit per dollar spent or an hour invested in preparing the data ,\nMm - hmm . Mm - hmm .\nif you have a choice between people who are pr more proficient in  {nonvocalsound} um , i more fluent , more  more close to being academic English , then it would seem to me to be a good thing .\nI guess  I maybe  Hmm . I\nBecause otherwise y you don't have the ability to have  Uh , so if  if you have a bunch of idiolects that 's the worst possible case . If you have people who are using English as a  as an interlanguage because they  they don't  uh , they can't speak in their native languages and  but their interlanguage isn't really a match to any existing , uh , language model ,\nUh - huh .\nthis is the worst case scenario .\nYeah . Yeah .\nWell , that 's pretty much what you 're going to have in the networking group .\nAnd\nRight .\nbecause  because they  most  the network group is almost entirely Germans and Spaniards .\nWell Oh . But the thing is , I think that these people are of high enough level in their  in their language proficiency that\nI see .\nAnd I 'm not objecting to accents .\nOK .\nI  I 'm  I 'm just thinking that we have to think at a  at a higher level view , could we have a language model , a  a grammar  a grammar , basically , that um , wo would be a  a possibility .\nUh - huh .\nSo y so if you wanted to bring in a model like Dan Jurafsky 's model , an and do some top - down stuff , it  to help th the bottom - up and merge the things or whatever , uh , it seems like um , I don't see that there 's an argument\nMm - hmm .\nI 'm  I  what I think is that why not have the corpus , since it 's so expensive to put together , uh , useful for the widest range of  of central corp things that people generally use corpora for and which are , you know , used in computational linguistics .\nMm - hmm .\nThat 's  that 's my point . Which  which includes both top - down and bottom - up .\nIt 's difficult .\nOK .\nYeah .\nOK , well , i i let 's  let 's see what we can get . I mean , it  it  I think that if we 're aiming at  at uh , groups of graduate students and professors and so forth who are talking about things together , and it 's from the Berkeley campus , probably most of it will be OK ,\nYes , that 's fine . That 's fine . Exactly . And my point in m in my note to Liz was I think that undergrads are an iff iffy population .\nbut  OK . OK .\nI definitely agree with that , I mean , for this purpose .\nOK .\nWell , not to mention the fact that I would be hesitant certainly to take anyone under eighteen , probably even an anyone under twenty - one .\nYeah .\nGrads and professors , fine .\nYeah .\nSo .\nOh , you age - ist !\nWhat 's that ? Well , age - ist .  The \" eighteen \" is because of the consent form .\nAge - ist .\nYeah .\nRight , Yeah .\nWe 'd hafta get  find their parent to sign for them .\n\" Age - ist \" . Yeah . Yeah .\nYes .\nYeah , that 's true .\nSo .", "topic_id": 0, "keywords": "error, meeting, pause, meetings, code", "dialogue_id": 39}, {"text": "I have a  uh , um , question . Well , Morgan , you were mentioning that Mari may not use the k equipment from IBM if they found something else , cuz there 's a\nThey 're  they 're  yeah , they 're d they 're uh  assessing whether they should do that or y do something else , hopefully over the next few weeks .\nCuz I mean , one remote possibility is that if we st if we inherited that equipment , if she weren't using it , could we set up a room in the linguistics department ? And  and I mean , there  there may be a lot more  or  or in psych , or in comp wherever , in another building where we could um , record people there . I think we 'd have a better chance\nI think we 'd need a real motivated partner to do that . We 'd need to find someone on campus who was interested in this .\nRight , but  Right . But if there were such a  I mean it 's a remote possibility , then um , you know , one of us could you know , go up there and record the meeting or something rather than bring all of them down here .\nYep .\nSo it 's just a just a thought if they end up not using the  the hardware .\nWell , the other thing  Yeah , I mean the other thing that I was hoping to do in the first place was to turn it into some kind of portable thing so you could wheel it around .\nRight .\nUh . But . Um , and\nWell , I know that space is really scarce on  at least in CS . You know , to  to actually find a room that we could use regularly might actually be very difficult .\nUh  Yeah .\nBut you may not need a separate room , you know ,\nThat 's true .\nYeah .\nthe idea is , if they have a meeting room and they can guarantee that the equipment will be safe and so forth , and if one of us is up there once a week to record the meeting or something\nTrue . Mm - hmm . Yep .\nWell , maybe John would let us put it into the phonology lab or something .\nHuh .\nYep .\nYou know .\nI  I think it 's not out of the question .\nYeah , I think it would be interesting because then we could regularly get another meeting .\nYeah .\nUm . So .\nanother type of meeting .\nYeah .\nRight .\nBut I  I  I think you need , uh , another portable thing a another portable equipment to  to do , eh , more e easier the recording process , eh , out from ICSI .\nRight .\nHmm .\nYeah .\nRight .\nEh and probably . I don't know .\nYeah .\nEh , if you  you want to  to record , eh , a seminar or a class , eh , in the university , you  you need   It - it would be eh eh very difficult to  to put ,  eh , a lot of , eh , head phones eh in different people when you have to  to record only with , eh , this kind of , eh , d device .\nYeah .\nYeah , but  I think if we  if we wanna just record with the tabletop microphones , that 's easy .\nOh - yeah .\nRight ? That 's very easy ,\nYe - Yeah , yeah .\nbut that 's not the corpus that we 're collecting .\nYeah .\nActually , that 's a int that raises an interesting point that came up in our discussion that 's maybe worth repeating . We realized that , um , when we were talking about this that , OK , there 's these different things that we want to do with it . So , um , it 's true that we wanna be selective in some ways , uh , the way that you were speaking about with , uh , not having an interlingua and uh , these other issues . But on the other hand , it 's not necessarily true that we need all of the corpus to satisfy all of it . So , a a as per the example that we wanna have a fair amount that 's done with a small n recorded with a small , uh , typ number of types of meetings But we can also have another part that 's , uh , just one or two meetings of each of a  of a range of them and that 's OK too . Uh , i We realized in discussion that the other thing is , what about this business of distant and close microphones ? I mean , we really wanna have a substantial amount recorded this way , that 's why we did it . But  what about  For th for these issues of summarization , a lot of these higher level things you don't really need the distant microphone .\nRight , I mean , I c I think there 's\nAnd you don't really need the close microphone , you mean .\nYou actually don't .\nYeah .\nYea - yeah yeah , you actually don't really even need any fancy microphone .\nWhich one did you mean ?\nYou d You don't ne it doesn't  you just need some microphone , somewhere .\nYe - Yeah . Yep .\nYou can use found data .\nTape recorder .\nYeah .\nYeah .\nOh .\nYeah .\nYou  you can .\nYou need some microphone ,\nYou can\nMm - hmm .\nbut I mean\nuse  Um , but I think that any  data that we spend a lot of effort {nonvocalsound} to collect ,\nYeah .\nyou know , each person who 's interested in  I mean , we have a cou we have a bunch of different , um , slants and perspectives on what it 's useful for , um , they need to be taking charge of making sure they 're getting enough of the kind of data that they want .\nRight .\nAnd  So in my case , um , I think there w there is enough data for some kinds of projects and not enough for others .\nNot enough for others , right .\nAnd so {nonvocalsound} I 'm looking and thinking , \" Well I 'd be glad to walk over and record people and so {nonvocalsound} forth if it 's  to help th in my interest . \"\nMm - hmm .\nAnd other people need to do that for themselves , uh , h or at least discuss it so that we can find some optimal\nRight . So that\nYeah .\nBut I think that  I 'm raising that cuz I think it 's relevant exactly for this idea up there that if you think about , \" Well , gee , we have this really complicated setup to do , \" well maybe you don't .\nYeah . For some of it .\nMaybe if  if  If really all you want is to have a  a  a recording that 's good enough to get a   uh , a transcription from later , you just need to grab a tape recorder and go up and make a recording .\nRight .\nYep .\nI mean , we  we could have a fairly  We could just get a DAT machine and\nWell , I agree with {nonvocalsound} Jane , though , on the other hand that\nYeah .\nSo that might be true , you may say for instance , summarization , or something that sounds very language oriented . You may say well , \" Oh yeah , you just do that from transcripts of a radio show . \" I mean , you don't even need the speech signal .\nRight .\nBut what you  what I was thinking is long term what would be neat is to be able to pick up on um  Suppose you just had a distant microphone there and you really wanted to be able to determine this . There 's lots of cues you 're not gonna have .\nRight .\nYeah .\nSo I  do think that long term you should always try to satisfy the greatest number of  of interests and have this parallel information , which is really what makes this corpus powerful .\nYeah .\nSpecial ? Yep .\nI  I  I  I  I agree .\nOtherwise , you know , lots of other sites can propose  individual studies , so\nUh but I  I think that the uh  i We can't really underestimate the difficulty  shouldn't really u underestimate the difficulty of getting a setup like this up .\nYep .\nAnd so ,  uh it took quite a while to get that together and to say , \" Oh , we 'll just do it up there , \"\nOK .\nIf you 're talking about something simple , where you throw away a lot of these dimensions , then you can do that right away . Talking about something that has all of these different facets that we have here , it won't happen quickly , it won't be easy , and there 's all sorts of issues about th you know  keeping the equipment safe , or else hauling it around , and all sorts of o\nSo then maybe we should {nonvocalsound}  try to bring people here .\nHere .\nI think the first priority should be to pry  to get  try to get people to come here .\nI mean , that 's that 's  OK , so\nWe 're set up for it .\nMm - hmm .\nThe room is  is really , uh , underused .\nOK .\nUh\nRight .\nI thought the free lunch idea was a great idea .\nYeah , I thought so too .\nYeah .\nFree lunch is good .\nYeah , I  And I think we can get people to come here , that  But the issue is you definitely wanna make sure that the kind of group you 're getting is the right group so that you don't waste a lot of your time {nonvocalsound} and the overhead in bringing people down .\nMm - hmm .\nNo crunchy food .\nYeah .\nSo   Well , it would be  lunch afterwards .\nWell , I was thinking , lunch after .\nYeah .\nRight . And they 'd have to do their digits or they don't get dessert .\nYep .\nYeah , they have to do their digits or they don't  get  they don't  get their food .\nYeah .\nUm , I had a  I spoke with some people up at Haas Business School who volunteered .\nYeah\nShould I pursue that ?\nOh , definitely , yeah .\nYeah . So . They  they originally  They 've decided not to do  go into speech .\nYeah .\nSo I 'm not sure whether they 'll still be so willing to volunteer , but I 'll send an email and ask .\nTell them about the free lunch .\nI 'll tell them about the free lunch .\nYeah .\nAnd they 'll say there 's no such thing .\nYeah .\nSo .\nI 'd love to get people that are not linguists or engineers , cuz these are both weird\nRight .\nYeah .\nYeah .\nThe  the   The oth the other h\nwell , I know , I shouldn't say that .\nThat 's alright . No , the they  they 're very weird .\nWe need a wider sampling .\n\" Beep . \"\nYeah .\nUh , \" beep \"\nThe problem with engineers is \" beep . \"\nUh , the  the  They make funny sounds . The o the o the other  The other thing is , uh , that we  we talked about is give to them  uh , burn an extra CD - ROM .\nYep . Let them have their meeting .\nand give them  So if they want a  {nonvocalsound} basically and audio record of their\nWell , I thought that was  I thought he meant , \" Give them a music CD , \" like they g  Then he said a CD of the  of their speech\nOh .\nand I guess it depends of what kind of audience you 're talking to , but   You know , I personally {nonvocalsound} would not want a {nonvocalsound} CD  of my meeting ,\nMmm . Of the meeting ?\nbut  maybe  yeah ,  maybe you 're\nIf you 're having some planning meeting of some sort and uh you 'd like\nright .  Right . Right .\nOh , that 's a good idea .\nIt 'd be fun . I think it would just be fun , you know , if nothing else , you know .\nYeah .\nYeah .\nRight .\nIt 's a novelty item .\nBut it als It  it  it also I think builds up towards the goal .\nRight .\nWe 're saying , \" Look , you know , you 're gonna get this . Is - is isn't that neat . Then you 're gonna go home with it . It 's actually p It 's probably gonna be pretty useless to you ,\nYep .\nbut you 'll ge appreciate , you know , where it 's useful and where it 's useless ,\nRight .\nand then , we 're gonna move this technology , so it 'll become useful . \"\nYeah .\nSo .\nNo , I think that 's a great idea , actually .\nWhat if you could tell them that you 'll give them the  the transcripts when they come back ?\nAlth\nBut we might need a little more to incentivize them ,  that 's all .\nOh , yeah . I mean , anyone can have the transcripts . So . I thought we could point that out .\nOh yeah .\nYeah .\nWell , that 's interesting .\nI hav I have to uh raise a little eensy - weensy concern about doing th giving them the CD immediately , because of these issues of , you know , this kind of stuff ,  where maybe   You know ?\nGood point . That 's a very good point .\nSo .\nSo we can  so we can\nWe could burn it after it 's been cleared with the transcript stage .\nr Right .\nAnd then they  they get a CD , but just not the same day .\nOh , right .\nYeah , that 's right .\nIf  It should be the same CD - ROM that we distribute publically ,\nThat 's a good point . Right , it can't be the internal one .\nright ?\nAlthough it 's\nOtherwise they 're not allowed to play it for anyone .\nThere we go .\nThat 's right .\nOh , I like that . Well put . Well put . So , after the transcript screening phase .\nYeah , that 's true .\nThings have been weeded out .\nOtherwise we 'd need two lawyer stages .\nYeah , that 's right , say  \" Yeah , well , I got this CD , and , Your Honor , I  \"\nYeah .\nThat 's a good point .\nYeah so that 's  so let 's start with Haas , and Yeah .\nSorry to have to  {nonvocalsound} Sorry I have to  leave .\nOh , that 's fine .\nI will be here full - time next week .\nOK , see you .\nOK .\nNo . Bye .\nThat 's alright .\nSee you .\nOK .\nSee you .", "topic_id": 1, "keywords": "meetings, recording, meeting, recorder, ibm", "dialogue_id": 39}, {"text": "So , uh  Let 's see . So that was that topic , and  then um , I guess another topic would be  where are we in the whole disk resources  question for\nWe are slowly slowly getting to the point where we have uh enough sp room to record meetings . So I uh did a bunch of archiving , and still doing a bunch of archiving , I  I 'm in the midst of doing the P - files from uh ,  Broadcast News . and it took eleven hours   to do  to uh copy it .\nEleven ?\nAnd it 'll take another eleven to do the clone .\nWhere did you copy it to ?\nWell , it 's Abbott . It 's Abbott , so it just  But it 's  it 's a lot of data .\nSk - It 's copying from one place on Abbott to another place on Abbott ?\nTape .\nTape ?\nOh , on the tape .\nOh !\nI did an archive .\nI 'm sorry .\nAh !\nSo I 'm archiving it , and then I 'm gonna delete the files .\nOh .\nSo that will give us ten gigabytes of free space .\nEleven hours ?\nWow !\nOh .\nYeah , the archiving m  program does take a long time .\nAnd  and\nYeah .\nYep . And so one That  that will be done , like , in about two hours . And so uh ,  at that point we 'll be able to record five more meetings . So .\nYeah .\nOne thing  The good news about that  that is that once  once it 's archived , it 's pretty quick to get back .\nYeah .\nIs it ?\nI mean , it  it  it  The other direction is fast , but this direction is really slow .\nRight .\nHmm .\nWell , especially because I 'm generating a clone , also .\nYeah .\nSo . And that takes a while .\nYeah .\nYeah , OK .\nGenerating a clone ?\nYeah , that 's a good point .\nTwo copies .\nYeah .\nOh !\nOne offsite , one onsite .\nOh ! Hunh !\nS\nNow , what will uh  Is the plan to g  to  So  stuff will be saved , it 's just that you 're relocating it ? I mean , so we 're gonna get more disk space ? Or did I  ?\nNo , the  the  these are the P - files from Broadcast News , which are regeneratable  regeneratable\nOK . Oh , good . I see .\num , if we really need to , but we had a lot of them . And  for the full , uh , hundred forty hour sets .\nOK .\nAnd so they  they were two gigabytes per file and we had six of them or something .\nYeah .\nWow . Wow .\nW w we are getting more space . We are getting , uh , another disk rack and  and four thirty - six gigabyte disks . Uh  so  uh  but that 's not gonna happen instantaneously .\nWonderful .\nOr maybe six .\nOr maybe six ?\nThe SUN , ha uh , takes more disks than the Andatico one did . The SUN rack takes   Th - One took four and one took six , or maybe it was eight and twelve . Whatever it was , it was ,  you know , fifty percent more .\nHow many  How much\nIs there a difference in price or something ?\nWell , what happened is that we  we bought all our racks and disks from Andatico for years , according to Dave , and Andatico got bought by another company and doubled their prices .\nOh !\nOh .\nAnd so , uh , we 're looking into other vendors . \" We \"  By \" we \" of course I mean Dave .\nWow .\nMm - hmm .\nSo .\nHmm . I 've been looking at the , uh , Aurora data and , um , first  first look at it , there were basically three directories on there that could be moved . One was called Aurora , one was Spanish , which was Carmen 's Spanish stuff , and the other one was , um , SPINE .\nSPINE .\nAnd so , um , I wrote to Dan and he was very concerned that the SPINE stuff was moving to a non - backed - up disk . So , um , I realized that well , probably not all of that should be moved , just  the  CD - ROM type data , the   the static data . So I moved that , and then um , I asked him to check out and see if it was OK . before I actually deleted the old stuff , um , but I haven't heard back yet . I told him he could delete it if he wanted to , I haven't checked  today to see if he 's deleted it or not . And then Carmen 's stuff , I realized that when I had copied all of her stuff to XA , I had copied stuff there that was dynamic data . And so , I had to redo that one and just copy over the static data . And so I need to get with her now and delete the old stuff off the disk . And then I lo haven't done any of the Aurora stuff . I have to meet with , uh , Stephane to do that . So .\nSo , but , uh y you 're figuring you can record another five meetings or something with the space that you 're clearing up from the Broadcast News , but , we have some other disks , some of which you 're using for Aurora , but are we g do we have some other  other space now ?\nYep . So , so , uh , we have space on the current disk right now , where Meeting Recorder is , and that 's probably enough for about four meetings .\nYeah .\nIs that the one that has  is that DC ?\nYeah .\nSo . Yep . No , no , well , it 's wherever the Meeting Recorder currently is . I think it 's DI .\nOK , I  but the stuff I 'm moving from Aurora is on the DC disk that we\nI don't remember . Th - I think it 's DC - It 's whatever that one is .\nOK , DC .\nI just don't remember , it might be DC .\nYeah .\nAnd that has enough for about four more meetings right now . Yeah , I mean we were at a hundred percent and then we dropped down to eighty - six for reasons I don't understand .\nMm - hmm .\nUm , someone deleted something somewhere . And so we have some room again . And then with Broadcast News , that 's five or six more meetings , so , you know , we have a couple weeks . Uh , so , yeah , I think  I think we 're OK , until we get the new disk .\nOK .\nSo should , um  One question I had for you was , um , we need   we sh probably should move the Aurora an and all that other stuff off of the Meeting Recorder disk . Is there another backed - up  disk that you know of that would  ?\nWe should put it onto the Broadcast News one . That 's probably the best thing to do . And that way we consolidate Meeting Recorder onto one disk  rather than spreading them out .\nOK . Right . Right . Do you know what  happen to know what disk that is off  ? OK .\nNo . I mean , I can tell you , I just don't know off the top of my head .\nYeah . OK . Alright , I 'll find out from you .\nBut , so we could ' jus just do that at the end of today , once the archive is complete , and I 've verified it .\nOK .\nCuz that 'll give us plenty of disk .\nUh , OK , @ @  So , uh , then I guess th the last thing I 'd had on my  my agenda was just to hear  hear an update on  what  what Jose has been doing ,\nUh - huh . OK .\nso\nI have , eh ,  The result of my work during the last days .\nOK .\nThank you for your information because I  I read . Eh , and the  the last , eh , days , eh , I work , eh , in my house , eh , in a lot of ways and thinking , reading eh , different things about the  the Meeting Recording project .\nYeah .\nUh - huh .", "topic_id": 2, "keywords": "archiving, archive, copying, gigabytes, copies", "dialogue_id": 39}, {"text": "And I have , eh , some ideas . Eh , this information is very  very useful . Because  you have the  the  the distribution , now .\nI 'm glad to hear it . Glad to hear it .\nBut for me , eh is interesting because , eh , eh , here 's i is the demonstration of the overlap , eh ,  problem .\nI 've seen it already .\nIt 's a real problem ,  a frequently problem  uh , because you have overlapping zones eh , eh , eh , all the time .\nYeah . Yeah .\nYep .\nYeah .\nThroughout the meeting .\nEh , by a moment I have , eh , nnn , the , eh ,  n I  I did a mark of all the overlapped zones in the meeting recording , with eh , a exact  mark .\nMm - hmm . Oh , you did that by hand ?\nHeh ? That 's eh , yet b b Yeah , by  b b by hand  by hand because , eh ,  eh  \" Why . \"\nCan I see that ? Can I get a copy ?\nOh .\nMy  my idea is to work\nWow !\nI  I  I do I don I don't @ @  I don't know , eh , if , eh , it will be possible because I  I  I haven't a lot  eh , enough time to  to  to work . uh , only just eh , six months , as you know , but , eh , my idea is , eh , is very interesting to  to work  in  in the line of , eh , automatic segmenter .\nMm - hmm .\nEh but eh , eh , in my opinion ,  we need eh , eh , a reference  eh session to  t to  to evaluate the  the  the tool .\nYes , absolutely . And so are you planning to do that or have you done that already ?\nAnd  No , no , with i\nHave you done that or are you planning to do that ?\nSorry ? No , I  I  plan to do that .\nOK . Darn !\nI plan  I plan , but eh , eh , the idea  is the  is the following . Now ,  eh , I need ehm ,  to detect eh all the overlapping zones exactly . I  I will  I will eh , talk about eh ,  in the  in the blackboard about the  my ideas .\nYeah .\nMm - hmm .\nDuration .\nEh , um ,   eh  This information eh , with eh , exactly time marks eh , for the overlapping zones  eh  overlapping zone , and eh , a speaker  a  a pure speech eh , eh , speaker zone . I mean , eh zones eh of eh speech of eh , one speaker without any  any eh , noise eh , any  any acoustic event eh that eh , eh , w eh , is not eh , speech , real speech . And , I need t true eh , silence for that , because my  my idea is to  to study the nnn  the   the set of parameters eh , what , eh , are more m more discriminant to eh , classify .\nRight .\nthe overlapping zones in cooperation with the speech  eh zones . The idea is  to eh  to use  eh , I 'm not sure to  eh yet , but eh my idea is to use a  a cluster   eh algorithm or , nnn , a person strong in neural net algorithm to eh  to eh study what is the , eh , the property of the different feat eh feature , eh , to classify eh speech and overlapping eh speech .\nMmm .\nAnd my idea is eh , it would be interesting to  to have eh ,  a control set . And my control set eh , will be the eh , silence , silence without eh , any  any noise .\nMm - hmm .\nWhich means that we 'd still  You 'd hear the\nYeah , fans .\nYeah , acoustic with this .  With  with , yeah , the background .\nYeah .  That 's interesting . This is like a ground level , with  It 's not it 's not total silence .\nEh , I  I mean eh , noise eh , eh claps eh , tape clips , eh , the difference eh ,\nMm - hmm .\neh , eh , event eh , which , eh , eh , has , eh eh , a hard effect of distorti spectral distortion in the  in the eh  speech .\nSo  so you intend to hand - mark those and exclude them ?\nMm - hmm .\nMm - hmm .\nYeah , I have mark in  in  in  in that  Not in all  in all the  the file ,\nMm - hmm .\nonly eh , eh , nnn ,  mmm , I have eh , ehm  I don't remind  what is the  the  the  the quantity , but eh , I  I have marked enough speech on over and all the overlapping zones . I have , eh ,  two hundred and thirty , more or less , overlapping zones , and is similar to  to this information ,\nWhew ! Mm - hmm .\nGreat . Great .\nbecause with the program , I cross  the information of uh , of Jane  with eh , my my segmentation by hand . And  is eh , mor more similar .\nExcellent . Glad to hear it . Good .\nBut  Sorry , sorry .\nGo ahead .\nAnd the  the idea is , eh ,  I  I will use , eh ,  I want   My idea is , eh ,   to eh   {nonvocalsound} to classify .\nI should 've  got the digital camera . Oh well .\nI  I need eh , the exact eh , mark of the different , eh , eh , zones because I  I want to put , eh , for eh , each frame a label  indicating . It 's a sup supervised and , eh , hierarchical clustering process . I  I  I put , eh , eh , for each frame {nonvocalsound} a label indicating what is th the type , what is the class , eh , which it belong .\nMm - hmm .\nEh , I mean , the class you will {nonvocalsound} overlapping speech \" overlapping \" is a class , eh , \" speech \" {nonvocalsound} @ @ the class  that 's\nNonspeech .\nThese will be assigned by hand ?\na I  I  I ha I h I  I put the mark by hand ,\nBased on the  Uh - huh .\nbecause , eh ,  my idea is , eh , in  in the first session , I need , eh ,  I  I need , eh , to be sure that the information eh , that , eh , I  I will cluster , is  is right . Because , eh , eh , if not , eh , I will  I will , eh , return to the speech file to analyze eh , what is the problems ,\nWell , training , and validation . Sure . Mm - hmm .\neh . And  I  I 'd prefer  I would prefer , the to  to have , eh , this labeled automatically , but , eh , eh , fro th I need truth .\nYou need truth . Hmm .\nYeah , but this is what you 're starting with .\nYeah . Yeah . Yeah . Yeah .\nI 've gotta ask you . So , uh , the difference between the top two , i So  so  I start at the bottom , so \" silence \" is clear . By \" speech \" do you mean speech by one sp by one person only ?\nSpeech  Yeah .\nSo this is un OK , and then and then the top includes people speaking at the same time , or  or a speaker and a breath overlapping , someone else 's breath , or  or clicking , overlapping with speech  So , that  that 's all those possibilities in the top one .\nYeah . Yeah . Is\nOne or two or more .\nOne , two , three . but No , by th by the moment n Yeah . Yeah . Yeah . Yeah . Yeah .\nOK .\nEh , in the first moment , because , eh , eh , I  I have information , eh , of the overlapping zones , eh , information about if the , eh , overlapping zone is , eh , from a speech , clear speech , from a one to a two eh speaker ,  or three speaker , or is  is the zone where the breath of a speaker eh , overlaps eh , onto eh , a speech , another , especially speech .\nSo it 's basi it 's basically speech wi som with  with something overlapping , which could be speech but doesn't need to be .\nNo , no , es especially  eh , overlapping speech  from , eh , different eh , eh , speaker . Eh\nNo , but there 's  but , I think she 's saying \" Where do you  In these three categories , where do you put the instances in which there is one person speaking and other sounds which are not speech ? \"\nAh !\nWhich category do you put that in ?\nYeah , that 's right . That 's my question .\nYeah . Yeah , he here I  I put eh speech from eh , from , eh , one speaker  without , eh , eh , any  any  any events more .\nOh !\nRight , so where do you put speech from one speaker that does have a nonspeech event at the same time ?\nWhere ? Where  What is the class ?\nWhich catege which category ?\nLike a c\nNo . By the moment , no .\nYeah , yeah , that 's what he was saying before .\nFor  for the  by the @ @ no , @ @ because I  I  I  I want to limit the  the  nnn ,  the  the study .\nOh , so you  not  not marked .\nOh . So you don't  i i it 's not in that\nOK . Got it . Fine . So  so\nSo you 're not using all of the data .\nYeah , so that 's what he was saying before , is that he excluded those .\nThe  All  I  Exactly .\nYeah .\nYeah , you mean\nYeah .\nSo you 're ignoring overlapping events unless they 're speech with speech .\nYeah , be Yeah .\nYeah , that 's fine .\nOK .\n\" Why ? Why ? What 's the reason ? \" because  i it 's the first study . the first\nOh , no  no , it 's a perfectly sensible way to go . We just wondered  trying to understand what  what you were doing .\nWe 're just\nYeah .\nYeah .\nOK .\nYeah cuz you 've talked about other overlapping events in the past .\nYeah .\nSo , this is  this is  a subset .\nYeah . In the  in the future , the  the idea is to  to extend  the class ,\nIs  is\nto consider all the  all the information , you  you mentioned before\nYeah . Yeah , I  I don't think we were asking for that .\nOK .\nbut eh , the  the first idea  Because eh , I don't know  what hap what will happen  with the study .\nWe were jus just trying to understand\nYeah . Yeah , we just wanted to know what the category was here .\nRight .\nYeah . Sure .\nIs your silence category pure silence , or  ?\nYeah . i it 's pure\nWhat if there was a door - slam or something ?\nNo , no , it 's pure silence .\nPure silence .\nIt 's the control set .\nOK .\nOK ? It 's the control set . It 's pure si pure silence  with the  with the machine on the  on the roof .\nWhat you  Well  w  I  I think what you m I think what you mean  is that it 's nonspeech segments that don't have impulsive noises .\nWith the fan .\nYeah .\nRight ? Cuz you 're calling  what you 're calling \" event \" is somebody coughing  or clicking , or rustling paper , or hitting something , which are impulsive noises .\nYeah .\nBut steady - state noises are part of the background .\nYeah .\nWhich , are being , included in that . Right ?\nh here yet , yet I  I  I  I  I think  I  I think , eh , there are  that  some kind of noises that , eh , don't  don't wanted to  to be in that , eh , in that control set .\nYeah .\nSo it 's like a signal - noise situation . Yeah .\nWell  Yeah .\nBut I prefer , I prefer at  at the first , eh , the  the silence with eh , this eh this kind of the  of eh  of noise .\nWell , steady state .\nRight , it 's  I mean , it 's  \" Background \" might be  might be a better word than \" silence \" .\nYeah .\nIt 's just sort of that  the  the background acoustic\nYeah .\nRight . So  Fine . Go on .\nYeah .\nYeah .\nIs  is  is only  OK .\nYeah .\nAnd , um , with this information  The idea is eh , eh , nnn , I have a label for  for each , eh , frame and , eh with a cluster eh  algorithm I  and\nWell , we needed to get the categories , yeah .\nSorry . And eh I am going  to prepare a test bed , eh , well , eh , a  a set of  feature structure eh , eh , models .\nRight .\nAnd  my idea is\n\" Tone \" , whatever .\nso  so  on  because I have a pitch extractor yet .\nRight .\nMm - hmm .\nI have to  to test , but eh I\nYou have your own ?\nYeah , yeah , yeah .\nOh !\nI ha I have prepare . Is a modified version of  of  of a pitch tracker , eh , from , eh , Standar - eh Stanford University  in Stanford ? No . From , eh , em ,  Cambridge  University .\nOh ! What 's it written in ?\nEh , em , I  I  I don't remember what is the  the name of the  of the author , because I  I have several  I have eh , eh , em , eh , library tools , from eh , Festival and  of  from Edinburgh eh , from Cambridge , eh , and from our department .\nAh .\nMm - hmm . Mm - hmm .\nAnd  And I have to  because ,  in general the pitch tracker , doesn't work   very well and\nBad . Right . But , you know , as a feature , it might be OK . So , we don't know .\nYeah . Yeah . This  this is  And  th the idea is to  to , eh , to obtain , eh ,  for example , eh ,   eh diff eh , eh , different  well , no , a great number of eh FEC for example , eh ,  eh , twenty - five , eh , thirty  thirty parameters , eh , for  for each one . And in a first eh , nnn , step in the investi in the research in eh , my idea is try to , eh , to prove , what is the performance of the difference parameter , eh  to classify  the different , eh , what is the  the  the  the front - end approach to classify eh , the different , eh , frames of each class  eh and what is the  the , nnn , nnn , nnn , eh , what is the , the error  eh , of the data\nSupervised clustering . Mm - hmm .\nThis is the  the eh , first idea\nMm - hmm .\nand the second  is try to  eh , to use  some ideas eh , similar to the linear discriminant analysis .\nMm - hmm .\nEh ? Eh , similar , because the the idea is to  to study  what is the contribution of eh , each parameter to the process of classify correctly the different  the different parameters .\nMm - hmm . What sort of classifier ar ?\nEh , the  the  the classifier is  nnn by the moment is eh  is eh , similar , nnn , that the classifier used eh , in a quantifier  vectorial quantifier is eh , used to  to eh , some distance  to  to put eh , a vector eh , in  in a class different .\nUnimodal ?\nIs  Yeah ? W with a model , is  is only to cluster using a eh , @ @ or a similarity .\nMm - hmm .\nSo is it just one cluster per\nA another possibility it to use eh a netw netw a neural network .\nRight .\nBut eh what 's the p  What is my idea ? What 's the problem I  I  I  I see in  in  in   if you  you use the  the neural network ? If  w when  this kind of eh , mmm , cluster , clustering algorithm to can test , to can eh observe what happened you  you can't  you can't eh , eh put up with your hand  in the different parameter ,\nRight , you can't analyse it .\nbut eh  If you use a neural net is  is a good idea , but eh you don't know what happened in the interior of the neural net .\nWell , actually , you can do sensitivity analyses which show you what the importance of the different parce pieces of the input are .\nYeah .\nIt 's hard to  w w what you  It 's hard to tell on a neural net is what 's going on internally .\nYeah .\nBut it 's actually not that hard to analyse it and figure out the effects of different inputs , especially if they 're all normalized .\nYeah . Yeah .\nUm , but\nWell , using something simpler first I think is probably fine .\nWell , this isn't tru if  if  if you really wonder what different if  if\nYeah .\nDecision tree .\nBut\nYeah , then a decision tree is really good , but the thing is here he 's  he 's not  he 's not like he has one you know , a bunch of very distinct variables , like pitch and this  he 's talking about , like , a all these cepstral coefficients , and so forth ,\nRight .\nYeah . Yeah .\nRight .\nYeah .\nin which case a a any reasonable classifier is gonna be a mess , and it 's gonna be hard to figure out what  what uh\nAnd\nRight .\nI  I  I will include too the  the  the differential de derivates too .\nDeltas ,\nYeah .\nyeah . So .\nI  I mean , I think the other thing that one  I mean , this is , I think a good thing to do , to sort of look at these things at least  See what I 'd  I 'd  Let me tell you what I would do . I would take just a few features . Instead of taking all the MFCC 's , or all the PLP 's or whatever , I would just take a couple .\nYeah .\nOK ? Like  like C - one , C - two , something like that , so that you can visualize it .\nYeah .\nand look at these different examples and look at scatter plots .\nYeah .\nOK , so before you do  build up any kind of fancy classifiers , just take a look in two dimensions , at how these things are split apart .\nYeah .\nThat I think will give you a lot of insight of what is likely to be a useful feature when you put it into a more complicated classifier .\nYeah .\nAnd the second thing is , once you actually get to the point of building these classifiers ,  @ @ what this lacks so far is the temporal properties . So if you 're just looking at a frame and a time , you don't know anything about , you know , the structure of it over time , and so you may wanna build @ @  build a Markov model of some sort uh , or  or else have features that really are based on um on  on some bigger chunk of time .\nYeah .\nContext window ?\nYeah . Yeah .\nBut I think this is a good place to start . But don't uh anyway , this is my suggestion , is don't just , you know , throw in twenty features at it , the deltas , and the delta del and all that into some classifier , even  even if it 's K - nearest - neighbors , you still won't know\nYeah . Yeah , yeah .\nwhat it 's doing , even  You know it 's Uh , I think to know what it 's  to have a better feeling for what it 's\nYep .\nlook at  at som some picture that shows you , \" Here 's  These things uh , uh are  offer some separation . \"  And , uh , in LPC , uh , the thing to particularly look at is , I think  is something  like , uh , the residual\nYeah .\nUm So .\nYeah . S\nCan I ask ? It strikes me that there 's another piece of information um , that might be useful and that 's simply the transition . So , w if you go from a transition of silence to overlap versus a transition from silence to speech , there 's gonna be a b a big informative area there , it seems to me .\nYeah , because  Yeah yeah . Yeah . Yeah . I  Yeah . But eh I  I  Is my my  my own vision ,  of the  of the project .\nSo , some sort of  That 's\nMm - hmm .\nI  eh the  the Meeting Recorder project , for me , has eh , two  eh , w has eh several parts , several p  objective\nMm - hmm .\neh , because it 's a  a great project . But eh , at the first , in the acoustic , eh , eh , parts of the project , eh I think  you eh  we have eh   two main eh objective . One  one of these is to  eh to detect the change , the acoustic change . And  for that , if you don't use , eh ,  eh , a speech recognizer , eh broad class , or not broad class to  to try to  to    to label the different frames , I think  the Ike criterion  or BIC criterion eh will be enough to detect the change .\nOK .\nAnd  Probably .  I  I  I  I would like to  to t prove . Uh , probably . When you you have , eh , eh s eh the transition of speech or  or silence eh to overlap zone , this criterion is enough with   probably with , eh , this kind of , eh , eh the  the  the more eh use eh  use eh  used eh em  normal , regular eh parameter MF - MFCC . you  you have to  to  to find  you can find the  the mark . You can find the  nnn , the  the acoustic change . But eh eh I  I understand that you  your objective is  to eh classify , to know that eh that zone  not is only  a new zone in the  in the file , that eh you have eh , but you have to  to  to know that this is overlap zone . because in the future you will eh try to  to process that zone with a non - regular eh eh speech recognizer model , I suppose .\nMm - hmm .\nyou  you will pretend  to  to  to process the overlapping z eh zone with another kind of algorithm\nMm - hmm .\nbecause it 's very difficult to  to  to obtain the transcription  from eh using eh eh a regular , normal speech recognizer . That , you know ,  I  I  I think is the idea . And so  eh the , nnn  the  {nonvocalsound} the system  eh will have two models .\nClustering .\nA model to detect more acc the mor most accurately possible that is p uh , will be possible the , eh  the mark , the change and another  another model will @ @  or several models , to try s but  eh several model eh robust models , sample models to try to classify the difference class .\nOK .\nI 'm  I 'm  I 'm sorry , I didn't understand you  what you said . What  what model ?\nEh , the  the classifiers of the of the n to detect the different class to the different zones before try to  to recognize , eh with eh  to transcribe , with eh a speech recognizer .\nMm - hmm .\nAnd my idea is to use eh , for example , a neural net\nSo p\nwith  the  information we obtain from this eh  this eh study of the parameter with the  selected  parameter to try to eh  to put the class of each frame . Eh  for  the difference  zone\nFeatures . Yeah .\nyou  you eh , eh  have obtained in the first eh , step  with the  for example , BIC eh , eh  criterion compare model\nMm - hmm .\nAnd   You I don't - u\nOK , but , I  I think  in any event we 're agreed that the first step is\ni\nYeah .\nBecause what we had before for  for uh , speaker change detection did not include these overlaps .\nYeah .\nSo the first thing is for you to  to build up something that will detect the overlaps .\nYeah .\nRight ? So again , I think the first thing to do to detect the overlaps is to look at these uh , in  in  in  in\nFeatures ?\nYeah .\nWell , I  again , the things you 've written up there I think are way too  way too big .\nYeah .\nOK ? If you 're talking about , say , twelfth  twelfth - order uh MFCC 's or something like that it 's just way too much .\nYeah .\nYou won't be able to look at it . All you 'll be able to do is put it into a classifier and see how well it does .\nYeah .\nWhereas I think if you have things  if you pick one or two dimensional things , or three of you have some very fancy display , uh , and look at how the  the different classes separate themselves out , you 'll have much more insight about what 's going on .\nIt will be enough .\nWell , you 'll  you 'll get a feeling for what 's happening , you know ,\nYeah .\nso if you look at   Suppose you look at first and second - order cepstral coefficients for some one of these kinds of things and you find that the first - order is much more effective than the second ,  and then you look at the third and there 's not  and not too much there ,  you may just take first and second - order cepstral coefficients ,\nYeah . Yeah .\nright ? And with LPC , I think LPC per se isn't gonna tell you much more than  than  than the other , maybe . Uh , and uh on the other hand , the LPC residual , the energy in the LPC residual ,  will say how well , uh  the low - order LPC  model 's fitting it , which should be  pretty poorly for two two or more  people speaking at the same time , and it should be pretty well , for w for  for one .\nYeah . Yeah . Yeah .\nAnd so  I  i again , if you take a few of these things that are  are  prob um   promising features and look at them in pairs ,  uh , I think you 'll have much more of a sense of \" OK , I now have   uh , doing a bunch of these analyses , I now have ten likely candidates . \" And then you can do decision trees or whatever to see how they combine .\nYeah . Yeah .\nI 've got a question .\nYeah . This\nInteresting .\nSorry .\nHmm .\nbut eh , eh  eh eh eh I don't know it is the first eh way to  to  do that and I would eh like to  to know what eh , your opinion . Eh  all this study in the f in the first moment , I  I w I  I will pretend to do  with eh eh equalizes speech . The  the equalizes speech , the speech eh , the mixes of speech .\nWith\nWith what ? With what ?\nRight . Mixed .\nthe  the mix , mixed speech .\n\" Mixed \" . Thank you .\nEh , why ? Because eh the spectral distortion is    more eh  a lot eh clearer , very much clearer if we compare with the PDA .\nRight .\nPDA speech file is eh  it will be eh difficult . I\nSo it 's messier .\nYeah ,\nThe  the PDA is messier .\nfff !  Because the n the noise eh to sp the signal - to - noise relation is eh  is  is low .\nOK .\nYeah , I think that that 's a good way to start .\nAnd ,  I don't know\nBut .\nI don't know eh uh i i that eh the   the result of the  of the study eh with eh  with eh this eh  this speech , the mix speech eh  will work  exactly  with the  eh PDA files .\nIt would be interesting in itself to see . Well , I think that would be an interesting result .\neh What , I  I mean , what what is the effect of the low ' signal to  to  to noise relation , you know , eh with\nN u We Well , I think  I think  I think it 's not a  it 's not at all unreasonable . It makes sense to start with the simpler signal because if you have features which don't  aren't even helpful in the high signal - to - noise ratio , then there 's no point in putting them into the low signal ratio , one would think , anyway .\nYeah .\nAnd so , if you can get  @ @  Uh again , my prescription would be that you would , with a mixed signal , you would take a collection of possible uh , features  look at them , look at how these different classes that you 've marked , separate themselves ,   and then collect , uh in pairs ,  and then collect ten of them or something , and then proceed  with a bigger classifier .\nYeah . Yeah .\nAnd then if you can get that to work well , then you go to the other signal . And then , and you and you know , they won't work as well , but how m you know , how much\nRight .\nYeah . Yeah . Yeah .\nAnd then you can re - optimize , and so on .\nYeah . But it I think it would be interesting to try a couple with both . Because it  I think it would be interesting to see if some features work well with close mixed , and  And don't\nHmm .\nAh , yeah , yeah yeah yeah .\nThat 's  well , the  It  it 's  it 's true that it also , it could be  useful to do this exploratory analysis where you 're looking at scatter plots and so on in both cases . Sure .\nBut\nMm - hmm .\nI  I  I  I think that the  the eh parameter we found , eh , eh  worked with both eh , speech file ,\nThat 's good .\nbut eh what is the  the  the relation of eh  of the  performance when eh you use eh the , eh eh speech file the PDA speech files .\nHmm .\nYeah , I don't know .\nRight .\nBut it  I  I  I  I think it will be important . Because eh people eh eh , different groups eh has eh experience with this eh kind of problem . Is  eh is not easy eh to  to solve , because if you  I  I   I have seen the  the  the speech file from eh PDA , and s some parts is  very difficult because you  you don't see the spectrum  the spectrogram .\nRight . Yeah , they 're totally hidden .\nIs very difficult to apply eh , eh a parameter to detect change when you don't see .\nYeah . Yeah . Well , that  that  that 's another reason why very simple features , things like energy , and things  things like harmonicity , and  residual energy are uh , yeah are  are better to use than very complex ones because they 'll be more reliable .\nBut I suppose\nAre probably better , yep .\nYeah , yeah yeah , I  I  I will put eh the energy here . Yeah . Yeah . Yeah .\nCh - Chuck was gonna ask something I guess .\nYou have a question .\nYeah , I  maybe this is a dumb question , but w I thought it would be   I thought it would be easier if you used a PDA\nNah .\nbecause can't you , couldn't you like use beam - forming or something to detect speaker overlaps ? I mean\nWell , if you used the array , rather than the signal from just one .\nUh - huh .\nYeah , no , you you 're  you 're right\nBut that 's\nthat  In fact , if we made use of the fact that there are two microphones , you do have some location information . which we don't have with the one and  and so that 's\nIs that not allowed with this project ?\nUh , well , no , I mean , we we don't have any rules , r really .\nBut I didn't mean  I w  Given  given the goal .\nI think   I  I think  I think it 's  it 's  it 's a  it 's an additional interesting question .\nI mean , is  is that violation of the\nOh . No . Yeah .\nI mean , I think you wanna know whether you can do it with one , because you know it 's not necessarily true that every device that you 're trying to do this with will have two .\nMm - hmm\nYeah .\nUh , if , on the other hand , we show that there 's a huge advantage with two , well then that could be a real point .\nYeah .\nBut , we don't n even know yet what the effect of detecting  having the ability to detect overlaps is . You know , maybe it doesn't matter too much .\nRight . Right . OK .\nYeah . Yeah .\nSo , this is all pretty early stages .\nI see .\nYeah . Yeah , yeah , yeah .\nBut no , you 're absolutely right . That 's  a good thing to consider .\nOK .\nThere  there is a complication though , and that is if a person turns their back to the  to the PDA , then some of the positional information goes away ?\nYeah .\nWell , it  it  it does , i it d it does , but the  the  the issue is that  that\nNo , it 's not  it 's not that so much as\nAnd then , And if they 're on the access   on the axis of it , that was the other thing I was thinking .\nMm - hmm .\nHe  You mentioned this last time , that  that if  if you 're straight down the midline , then  then  the r the left - right 's gonna be different ,\nYeah , we hav need to put it on a little turntable ,\nI  I   I  I  I th\nand\nWell , it 's\nYeah .\nand  and  and in his case , I mean , he 's closer to it anyway .\nYeah . Yeah .\nIt seems to me that  that it 's not  a p uh , you know , it 's  this  the topograph the topology of it is  is a little bit complicated .\nBut it 's another source of information .\nI  I  Yeah .\nI don't  I don't know ho\nI  I  I think  Sorry . I  I  I think because the the the distance between the two microph eh , microphone , eh , in the PDA is very near . But it 's uh  from my opinion , it 's an interesting idea to  to try to study the binaural eh problem eh , with information , because I  I found difference between the  the speech from  from each micro eh , in the PDA .\nI would guess\nYep .\nYeah , it 's timing difference . It - it 's not amplitude ,\nOh yeah ! Oh I agree ! And we use it ourselves .\nright ? S Right .\nI mean , I know  I n I know that 's a very important cue .\nYep .\nYeah .\nBut I 'm just  I 'm just saying that the way we 're seated around a table , is not the same with respect to each  to each person with respect to the PDA ,\nNo . No . No , no , no .\nso we 're gonna have a lot of differences with ref respect to the speaker .\nThat 's  That 's fine .\nBut th I don't think that matters , though .\nBut\nThat 's  So  so i @ @  I think the issue is , \" Is there a clean signal coming from only one direction ? \"\nRight .\nIf it 's not coming from just one direction , if it  if th if there 's a broader pattern , it means that it 's more likely there 's multiple people speaking ,\nYeah .\nwherever they are .\nSo it 's sort of like how  how confused is it about where the beam is .\nIs it a  is it\nYeah .\nYeah , is there a narrow  Is there a narrow beam pattern or is it a  a distributed beam pattern ? So if there 's a distributed beam pattern , then it looks more like it 's  it 's uh , multiple people .\nYeah .\nWherever you are , even if he moves around .\nOK . Yeah . OK , it just  it just seemed to me that  uh , that this isn't the ideal type of separation . I mean , I  I think it 's  I can see the value o\nOh , ideal would be to have the wall filled with them , but I mean   But the thing is just having two mikes  If you looked at that thing on  on Dan 's page , it was  When  when there were two people speaking , and it looked really really different .\nYeah .\nYeah , OK .\nYeah . Yeah .\nYep .\nOh yeah yeah . OK .\nWhat looked different ?\nYeah .\nYeah .\nUh , well , basic he was looking at correlation .\nCross - co cross - correlation .\nCorrelation , yeah .\nJust cross - correlation between two sides .\nDid - Sorry , b uh I 'm not sure what Dan 's page is that you mean . He was looking at the two\nSo cross - correlation is pretty sensitive .\nUh , his a web page .\nYou take the signal from the two microphones and you cros and you cross - correlate them with different lags .\nSubtract them .\nOK .\nMm - hmm .\nUh - huh .\nYeah .\nAnd you find  They get peaks .\nOK . So when one person is speaking , then wherever they happen to be at the point when they 're speaking ,  then there 's a pretty big maximum right around that point in the l in  in the lag .\nOK . OK .\nSo if  at whatever angle you are ,  at some lag corresponding to the time difference between the two there , you get this boost in the  in  in the cross - correlation value  function .\nSo  so if there 's two\nAnd if there are multiple people talking , you 'll see two peaks .\nIt 's spread out .\nYeah .\nWell , let me ask you , if  if both people were over there , it would be less effective than if one was there and one was across , catty - corner ?\nYeah .\nYeah . The - the  Oh , I 'm sorry ,\nNo ?\nif they 're right next to one another ?\nIf I was  if I was here and Morgan was there and we were both talking , it wouldn't work .\ni i\nNext  next one over n over  on this side of the P  PDA .\nRight .\nYeah .\nThere we go . Good example , the same one I 'm asking .\nYeah .\nYeah , e I see .\nYes .\nYeah .\nVersus you  versus  you know , and we 're catty - corner across the table , and I 'm farther away from this one and you 're farther away from that one .\nOr  or even if , like , if people were sitting right across from each other , you couldn't tell the difference either .\nYeah . Yeah . Yeah .\nYeah . Oh , yeah .\nIt seems like that would be pretty strong .\nYeah .\nAcross  the same axis , you don't have as much to differentiate .\nYeah .\nWell , we d yeah , we don't have a third dimension there . Yeah , so it 's\nAnd so my point was just that it 's  it 's gonna be differentially  differentially varia valuable .\nRight .\nI mean , it 's not to say  I mean , I certainly think it 's extremely val  And we  we humans  n n depend on  you know , these  these binaural cues .\nYeah , yeah .\nBut it 's almost  but it 's almost a   I think what you 're talking about i there 's two things .\nBut .\nMust do .  Yeah .\nThere 's a sensitivity issue , and then there 's a pathological error uh issue . So th the one where someone is just right directly in line is sort of a pathological error .\nYes . Yeah .\nYeah .\nIf someone just happens to be sitting right there then we won't get good information from it .\nOK . and i and if there  So it  And if it 's the two of you guys on the same side\nUh , if they 're  if they 're close , it 's just a question of the sensitivity .\nYep .\nSo if the sensitivity is good enough  and we just  we just don't have enough , uh , experience with it to know how\nYeah . OK . Yeah yeah , OK . Yeah .\nBut\nYeah .\nOh I 'm not  I 'm not trying to argue against using it , by any means . I just wanted to point out that  that weakness , that it 's topo topologically impossible to get it perfect for everybody .\nYeah . Mm - hmm .\nAnd I think Dan is still working on it . So . He actually  he wrote me about it a little bit , so .\nGreat . No , I don't mean to discourage that at all .\nI mean , the other thing you can do  uh , if  I mean , i We 're assuming that it would be a big deal just to get somebody  convince somebody to put two microphones in the PDA . But if you h put a third in ,  you could put in the other axis . And then you know  then you 're sort of  Yeah , then  then you pretty much could cover\nOnce you got two\nInteresting .\nYeah .\nWell what about just doing it from these mikes ?\nInteresting .\nYou know ?\nYeah .\nYep .\nIt will be more interesting to study the PZM because the  the  the separation  I  I think\nUh @ @   But - but that 's  I mean , we can we 'll be  all of this is there for us to study .\nThen they 're much broader . Yeah , we can do whatever we want .\nYeah .\nBut   but  but the thing is , uh , one of the  at least one of the things I was hoping to get at with this is what can we do with what we think would be the normal situation if some people get together and one of them has a PDA .\nWhatever you 're interested in .\nYeah .\nThat 's what I was asking about , what are the constraints ?\nYeah . Yeah . Yeah .\nRight . Yeah .\nYeah .\nWell , that 's  that 's the constraint of one question that I think both Adam and I were  were  were interested in .\nWell\nMm - hmm .\nYep .\nMm - hmm .\nYeah .\nUh , but  you know if you can instrument a room , this is really minor league compared with what some people are doing , right ? Some people at  at  uh , yeah , at Brown and  and  and  and  at uh  um and at Cape ,\nBig micro @ @ arrays .\nYeah .\nDidn't they have something at Cape ?\nthey both have these , you know , big arrays on the wall . And you know , if you could do that , you 've got microphones all over the place\nVery finely .\nuh , you know p tens of microphones , and  and uh\nOh ! I saw a demo .\nOh , right , oh , yeah .\nAnd if you do that then you can really get very nice uh kind of selectivity\nYeah .\nOh , I saw one that was like a hundred microphones , a ten by ten array .\nYeah . Yeah .\nAnd you could  In a noisy room , they could have all kinds of noises and you can zoom right in on somebody .\nHundred .\nAnd they had very precision .\nYeah . Yeah .\nRight .\nVery complex , uh  Yeah .\nYe - Pretty much . Yeah .\nIt was all in software and they  and you could pick out an individual beam and listen to it .\nThat is cool .\nYeah .\nIt was  yeah , it was interesting .\nYeah .\nBut , the reason why I haven't focused on that as the fir my first concern is because um , I 'm interested in what happens for people , random people out in some random place where they 're p having an impromptu discussion . And you can't just always go , \" well , let 's go to this heavily instrumented room that we spent tens of thousands of dollars to se to set up \" .\nYeah .\nNo , what you need to do is you 'd have a little fabric thing that you unroll and hang on a wall .\nYeah .\nIt has all these mikes and it has a plug - in jack to the PDA .\nInteresting .\nBut I think\nThe other thing actually , that gets at this a little bit of something else I 'd like to do , is what happens if you have two P D\nYep .\nYeah .\nand they communicate with each other ? And then  You know , they 're in random positions , the likelihood that  I mean , basically there wouldn't be any  l likely to be any kind of nulls , if you even had two . If you had three or four it 's  Yeah .\nOoo !", "topic_id": 3, "keywords": "overlap, overlaps, overlapping, overlapped, meeting", "dialogue_id": 39}, {"text": "That 's on my web pages .\nNetwork !\nYeah .\nInteresting .\nThough  All sorts of interesting things you can do with that ,\nInteresting .\nI mean , not only can you do microphone arrays , but you can do all sorts of um multi - band as well .\nHmm .\nYeah .\nYeah .\nSo it 's  it would be neat .\nAh !\nI still like my rug on the wall idea , so if anybody patents that , then\nBut  I think\nWell , you could have strips that you stick to your clothing .\nin terms of\nYeah !\nYeah .\nHats ?\nIn terms of the research  th research , it 's really  it 's whatever the person who is doing the research wants to do .\nShirts .\nSo if  if Jose is interested in that , that 's great . But if  if he 's not , that 's great too .\nYeah .\nYeah , yeah .\nYeah . Um , I  i I  i I would actually kind of like us to wind it down , see if we can still get to the end of the , uh , birthdays thing there .\nCatch some tea ? Um .\nSo\nWell , I had a couple things that I did wanna bring out .\nOK .\nOne is , do we need to sign new  these again ?\nWell , it 's slightly different . So I  I would say it would be a good idea .\nAre they new ?\nCuz  it  it 's slightly different .\nYep .\nOh .\nOh , this morning we didn't sign anything cuz we said that if anybody had signed it already , we didn't have to .\nYeah , I  I should 've checked with Jane first , but the ch the form has changed .\nIt 's slightly different .\nSo we may wanna have everyone sign the new form .\nAh - oh .\nOK .\nUm , I had some things I wanted to talk about with the thresholding stuff I 'm doing .\nI had to make one\nBut , if we 're in a hurry , we can put that off . Um and then also anonymity , how we want to anonymize the data . Uh .\nWell , should I  I mean I have some results to present , but I mean I guess we won't have time to do that this time . But it seems like um the anonymization is uh , is also something that we might wanna discuss in greater length .\nUm . I mean , wha what\nIf  if we 're about to wind down , I think  what I would prefer is that we uh , delay the anonymization thing till next week , and I would like to present the results that I have on the overlaps .\nWe still have to do this , too , right ?\nRight .\nDigits ?\nRight .\nNo - well , we don't have to do digits .\nWell , why don't we  Uh , so @ @ OK . @ @  It sounds like u uh , there were  there were a couple technical things people would like to talk about . Why don't we just take a couple minutes to  to briefly  do them , and then  and then  and then  and then  and then we\nOK , go ahead , Jane .\nI 'd  Oh , I 'd prefer to have more time for my results . e Could I do that next week maybe ?\nOK . Oh , yeah . Sure .\nOK , that 's what I 'm asking .\nOh yeah , yeah .\nAnd I think the anonymization , if y if you want to proceed with that now , I just think that that 's  that 's a discussion which also n really deserves a lo a  you know , more that just a minute .\nWe could s\nMm - hmm .\nI really do think that , because you raised a couple of possibilities yourself , you and I have discussed it previously , and there are different ways that people approach it , e and I think we should\nAlright . We 're  we 're just  We 're getting enough data now that I 'd sort of like to do it now , before I get overwhelmed with  once we decide how to do it\nWell , OK .\ngoing and dealing with it .\nIt 's just  Yeah . OK . I  I 'll give you the short version , but I do think it 's an issue that we can't resolve in five minutes .\nMm - hmm .\nOK , so  the  the short thing is um , we have uh , tape recording uh , uh , sorry , digitized recor recordings . Those we won't be able to change . If someone says \" Hey , Roger so - and - so \" .\nRight .\nSo that 's gonna stay that person 's name .\nYep .\nNow , in terms of like the transcript , the question becomes what symbol are you gonna put in there for everybody 's name , and whether you 're gonna put it in the text where he says \" Hey Roger \" or are we gonna put that person 's anonymized name in instead ?\nNo , because then that would give you a mapping , and you don't wanna have a mapping .\nOK , so first decision is , we 're gonna anonymize the same name for the speaker identifier and also in the text whenever the speaker 's name is mentioned .\nI don't\nNo . Because that would give you a mapping between the speaker 's real name and the tag we 're using , and we don't want\nI  I don't think you understood what I  what I said .\nOK .\nSo  uh , so in  within the context of an utterance , someone says \" So , Roger , what do you think ? \" OK . Then , uh , it seems to me that  Well , maybe I  uh it seems to me that if you change the name , the transcript 's gonna disagree with the audio , and you won't be able to use that .\nRight , you don't wanna do that .\nWe don't  we wanna  we ha we want the transcript to be \" Roger \" .\nYeah .\nBecause if we made the  the transcript be the tag that we 're using for Roger , someone who had the transcript and the audio would then have a mapping between the anonymized name and the real name , and we wanna avoid that .\nOK , well , but then there 's this issue of if we 're gonna use this for a discourse type of thing , then  and , you know , Liz was mentioning stuff in a previous meeting about gaze direction and who 's  who 's the addressee and all , then to have \" Roger \" be the thing in the utterance and then actually have the speaker identifier who was \" Roger \" be \" Frank \" , that 's going to be really confusing and make it pretty much useless for discourse analysis .\nOh . Ugh ! That 's a good point .\nNow , if you want to , you know , I mean , in some cases , I  I  I know that Susan Ervin - Tripp in some of hers , uh , actually did do uh , um , a filter of the s signal where the person 's name was mentioned , except\nYeah Yeah , once you get to the publication you can certainly do that .\nAnd  and I  cer and I  So , I mean , the question then becomes one level back . Um , how important is it for a person to be identified by first name versus full name ? Well , on the one hand , uh , it 's not a full identity , we 're taking all these precautions , um and they 'll be taking precautions , which are probably even the more important ones , to  they 'll be reviewing the transcripts , to see if there 's something they don't like   OK . So , maybe , uh , maybe that 's enough protection . On the other hand , this is a small  this is a small pool , and people who say things about topic X e who are researchers and well - known in the field , they 'll be identifiable and simply from the  from the first name . However , taking one step further back , they 'd be identifiable anyway , even if we changed all the names .\nRight .\nMmm .\nSo , is it really , um   You know ?\nUgh !\nNow , in terms of like  so I  I did some results , which I 'll report on n next time , which do mention individual speakers by name .\nMm - hmm .\nNow , there , the Human Subjects Committee is very precise . You don't wanna mention subjects by name in published reports . Now , it would be very possible for me to take those data put them in a  in a study , and just change everybody 's name for the purpose of the publication . And someone who looked\nYou can go , you know , uh , \" Z \"  uh , for instance .\nYeah , exactly . Doesn't matter if\nUh . Um , yeah , I mean , t it doesn't  I mean , I 'm not knowledgeable about this , but it certainly doesn't bother me to have someone 's first name in  in the  in the transcript .\nThat 's the same thing you saw .\nOK .\nUh , I think  you don't wanna have their full name to be uh , listed .\nYeah , and  and in the form that they sign , it does say \" your first name may arise in the course of the meetings \" .\nYeah .\nAnd so\nWell\nYeah . So again , th the issue is if you 're tracking discourse things , you know , if someone says , uh , uh , \" Frank said this \" and then you wanna connect it to something later , you 've gotta have this part where that 's \" Frank colon \" .\nOr \" your name \" .\nYeah , shoot !\nRight ?\nYeah , and  and  you know , even more i i uh , immediate than that just being able to , uh  Well , it just seems like to track  track from one utterance to the next utterance who 's speaking and who 's speaking to whom , cuz that can be important .\nMm - hmm .\nS i You know , \" You raised the point , So - and - so \" , it 's be kind of nice to be able to know who \" you \" was .\nShoot !\nYeah .\nI  I 'm thinking too much .\nAnd ac  and actually you remember  furthermore , you remember last time we had this discussion of how you know , I was sort of avoiding mentioning people 's names ,\nYeah , I was too . Yeah .\nand  and it was  and we made the decision that was kind of artificial . Well , I mean , if we 're going to step in after the fact and change people 's names in the transcript , we 've basically done something one step worse .\nYep . Well , I would sug I  I  don't wanna change the names in the transcript ,\nYeah .\nYeah .\nbut that 's because I 'm focused so much on the acoustics instead of on the discourse , and so I think that 's a really good point .\nMisleading .\nYeah .\nYou 're right , this is going to require more thought .\nYeah . L let me just back up this to make a  a brief comment about the , uh , what we 're covering in the meeting . Uh I realize when you 're doing this that uh  I mean , I didn't realize that you had a bunch of things that you wanted to talk about . Uh , and so , uh  and so I was proceeding some somewhat at random , frankly . So I think what would be helpful would be uh , i and I 'll  I 'll mention this to  to Liz and Andreas too , that um , before the meeting if anybody could send me , any  any , uh , uh , agenda items that they were interested in and I 'll  I 'll take the role of organizing them uh , into  into the agenda ,\nOK . Sure .\nbut I 'd be very pleased to have everyone else  completely make up the agenda . I 've no desire to   to make it up , but if  if no one 's told me things , then I 'm just proceeding from my  my guesses , and  and uh , and i ye yeah , I  I 'm sorry it ended up with your out your time to  I mean , I 'm just always asking Jose what he 's doing , you know , and   and so it 's   There 's uh , there 's obviously other things going on .\nMm - hmm .\nOh , it 's not a problem . Not a problem . Yeah . I just  I just couldn't do it in two minutes .\nHow will we  how would the person who 's doing the transcript even know who they 're talking about ? Do you know what I 'm saying ?\n\" The person who 's doing the transcript  \"  The IBM people ?\nYeah . I mean , so so  how is that information gonna get labeled anyway ?\nHow do you mean , who  what they 're  who they 're talking about ?\nI mean , so if I 'm saying in a meeting , \" oh and Bob , by the way , wanted  wanted to do so - and - so \" ,\nHow do you mean ?\nThey 're just gonna write \" Bob \" on it or do @ @\nif you 're doing  Yeah , @ @ they 're just gonna write \" Bob \" . And so . If you 're  if you 're doing discourse analysis ,\nThey won't be able to change it themselves .\nWhat ar how are they gonna do any of this ?\nYeah , really .\nWell , I  I 'm betting we 're gonna have huge chunks that are just totally un untranscribable by them .\nI mean , they 're gonna say speaker - one , or speaker - two or speaker I mean I  I\nThey can't do that .\nYeah , I think\nWell , the current one they don't do speaker identity .\nbecause in NaturallySpeaking , or , excuse me , in ViaVoice , it 's only one person . and so in their current conventions there are no multiple speaker conventions .\nSo it may just be one long transcript of a bunch of words .\nYep .\nOh .  I think that  My understanding from Yen Is it Yen - Ching ? Is that how you pronounce her name ?\nUh  Yu - Ching , Yu - Ching . Yeah .\nOh , uh Yu - Ching ? Yu - Ching ?\ny Yu - Ching .\nwas that um , they will  that they will adopt the  part of the conventions that  that we discussed , where they put speaker identifier down . But , you know , h they won't know these people , so I think it 's  Well , they 'll  they 'll adopt some convention but we haven't specified to them  So they 'll do something like speaker - one , speaker - two , is what I bet , but I 'm betting there 'll be huge variations in the accuracy of  of their labeling the speakers . We 'll have to review the transcripts in any case .\nAnd it  and it may very well be  I mean , since they 're not going to sit there and  and  and worry ab about , uh , it being the same speaker , they may very well go the  eh the  the first se the first time it changes to another speaker , that 'll be speaker - two .\nYeah .\nAnd the next time it 'll be speaker - three even if it 's actually speaker - one .\nYou know  Uh - huh . You know , that would be a very practical solution on their part .\nYeah . It 's a good idea .\nYeah .\nAnd  and  but then we would need to label it .\nYeah we  we can probably regenerate it pretty easily from the close - talking mikes .\nYeah . Yeah , I think\nAnd that 's OK .\nYes , I was thinking , the temp the time values of when it changes .\nYeah .\nYeah .\nSo . But I mean that doesn't  This doesn't answer the  the question .\nYeah .\nBut that\nThat 'd be very efficient .\nThe p It 's a good point , \" which  what do you do for discourse tracking ? \"\nBecause y y you don't know to know , eh  you don't need to know what i what is the iden identification of the  of the speakers . You only eh want to know\nHmm . For  for acoustics you don't but for discourse you do .\nWell , you do .\nAh , for discourse , yeah . Yeah . Yeah .\nYeah . If  if  if  if someone says , uh , \" what  what is Jose doing ? \" and then Jose says something , you need to know that that was Jose responding .\nYeah , yeah . Yeah . Yeah . Yeah , yeah , yeah . Yeah . Yeah ,\nUgh ,  that 's a problem .\nUh , so .\nMm - hmm .\nYeah .\nUnless we adopt a different set of norms which is to not id to make a point of not identifying people by name , which then leads you to be more contextually ex explicit .\nThat would be hard .\nWell , people are very flexible . You know ? I mean , so when we did this las last week , I felt that you know , now , Andreas may , uh , @ @  uh , he  he  i sometimes people think of something else at the same time and they miss a sentence or something , and  and because he missed something , then he missed the r the initial introduction of who we were talking about , and was  was unable to do the tracking .\nMm - hmm .\nBut I felt like most of us were doing the tracking and knew who we were talking about and we just weren't mentioning the name . So , people are really flexible .\nYeah .\nBut , you know , like , at the beginning of this meeting  Or , you I think said ,  you know , or s Liz , said something about um , uh , \" is Mari gonna use the equipment ? \" I mean , how would you say that ?\nYeah ?\nI mean , you have to really think , you know , about what you 're saying bef\nif you wanted to anonymize .\nYeah .  Yeah , is\n\" Is you know who up in you know where ? \"\nYeah . Yeah .\nMm - hmm .\nRight ? Use the\nI think it would be really hard if we made a policy where we didn't say names , plus we 'd have to tell everybody else .\nYeah , darn ! I mean , what I was gonna say is that the other option is that we could bleep out the names .\nWell , it\nYeah .\nbut then , again that kills your discourse analysis .\nRight .\nUh - huh .\nYeah .\nUgh !\nYeah .\nYeah .\nYeah .\nI  I think the  I think  I don't know , my own two cents worth is that you don't do anything about what 's in the recordings , you only anonymize to the extent you can , the speakers have signed the forms and all .\nThat 's  that 's the issue .\nWell , but that but that  as I said , that  that  that works great for the acoustics , but it  it hurts you a lot for trying to do discourse .\nWell .\nWhy ?\nMm - hmm .\nBecause you don't have a map of who 's talking versus  their  name that they 're being referred to .\nYeah .\nYeah . Th - Bec\nYeah .\nI thought we were gonna get it labelled speaker - one , speaker - two\nSure but , h then you have to know that Jose is speaker - one and\nWhy do you have to know his name ?\nOK , so suppose someone says , \" well I don't know if I really heard what  uh , what Jose said . \"\nYeah .\nYeah .\nAnd then , Jose responds .\nYeah .\nAnd part of your learning about the dialogue is Jose responding to it . But it doesn't say \" Jose \" , it says \" speaker - five \" .\nOK .\nYeah . Yeah .\nSo  uh  u\nOh , I see , you wanna associated the word \" Jose \" in the dialogue with the fact that then he responded .\nRight .\nSomeone who 's doing discourse would wanna do that .\nAnd so , if we pass out the data to someone else , and it says \" speaker - five \" there , we also have to pass them this little guide that says that speaker - five is Jose ,\nAnd that violates our privacy .\nand if were gonna do that we might as well  give them \" Jose \"  say it was \" Jose \" .\nYeah . Yeah .\nAnd that violates our privacy issue .\nYeah .\nMm - hmm . Yeah .\nYeah .\nNow , I  I think that we have these two phases in the  in the data , which is the one which is o our use , University of Washington 's use , IBM , SRI .\nYeah .\nAnd within that , it may be that it 's sufficient to not uh change the  to not incorporate anonymization yet , but always , always in the publications we have to .\nMm - hmm .\nAnd I think also , when we take it that next step and distribute it to the world , we have to . But I  but I don that 's  that 's a long way from now and  and it 's a matter of  between now and then of d of deciding how\nMaking some decisions ?\ni i it  You know , it may be s that we we 'll need to do something like actually X out that part of the um  the audio , and just put in brackets \" speaker - one \" .\nYeah . For the public one .\nthe ? ?\nYou know , what we could do also is have more than one version of release .\nYeah .\nYou know .\nOne that 's public and one  one that requires licensing . And so the licensed one would  w we could  it would be a sticky limitation .\nUh - huh .\nYou know , like  Well , we can talk about that later .\nI think that 's risky . I think that the public should be the same . I think that when we do that world release , it should be the same .\nI  I agree . I  I agree with Jane .\nFor a bunch of reasons , legal .\nI  I think that we  we have a  need to have a consistent licensing policy of some sort , and\nBut I also think a consistent licensing policy is important .\nWell , one thing to to take into consideration is w are there any um  For example , the people who are funding this work , they want this work to get out and be useful for discourse .\nYeah .\nIf we all of a sudden do this and then release it to the public and it 's not longer useful for discourse , you know\nWell , depending on how much editing we do , you might be able to  still have it useful . because for discourse you don't need the audio . Right ? So you could bleep out the names in the audio .\nMm - hmm .\nand use the anonymized one through the transcript .\nBut if you release both\nUh .\nExcuse me . We  we do need audio for discourse .\nBut , n excuse me , but you could bleep out just the names .\nShe  No , but she 's saying , from the argument before , she wants to be able to say if someone said \" Jose \" in their  in their thing , and then connect to so to what he said later , then you need it .\nRight . But in the transcript , you could say , everywhere they said \" Jose \" that you could replace it with \" speaker - seven \" .\nOh I see . I see .\nYeah . But I   I also wanna say that people\nAnd then it wouldn't meet  match the audio anymore . But it would be still useful for the\nUh - huh .\nBut if both of those are publically available\nYeah . That 's good .\nBut they  Right .\nAnd th and the other thing is if  if  if Liz were here ,  what she might say is that she wants to look if things that cut across between the audio and the dialogue ,\nWell , you see ? So , it 's complicated .\nand so ,  uh ,\nMm - hmm . Yeah .\nyeah . Sorry .\nI think we have to think about w @ @  how . I think that this can't be decided today .\nYeah , OK , good point .\nBut it 's g but I think it was good to introduce the thing and we can do it next time .\nYeah .\nI didn't think  when I wrote you that email I wasn't thinking it was a big can of worms , but I guess it is .\nOK .\nOK . Yeah , a lot of these things are .\nDiscourse .\nWell it  Discourse , you know  Also I wanted to make the point that  that discourse is gonna be more than just looking at a transcript .\nYeah , ab absolutely . Oh , yeah , sure .\nIt 's gonna be looking at a t You know , and prosod prosodic stuff is involved , and that means you 're going to be listening to the audio , and then you come directly into this  confronting this problem .\nMaybe we should just not allow anybody to do research on discourse ,\nSo .\nand then , we wouldn't have to worry about it .\nOK .\nYeah , we should just market it to non - English speaking countries .\nOK .\nUh , maybe we should only have meetings between people who don't know one another and who are also amnesiacs who don't know their own name .\nDid you read the paper on Eurospeech ?\nWe could have little labels . I  I  I wanna introduce my Reservoir Dogs solution again , which is everyone has like \" Mister White \" , \" Mister Pink \" ,  \" Mister Blue \" .\nMister White .\nYeah . Did you read the paper a few years ago where they were reversing the syllables ? They were di they they had the utterances . and they would extract out the syllables and they would play them backwards .\nBut  so , the syllables were in the same order , with respect to each other , but the acous\nEverything was in the same order , but they were  the individual syll  syllables were played backwards . And you could listen to it ,  and it would sound the same .\nWhat did it sound like ?\nPeople had no difficulty in interpreting it . So what we need is something that 's the reverse , that a speech recognizer works exactly the same on it but people can't understand it .\nOh , well that 's  there 's an easy way to do that . Jus - jus just play it all backwards .\nOh right . The speech recognizer 's totally symmetric , isn't it .\nWhat , what does the speech recognizer care ?\nAh , anyway .\nUm ,\nOh , do we do digits ? Or  ? What do we do ?\nUh  OK , we 'll quickly do digits .\nLet 's do digits . Yeah , we  we  we already missed the party .\nOr do we just quit ?\nOK .\nSo .\nYeah .\nOK , go off here .\nI think it would be fun sometime to read them with different intonations . like as if you were talking like , \" nine eight six eight seven ? \"\nWell , you know , in the  in the one I transcribed , I did find a couple instances   I found one instance of contrastive stress , where it was like the string had a  li So it was like \" nine eight two four , nine nine two four \" .\nOh , really . So they were like looking ahead ,\nAnd\nhuh ?\nWell , they differed . I mean , at that  that session I did feel like they did it more as sentences . But , um , sometimes people do it as phone numbers .  I mean , I 've  I  am sort of interested in  in  And sometimes , you know , I s And I  I never know . When I do it , I  I ask myself what I 'm doing each time .\nYeah , yeah .\nYep .\nWell , I was thinking that it must get kind of boring for the people who are gonna have to transcribe this\nand I\nThey may as well throw in some interesting intonations .\nWell , except ,\nI like your question intonation .\nyeah .\nThat 's very funny . I haven't heard that one .\nWe have the transcript . We have the actual numbers they 're reading , so we 're not necessarily depending on that . OK , I 'm gonna go off .", "topic_id": 4, "keywords": "idea, hats, shirts, clothing, practical", "dialogue_id": 39}, {"text": "OK .\nOK , so  We  we had a meeting with , uh  with Hynek , um , in  in which , uh , uh , Sunil and Stephane , uh  summarized where they were and  and , uh , talked about where we were gonna go . So that  that happened sort of mid - week . Uh .\nD did  did you guys get your code pushed together ?\nOh , yeah . Yeah . It 's  it 's  it 's  it was updated yesterday ,\nCool .\nright ?\nYeah .\nYeah .\nYou probably received the mail .\nOh , right , I saw  I saw the note .\nYeah .\nMm - hmm .\nWhat was the update ?\nWhat was the update ? So there is th then  the  all the new features that go in .\nYeah .\nThe , um , noise suppression , the re - synthesis of speech after suppression . These are the\nIs the , um  the CVS mechanism working  well ?\nYeah .\nAre  are people , uh , up at OGI grabbing code uh , via that ?\nUh , I don't think  I don't think\nOr  ?\nI don't know if they use it , but .\nYeah , I I don't think anybody up there is like  working on it right now .\nUh - huh . Mmm .\nI think it more likely that what it means is that when Sunil is up there  he will grab it .\nYeah . Yeah . So right now nobody 's working on Aurora there .\nYeah .\nThey 're  Yeah . They 're working on a different task .\nI see . I see .\nYeah .\nOK .\nBut what 'll happen is  is he 'll go back up there and , uh , Pratibha will come back from  from , uh , the east coast . Uh .\nMm - hmm .\nAnd , uh  and  and I guess actually , uh , after Eurospeech for a little bit , uh , he 'll go up there too . So , actually everybody  who 's working on it  will be up there for at least a little while . So they 'll remotely access it  from there .\nSo has  Has anybody tried remotely accessing the CVS using , uh , uh , SSH ?\nYeah .\nUm , I don't know if Hari did that or  You d\nI  can actually do it today . I mean , I can just log into\nHave you tried it yet ?\nNo , I didn't . So I I 'll try it today .\nOK .\nGood idea .\nActually I  I tried wh while  when I installed the  repository , I tried from Belgium .\nYeah .\nYeah .\nI logged in there and I tried  to import\nYeah ? It worked good ?\nYeah , it works .\nOh , good !\nBut it 's  So , right now it 's the mechanism with SSH .\nOh .\nGreat !\nI don't  s I didn't set up  You can also set up a CVS server  on a new port . It 's like well  uh , a main server , or d You can do a CVS server .\nYeah . Right . Then that 's using the CVS password mechanism and all that ,\nBut . Yeah , right .\nright ?\nBut I didn't do that because I was not sure about  security problems . I  I would have to\nSo w when you came in from Belgian   Belgium , using SSH , uh , was it asking you for your own  password into ICSI ? So if yo you can only do that if you have an account at ICSI ?\nRight . Yeah .\nOK .\nYeah .\nCuz there is an  a way to set up anonymous CVS right ?\nYeah , you ha in this way you ca you have to set up a CVS server but then , yeah , you can access it .\nSo that  Oh , OK .\nyou  you can set up priorities .\nSo the anonymous mechanism\nYou can access them and mostly if you  if y the set the server is set up like this .\nOK . Because a lot of the open source stuff works with anonymous CVS and I 'm just wondering  Uh , I mean , for our transcripts we may want to do that .\nMm - hmm .\nYeah .\nUh .\nYeah , for this stuff I don't think we 're  quite up to that . I mean , we 're still so much in development .\nMm - hmm . Yeah ,\nWe want to have just the insiders .\nyeah , yeah . Oh , I wasn't suggesting for this . I 'm  thinking of the Meeting Recorder  stuff\nYeah .\nbut . Yeah . OK . Cool .", "topic_id": 0, "keywords": "thinking, speech, noise, code, suppression", "dialogue_id": 40}, {"text": "Yeah . So , uh\nWhat 's new ?\nWell , I mean , I think maybe the thing to me might be  I me I 'm sure you 've just been working on  on , uh , details of that since the meeting , right ? And so\nMmm , since the meeting , well , I  I 've been  I 've been train training a new VAD and a new  feature net .\nThat was  that was Tuesday . OK .\nSo they should be ready . Um .\nBut I guess maybe the thing  since you weren't  yo you guys weren't at that  that meeting , might be just  just to , um , sort of recap , uh , the  the conclusions of the meeting .\nMm - hmm .\nOh , great .\nSo .\nYou 're talking about the meeting with Hynek ?\nYeah . Cuz that was sort of , uh  we  we 'd sort of been working up to that , that  that , uh , he would come here this week and  and we would sort of\nUh - huh .\nSince he 's going out of town like now , and I 'm going out town in a couple weeks , uh , and time is marching , sort of , given all the mu many wonderful things we could be working on , what  what will we actually focus on ?\nMm - hmm .\nAnd , uh  and what do we freeze ? And , you know , what do we  ? So , um . I mean , this  software that these guys created was certainly a  a key part . So then there 's something central and there aren't at least a bunch of different versions going off in  in ways that  differ  trivially . Uh , um , and , um ,\nYeah . That 's  that 's nice .\nand then within that , I guess the idea was to freeze a certain set of options for now , to run it , uh , a particular way , and decide on what things are gonna be experimented with , as opposed to just experimenting with everything . So keep a certain set of things constant . So , um . Uh , maybe describe roughly what  what we are keeping constant for now , or  ?\nYeah . Well . So we 've been working like six weeks on  on the noise compensation and we end up with something that seems reasonable . Um .\nAre you gonna use  which of the two techniques ?\nSo finally it 's  it 's , um , Wiener filtering on FFT bins . And it uses , uh , two steps , smoothing of the transfer function , the first step , that 's along time , which use recursion . And  after this step there is a further smoothing along frequency , which use a sliding window of twenty FFT bins . Mmm . And , uh\nSo this is on the  uh , before any mel scaling has been done ?\nYeah , yeah .\nThis is\nIt was\nThis  this smoothing is done on the estimate , um , of what you 're going to subtract ? Or on the thing that has already had something subtracted ?\nYeah . Uh ,  it 's on the transfer function . So\nOh , it 's on the transfer function for the Wiener filter .\nYeah .\nYeah , OK .\nYeah , so basically we tried  different configuration within this idea . We tried u u applying this on mel bands , having spectral subtraction instead of wiener filtering . Um . Well , finally we end up with  this configuration that works , uh , quite well . So we are going to fix this for the moment and work on the other aspects of  the whole system .\nMm - hmm .\nSo\nActually , let me int eh , Dave isn't here to talk about it , but let me just interject . This module , in principle , i I mean , you would know whether it 's  true in fact , is somewhat independent from the rest of it . I mean , because you  you re - synthesize speech , right ?\nMm - hmm .\nSo , um . Uh , well you don't  I guess you don't re - synthesize speech , but you could\nWe  we do not fo\nUh , but you could .\nWell  well , we do , but we don't  don't re - synthesize . In  in the program we don't re - synthesize and then re - analyze once again . We just use the clean FFT bins .\nBut you have a re - synthesized thing that you  that 's an  an option here .\nThis is an option that  then you can  Yeah .\nYeah , I gu I guess my point is that , um , i in some of the work he 's doing in reverberation , one of the things that we 're finding is that , uh , it 's  it 's  for the  for an artificial situation , we can just deal with the reverberation and his techniques work really well . But for the real situation uh , problem is , is that you don't just have reverberation , you have reverberation in noise . And if you don't include that in the model , it doesn't work very well . So in fact it might be a very nice thing to do , to just take the noise removal part of it and put that in front of what he 's looking at . And , uh , generate new files or whatever , and  and , uh , uh  and then do the reverberation part .\nMm - hmm .\nSo it 's\nMmm .\nAnyway .\nSo Dave hasn't  tried that yet ?\nNo , no . He 's  I mean , e\nI guess he 's busy with\nYeah , prelims , right .\nPre - prelim hell .\nYeah .\nYeah .\nSo .\nYeah .\nUh , but  but , you know , that 'll  uh , it 's clear that we , uh  we are not  with the real case that we 're looking at , we can't just look at reverberation in isolation because the interaction between that and noise is  is considerable . And that 's I mean , in the past we 've looked at , uh , and this is hard enough , the interaction between channel effects and  and , uh  and additive noise , uh , so convolutional effects and  and additive effects . And that 's hard enough . I mean , I don't think we really  I mean , we 're trying to deal with that . In a sense that 's what we 're trying to deal with in this Aurora task . And we have , uh , the , uh , uh , LDA stuff that in principle is doing something about convolutional effects . And we have the noise suppression that 's doing something about noise . Uh , even that 's hard enough . And  and the on - line normalization as well , in that s category . i i There 's all these interactions between these two and that 's part of why these guys had to work so hard on  on juggling everything around . But now when you throw in the reverberation , it 's even worse , because not only do you have these effects , but you also have some long time effects . And , um , so Dave has something which , uh , is doing some nice things under some conditions with  with long time effects but when it 's  when there 's noise there too , it 's  it 's  it 's pretty hard . So we have to start  Since any  almost any real situation is gonna have  uh , where you have the microphone distant , is going to have both things , we  we actually have to think about both at the same time .\nHmm .\nSo , um  So there 's this noise suppression thing , which is sort of worked out and then , uh , maybe you should just continue telling what  what else is in the  the form we have .\nYeah , well ,  the , um , the other parts of the system are the  the blocks that were already present before and that we did not modify a lot .\nSo that 's  again , that  that 's the Wiener filtering , followed by , uh  uh , that 's done at the FFT level . Then\nYeah , th then the mel filter bank ,\nMm - hmm .\nthen the log operation ,\nMm - hmm .\nMmm .\nThe  the  the filtering is done in the frequency domain ?\nYeah .\nYeah , OK . And then the mel and then the log , and then the\nThen the LDA filter ,\nLDA filter .\nmmm , then the downsampling ,\nAnd then uh downsample ,\nDCT ,\nDCT ,\nthen , um , on - line normalization ,\non - line norm ,\nfollowed by  upsampling . Then finally , we compute delta and we put the neural network also .\nRight , and then in parallel with  an  a neural net . And then following neural net , some  probably some orthogonalization .\nYeah .\nUh  Um .\nAnd finally frame dropping , which um ,  would be a neural network also , used for estimated silence probabilities . And the input of this neural network would be somewhere between log  mel bands or one of the earlier stages of the processing .\nMm - hmm . So that 's sort of  most of this stuff is  yeah , is operating parallel with this other stuff .\nMm - hmm .\nYeah . So the things that we , um , uh , I guess we sort of  uh , There 's  there 's some , uh , neat ideas for  V A So , I mean , in  I think there 's sort of like  There 's a bunch of tuning things to improve stuff . There 's questions about  various places where there 's an exponent , if it 's the right exponent , or  ways that we 're estimating noise , that we can improve estimating noise . And there 's gonna be a host of those . But structurally it seemed like the things  the main things that  that we brought up that , uh , are  are gonna need to get worked on seriously are , uh , uh , a   a significantly better VAD , uh , putting the neural net on , um , which , you know , we haven't been doing anything with , the , uh , neural net at the end there , and , uh , the , uh ,  opening up the second front . Uh .\nThe other half of the channel ?\nYeah , yeah , I mean , cuz we  we have  we have , uh , uh , half the  the , uh , data rate that they allow .\nThat what you mean ?\nAnd , uh , so the initial thing which came from , uh , the meeting that we had down south was , uh , that , um , we 'll initially just put in a mel spectrum as the second one . It 's , you know ,  cheap , easy . Uh . There 's a question about exactly how we do it . We probably will go to something better later , but the initial thing is that cepstra and spectra behave differently ,\nMm - hmm .\nso . Um ,  I think Tony Robinson used to do  I was saying this before . I think he used to do mel , uh , spectra and mel cepstra . He used them as alternate features . Put them together .\nHmm .\nUh .\nSo if you took the system the way it is now , the way it 's fro you 're gonna freeze it , and it ran it on the last evaluation , where it would it be ?\nMm - hmm . It , uh ,\nIn terms of ranking ?\nRi - right now it 's second .\nSecond .\nUm .\nMm - hmm .\nAlthough you  you know , you haven't tested it actually on the German and Danish , have you ?\nNo , we didn't . No , um .\nYeah .\nSo on the ones that you did test it on it would have been second ?\nYeah . Would it  I mean  But  When you 're saying second , you 're comparing to the numbers that the , uh  that the best system before got on , uh  also without German and Danish ?\nYeah , yeah .\nYeah , OK .\nAnd th the ranking actually didn't change after the German and Danish . So , yeah .\nWell ranking didn't before , but I 'm just asking where this is to where theirs was without the German and Danish ,\nYeah .\nYeah .\nMmm .\nYeah .\nright ?\nYeah , yeah .\nSo .\nWhere  where  where were we actually on the last test ?\nOh , we were also esp essentially second , although there were  there were  I mean , we had a couple systems and they had a couple systems . And so , I guess by that  we were third , but I mean , there were two systems that were pretty close , that came from the same place .\nUh - huh . I see . OK .\nUh , so institutionally we were   we were second , with , uh , the third  third system .\nWe 're  so this second that you 're saying now is system - wide second ?\nSee  Uh , no I think it 's also institutional , isn't it ?\nStill institutionally second ?\nRight ? I mean , I think both of their systems probably\nUh , we are between their two systems . So\nOh , are we ?\nI  It is a triumph .\nYeah .\nIs it ?\nTheir  their first system is fifty - four point something . And , uh , we are fifty - three point something .\nBut everything is  within the range of one  one percent .\nAnd their second system is also fifty - three point something . Yeah , one percent .\nYeah , so  so basically they 're all  they 're all pretty close .\nOh , wow !\nSo .\nThat 's very close .\nYeah .\nYeah .", "topic_id": 1, "keywords": "hynek, meeting, busy, new, talking", "dialogue_id": 40}, {"text": "And  and ,  um , you know , in some sense we 're all doing fairly similar things . Uh , I mean , one could argue about the LDA and so forth but I  I think , you know , in a lot of ways we 're doing very similar things . But what  what\nSo how did they fill up this  all these  these bits ? I mean , if we 're u\nUm , why are we using half ? Well , so you could  you c\nYeah . Or how are they using more than half , I guess maybe is what I\nYeah , so I  I think  uh , you guys are closer to it than me , so correct me if I 'm wrong , but I  I think that what 's going on is that in  in both cases , some kind of normalization is done to deal with convola convolutional effects . Uh , they have some cepstral  modification ,\nMm - hmm .\nright ? In our case we have a couple things . We have the on - line normalization and then we have the LDA RASTA . And  they seem to comple complement each other enough and be different enough that they both seem to help  help us . But in any event , they 're both doing the same sort of thing . But there 's one difference . The LDA RASTA , uh , throws away high modulation frequencies . And they 're not doing that .\nSo th So\nSo that if you throw away high modulation frequencies , then you can downsample .\nGet down .\nI see . I see .\nSo\nSo what if you didn't  So do you explicitly downsample then ? Do we explicitly downsample ?\nYeah .\nYeah .\nAnd what if we didn't do that ? Would we get worse performance ?\nUm  Yeah , not better , not worse .\nI think it doesn't affect it , does it ?\nI see . OK .\nYeah . So I think the thing is , since we 're not evidently throwing away useful information , let 's try to put in some useful information .\nYeah . Yeah .\nAnd , uh , so I  you know , we  we 've found in a lot of ways for quite a while that having a second stream uh , helps a lot . So that 's  that 's put in , and you know , it may even end up with mel spectrum even though I 'm saying I think we could do much better , just because it 's simple .\nMm - hmm .\nUm . And you know , in the long run having something everybody will look at and say , \" oh , yeah , I understand \" , is  is very helpful .\nSo you would  you 're  You 're thinking to put the , uh , mel spectrum in before any of the noise removal stuff ? or after ?\nWell , that 's a question . I mean , we were talking about that . It looks like it 'd be straightforward to  to , uh , remove the noise , um , and , uh ,\nCuz that happens before the mel conversion , right ?\nYeah . So , I mean , to do it after the mel conversion  uh , after the noise removal , after the mel conversion . There 's even a question in my mind anyhow of whether th you should take the log or not . Uh . I sort of think you should , but I don't know .\nWhat about norm normalizing also ?\nRight . Uh . Well , but normalizing spectra instead of cepstra ?\nYeah .\nYeah , probably . Some kind would be good . You know ? I would think .\nWell , it  it  it  it  so it actually makes it dependent on the overall energy of the  uh , the frame .\nIf you do or don't normalize ?\nIf yo if you don't normalize and  if  if you don't normalize .\nRight . Yes , so I mean , one would think that you would want to normalize . But I  I  w w My thought is , uh , particularly if you take the log , try it . And then if  if normalization helps , then y you have something to compare against , and say , \" OK , this much effect \"  I mean , you don't want to change six things and then see what happens . You want to change them one at a time .\nMm - hmm .\nSo adding this other stream in , that 's simple in some way . And then  saying , oh  uh  particularly because we 've found in the past there 's all these  these  these different results you get with slight modifications of how you do normalization . Normalization 's a very tricky , sensitive thing and  you learn a lot . So , I would think you would wanna  have some baseline that says , \" OK , we don't normalize , this is what we get \" , when we do this normalization , when we do that normalization . But  but the other question is  So I think ultimately we 'll wind up doing some normalization . I agree .\nSo this second stream , will it add latency to the system\nNo , it 's in parallel .\nor  ?\nPara\nWe 're not talking about computation time here .\nS\nWe 're ta I think we 're pretty far out .\nYeah .\nSo it 's just in terms of what data it 's depending on . It 's depending on the same data as the other .\nSame data .\nSo it 's in parallel .\nOK .\nUh - huh .\nSo with this , uh , new stream would you train up a VAD on both  both features , somehow ?\nNo , I guess the VAD has its own set of features .\nOK . that 's\nI mean , which could be this  one of these streams , or it can be something derived from  these streams .\nYeah .\nOK .\nAnd there is also the idea of using TRAPS , maybe , for the VAD , which , um\nYeah , that 's also\nWell , Pratibha apparently showed , when , she was at IBM , that it 's a good idea . So .\nWould  would that fit on the handset , or  ? Oh !\nI have no idea .\nOK .\nWell , it has t I mean the  th\nIt would have to fit but  Yeah .\nYeah , if it has to fit the delays and all this stuff .\nWell , there 's the delays and the storage ,\nOK .\nyeah . But I don't think the storage is so big for that .\nRight .\nYeah .\nI think th the biggest we 've run into for storage is the neural net . Right ?\nYeah .\nYeah . Um . And so I guess the issue there is , are we  are we using neural - net - based TRAPS , and  and how big are they ? So that 'll  that 'll be , you know , an issue .\nOh , right .\nMaybe they can be little ones .\nYeah . Cuz sh Right .\nMini - TRAPS .\nCuz she also does the , uh  the correlation - based , uh , TRAPS , with without the neural net , just looking at the correlation between\nRight . And maybe for VAD they would be OK . Yeah . Yeah .\nYeah .\nThat 's true .\nYeah .\nOr a simple neural net , right ? I mean , the thing is , if you 're doing correlation , you 're just doing a simple  uh , uh  uh , dot product , you know , with some weights which you happened to learn from this  learn from the data .\nMm - hmm .\nAnd so , uh , putting a nonlinearity on it is ,  you know , not that big a deal . It certainly doesn't take much space .\nMm - hmm . Right .\nSo , uh , the question is , how complex a function do you need ? Do you need to have an added layer or something ? In which case , uh , potentially , you know , it could be big . So .\nMm - hmm .\nSo , uh , uh  So what 's next ? Maybe s s remind us .\nSo the meeting with Hynek that you guys just had was to decide exactly what you were gonna freeze in this system ? Is that  ? Or was there  ? Were you talking about what t new stuff , or  ?\nWhat to freeze and then what to do after we froze .\nMmm .\nYeah . And like I was saying , I think the  you know , the basic directions are , uh , uh  I mean , there 's lots of little things , such as improve the noise estimator but the bigger things are adding on the neural net and , uh , the second stream . And then , uh , improving the VAD . Uh . So .\nSo , I 'll , um  I 'll actually  after the meeting I 'll add the second stream to the VAD and maybe I 'll start with the feature net in that case . It 's like , you 're looking at the VAD , right ?\nUh , yeah . I I 've a new feature net ready also .\nI 'll  For the VAD ?\nNo , uh . Well p two network , one VAD and one  feature net .\nOh , you already have it ?\nMm - hmm .\nOK , so just figure how to take the features from the final\nYeah .\nOK .\nUm . But , yeah , I think there are plenty of issues to work on for the feature net @ @ .\nFeature net .", "topic_id": 2, "keywords": "normalization, normalizing, lda, normalize, convola", "dialogue_id": 40}, {"text": "What about the , um  uh , the new part of the evaluation , the , uh , Wall Street Journal part ?\nRight . Right . Um . Have you ever  ? Very good question . Have you ever worked with the Mississippi State h uh , software ?\nSorry .\nNo . Not yet .\nOh . Well you  you may be called upon to help , uh , uh , on account of , uh , all the work in this stuff here has been , uh , with small vocabulary .\nOK . Mm - hmm . So what  how is the , uh , interaction supposed to happen ? Uh , I remember the last time we talked about this , it was sort of up in the air whether they were going to be taking , uh , people 's features and then running them or they were gonna give the system out or\nYeah . Yeah .\nOh , so they 're gonna just deliver a system basically .\nYeah , yeah .\nDo we already have it ?\nYeah , th I  I guess it 's almost ready .\nUh - huh .\nSo  That 's what  So they have released their , uh , document , describing the system .\nMaybe you could , uh , point it  at Chuck ,\nI see .\nbecause , I mean\nSure .\nSo we 'll have to grab this over CVS or something ?\nIt - no , it 's just downloadable from their  from their web site .\nIs that how they do it ? OK .\nCuz one of the things that might be helpful , if you 've  if you 've got time in all of this is , is if  if these guys are really focusing on improving , uh , all the digit stuff , uh , maybe  and you got the front - end from them , maybe you could do the runs for the\nOK . Mm - hmm .\nand  and , you know , iron out hassles that  that you have to , uh , tweak Joe about or whatever ,\nSure .\nbecause you 're more experienced with running the large vocabulary stuff .\nOK .\nS\nSo I 'll point you to the web site and the mails corresponding . So I\nAnd it  but it 's not ready yet , the system ?\nUh , I  I think they are still , uh , tuning something on that . So they 're like , d they 're varying different parameters like the insertion penalty and other stuff , and then seeing what 's the performance .\nAre those going to be parameters that are frozen , nobody can change ? Or  ?\nUh , w I guess there is , uh , time during which people are gonna make suggestions .\nOh , but everybody 's gonna have to use the same values .\nAfter that .\nOh ! Interesting .\nYeah , I guess .\nOK .\nSo these sugges these  this , uh , period during which people are gonna make suggestions is to know whether it is actually biased towards any set of features or\nYeah , so I th th certainly the thing that I would want to know about is whether we get really hurt , uh , on in insertion penalty , language model , scaling , sorts of things .\nUsing our features .\nYeah , yeah .\nYeah .\nUh , in which case , um , H Hari or Hynek will need to , you know , push the case  more about  about this .\nMm - hmm .\nUm .\nAnd we may be able to revisit this idea about , you know , somehow modifying our features to work with\nYes . In this case , that 's right .\nYeah .\nThat 's right . Um , some of that may be , uh , a last minute rush thing because if the  if our features are changing  Uh .\nYeah .\nUh . But , um . Yeah , the other thing is that even though it 's months away , uh , it 's starting to seem to me now like November fifteenth is right around the corner . And , um , if they haven't decided things like this , like what the parameters are gonna be for this , uh , when \" deciding \" is not just somebody deciding . I mean , in fact there should be some understanding behind the , uh ,  deciding , which means some experiments and  and so forth . It  it  it seems pretty tight to me .\nSo wha what 's the significance of November fifteenth ?\nThat 's when the evaluation is .\nOK .\nYeah . So , yeah , so after  But , you know , they may even decide in the end to push it off . It wouldn't , you know , entirely surprise me . But , uh , due to other reasons , like some people are going away , I 'm  I 'm hoping it 's not pushed off for  a l a long while . That would be , uh  put us in an awkward position . But  Anyway .\nOK .\nGreat . Yeah , I think that 'll be helpful . There 's  there 's not anybody OGI currently who 's  who 's , uh , working with this and  and\nIs  is this part of the evaluation just a small part , or ho how important is this to the overall  ?\nI  I think it 's  it 's , um  it depends how badly  you do . I mean , I think that it  it is  Uh .\nb\nThis is one of those things that will be debated afterwards ?\nYeah . Well , I mean , it 's  it 's  Conceptually , it  my impression , again , you guys correct me if I 'm wrong , but  my impression is that , um , they want it as a double check . That you haven't come across  you haven't invented features which are actually gonna do badly for a  a significantly different task , particularly one with larger vocabulary . And , um , but it 's not the main emphasis .\nMmm .\nI mean , the truth is , most of the applications they 're looking at are pretty small vocabulary .\nMmm .\nSo it 's  it 's a double check . So they 'll probably assign it some sort of low weight .\nSeems to me that if it 's a double check , they should give you a one or a zero . Y you passed the threshold or you didn't pass the threshold , and they shouldn't even care about what the score is .\nYeah . But , I mean , we 'll  we 'll  we 'll see what they come up with . Uh , but in  in the current thing , for instance , where you have this well - matched , moderately - matched , and  and mis highly - mismatched , uh , the emphasis is somewhat on the  on the well - matched , but it 's only a  a marginal ,\nYeah .\nright ? It 's like forty , thirty - five , twenty - five , or something like that . So you still  if you were way , way off on the highly - mismatched , it would have a big effect .\nYeah .\nMm - hmm .\nAnd , um , it wouldn't surprise me if they did something like that with this . So again , if you 're  if you get  If it doesn't help you much , uh , for noisy versions of this  of large vocabulary data , then , uh , you know , it may not hurt you that much .\nOh .\nBut if it  if you don't  if it doesn't help you much at all , um , or to put it another way , if it helps some people a lot more than it helps other people , uh , if their strategies do , then\nMm - hmm . So is this , uh  ? Uh , Guenter was putting a bunch of Wall Street Journal data on our disks .\nThat 's it .\nSo that 's the data that we 'll be running on ?\nYeah .\nI see . OK .\nYeah . So  we have the data , just not the recognizer . OK .\nSo this test may take quite a while to run , then . May - judging by the amount of data that he was putting on .\nUh , well there 's training and test , right ?\nI  I guess , I 'm not sure .\nNo , I mean , if it 's like the other things , there 's  there 's data for training the H M Ms and  and data for testing it .\nI just\nSo I wouldn't  So it  it 's\nOK . So there 's\nSo , training the recognizer , but , um Um . But I think it 's trained on clean and  Is it trained on clean and  and test on  ?\nThe Wall Street ?\nYeah .\nApparently , no . It 's training on a range between ten and twenty DB , I think , and testing between five and fifteen .\nMm - hmm . Yeah .\nThat 's what I got  on\nOK .\nIt 's , uh  It 's like a medium  medium - mismatch condition , sort of .\nYeah ,\nI see .\nand  So the noise is  There is a range of different noises also  um  which are selected randomly and added randomly , uh , to the files . And there are noises that are different from the noises used  on TI - digits .\nYeah . Yeah . I mean , I wouldn't imagine that the amount of testing data was that huge . They probably put training  uh , almost certain they put training data there too . Maybe not . So . That 's that . Anybody have anything else ?\nUh , one  one last question on that . When did they estimate that they would have that system available for download ?\nUm , I guess  I guess one  some preliminary version is already there .\nOh , so there 's w something you can download to just learn ?\nYeah , it 's already there . Yeah .\nOK ,\nBut they 're actually parallel - y doing some modifications also , I think .\ngood .\nSo I guess the f final system will be frozen by middle of , like , one more week maybe .\nOK .\nOh , well that 's pretty soon .\nYeah , that 's just one more .\nIs this their , um , SVM recognizer ?\nNo , it 's just a straightforward HMM .\nYou know , their  their  They have a lot of options  in their recognizer and  and the SVM is one of the things they 've done with it , but it 's not their more standard thing .\nOh , OK . Uh - huh .\nFor the most part it 's  it 's Gaussian mixtures .\nOh , OK . Oh , OK .\nYeah .\nIt 's just a HMM , Gaussian mixture model .\nGaussian mixture HMM .\nYeah .\nOK .\nYeah , the SVM thing was an HMM also . It was just a  it  it  it was like a hybrid , like\nMm - hmm .\nYeah , this is a g yeah , this i\nwhat ?\nyeah .\nYeah .\nSo , just so that I understand , they 're providing scripts and everything so that basically , uh , you  you push a button and it does training , and then it does test , and everything ? Is that  the idea ?\nI  I  I think  yeah , I  I guess something like that . It 's like   as painless as possible ,\nMm - hmm .\nis what  Do they provide all the scripts , everything , and then  Just ,\nI see . Hmm . Somehow yo there 's hooks to put your features in and\nju Yeah , I th I think .\nHmm .\nHmm . Yeah , um . In fact , I mean , if you look into it a little bit , it might be reasonable  You know Joe , right ? Yeah .\nMm - hmm .\nJust to sort of ask him about the issue of , um , different features having different kinds of , uh , scaling characteristics and so on . So that , you know , w w possibly having entirely different optimal values for  for the usual twiddle factors and what 's  what 's the plan about that ?\nOK .\nSo sh shall we , like , add Chuck also to the mailing lists ? It may be better , I mean , in that case if he 's going to\nYeah .\nBecause there 's a mailing list for this .\nIs that OK ?\nYeah , that 'd be great .\nYeah , I guess maybe Hari or Hynek , one of them , has to  send a mail to Joe . Or maybe if you\nI  I could send him an email .\nWell , yeah , to add or maybe wh\nI  I know him really well .\nYeah , so that 's just fine .\nI  I was just talking with him on email the other day actually .\nSo\nUh , yeah , and just , um , se maybe see .\nSo\nAbout other things , but .\nDo you have Hari 's , uh  ?\nI have Hari 's\nYeah , so maybe just CC Hari and say that you 've just been asked to handle the large vocabulary part here , and , uh , you know ,\nOK . Would it be better if I asked Hari to ask Joe ?\nUh . Why don't you just ask Joe but CC Hari , and then in the note say , \" Hari , hopefully this is OK with you \" .\nOK .\nAnd then if Joe feels like he needs a confirmation , Hari can answer it .\nOK .\nYeah .\nThat way you can get started asking  Joe quickly while he 's  while he 's maybe still , you know , putting in nails and screws and Yeah .\nAnd there is an , uh , archive of all the mails that has been  gon that has gone , uh , between these people  among these people . So just you can see all this  mails in the ISIP web site\nOK .\nMississippi web site .\nOK . Is that a password controlled  ?\nYeah , it 's password protected .\nOK .\nSo , like  like , it 's , like\nHave you thought about  how long  would be uh , most useful for you to go up to OGI ?\nI don't know , uh . We can   For September , we can set up a work schedule and we can maybe work independently . And then at some point it maybe be better to work together again .\nOh , so you 're  you 're imagining more that you would come back here first for a while and then  and then go up there ?\nI\nI mean , it 's to you .\nMaybe , yeah .\nI ju you guys are Well , y anyway , you don't have to decide this second but thi think about it  about what  what you would think would be the  the best way to work it . I 'll\nBut , uh  Huh . Mm - hmm .\nsupport it either way , so .\nMm - hmm Right .", "topic_id": 3, "keywords": "evaluation, software, applications, interaction, document", "dialogue_id": 40}, {"text": "OK . Uh . Got anything to tell us ?\nUm . Well , I 've been reading some literature about clustering of data . Just , um , I guess , let me put it in context . OK , so we 're talking about discovering intermediate categories to , um  to classify . And , uh , I was looking at some of the work that , uh , Sangita was doing on these TRAPS things . So she has , um  she has temporal patterns for , um , a certain set of phonemes , from  from TIMIT , right ? the most common phonemes . And each one of them has  has a  a nice pattern over time , a one  one second window . And it has  has these patterns . Um , so she has , um a TRAP for each one of the phonemes , um , times fifteen , for each of the fifteen critical bands . And , um ,  she does this agglomerative hierarchical clustering which  which basically , um , is a clustering algorithm that , uh , starts with many , many , many different points  many different clusters  uh , corresponding to the number of data , uh , patterns that you have in the data . And then you have this distance mej metric which , uh , measures how  how closely related they are . And you start , um  by merging the patterns that are most closely related .\nAnd you create a tree .\nAnd y yeah , yeah , a dendrogram tree .\nMm - hmm .\nUm .\nAnd then you can pick , uh , values anywhere along that tree to fix your set of clusters .\nRight , usually it 's when , um  when the sol similarity measures , um , don't go down as much .\nMm - hmm .\nAnd so , uh  so you stop at that point . And what she found was , sh um , was there were five broad , um  broad categories , uh , corresponding to , uh , things like , uh , fricatives and , uh , vocalic , um , and , uh , stops .\nMm - hmm .\nAnd , uh , one for silence and  and another one for schwa  schwa sounds . Um , and , um , I was thinking about ways to  to generalize this because w you 're  it 's sort of like a  it 's not a completely automatic way of clustering , because yo beforehand you have these  these TRAPS and you 're saying that  that these frames correspond to this particular phoneme . Um , and that 's  that 's constraining your  your clustering to  to the set of phonemes that you already have . Um , whereas maybe we want to just take  take a look at , um , arbitrary windows in time , um , of varying length , um , and cluster those .\nMm - hmm .\nAnd I 'm thinking if we  if we do that , then we would probably , um , at some point in the clustering algorithm find that we 've clustered things like , OK , thi this is a transition , um , this is a relatively stable  stable point .\nMm - hmm .\nUm , and I 'm hoping to find other things of  of similarity and maybe use these things as the intermediate , um  intermediate categories that , uh , um , I 'll later classify .\nMm - hmm .\nAre you looking at these in narrow bands ?\nUm , right . F um , I 'm\nCuz that 's what you 're gonna be using , right ?\nYeah , yeah . I  I haven't exactly figured out , um , the exact details for that but , uh , the  the representation of the data that I was thinking of , was using , um , critical band , um , energies ,  um , over different lengths of time . So  Yeah .\nYeah , I mean , it seems somehow that needs th uh , there 's a couple things that I wonder about with this . I mean , so one is  is ,  again , looking at the same representation ,\nOK .\nI mean , if you 're going for this sort of thing where you have  uh , little detectors that are looking at narrow bands , then what you 're going to be looking for should be some category that you can find with the narrow bands .\nMm - hmm .\nThat  that seems to be kind of fundamental to it . Um , and then the other thing , uh , is  that I wonder about with it , and  and don't take this in the wrong way , like I  I know what I 'm doing or anything ,\nRight .\nbut , I mean .  Um , just wondering really .\nMm - hmm .\nUm , the sort of standard answer about this sort of thing is that if you 're trying to find  the right system in some sense , whether you 're trying by categories or  or parameters  um , and your goal is discrimination , then having choices based on discrimination as opposed to , um , unsupervised nearness of things , um , is actually better .\nHmm .\nUm , and I don't know if that  I mean , since you 're dealing with issues of robustness , you know , maybe  maybe this isn't right , but it 'd be something I 'd be concerned about . Because , for instance , you can imagine , uh , uh , i i if you remember from  from , uh  from your  your quals , John Ohala saying that , uh , \" buh \"  and \" puh \"  differed , uh , not really cuz of voicing but because of aspiration . I mean , in as far as wha what 's really there in the acoustics .\nMm - hmm .\nSo , um , if you looked  if you were doing some coarse clustering , you probably would put those two sounds together . And yet , I would gue I would guess that many of your recognition errors were coming from , uh , um , pfft ,  screwing up on this distinction .\nMm - hmm .\nSo , in fact , it 's a little hard because recognizers , to first order , sort of work . And the reasons we 're doing the things we 're doing is because they don't work as well as we 'd like . And since they sort of work , uh , it means that they are already doing  if you go and take any recognizer that 's already out there and you say , \" how well is it distinguishing between  schwas and stops ? \"\nMm - hmm .\nBoy , I bet they 're all doing nearly perfectly on this , right ?\nMm - hmm .\nSo these  these big categories that differ in huge obvious ways , we already know how to do . So , what are we bringing to the party ? I mean , in fact what we wanna do is have something that , particularly in the presence of noise , uh , is better at distinguishing between , uh , categories that are actually close to one another , and hence , would probably be clustered together .\nMmm .\nSo that 's th that 's the hard thing . I mean , I understand that there 's this other constraint that you 're considering , is that you wanna have categories that , uh  that would be straightforward for , say , a human being to mark if you had manual annotation . And it 's something that you really think you can pick up . But I think it 's also essential that you wanna look at what are the  confusions that you 're making and how can you come up with , uh , categories that , uh , can clarify these confusions .\nMm - hmm . Hmm .\nSo , I mean , the standard sort of way of doing that is take a look at the algorithms you 're looking at , but then throw in some discriminative aspect to it . Y y this is more like , you know , how does LDA differ from PCA ? I mean , they 're the same sort of thing . They 're both orthogonalizing .\nRight .\nBut , you know  and  and , um , this is a little harder because you 're not just trying to find parameters . You 're actually trying to find the  the  the  the categories themselves . Uh , so a little more like brain surgery , I think on yourself . Uh . So , uh\nYeah .\nUm , anyway . That 's my  thought .\nOK .\nYou 've been thinking about this problem for a long time actually . I mean , well  W actually , you stopped thinking about it for a long time , but you used to think about it  a lot .\nYeah .\nAnd you 've been thinking about it more now ,\nYeah .\nthese categories .\nYeah .\nMm - hmm .\nI guess  I don't  I don't  um , it 's not clear to me how to reconcile , you know , what you 're saying , which I think is right , with  the way I 've been looking at it . That it 's  it 's  it 's all not very clear to me . But it seems to me that the desire  the desirable feature to have is something that , um , is bottom - up . You know , however we do that .\nMm - hmm .\nAnd and so I guess what I don't understand is how to do that and still be discriminative , because to be discriminative you have to have categories and the only categories that we know of to use are sort of these human  human sig significant  categories that are significant to humans , like phonemes , things like that .\nRight .\nBut that 's sort of what you want to avoid . And so that feels  I don't know how to get out of this .\nWell , here 's a  here 's a , uh , uh Here 's a generic and possibly useless thought , which is ,  um , what do you really  I mean , in a sense the only s s systems that make sense , uh , are ones that  that have something from top - down in th in them . Right ? Because if e even the smallest organism that 's trying to learn to do anything , if it doesn't have any kind of reward for doing  or penal penalty for doing anything , then it 's just going to behave randomly .\nMm - hmm .\nSo whether you 're talking about something being learned through evolution or being learned through experience , it 's gotta have something come down to it that gives its reward or , you know , at least some reinforcement learning ,\nRight .\nright ?\nSo the question is , how far down ?\nAnd\nWe could stop at words , but we don't , right ? We go all the way down to phonemes .\nRight , but I me I  I think that maybe in some ways part of the difficulty is  is trying to deal with the  with these phonemes . You know , and  and  and i it 's almost like you want categories if  if our  if our , uh , um ,  metric of  of goodness , uh , i if our\nMm - hmm .\ncorrection  if our metric of badness  is word error rate then , um , maybe we should be looking at words .\nMm - hmm .\nI mean , for  for  for very nice , uh , reasons we 've looked for a while at syllables , and they have a lot of good properties , but i i i if you go all the way to words , I mean , that 's really  I mean , d w In many applications you wanna go further . You wanna go to concepts or something , or have  have  have concepts , actions , this sort of thing .\nYeah . But words would be a nice\nBut , words aren't bad , yeah . And  and\nYeah , so the common  right , the common wisdom is you can't do words because there 's too many of them , right ? So you have to have some smaller set that you can use , uh , and  and so everybody goes to phonemes . But the problem is that we  we build models of words in terms of phonemes and these models are  are really cartoon - ish , right ? So when you look at conversational speech , for example , you don't see the phonemes that you  that you have in your word models .\nYeah . But  but  but we 're not trying for models of words here . See , so her here 's maybe where  If the issue is that we 're trying to come up with , um , some sort of intermediate categories which will then be useful for later stuff , uh , then  maybe it doesn't matter that we can't have enough\nMm - hmm . Mm - hmm .\nI mean , what you wanna do is  is build up these categories that are  that are best for word recognition .\nRight . Right .\nAnd  and somehow if that 's built into the loop of what the categories  I mean , we do this every day in this very gross way of  of running o a thousand experiments\nRight .\nbecause we have fast computers and picking the thing that has the best word error rate .\nYeah .\nIn some way  I mean , we derive that all the time . In some ways it 's really not  a bad  bad thing to do because it tells you in fact how your adjustments at the very low level affect the  the final goal .\nMm - hmm . Mm - hmm .\nUm , so maybe there 's a way to even put that in in a much more automatic way ,\nRight .\nwhere you take , you know , something about the error at the level of the word or some other  it could be syllable  but in some large unit ,\nUh - huh .\nuh , and uh  yeah , you may not have word models , you have phone models , whatever , but you sort of  don't worry about that , and just somehow feed it back through .\nMm - hmm .\nYou know , so that 's , uh , wh what I called a useless comments because I 'm not really telling you how to do it . But I mean , it 's a   it 's  it 's , you know  it\nNo , but I think the important part in there is that , you know , if you want to be discriminative , you have to have uh , you know , categories .\nRight .\nAnd I think this  the important categories are the words , and  not the phones .\nYeah . Yeah .\nMaybe . And so  Right . If you can put the words in to the loop somehow for determining goodness of your sets of clusters  Uh\nNow , that being said , I think that  that if you have something that is , um  i Once you start dealing with spontaneous speech , all the things you 're saying are  are really true .\nMm - hmm .\nIf you  have read speech that 's been manually annotated , like TIMIT , then , you know , i i you the phones are gonna be right , actually ,  for the most part .\nYeah . Yeah ,\nSo  so , uh , it doesn't really hurt them to  to do that , to put in discrimination at that level .\nyeah .\nUm , if you go to spontaneous speech then it 's  it 's trickier and  and  and , uh , the phones are  uh , you know , it 's gonna be based on bad pronunciation models that you have of\nand , um  And it won't allow for the overlapping phenomenon\nMmm . So it 's almost like there 's this mechanism that we have that , you know , when  when we 're hearing read speech and all the phonemes are there you know , we  we deal with that , but  but when we go to conversational , and then all of a sudden not all the phonemes are there , it doesn't really matter that much to us as humans because we have some kind of mechanism that allows for these word models , whatever those models are , to be  munged , you know , and  and it doesn't really hurt , and I 'm not sure how   how to build that in . Uh .\nYeah , I mean , I guess the other thing i is  is to think of a little bit  I mean , we when y when you start looking at these kind of results I think it usually is  is pretty intuitive , but start looking at um , what are the kinds of confusions that you do make , uh , you know , between words if you want or  or  or , uh , even phones in  in  in  in read speech , say , uh , when there is noise . You know , so is it more across place or more across manner ? Or is it cor you know , is it  ?\nMm - hmm .\nI mean , I know one thing that happens is that you  you  you , uh , you lose the , um , uh , low energy phones . I mean , if there 's added noise then low energy phones  sometimes don't get heard . And if that  if that is  if it  uh , if that turns it into another word or  or different  you know , or another pair of words or something , then it 's more likely to happen . But , um , I don't know , I w I would  I would guess that you 'd\nMm - hmm .\nW I don't know . Anyway , that 's\nI think part of the difficulty is that a l a lot of the robustness that we have is probably coming from a much higher level .\nMm - hmm .\nYou know , we understand the context of the situation when we 're having a conversation . And so if there 's noise in there , you know , our brain fills in and imagines what  what should be there .\nWell that\nYeah . We 're  we 're doing some sort of prediction of what\nYeah , exactly .\nOh , sure , that 's really big .\nYeah .\nUh , but I mean , even if you do um , uh , diagnostic rhyme test kind of things , you know , where there really isn't an any information like that , uh , people are still better in noise than they  than they are in  in , uh  uh , than the machines are .\nHmm .\nSo , I mean , that 's  i Right . We can't  we can't get it at all without any language models . Language models are there and important but  but , uh  Uh . If we 're not working on that then  we should work on something else and improve it , but  especially if it looks like the potential is there . So  Should we do some digits ?\nYeah .\nSince we 're here ?\nGo ahead , Morgan .\nOK .\nOK .\nThat 's all folks .", "topic_id": 4, "keywords": "cluster, clusters, clustering, clustered, patterns", "dialogue_id": 40}, {"text": "OK . We seem to be recording .\nAlright !\nSo , sorry about not\nWe 're not crashing .\nNumber four .\nnot pre - doing everything . The lunch went a little later than I was expecting , Chuck .\nHmm ?\nOK .\nChuck was telling too many jokes , or something ?\nYep . Pretty much .\nYeah .\nOK .  Does anybody have an agenda ?\nNo .\nWell , I 'm  I sent a couple of items . They 're  they 're sort of practical .\nI thought  somebody had .\nI don't know if you 're\nYeah , that 's right .\nif  if that 's too practical for what we 're  focused on .\nI mean , we don't want anything too practical .\nYeah , we only want th useless things .\nYeah , that would be\nYeah . No , why don't we talk about practical things ?\nOK .\nSure .\nWell , um , I can  give you an update on the  transcription effort .\nGreat .\nUh , maybe {nonvocalsound} raise the issue of microphone , uh , um procedures with reference to the  cleanliness of the recordings .\nOK , transcription , uh , microphone issues\nAnd then maybe {nonvocalsound} ask , th uh , these guys . The  we have great  great , uh , p steps forward in terms of the nonspeech - speech pre - segmenting of the signal .\nOK .\nWell , we have steps forward .\nYeah .\nWell , it 's a  it 's a big improvement .\nI would prefer this .\nYes . Yeah , well . OK . Uh\nWe talk about the   the results of\nYou have some  Yeah .\nI have a little bit of IRAM stuff\nOK .\nuse\nbut  I 'm not sure if that 's of general interest or not .\nUh , bigram ?\nIRAM .\nIRAM .\nIRAM .\nIRAM , bigram ,\nWell , m maybe .\nBi - Bigram .\nyou know .\nYeah , let 's  let 's see where we are at three - thirty .\nHmm .\nUm\nSince , uh  since I have to leave as usual at three - thirty , can we do the interesting stuff first ?\nI beg your pardon ?\nWell\nWhich is  ?\nWhat 's the interesting stuff ?\nI beg your pardon ?\nYeah .\nYeah . Th - now you get to tell us what 's the interesting part .\nPlease specify .\nBut\nWell , uh , I guess the work that 's been  done on segmentation would be most\nYeah .\nI think that would be a good thing to start with .\nYeah .\nOK . Um , and , um ,  the other thing , uh , which I 'll just say very briefly that maybe relates to that a little bit , which is that , um , uh , one of the suggestions that came up in a brief meeting I had the other day when I was in Spain with , uh , Manolo Pardo and  Javier , uh , Ferreiros , who was  here before , was , um , why not start with what they had before but add in the non - silence boundaries . So , in what Javier did before when they were doing , um  h he was looking for , uh , speaker change  points .\nMm - hmm .\nUm . As a simplification , he originally did this only using  silence as , uh , a  putative , uh , speaker change point .\nYeah .\nAnd , uh , he did not , say , look at points where you were changing broad sp uh , phonetic class , for instance . And for Broadcast News , that was fine . Here obviously it 's not .\nYeah .\nAnd , um , so one of the things that they were pushing in d in discussing with me is , um , w why are you spending so much time , uh , on the , uh , feature issue , uh , when perhaps if you sort of deal with what you were using before\nUh - huh .\nand then just broadened it a bit , instead of just ta using silence as putative change point also  ?\nNnn , yeah .\nSo then you 've got  you already have the super - structure with Gaussians and H - you know , simple H M Ms and so forth . And you  you might  So there was a  there was a little bit of a  a  a  a difference of opinion because I  I thought that it was  it 's interesting to look at what features are useful .\nYeah .\nBut , uh , on the other hand I saw that the  they had a good point that , uh , if we had something that worked for many cases before , maybe starting from there a little bit  Because ultimately we 're gonna end up  with some s su kind of structure like that ,\nYeah .\nwhere you have some kind of simple HMM and you 're testing the hypothesis that ,  uh , there is a change .\nYeah .\nSo  so anyway , I just  reporting that .\nOK .\nBut , uh , uh  So . Yeah , why don't we do the speech - nonspeech discussion ?\nYeah . Do  I  I hear  you  you didn't\nSpeech - nonspeech ? OK .\nUh - huh . Yeah .\nUm , so , uh , what we basically did so far was using the mixed file to  to detect s speech or nonspeech  portions in that .\nMm - hmm .\nAnd what I did so far is I just used our old Munich system , which is an HMM - ba based system with Gaussian mixtures for s speech and nonspeech . And it was a system which used only one Gaussian for silence and one Gaussian for speech . And now I added , uh , multi - mixture possibility for   for speech and nonspeech .\nMm - hmm . Mm - hmm .\nAnd I did some training on  on one dialogue , which was transcribed by  Yeah . We  we did a nons s speech - nonspeech transcription .\nJose .\nAdam , Dave , and I , we did , for that dialogue and I trained it on that . And I did some pre - segmentations for  for Jane . And I 'm not sure how good they are or what  what the transcribers say . They  they can use it or  ?\nUh , they  they think it 's a terrific improvement . And , um , it real it just makes a  a world of difference .\nHmm .\nAnd , um , y you also did some something in addition which was , um , for those in which there {nonvocalsound} was , uh , quiet speakers in the mix .\nYeah . Uh , yeah . That  that was one  one  one thing , uh , why I added more mixtures for  for the speech . So I saw that there were loud  loudly speaking speakers and quietly speaking speakers .\nMm - hmm .\nAnd so I did two mixtures , one for the loud speakers and one for the quiet speakers .\nAnd did you hand - label who was loud and who was quiet , or did you just  ?\nI did that for  for five minutes of one dialogue\nRight .\nand that was enough to  to train the system .\nW What  ?\nYeah .\nAnd so it  it adapts , uh , on  while running . So .\nWhat kind of , uh , front - end processing did you do ?\nHopefully .\nOK .\nIt 's just our  our old Munich , uh , loudness - based spectrum on mel scale twenty  twenty critical bands and then loudness .\nMm - hmm .\nAnd four additional features , which is energy , loudness , modified loudness , and zero crossing rate . So it 's twenty - four  twenty - four features .\nMmm .\nMm - hmm .\nAnd you also provided me with several different versions ,\nYeah .\nwhich I compared .\nYeah .\nAnd so you change {nonvocalsound} parameters . What  do you wanna say something about the parameters {nonvocalsound} that you change ?\nYeah . You can specify  the minimum length of speech or  and silence portions which you want . And so I did some  some modifications in those parameters , basically changing the minimum  minimum  length for s for silence to have , er to have , um  yeah  to have more or less , uh , silence portions in inserted . So .\nRight . So this would work well for , uh , pauses and utterance boundaries and things like that .\nYeah .\nYeah . Yeah .\nBut for overlap I imagine that doesn't work at all ,\nYeah .\nYeah .\nthat you 'll have plenty of s sections that are\nYeah .\nYeah .\nThat 's it . Yeah .\nMm - hmm , mm - hmm .\nYeah .\nBut\nThat 's true . But {nonvocalsound} it  it saves so much time  the  the {nonvocalsound} transcribers\nUm\nYep .\njust enormous , enormous savings . Fantastic .\nThat 's great . Um , just qu one quickly , uh , still on the features . So  you have these twenty - four features .\nYeah .\nUh , a lot of them are spectral features . Is there a  a transformation , uh , like principal components transformation or something ?\nNo .\nYeah . It was IS two .\nNo . W w we  originally we did that\nJust\nbut we saw , uh , when we used it , uh , f for our close - talking microphone , which  yeah , for our  for our recognizer in Munich  we saw that w it 's  it 's not  it 's not so necessary . It  it works as well f with  with  without , uh , a LDA or something .\nOK . OK . No , I was j  curious .\nYeah .\nMm - hmm .\nYeah , I don't think it 's a big deal for this application ,\nYeah .\nRight .\nbut  but  Yeah , it 's a\nMm - hmm . OK . But then there 's another thing that also Thilo 's involved with , which is , um  OK , and  and also Da - Dave Gelbart . So there 's this  this problem of  and w and  so we had this meeting . Th - the {nonvocalsound}  also Adam , before the  the  before you went away . Uh we , um  regarding the representation {nonvocalsound} of overlaps , because at present , {nonvocalsound}  um , because {nonvocalsound} of the limitations of  th the interface we 're using , overlaps are , uh , not being {nonvocalsound} encoded by {nonvocalsound} the transcribers in as complete {nonvocalsound} and , uh , detailed a way as it might be , and as might be desired  I think would be desired in the corpus ultimately .\nMm - hmm .\nSo we don't have start and end points {nonvocalsound} at each point where there 's an overlap . We just have the  the {nonvocalsound} overlaps {nonvocalsound} encoded in a simple bin . Well , OK . So {nonvocalsound} @ @ the limits of the {nonvocalsound} over of  of the interface are  such that we were  at this meeting we were entertaining how we might either expand {nonvocalsound} the  the  interface or find other tools which already  do what would be useful . Because what would ultimately be , um , ideal in my  my view and I think  I mean , I had the sense that it was consensus , is that , um , a thorough - going musical score notation would be {nonvocalsound} the best way to go . Because {nonvocalsound} you can have multiple channels , there 's a single time - line , it 's very clear , flexible , and all those nice things .\nMm - hmm .\nOK . So , um , um , I spoke  I had a meeting with Dave Gelbart on  on  and he had , uh , excellent ideas on how  the interface could be  modified to  to do this kind of representation . But , um , he  in the meantime you were checking into the existence of already , um , existing interfaces which might already have these properties . So , do you wanna say something about that ?\nYes . Um , I  talked with , uh , Munich guys from  from Ludwi - Ludwig Maximilians University , who do a lot of transcribing and transliterations .\nMm - hmm .\nAnd they basically said they have  they have , uh , a tool they developed  themselves and they can't give away , uh , f it 's too error - prone , and had  it 's not supported , a a a and\nYeah .\nBut , um , Susanne Bur - Burger , who is at se CMU , he wa who was formally at  in Munich and w and is now at  with CMU , she said she has something which she uses to do eight channels , uh , trans transliterations , eight channels simultaneously ,\nExcuse me .\nbut it 's running under Windows .\nUnder Windows .\nSo I 'm not sure if  if  if we can use it .\nMm - hmm .\nShe said she would give it to us .\nMm - hmm .\nIt wouldn't be a problem . And I 've got some  some kind of manual  down in my office .\nWell , maybe we should get it and if it 's good enough we 'll arrange Windows machines to be available .", "topic_id": 0, "keywords": "recordings, recording, talking, discussing, dialogue", "dialogue_id": 41}, {"text": "Yeah .\nMm - hmm . We could  uh , potentially {nonvocalsound} so .\nSo .\nI also wanted to be sure  I mean , I 've  I 've seen the  this  this is called Praat , PRAAT , {nonvocalsound} which I guess means spee speech in Dutch or something .\nYep .\nYeah , but then I 'm not sure  that 's the right thing for us .\nBut  In terms {nonvocalsound} of it being {nonvocalsound} Windows {nonvocalsound} versus\nYeah .\nNo , no . Praat isn't  Praat 's multi - platform .\nBut I 'm just wondering , is  ?\nNo . No , Praat  Yeah . Yeah .\nOh ! I see .\nYeah .\nOh , I see . So Praat may not be\nThat 's not Praat . It 's called \" trans transedit \"  I think .\nIt 's a different one .\nThe  the , uh  the tool from  from Susanne .\nI see . Oh , I see . OK . OK . Alright .\nThe other thing , uh , to keep in mind , uh  I mean , we 've been very concerned to get all this rolling so that we would actually have data ,\nMmm , yeah .\nbut , um , I think our outside sponsor is actually gonna kick in\nMm - hmm .\nand ultimately that path will be smoothed out . So I don't know if we have a long - term need to do lots and lots of transcribing . I think we had a very quick need to get something out and we 'd like to be able to do some later because just it 's inter it 's interesting . But as far a you know , uh , with  with any luck we 'll be able to wind down the larger project .\nOh .\nBut you s\nWhat our decision was is that  we 'll go ahead with what we have with a not very fine time scale on the overlaps .\nYeah .\nRight . Yeah .\nAnd  and do what we can later  to clean that up if we need to .\nMm - hmm .\nRight .\nAnd  and I was just thinking that , um ,  if it were possible to bring that in , like ,  you know , this week , then {nonvocalsound} when they 're encoding the overlaps {nonvocalsound} it would be nice for them to be able to specify when  you know , the start points and end points of overlaps .\nUh - huh .\nuh Th - they 're {nonvocalsound} making really quick progress .\nYeah . That 's great .\nAnd , um , so my  my goal was  w m my charge was to get eleven hours by the end of the month . And it 'll be  I 'm  I 'm  I 'm clear that we 'll be able to do that .\nThat 's great .\nAnd did you , uh , forward Morgan Brian 's  thing ?\nYeah .\nI sent {nonvocalsound} it to , um  who did I send that to ? I sent it to a list and I thought {nonvocalsound} I sent it to {nonvocalsound} the {nonvocalsound}  e to the local list .\nMeeting Recorder .\nOh , you did ? OK . So you probably did get that .\nYou saw that ? So Brian did tell {nonvocalsound} me that {nonvocalsound} in fact what you said , that , {nonvocalsound} uh  that {nonvocalsound} our  that they are  making progress and that he 's going  that {nonvocalsound} they 're {nonvocalsound} going  he 's gonna check the f the output of the first transcription and  and\nI mean , basically it 's  it 's all the difference in the world . I mean , basically he 's  he 's on it now .\nYeah .\nOh , that 's  this is a new development .\nSo  so  so this is  so i it 'll happen .\nOK . Super . Super . OK . Great .\nYeah . I mean , basically it 's just saying that one of our  one of our best people is on it ,\nYeah .\nyou know , who just doesn't happen to be here anymore . Someone else pays him . So\nBut about the need for transcription ,\nIsn't that great ?\nI mean , don't we  didn't we previously  decide that the  IBM  transcripts would have to be  checked anyway and possibly augmented ?\nSo .  Yeah .\nYes . That 's true .\nSo , I think having a good tool is worth something no matter what .\nMm - hmm .\nYeah . S OK . That 's  that 's a good point .\nYeah , and Dave Gelbart did volunteer ,\nGood .\nand since he 's not here , I 'll repeat it  to at least modify Transcriber , which , if we don't have something else that works , I think that 's a pretty good way of going .\nMmm .\nMm - hmm .\nAnd we discussed on some methods to do it . My approach originally , and I 've already hacked on it a little bit  it was too slow because I was trying to display all the waveforms . But he pointed out that you don't really have to . I think that 's a good point .\nMm - hmm .\nMm - hmm .\nThat if you just display the mix waveform and then have a user interface for editing the different channels , that 's perfectly sufficient .\nHmm .\nYeah , exactly . And just keep those {nonvocalsound} things separate . And  and , um , Dan Ellis 's hack already allows them to be {nonvocalsound} able to display  different {nonvocalsound} waveforms to clarify overlaps and things ,\nNo . They can only display one ,\nso that 's already\nbut they can listen to different ones .\nOh , yes , but  Well ,  uh , yes , but {nonvocalsound} what I mean is  that , uh , from the transcriber 's {nonvocalsound} perspective , uh , those {nonvocalsound} two functions are separate . And Dan Ellis 's hack handles the ,  um , choice {nonvocalsound}  the ability to choose different waveforms  from moment to moment .\nBut only to listen to , not to look at .\nYeah .\nUm\nThe waveform you 're looking at doesn't change .\nYeah .\nThat 's true .\nYeah .\nYeah , but {nonvocalsound} that 's  that 's OK , cuz they 're  they 're , you know , they 're focused on the ear anyway .\nRight .\nAnd then  and then\nHmm .\nthe hack to  preserve the overlaps {nonvocalsound} better would be one which creates different output files for each channel ,\nRight .\nwhich then {nonvocalsound} would also serve Liz 's request  of having , you know , a single channel , separable , uh , cleanly , easily separable ,\nMm - hmm .\nuh , transcript tied to a single channel , uh , audio .\nMm - hmm . Have , uh , folks from NIST been in contact with you ?\nNot directly . I 'm trying to think if  if I could have gotten it over a list .\nOK .\nI don't  I don't think so .\nOK . Well , holidays may have interrupted things , cuz in  in  in  They  seem to want to  get absolutely clear on standards for  transcription standards and so forth with  with us .\nOh ! This was from before December . Yeah .\nRight . Because they 're  they 're presumably going to start recording next month .\nOK . OK .\nOh , we should definitely get with them then ,\nSo .\nand agree upon a format . Though I don't remember email on that . So was I not in the loop on that ?\nUm . Yeah , I don't think I mailed anybody . I just think I told them to contact Jane  that , uh , if they had a\nOh , OK .\nThat 's right .\nif , uh  that  that , uh , as the point person on it .\nYeah , I think that 's right .\nBut\nJust , uh\nSo , yeah . Maybe I 'll , uh , ping them a little bit about it to  get that straight .\nOK . I 'm keeping the conventions  absolutely  as simple {nonvocalsound} as possible .\nYeah . So is it  cuz with any luck there 'll actually be a  a  there 'll be collections at Columbia , collections at  at UW  I mean Dan  Dan is very interested in doing some other things ,\nRight .\nYeah . Yeah .\nWell , I think it 's important both for the notation and the machine representation to be the same .\nand collections at NIST . So  Yeah .\nSo .\nN there was also this , {nonvocalsound} uh , email from Dan regarding the  speech - non nonspeech segmentation thing .\nYep .\nYeah .\nYeah .\nI don't know if , uh , uh , we wanna , uh  and Dan Gel - and Dave Gelbart is interested in pursuing the aspect {nonvocalsound} of using amplitude {nonvocalsound} as a  a  a  as a basis for the separation .\nCross - correlation .\nOh , yeah . He was talking  he was talking  I mean , uh , we  he had\nCross\nYeah , cross - correlation .\nCross\nI had mentioned this a couple times before , the c the commercial devices that do , uh ,  uh , voice , uh  you know , active miking ,\nUh - huh .\nbasically look at the amp at the energy at each of the mikes . And  and you basically compare the energy here to  some function of all of the mikes .\nYeah .\nYeah .\nOK .\nSo , by doing that , you know , rather than setting any , uh , absolute threshold , you actually can do pretty good , uh , selection of who  who 's talking .\nOK .\nUh  And those  those systems work very well , by the way , I mean , so people use them in  panel discussions and so forth with sound reinforcement differing in  in sort of ,\nUh - huh .\nuh  and , uh , those  if  Boy , the guy I knew who built them , built them like twenty  twenty years ago ,\nHmm .\nso they 're   it 's  the  the techniques work pretty well .\nFantastic . Cuz there is one thing that we don't have right now and that is the automatic , um , channel identifier .\nSo .\nThat  that , you know , that would g help in terms of encoding of overlaps .\nMm - hmm .\nThe  the transcribers would have less , uh , disentangling to do  if that were available .\nYeah . So I think , you know , basically you can look at some  p you have to play around a little bit , uh , to figure out what the right statistic is ,\nBut .\nMm - hmm .\nMm - hmm .\nbut you compare each microphone to some statistic based on the   on the overall\nYeah .\nMm - hmm .\nOK .\nUh , and we also have these  we have the advantage of having  distant mikes too . So that , you cou yo\nYeah , although the  the  using the close - talking I think would be much better . Wouldn't it ?\nYeah .\nUm . I  I don't know .\nYeah .\nI just  it 'd be  If I was actually working on it , I 'd sit there and  and play around with it , and  and get a feeling for it . I mean , the  the  the , uh  But , uh , you certainly wanna use the close - talking , as a  at least .\nRight .\nI don't know if the other would  would add some other helpful dimension or not .\nMm - hmm .\nMm - hmm . OK . What  what are the different , uh , classes to  to code , uh , the  the overlap , you will use ?\nUm , to code d\nWhat you  you\nso types of overlap ?\nYeah .\nUm , so {nonvocalsound} at a meeting that wasn't transcribed , we worked up a  a typology .\nYeah .\nAnd , um\nLook like , uh , you t you explaining in the blackboard ? The  ? Yeah ? Yeah .\nYes , exactly . That hasn't changed . So it {nonvocalsound} i the  it 's basically a two - tiered structure where the first one is whether {nonvocalsound} the person who 's interrupted continues or not . And then below that there 're {nonvocalsound} subcategories , uh , that have more to do with , {nonvocalsound} you know , is it ,  uh , simply {nonvocalsound} backchannel\nMm - hmm .\nor is {nonvocalsound} it , um , someone completing someone else 's thought , or is it someone in introducing a new thought .\nRight . And I hope that if we do a forced alignment with the close - talking mike , that will be enough to recover at least some of the time the time information of when the overlap occurred .\nHuh . Yeah . Yeah .\nMm - hmm . Well ,  one would\nWe hope .\nYeah . Who knows ?\nThat 'd be  that 'd be nice . I mean ,  I  I  I  I 've\nSo who 's gonna do that ? Who 's gonna do forced alignment ?\nWell , u uh , IBM was going to . Um\nOh , OK .\nOh .\nand I imagine they still plan to but  but , you know , I haven't spoken with them about that recently .\nOK .\nUh - huh .\nWell , uh , my suggestion now is  is on all of these things to , uh , contact Brian .\nOK . I 'll do that .\nYeah .\nThis is wonderful {nonvocalsound} to have a direct contact like that .\nYeah .\nuh Well , th lemme ask {nonvocalsound} you this .\nYeah .\nIt occurs to me   one of my transcribers t {nonvocalsound} told {nonvocalsound} me today that she 'll {nonvocalsound} be finished with one meeting ,  um , by\nMm - hmm .\nwell , she said tomorrow but then she said {nonvocalsound}  you know , but {nonvocalsound}  the , you know  let 's  let 's just , uh , say\nMm - hmm .\nmaybe the day after just to be s on the safe side . I could send Brian the , {nonvocalsound} um  the {nonvocalsound} transcript . I know these {nonvocalsound} are  er , uh , I could send him that {nonvocalsound} if {nonvocalsound} it would be possible , {nonvocalsound} or a good idea or not , to {nonvocalsound} try {nonvocalsound} to do a s forced alignment on what we 're  on the way we 're encoding overlaps now .\nWell , just talk to him about it .\nYep .\nGood .\nI mean , you know , basically he 's  he just studies , he 's a colleague , a friend , and ,\nYeah !\nuh , they  and  and , you know , the  the organization always did wanna help us .\nSuper . Super .\nIt was just a question of getting , you know , the right people connected in , who had the time .\nRight .\nYeah , yeah .\nSo , um , eh\nIs he on the mailing list ? The Meeting Recorder mailing li ?\nOh !\nWe should add him .\nYeah . I  I  I don't know for sure .\nYeah .\nDid something happen , Morgan , that he got put on this , or was he already on it ,\nAdd him .\nor  ?\nNo , I , eh , eh , p It  it oc I  h it 's  Yeah , something happened . I don't know what .\nHe asked for more work .\nHuh .\nBut he 's on it now .\nThat would be {nonvocalsound} like  that 'd be like him . He 's great .\nRight . So , uh , where are we ? Maybe , uh , uh , brief  Well , let 's  why don't we talk about microphone issues ?\nYeah . That 'd be great .\nThat was  that was a\nUm , so one thing is that I did look on Sony 's for a replacement for the mikes   for the head m head - worn ones cuz they 're so uncomfortable . But I think I need someone who knows more about mikes than I do , because I couldn't find a single other model that seemed like it would fit the connector , which seems really unlikely to me . Does anyone , like , know stores or  know about mikes who  who would know the right questions to ask ?\nOh , I probably would . I mean , my knowledge is twenty years out of date but some of it 's still the same .\nMm - hmm .\nSo  Uh , so maybe we c we can take a look at that .\nYou couldn't  you couldn't find the right connector to go into these things ?\nYep . When I looked , i they listed one microphone and that 's it\nHuh !\nas having that type of connector . But my guess is that Sony maybe uses a different number for their connector than everyone else does . And  and so\nMm - hmm . Well , let 's look at it together\nit seems  it seems really unlikely to me that there 's only one .\nand\nAnd there 's no adaptor for it ?\nYeah .\nSeems like there 'd be a  OK .\nAs I said , who knows ?\nMm - hmm .\nWho  who are we buying these from ?\nUm ,\nThat 'd be\nI have it downstairs . I don't remember off the top of my head .\nYeah . OK . Yeah . We  we can try and look at that together .\nAnd then , uh  just in terms of how you wear them  I mean , I had thought about this before . I mean , when  when  when you use a product like DragonDictate , they have a very extensive description about how to wear the microphone and so on .\nOh .\nBut I felt that in a real situation we were very seldom gonna get people to really do it and maybe it wasn't worth concentrating on . But\nWell , I think that that 's  that 's a good back - off position . That 's what I was saying  earlier , th that , you know , we are gonna get some  recordings that are imperfect and , hey , that 's life . But I  I think that it  it doesn't hurt , uh , the naturalness of the situation to try to have people  wear the microphones properly , if possible ,\nMm - hmm .\nbecause ,  um , the natural situation is really what we have with the microphones on the table .\nOh . That 's true .\nI mean , I think ,  you know , in the target applications that we 're talking about , people aren't gonna be wearing head - mounted mikes anyway .\nYeah .\nYeah .\nSo this is just for u these head - mounted mikes are just for use with research .\nMm - hmm .\nYeah .\nAnd , uh , it 's gonna make  You know , if  if An - Andreas plays around with language modeling , he 's not gonna be m wanna be messed up by people breathing into the microphone .\nRight .\nSo it 's  it 's , uh , uh\nWell , I 'll dig through the documentation to DragonDictate and ste s see if they still have the little  form .\nBut it does happen .\nYeah .\nRight ? I mean , and any\nIt 's interesting , uh , I talked to some IBM guys , uh , last January , I think , I was there . And  so people who were working on the  on their ViaVoice dictation product .\nYeah .\nAnd they said , uh , the breathing is really a  a terrible problem  for them , to  to not recognize breathing as speech .\nWow .\nSo , anything to reduce breathing is  is  is a good thing .\nYeah .\nWell , that 's the  It seemed to me when I was using Dragon that it was really microphone placement helped an  in , uh  an enormous amount .\nMm - hmm .\nSo you want it enough to the side so that when you exhale through your nose , it doesn't  the wind doesn't hit the mike .\nRight . Mm - hmm .\nAnd then , uh  Everyone 's adjusting their microphones , of course . And then just close enough so that you get good volume . So you know , wearing it right about here seems to be about the right way to do it .\nYeah .\nYeah .\nIs  Uh - huh .\nI remember when I was  when I  I  I  I used , uh , um ,  a prominent laboratory 's , uh , uh , speech recognizer about ,  uh  This was , boy , this was a while ago , this was about twelve  twelve years ago or something . And , um , they were  they were perturbed with me because I was breathing in instead of breathing out . And they had models for  they   they had Markov models for br breathing out but they didn't have them for breathing in .\nYeah .\nUh\nThat 's interesting . Well , what I wondered is whether it 's possible to have   to maybe use the display at the beginning\nYeah .\nto be able to  to judge how  how correctly  I mean , have someone do some routine whatever , and  and then see if when they 're breathing it 's showing .\nI mean , when  when it 's on , you can see it .\nI don't know if the  if it 's\nI\nYou can definitely see it .\nCan you see the breathing ?\nAbsolutely .\nCuz I\nAbsolutely .\nOh .\nYeah .\nAnd so , you know , I 've  I 've sat here and watched sometimes the breathing ,\nI\nand the bar going up and down , and I 'm thinking , I could say something , but\nI mean , I think\nI don't want to make people self - conscious . Stop breathing !\nIt  it 's going to be imperfect .\nYeah . Uh - huh .\nYou 're not gonna get it perfect . And you can do some , uh , you know , first - order thing about it , which is to have people move it , uh , uh , a away from being just directly in front of the middle\nYeah .\nGood .\nbut not too far away .\nYeah , i\nAnd then , you know , I think there 's not much  Because you can't al you know , interfere w you can't fine tune the meeting that much , I think .\nRight .\nYeah .\nIt 's sort of\nThat 's true . It just seems like i if something l simple like that can be tweaked  and the quality goes , you know , uh , dramatically up , then it might be worth  doing .\nYep . And then also  the position of the mike also . If it 's more directly , you 'll get better volume . So  so , like , yours is pretty far down  below your mouth . Yeah .\nYeah .\nBut  Mm - hmm . My  my feedback from the transcribers is he is always close to crystal clear and  and just fan fantastic to\nYeah .\nMmm , yeah .\nMm - hmm .\nI don't know why that is .\nWell , I mean , you  Yeah , of course . You 're  you 're also  uh , your volume is  is greater . But  but still , I mean , they  they say\nI 've been eating a lot .\nI it makes their  their job extremely easy .\nUh .\nYeah .\nAnd then there 's mass .\nMm - hmm .\nAnyway .\nI could say something about  about the  Well , I don't know what you wanna do . Yeah .\nAbout what ?\nAbout the transcribers or anything or  ? I don't know .\nWell , the other\nBut , uh , just to  to , um\nwhy don't we do that ?\nOne more remark , uh , concerning the SRI recognizer . Um . It is useful to transcribe and then ultimately train models for things like breath , and also laughter is very , very frequent and important to   to model .\nMm - hmm .\nSo ,\nSo ,\nif you can in your transcripts mark\nmark them ?\nmark very audible breaths and laughter especially ,\nMmm .\num\nThey are .\nOK .\nThey 're putting  Eh , so in curly brackets they put \" inhale \" or \" breath \" .\nOh , great .\nMm - hmm .\nIt  they  and then in curly brackets they say \" laughter \" . Now they 're   they 're not being  awfully precise , uh , m So they 're two types of laughter that are not being distinguished .\nMm - hmm .\nOne is  when sometimes s someone will start laughing when they 're in the middle of a sentence .\nMm - hmm .\nAnd  and then the other one is when they finish the sentence and then they laugh . So , um , I  I did s I did some double checking to look through  I mean ,  you 'd need to have extra e extra complications , like time tags indicating the beginning and ending of   of the laughing through the utterance .\nIt 's not so  I don't think it 's , um\nAnd that  and what they 're doing is in both cases just saying \" curly brackets laughing \" a after the unit .\nAs  as long as there is an indication that there was laughter somewhere between  two words  I think that 's sufficient ,\nYeah .\nGood . Oh !\nAgainst  they could do forced alignment .\nOK .\nbecause actually the recognition of laughter once you kn um  you know , is pretty good .\nYeah .\nSo as long as you can stick a  you know , a t a tag in there that  that indicates that there was laughter ,\nOh , I didn't know that .\nthat would probably be , uh , sufficient to train models .\nOK .\nThat would be a really interesting  prosodic feature ,\nThen\nYeah .\nAnd let me ask y and I gotta ask you one thing about that .\nwhen\nHmm .\nSo , um , if they laugh between two words , you  you 'd get it in between the two words .\nMm - hmm . Right .\nBut if they laugh across three or four words you  you get it after those four words . Does that matter ?\nYeah .\nWell , the thing that you  is hard to deal with is whe  when they speak while laughing . Um , and that 's , uh  I don't think that we can do very well with that .\nRight .\nSo\nYeah .\nBut , um , that 's not as frequent as just laughing between speaking ,\nOK .\nSo are  do you treat breath and laughter as phonetically , or as word models , or what ?\nso\nUh is it ?\nHuh . I  I think it 's frequent in  in the meeting .\nI think he 's right . Yeah .\nWe tried both . Uh , currently , um , we use special words . There was a  there 's actually a word for  uh , it 's not just breathing but all kinds of mouth\nMm - hmm . Mouth stuff ?\nuh , mouth  mouth stuff . And then laughter is a  is a special word .\nHow would we do that with the hybrid system ?\nSame thing .\nSo train a phone  in the neural net ?\nSame thing ? Yeah . Yeah . You ha Oh . And each of these words has a dedicated phone .\nNo\nOh , it does ?\nSo the  so the  the mouth noise , uh , word has just a single phone , um , that is for that .\nRight . So in the hybrid system we could train the net with a laughter phone and a breath sound phone .\nYeah .\nYeah . Yeah .\nI mean , it 's  it 's  it 's always the same thing .\nMm - hmm .\nRight ? I mean , you could  you could say well , let  we now think that laughter should have three sub sub  sub - units in the  the three states , uh  different states .\nYeah .\nAnd then you would have three  I mean , you know , eh , eh , it 's u\nDo whatever you want .\nAnd the  the pronun the pronunciations  the pronunciations are l are somewhat non - standard .\nYeah .\nYeah , yeah .\nNo .\nThey actually are  uh , it 's just a single , s uh , you know , a single phone in the pronunciation , but it has a self - loop on it , so it can\nTo  go on forever ?\nr can go on forever .\nAnd how do you handle it in the language model ?\nIt 's just a  it 's just a word .\nIt 's just a word in the language model .\nWe train it like any other word .\nCool .\nYeah . We also tried ,  um , absorbing these  uh , both laughter and  and actually also noise , and , um\nYeah .\nYes . OK . Anyway . We also tried absorbing that into the pause model  I mean , the  the  the model that  that matches the stuff between words .\nMm - hmm .\nAnd , um , it didn't work as well . So .\nHuh . OK .\nMm - hmm .\nCan you hand me your digit form ?\nSorry .\nI just wanna mark that you did not read digits .\nOK . Say hi for me .\nGood . You  you did get me to thinking about  I  I 'm not really sure which is more frequent , whether f f laughing  I think it may be an individual thing . Some people are more prone to laughing when they 're speaking .\nYeah .\nI was noticing that with Dan in the one that we , uh  we hand tran hand - segmented ,\nYeah . I think\nBut I can't\nYeah .\nthat  th he has these little chuckles as he talks .\nYeah . OK .\nI 'm sure it 's very individual . And  and  one thing that c that we 're not doing , of course , is we 're not claiming to , uh , get  be getting a representation of mankind in these recordings . We have  this very , very tiny sample of  of\nYeah .\nYeah .\nYeah .\nSpeech researchers ?\nUh , yeah . And   Yeah , r right .\nSpeech research .\nSo , uh , who knows . Uh  Yeah . Why don why don't we just  since we 're on this vein , why don't we just continue with , uh , what you were gonna say about the transcriptions\nOK .\nand  ?\nUm , um , the  I  I 'm really very for I 'm extremely fortunate with the people who , uh , applied and who are transcribing for us . They  are , um , um , uh really perceptive and very , um  and I 'm not just saying that cuz they might be hearing this .\nCuz they 're gonna be transcribing it in a few days .\nNo , they 're super . They 're  the they  very quick .\nOK . Turn the mikes off and let 's talk .\nYeah , I know . I am  I 'm serious . They 're just super . So I , um , e you know , I  I brought them in and , um , trained them in pairs because I think people can raise questions\nThat 's a good idea .\nyou know , i i the they think about different things and they think of different  and um , I trained them to , uh , f on about a minute or two of the one that was already transcribed . This also gives me a sense of  You know , I can  I can use that later , with reference to inter - coder reliability kind of issues . But the main thing was to get them used to the conventions and ,  you know , the idea of the  th th the size of the unit versus how long it takes to play it back so these  th sort of calibration issues . And then , um , I just set them loose and they 're  they all have e a already background in using computers . They 're , um  they 're trained in linguistics .\nGood . Oh , no . Is that good or bad ?\nThey got\nUh - huh .\nWell , they they 're very perce they 'll  So one of them said \" well , you know , he really said \" n \" , not really \" and \" ,\nYeah . Yeah .\nso what   what should I do with that ? \"\nYeah .\nAnd I said , \" well for our purposes ,\nYeah .\nI do have a convention . If it 's an  a noncanonical p \" That one , I think we  you know , with Eric 's work , I sort of figure we  we can just treat that as a variant . But I told them if  if there 's an obvious speech error , uh , like I said in one thing ,\nOK . Yes .\nand I gave my  my example , like I said , \" microfon \"  in instead of \" microphone \" . Didn't bother  I knew it when I said it . I remember s thinking \" oh , that 's not correctly pronounced \" . But it  but I thought  it 's not worth fixing cuz often when you 're speaking everybody knows what  what you mean .\nYou 'll self - repair . Yeah .\nYeah .\nBut I have a convention that if it 's obviously a noncanonical pronunciation  a speech error with  you know , wi within the realm of resolution that you can tell in this native English  American English speaker , you know that I didn't mean to say \" microfon . \" Then you 'd put a little tick at the beginning of the word ,\nYeah .\nand that just signals that , um , this is not standard , and then in curly brackets \" pron {nonvocalsound} error \" . And , um , and other than that , it 's w word level . But , you know , the fact that they noticed , you know , the \" nnn \" . \" He said \" nnn \" , not \" and \" . What shall I do with that ? \" I mean , they 're very perceptive . And  and s several of them are trained in IPA . C they really could do phonetic transcription if  if we wanted them to .\nMm - hmm . Right . Well   Well , you know , it might be something we 'd wanna do with some , uh , s small subset  of the whole thing .\nHmm . Where were they when  we needed them ?\nI think\nWe certainly wouldn't wanna do it with everything .\nAnd I 'm also thinking these people are a terrific pool . I mean , if , uh  so I  I told them that , um , we don't know if this will continue past the end of the month\nUh - huh .\nand I also  m I think they know that the data p source is limited and I may not be able to keep them employed till the end of the month even , although I hope to .\nThe other thing we could do , actually , uh , is , uh , use them for a more detailed analysis of the overlaps .\nAnd  Oh , that 'd be so super . They would be so  s so terrific .\nI mean , this was something that we were talking about .\nRight ?\nWe could get a very detailed overlap if they were willing to transcribe each meeting four or five times . Right ? One for each participant . So they could by hand\nWell , that 's one way to do it .\nYeah .\nBut I 've been saying the other thing is just go through it for the overlaps .\nYeah .\nMm - hmm , that 's right .\nRight ?\nAnd with the right in interface\nGiven that y and  and do  so instead of doing phonetic , uh , uh , transcription for the whole thing ,\nYeah .\nwhich  we know from the  Steve 's experience with the Switchboard transcription is , you know , very , very time - consuming . And   and you know , it took them I don't know how many months to do  to get four hours . And so  that hasn't been really our focus . Uh , we can consider it . But , I mean , the other thing is since we 've been spending so much time thinking about overlaps is  is maybe get a much more detailed analysis of the overlaps .\nYeah .\nMm - hmm .\nBut anyway , I 'm  I 'm open to c our consideration .\nThat 'd be great .\nHmm .\nI  I don't wanna say that by fiat .\nYeah .\nI 'm open to every consideration of  what are some other kinds of detailed analysis that would be most useful .\nMm - hmm .\nAnd , uh , uh ,\nHmm .\nI  I  I think  this year we  we actually , uh , can do it .\nOh , wonderful .\nIt 's a  we have  we have  due to @ @  variations in funding we have  we seem to be doing , uh , very well on m money for this  this year , and  next year we may have  have much less .\nIs  you mean two thousand one ?\nSo I don't wanna hire a\nCalendar year or  ?\nUh , I mean , calendar year two thousand one .\nOK .\nYeah . So it 's  uh , it 's  we don't wanna hire a bunch of people , a long - term staff ,\nFull - time . Yeah .\nMm - hmm . Yeah .\nbecause  the  the funding that we 've gotten is sort of a big chunk for this year . But  having  temporary people doing some specific thing that we need is actually a perfect match to that kind of , uh , funding .\nWonderful .\nYeah .\nAnd then school will start in  in the sixt on the sixteenth .\nSo .\nSome of them will have to cut back their hours at that point .\nYeah .\nAre they working full - time now , or  ?\nBut  {nonvocalsound}  Some of them are .\nWow .\nYeah . Well , why do I wouldn't say forty - hour weeks . No . But what I mean is  Oh , I shouldn't say it that way because {nonvocalsound} that does sound like forty - hour weeks . No . I th I  I would say they 're probably {nonvocalsound}  they don't have o they don't have other things that are taking away their time .\nI don't see how someone could do forty hours a week on transcription .\nHmm .\nBut {nonvocalsound} it 's  you can't .\nYeah . Yeah .\nNo . You 're right . It 's  i it would be too taxing . But , um , they 're putting {nonvocalsound} in a lot of\nYeah .\nAnd  and I checked them over .\nI\nI  I  I haven't checked them all , but  just spot - checking . They 're fantastic .\nI think it would be\nI remember when we were transcribing BeRP , uh , uh ,  uh , Ron Kay , uh , volunteered to  to do some of that . And , he was  the first  first stuff he did was transcribing Chuck . And he 's saying \" You  you know , I always thought Chuck spoke really well . \"\nYeah . Yeah . Well , you know , and I also thought , y Liz has this , eh , you know , and I do also , this  this interest in the types of overlaps that are involved . These people would be {nonvocalsound} great choices for doing coding of that type if we wanted ,\nWe 'd have to mark them .", "topic_id": 1, "keywords": "nonvocalsound, transcribers, transcribe, trans, linguistics", "dialogue_id": 41}, {"text": "or whatever . So , um .\nMm - hmm .\nMm - hmm .\nI think it would also be interesting to have , uh , a couple of the meetings have more than one transcriber do ,\nYeah .\ncuz I 'm curious about inter - annotator agreement .\nMm - hmm .\nYeah .\nOK . Yeah . Th - that 'd be  I think that 's a  a good idea .\nYeah .\nYou know , there 's also , the e In my mind , I think A An - Andreas was  leading to this topic , the idea that , um ,  we haven't yet seen the  the type of transcript that we get from IBM , and it may just be , you know , pristine . But on the other hand , given the lesser interface  Cuz this is , you know  we 've got a good interface , we 've got great headphones , m um\nIt could be that they will uh  theirs will end up being a kind of fir first pass or something .\nSomething like that .\nMaybe an elaborate one , cuz again they probably are gonna do these alignments , which will also clear things up .\nThat 's  that 's true . Al - although you have to s Don't you have to start with a close enough approximation {nonvocalsound} of the  of the verbal part {nonvocalsound} to be able to  ?\nWell , tha that 's  that 's debatable .\nOK .\nRight ? I mean , so the  so the argument is that if your statistical system is good  it will in fact , uh , clean things up .\nOK .\nRight ? So it it 's got its own objective criterion .\nYeah .\nAnd , uh , so in principle you could start up with something that was kind of rough  I mean , to give an example of , um , something we used to do , uh , at one point , uh , back  back when Chuck was here in early times , is we would take , um ,  da take a word and , uh , have a canonical pronunciation and , uh , if there was five phones in a word ,  you 'd break up the word ,  uh , into five equal - length pieces which is completely gross .\nWrong .\nYeah .\nRight ? I mean , th the timing is off  all over the place in just about any word .\nMm - hmm . OK .\nBut it 's O K . You start off with that and the statistical system then aligns things , and eventually you get something that doesn't really look too bad .\nOh , excellent . OK .\nSo  so I think using a  a good  aligner , um , actually can  can help a lot . Um .  But , uh , you know , they both help each other . If you have a  if you have a better starting point , then it helps the aligner . If you have a good alignment , it helps the , uh , th the human in  in taking less time to correct things .\nOK .\nSo  so\nExcellent . I guess there 's another aspect , too , and I don't know  uh , this  this is  very possibly a different , uh , topic . But , {nonvocalsound} uh , just let me say  with reference to this idea of , um ,  higher - order organization within meetings . So like in a  you know , the topics that are covered during a meeting with reference to the other , uh , uses of the data ,\nMm - hmm .\nso being able to  find where so - and - so talked about such - and - such , then , um , um  e I mean , I  I  I did sort of a   a rough  pass {nonvocalsound} on encoding , like , episode - like level things on the , uh , transcribed meeting\nMm - hmm .\nalready transcribed meeting . And I don't know if , um\nMm - hmm .\nwhere {nonvocalsound} that  i if that 's something that we wanna do with each meeting , sort of like a , um  it 's like a manifest , when you get a box full of stuff , or  or if that 's , um\nMm - hmm .\nI mean , i I  I don't know what uh , level of detail would be most useful . I don't know i if that 's something that  I should do when I look over it , or if we want someone else to do , or whatever .\nMm - hmm .\nBut this issue of the contents of the meeting in an outline form . OK .\nYeah . Meaning really isn't my thing . Um\nI think it just  whoever is interested can do that . I mean , so if someone wants to use that data\nOK .\nWe 're running a little short here .\nThat 's fine .\nWe , uh , uh , cou trying to\nI 'm finished .\neh , was  p Well , you know , the thing I 'm concerned about is we wanted to do these digits\nOh , yeah .\nand  and I haven't heard , uh , from Jose yet .\nOh , yes .\nOK . What do you want ?\nMm - hmm .\nSo\nWe could skip the digits .\nUh\nWe don't have to read digits each time .\nUh  I  I  I think it  you know , another  another bunch of digits . More data is good .\nOK .\nYeah . Sure .\nSo  so I 'd like to do that . But I think , do you , maybe , eh  ? Did you prepare some whole thing you wanted us just to see ?\nYeah . It 's  it 's prepared .\nOr what was that ? Yeah .\nOh , k Sorry .\nUh , how long a  ?\nI  I think it 's  it 's fast , because , uh , I have the results , eh , of the study of different energy without the law length . Eh , um , eh , in the  in the measurement , uh , the average , uh , dividing by the  by the , um , variance . Um , I  th i\nYeah .\nthe other , uh  the  the last w uh , meeting  eh , I don't know if you remain we have problem to  with the   with  with the parameter  with the representations of parameter , because the  the valleys and the peaks in the signal , eh , look like , eh , it doesn't follow to the  to the energy in the signal .\nYes . Right .\nAnd it was a problem , uh , with the scale .\nWith what ?\nEh , the scale .\nScale .\nScale .\nEh , and I  I change the scale and we can see the  the variance .\nOK . But the bottom line is it 's still not , uh , separating out very well .\nYeah . Yeah .\nRight ?\nThe distribution  the distribution is  is similar .\nOK . So that 's  that 's  that 's enough then . OK .\nYeah .\nNo , I mean , that there 's no point in going through all of that if that 's the bottom line , really .\nYeah .\nMm - hmm .\nYeah .\nSo , I  I think we have to start  Uh , I mean , there there 's two suggestions , really , which is , uh  what we said before is that ,\nMmm , yeah .\num , it looks like , at least that you haven't found an obvious way to normalize so that the energy is anything like a reliable , uh , indicator of the overlap .\nYeah . Yeah .\nUm , I  I 'm  I 'm still  a little f think that 's a little funny . These things l @ @ seems like there should be ,\nYeah .\nbut   but you don't want to keep , uh  keep knocking at it if it 's  if you 're not getting any  any result with that . But , I mean , the other things that we talked about is , uh ,  pitch - related things and harmonicity - related things ,\nYeah .\nso  which we thought also should be some kind of a reasonable indicator . Um  But , uh , a completely different tack on it wou is the one that was suggested , uh , by your colleagues in Spain ,\nYeah .\nwhich is to say , don't worry so much about the , uh , features .\nYeah .\nThat is to say , use , you know , as  as you 're doing with the speech , uh , nonspeech , use some very general features .\nYeah .\nYeah .\nAnd , uh , then , uh , look at it more from the aspect of modeling .\nYeah .\nYou know , have a  have a couple Markov models and  and , uh , try to indi try to determine , you know , w when is th when are you in an overlap , when are you not in an overlap .\nHmm .\nAnd let the , uh , uh , statistical system  determine what 's the right way to look at the data .\nYeah .\nI  I , um , I think it would be interesting to find individual features and put them together . I think that you 'd end up with a better system overall .\nYeah .\nBut given the limitation in time  and given the fact that Javier 's system already exists  doing this sort of thing ,\nYeah .\nuh , but , uh , its main limitation is that , again , it 's only looking at silences which would\nYeah . Yeah .\nmaybe that 's a better place to go .\nYeah .\nMm - hmm .\nSo .\nI  I  I think that , eh , the possibility , eh , can be that , eh , Thilo , eh , working , eh , with a new class , not only , eh , nonspeech and speech , but , eh , in  in  in the speech class ,\nMm - hmm . Mm - hmm .\ndividing , eh , speech , eh , of  from a speaker and overlapping , to try  to  to do , eh , eh , a fast  a fast , eh ,  experiment to  to prove that , nnn , this fea eh , general feature ,  eh , can solve the  the  the problem ,\nYeah .\nand wh what  nnn , how far is\nMaybe . Yeah .\nAnd , I  I have prepared the  the pitch tracker now .\nMm - hmm .\nAnd I hope the  the next week I will have , eh , some results and we  we will show  we will see , eh , the  the parameter  the pitch ,  eh , tracking in  with the program .\nI see .\nAnd , nnn , nnn\nHa - h have you ever looked at the , uh , uh  Javier 's , uh , speech segmenter ?\nNo . No .\nNo .\nOh . Maybe m you could , you kn uh show Thilo that .\nYeah .\nYeah . Sure .\nYeah .\nCuz again the idea is there  the limitation there again was that he was  he was only using it to look at silence as a  as a  as a  as a p putative split point between speakers .\nYeah .\nBut if you included , uh , broadened classes then  in principle maybe you can  cover the overlap cases .\nOK .\nYeah .\nYeah , but I 'm not too sure if  if we can  really represent  overlap with  with the s  detector I  I  I used up to now ,\nMmm , yeah .\nUh\nMm - hmm .\nI think with\nthe  to speech - nonspeech as\nThat 's right . But I think Javier 's\nit 's only speech or it 's  it 's  it 's nonspeech .\nAh . Yeah .\nMm - hmm .\nI think Javier 's might be able to .\nSo .\nN n\nIt doesn't have the same Gaus - uh , H M M modeling ,\nYeah .\nwhich is I think a drawback .\nOK .\nBut , uh\nWell , it 's  sort of has a simple one .\nMmm , yeah .\nDoes it ?\nRight ? It 's  it 's just  it 's just a  isn't it just a Gaussian\nYeah .\nfor each  ?\nYeah . And then  he ch you choose optimal splitting .\nHmm .\nMm - hmm .\nYeah . Oh , it doesn't have  it doesn't have any temporal , uh  ?\nMaybe I 'm misremembering , but I did not think it had a Markov\nI thought it  Yeah . I gues I guess I don't remember either . Uh . It 's been a while .\nYeah . Uh , I could have a look at it .\nJavier\nUh .\nSo .\nYou mean Ja - eh , eh , Javier program ?\nMm - hmm .\nNo , Javier di doesn't worked with , uh , a Markov\nYeah , I didn't think so .\nHe on only train\nOh , OK . So he 's just  he just computes a Gaussian over potential\nYep .\nYeah . It was only Gaussian .\nOh , I see . I see .\nAnd so I  I think it would work fine for detecting overlap .\nThis is the idea .\nAnd  and\nIt 's just , uh , that i it  he has the two - pass issue that  What he does is , as a first pass he  he  p he does , um , a guess at where the divisions might be and he overestimates . And that 's just a data reduction step , so that you 're not trying at every time interval .\nOK .\nAnd so those are the putative  places where he tries .\nYeah .\nYeah . OK .\nAnd right now he 's doing that with silence and that doesn't work with the Meeting Recorder . So if we used another method to get the first pass , I think it would probably work .\nYeah . Yeah . Sure . Yeah . Yeah , OK .\nIt 's a good method . As long as the len as long the segments are long enough .\nYeah .\nThat 's the other problem .\nSo\nO - k OK . So let me go back to what you had , though .\nYeah .\nUm .\nMm - hmm .\nThe other thing one could do is  Couldn't  I mean , it 's  So you have two categories\nYeah .\nand you have Markov models for each . Couldn't you have a third category ? So you have , uh  you have ,  uh , nonspeech , single - person speech , and multiple - person speech ?\nHe has this on his board actually . Don't you have , like those  those several different  categories on the board ?\nRight ? And then you have a Markov model for each ?\nUm  I 'm not sure . I  I thought about , uh , adding , uh , uh , another class too . But it 's not too easy , I think , the  the transition between the different class , to model them in  in the system I have now . But it  it  it could be possible , I think ,\nI see . I see .\nin principle .\nYeah , I mean , I  This is all pretty gross .\nYeah .\nI mean , the  th the reason why , uh , I was suggesting originally that we look at features is because I thought , well , we 're doing something we haven't done before ,\nYeah .\nwe should at least look at the space and understand\nYeah .\nYeah .\nIt seems like if two people  two or more people talk at once , it should get louder ,\nYeah .\nuh , and , uh , uh , there should be some discontinuity in pitch contours ,\nI had the impression .\nYeah .\nYeah .\nand , uh , there should overall be a , um , smaller proportion of the total energy that is explained by any particular harmonic  sequence in the spectrum .\nRight .\nYeah .\nSo those are all things that should be there .\nYeah .\nMm - hmm .\nSo far , um , uh , Jose has  has been  By the way , I was told I should be calling you Pepe , but\nYeah .\nby your friends , but Anyway ,\nYeah .\num , uh , the  has  has , uh , been exploring , uh , e largely the energy issue and , um , as with a lot of things , it is not  uh , like this , it 's not as simple as it sounds .\nYeah .\nAnd then there 's , you know  Is it energy ? Is it log energy ? Is it LPC residual energy ? Is it  is it   is it , uh , delta of those things ? Uh , what is it no Obviously , just a simple number   absolute number isn't gonna work . So  it should be with  compared to what ? Should there be a long window for the  normalizing factor and a short window for what you 're looking at ?\nYeah .\nOr , you know , how b short should they be ? So ,\nHmm .\nth he 's been playing around with a lot of these different things and  and so far at least has not come up with  any combination that really gave you an indicator .\nYeah .\nSo I  I still have a hunch that there 's  it 's in there some place , but it may be  given that you have a limited time here , it  it just may not be the best thing to   to  to focus on for the remaining of it .\nYeah . To overrule , yeah .\nSo pitch - related and harmonic - related , I 'm  I 'm  somewhat more hopeful for it .\nYeah . Yeah .\nBut it seems like if we just wanna get something to work ,\nYeah .\nYeah .\nthat , uh , their suggestion of  of  Th - they were suggesting going to Markov models , uh , but in addition there 's an expansion of what Javier did . And one of those things , looking at the statistical component ,\nOne .\nYeah .\neven if the features that you give it are maybe not ideal for it , it 's just sort of this general filter bank\nYeah .\nor   or cepstrum or something , um  Eee  it 's in there somewhere probably .\nBut , eh , what did you think about the possibility of using the Javier software ? Eh , I mean , the , uh  the , uh  the BIC criterion , the  the  t to train the  the Gaussian , eh , using the  the mark , eh , by hand , eh , eh , to distinguish be mmm , to train overlapping zone and speech zone . I mean , eh ,  I  I  I think that an interesting , eh , experiment , eh , could be , th eh , to prove that , mmm , if s we suppose that , eh , the  the first step   I mean , the  the classifier what were the classifier from Javier or classifier from Thilo ? W What happen with the second step ? I  I mean , what  what happen with the , eh  the , uh , clu the , uh  the clu the clustering process ?\nMm - hmm .\nUsing the  the Gaussian .\nYou mean Javier 's ?\nYeah .\nWhat do you mean ?\nI  I mean , that is  is enough  is enough , eh , to work well , eh , to , eh , separate or to distinguish , eh , between overlapping zone and , eh , speaker zone ? Because th  if  if we  if we , eh , nnn , develop an classifier  and the second step doesn't work  well , eh , we have  another problem .\nI  Yeah . I had tried doing it by hand at one point with a very short sample ,\nN\nand it worked pretty well , but I haven't worked with it a lot . So what I d I d I took a hand - segmented sample\nNnn , yeah .\nand I added ten times the amount of numbers at random ,\nYeah .\nand it did pick out pretty good boundaries .\nOh . Yeah . But is  is  if\nBut this was just very anecdotal sort of thing .\nBut it 's possible with my segmentation by hand  that we have information about the  the overlapping ,\nRight . So if we  if we fed the hand - segmentation to Javier 's and it doesn't work , then we know something 's wrong .\nuh  Yeah . The  N n Yeah . No . The demonstration by hand . Segmentation by hand I  I  I think is the fast experiment .\nYeah . I think that 's probably worthwhile doing .\nUh , we can prove that the\nUh - huh .\nWhether it 'll work or not .\nthis kind o emph emphasises parameter and Gaussian\nYeah .\nYeah .\nYep . Y do you know where his software is ? Have you used it at all ?\nI yeah have . I have .\nOK .\nSo . I  I have as well , so if you need  need help let me know .\nOK .\nLet 's read some digits .\nOK . uuh\nMm - hmm .\nAnd we are", "topic_id": 2, "keywords": "transcript, transcribed, annotator, alignments, ibm", "dialogue_id": 41}, {"text": "Yeah , I think I got my mike on . OK . Let 's see .\nOK . Ami , do yours then we 'll open it and I think it 'll be enough .\nMmm  Doesn't , uh  It should be the other way . Yeah , now it 's on .\nRight . OK .\nOK . So , we all switched on ?\nWe are all switched on , yeah .\nAlright . Anyway . So , uh , before we get started with the , uh , technical part , I just want to review what I think is happening with the  our data collection .\nWe are all switched on .\nSo   Uh , probably after today ,  that shouldn't come up in this meeting . Th - this  this is s should be im it isn't  There 's another thing going on of gathering data , and that 's pretty much independent of this . But , uh , I just want to make sure we 're all together on this . What we think is gonna happen is that , uh , in parallel starting about now  we 're gonna get Fey  to , where you 're working with me and Robert , draft a note that we 're gonna send out to various CogSci c and other classes saying , \" here 's an opportunity to be a subject . Contact Fey . \" And then there 'll be a certain number of um , hours during the week which she will be available and we 'll bring in people . Uh , roughly how many , Robert ? We d Do we know ?\nUm , fifty was our  sort of our first\nOK . So , we 're looking for a total of fifty people , not necessarily by any means all students but we 'll s we 'll start with  with that . In parallel with that , we 're gonna need to actually do the script . And , so , I guess there 's a plan to have a meeting Friday afternoon Uh , with  uh , Jane , and maybe Liz and whoever , on actually getting the script worked out . But what I 'd like to do , if it 's O K ,  is to s to , as I say , start the recruiting in parallel and possibly start running subjects next week . The week after that 's Spring Break , and maybe we 'll look for them  some subjects next door\nYeah .\nor  i\nYeah . Also , Fey will not be here during spring break .\nOh , OK , then we won't do it .\nSo .\nOK . So that 's easy . Um . So , is  Is that make sense to everybody ?\nYeah . Also , um , F  both Fey and I will , um ,  do something of which I may , eh  kindly ask you to  to do the same thing , which is we gonna check out our social infrastructures for possible subjects . Meaning ,  um , kid children 's gymnastic classes , pre - school parents and so forth . They also sometimes have flexible schedules . So , if you happen to be sort of in a non - student social setting , and you know people who may be interested in being subjects  We also considered using the Berkeley High School and their teachers , maybe , and get them interested in stuff .\nThat 's a good idea .\nAnd , um . So that 's as far as our brainstorming was concerned .\nOh , yeah . The high school 's a great idea .\nSo . But I  I will just make a first draft of the , uh , note , the \" write - up \" note , send it to you and Fey and then\nAnd why don't you also copy Jane on it ?\nAnd , um , Are we  Have we concurred that , uh , these  these forms are sufficient for us , and necessary ?\nUh , th I think they 're necessary . This  The permission form .\nMmm .\nUh , there has to be one ,\nNuh . N .\nand I think we 're just gonna use it as it is , and  Um\nN . You happy with that ?\nWell , yeah . There 's one tricky part about , um , they have the right um I The last paragraph  \" if you agree to participate you have the opportunity to have anything excised which you would prefer not to have included in the data set . \" OK ? Now that , we had to be included for this other one which might have , uh , meetings , you know , about something .\nMm - hmm .\nIn this case , it doesn't really make sense . Um , so what I 'd like to do is also have our subjects sign a waiver saying \" I don't want to see the final transcript \" .\nMm - hmm .\nAnd if they don't  If they say \" no , I 'm not willing to sign that \" , then we 'll show them the final transcript . But , um .\nYep . Makes sense .\nThat , uh  yeah , so we might actually , um S i Jane may say that , \" you know , you can't do this \" , uh , \" on the same form , we need a separate form . \" But anyway . I 'd  I 'd  I 'd like to , e e um , add an a little thi eh  a thing for them to initial , saying \" nah , do I don't want to see the final transcript . \"\nMm - hmm .\nBut other than that , that 's one 's been approved , this really is the same project , uh , rec you know . And so forth . So I think we just go with it .\nYeah . Yeah . OK . So much for the data , except that with Munich everything is fine now . They 're gonna  transcribe . They 're also gonna translate the , uh , German data from the TV and cinema stuff for Andreas . So . They 're  they all seem to be happy now ,  with that . So . w c sh should we move on to the technical sides ?", "topic_id": 0, "keywords": "gathering, meeting, brainstorming, meetings, plan", "dialogue_id": 42}, {"text": "Yep .\nWell I guess the good  good news of last week was the parser . So , um Bhaskara and I started working on the   the parser . Then Bhaskara went to class and once he came back , um ,  it was finished . So . It , uh  I didn't measure it , but it was about an hour and ten minutes .\nYep .\nAnd , um  and now it 's  We have a complete English parser that does everything the German parser does .\nSomething like that .\nWhich is  not a lot . But\nThat 's the , uh , point .\nThe  uh , that 's not a lot .\nOK .\nYes .\nRight .\nAnd um .\nWhat did you end up having to do ? I mean , wha Was there anything  interesting about it at all ?\nWell , if you , eh\nWe 'll show you .\nYeah , we can show us ,\nor are we gonna see that ?\nright ?\nWell , w w We d The first we did is we  we tried to  to do  change the  the \" laufen \" into \" run \" ,  or \" running \" ,  or \" runs \" .\nYep .\nAnd we noticed that whatever we tried to do , it no effect .\nMm - hmm .\nAnd we were puzzled .\nOK .\nAnd , uh , the reason was that the parser i c completely ignores the verb .\nMm - hmm .\nSo this sentence  sentence is  parses the p the same output ,\nHmm . Interesting parser property .\num , even if you leave out , um , all  all of this .\nI see . Yeah .\nSo it 's basically feature film and TV .\nToday\nThat 's what you need .\nOK .\nIf  if you 'd add  add Today and Evening , it 'll add Time or not .\nAnd the  t and the time , right ?\nSo it  i it does look at that .\nOK .\nBut all the rest is p simply frosting on the cake , and it 's optional for that parser .\nTrue .\nSo , you can sho You  you  Are  are you gonna show us the little templates ?\nAnd\nS\nYeah . We ar we can sh er  I can show you the templates . I  I also have it running here ,\nThe former end g \" Oh , I see . Uh - huh .\nso if I  do this now , um ,  you can see that it parsed the wonderful English sentence , \" Which films are on the cinema today  evening ? \" But , um .\nWell , that sounds\nUh do don't worry about it .\nNo i\nIt could be \" this evening , which  which films are on the cinema \" , or \" running in the cinema , which  \" uh , \" today evening \" , uh i \" Is anything happening in the cinema this evening ? \"\nOK . OK . Key words , e basically .\nWell\nGe - elaborate , or , more or less ,  uh\nActually , it 's a little tricky , in that there 's some allowable German orders which aren't allowable English orders and so forth . And it is order - based . So it  it  Isn't it ?\nNo .\nNo .\nOh . So it  it doe I it  These  u these optional elements ,\nIt is not\nit 's  it 's actually a set , not a sequence ?\nYeah . We were  I was afraid that , um\nOh !\nSo it really is key word matching , basically .\nReally a se\nUm .\ne yeah . Mm - hmm .\nOh , wow .\nUm , I mean , these sentences are just silly .\nHmm .\nI mean , uh , d these were not the ones we  we actually did it . Um . What 's an idiomatic of phrasing this ? Which films are  showing ?\nAre pl playing at the cinema ?\nplaying ?\nYeah .\nTonight ?\nI changed that file , actually , where it 's on my account .\nThis  this evening ?\nActually , you would say , \" which films are on tonight ? \"\nYou want to get it ? Or  is  di was it easy to get it ?\nUm . I have no net here .\nOh , OK .\nDo I ?\nOK . So . Wonderful parse , same thing . Um .\nRight .\nExcept that we d w we don't have this , uh , time information here now , which is , um  Oh . This  are the reserve . Anyways .  So . Um . These are the  sort of the ten different sentence types that the uh   the parser was able to do . And it still is , now in English .\nYeah .\nMm - hmm .\nAnd , um  Sorry . And , um you have already to make it a little bit more elaborate , right ?\nYeah , I mean I changed those sentences to make it , uh , more , uh , idiomatic . And , of course , you can have i many variations in those sentences , they will still parse fine . So , in a sense it 's pretty broad .\nOK .\nOK . So , if you want to look at the templates ,   they 're conveniently located in a file , \" template \" . Um , and this is what I had to do . I had to change , @ @  \" Spielfilm \" to \" film \" , uh , \" Film \" to \" movie \" , cinem \" Kino \" to \" cinema \"  to \" today \"  heu \" heute \" to \" today \" ,\nHuh .\nevening  \" Abend \" to \" evening \"\nCapitalized as well\nHmm .\nAnd , um .\nY i\nOne thing I was wondering , was , those functions there , are those things that modify the M - three - L basically ?\nYep .\nOK .\nAnd that 's  that 's the next step ,\np\nbut we 'll get to that in a second .\nOh .\nAnd so this means , um , \" this \" and \" see \" are not optional . \" Want I like \" is all maybe in there , but may also not be in there .\nSo  so , the point is , if it says \" this \" and \" see \" , it also will work in \" see \" and \" this \" ?\nS\nIn the other order ?\nYeah .\nwith those two key words ?\nShould we try it ?\n\" This is the one I want to see \" or whatever .\nOK . \" Action watch \" ,\nHmm .\nwhatever . Nothing was specialfi specified . except that it has some references to audio - visual media here .\nAV medium .\nWhere it gets that from\nYeah .\nIt 's correct , but I don't know where it gets it from .\n\" See \" .\nOh , \" see \" . Yeah . Yeah . Yep . OK .\nI mean it 's sort of\nAnd \" see this \"  is exactly the same thing .\nOK , so it is set - based . Alright .\nOne thing I was wondering was ,  those percentage signs , right ? So , I mean , why do we even have them ?\nYep .\nBecause  if you didn't have them\nUh , I 'll tell you why . Because it gives a  you a score .\nMm - hmm .\nAnd the value of the score is , v I assume , I guess , the more of these optional things that are actually in there , the higher the r score  it is .\nOh . OK . So that 's the main purpose . Alright .\nIt 's a match .\nRight .\nMm - hmm .\nOK .\nSo we  we shouldn't belittle it too much . It 's doing something , some things , and it 's very flexible . I 've just tried to\nMm - hmm .\nbe nice .\nRight .\nNo , no . Fine .\nRight  Yeah .\nYeah , yeah , yeah , flexible it is .\nBut\nOK .  Um , let 's hope that the generation will not be more difficult , even though the generator is a little bit more complex . Uh but we 'll  Mmm , that means we may need two hours and twenty minutes rather than an hour ten minutes ,\nAlright .\nI hope .\nRight .", "topic_id": 1, "keywords": "parses, parser, parsed, bhaskara, parse", "dialogue_id": 42}, {"text": "And the next thing I would like to be able to do , and it seems like this would not be too difficult either , is  to say , \" OK let 's now pretend we actually wanted to not only change the   the mapping of  of , uh , words to the M - three - L but we also wanted to change  add a new sentence type and and make up some  some new M - three - L  s \"\nYep . So That 'd be great . It would be a good exercise to just see  whether one can get that to run .\nSee th Mm - hmm .  Yep . And , um ,\nSo , that 's\nthat 's  shouldn't be too tough .\nFine , yeah . Yeah , so where are those  those functions \" Action \" , \" Goodbye \" , and so on , right ? Are they actually , um ,  Are they going to be called ? Um , are they present in the code for the parser ?\nYeah . I think what it does , it i i it does something sort of fancy . It loads um  It has these style sheets and also the , um , schemata . So what it probably does , is it takes the , uh ,  um  Is this where it is ? This is already the XML stuff ? This is where it takes its own , um , syntax , and converts it somehow . Um . Where is the uh\nWhat are you looking for ?\nUm , where it actually produces the  the XML out of the , uh , parsed  stuff .\nOh , OK .\nNo , this is not it . Uh . I can't find it now . You mean , where the  where the act how the action \" Goodbye \" maps into something\nYeah .\nYeah , where are those constructors defined ?\nOh .\nNope .\nNo , that 's not it .\nYeah . This is sort of what happens . This is what you would need to  to change  to get the , uh , XML changed . So when it encounts encounters \" Day \" ,  it will , uh , activate those h classes in the  in the XML stuff But , um  I saw those actions  uh , the \" Goodbye \" stuff somewhere . Hmm , hmm , hmm , hmm , hmm .\nGrep for it ?\nYeah . Let 's do that . Oh .\nMmm . M - three - L dot DTD ?\nYep .\nThat 's just a  specification for the XML format .\nYep . Well , we 'll find that out . So whatever  n this does  I mean this is , basically , looks l to me like a function call , right ?\nHmm ? Oh , yeah .\nAnd , um  So , whenever it  it encounters \" Goodbye \" , which we can make it do in a second , here\nThat function automatically generates an initialized XML structure ?\nI\nI think each of those functions act on the current XML structure , and change it in some way , for example , by adding a  a l a field to it , or something .\ny Yeah . They also seem to affect state ,\nMm - hmm .\ncause some of them  there were other actions uh , that  that s seemed to step  state variables somewhere ,\nRight .\nlike the n s \" Discourse Status Confirm \" . OK . So that 's going to be a call on the discourse\nYep .\nand  confirm that it 's\nW we Mm - hmm\nOh , you mean that 's not going to actually modify the tree ,\nI think that 's right .\ne\nbut it 's going to change the event .\nI think it 's actually  That looks like it 's state modification .\nOh . Oh .\ne mmm Um , well i There is a feature called \" Discourse - Status \" ,\nWhen there 's a feature .\nYeah .\nAnd so whenever I just say , \" Write \" , it will  it will put this in here .\nOh , so it always just  Is it  So it  Well , go back , then , cuz it may be that all those th things , while they look like function calls , are just a way of adding exactly that to the XML .\nh Yep .\nUh - huh ! I 'm not  I 'm not sure .\nSo , this\ne I 'm not sure  e that\nUm  well , we  we 'll see , when we say , let 's test something , \" Goodbye \" , causes it to c to create basically an \" Action Goodbye - End - Action \" .\nRight .\nWhich is a means of telling the system to shut down .\nRight .\nNow , if we know that \" Write \" produces a \" Feature Discourse - Status Confirm Discourse - Status \" . So if I now say \" Write , Goodbye , \" it should do that . It sho it creates this ,\nMm - hmm .\nRight .\n\" Confirm Goodbye \" .\nYep .\nRight there . But there is some kind of function call , because how does it know to put Goodbye in Content , but , uh , Confirm in Features ?\nOh . It d it  n That 's because\nSo So , it 's not just that it 's adding that field .\nRight .\nIt 's\nAbsolutely . Good point .\nOK .\nIt 's  it 's  the  It 's under what sub - type you 're doing it . Yeah .\nMm - hmm . Yeah .\nIt 's mystery functions .\nWell , sometimes it m Sometimes , i\nWell , they 're defined somewhere , presumably .\nYeah , each is  S so that 's funny .\nWhen it\nYou bury the s the state in the function Alright .\nit\nWell , it just automatically initializes things that are common , right ?\nUh\nSo it 's just a shorthand .\nYeah .\nFor example  Oh , this is German . Sorry . e So , now , this , it cannot do anymore . Nothing comes out of here .\nA \" not a number \" is a value . Awesome .\nSo , it doesn't speak German anymore , but it does speak English . And there is , here , a reference  So , this tells us that whatever is  has the ID \" zero \" is referenced here  by @ @  the restriction seed and this is exa \" I want  \" What was the sentence ?\n\" I want two seats here . \"\n\" need two seats here . \" Nuh . \" And where is it playing ? \" There should also be a reference to something , maybe . Our d This is re um Mmm . Here , we change  and so , we  Here we add something to the Discourse - Status , that the user wants to change something that was sort of done before And , uh  and that , whatever is being changed has something to do with the cinema .\nSo then , whatever takes this M - three - L is what actually changes the state , not the  Yeah , OK .\nNo , right , the Discourse Maintainer ,\nYeah .\nyeah . I see . And it  and it runs around looking for Discourse Status tags , and doing whatever it does with them . And other people ignore those tags . Alright . So , yeah . I definitely think it 's   It 's worth the exercise of trying to actually add something that isn't there .\nHmm ?\nUh Disc\nSort of get a complete understanding of the whole thing .\nYeah , a kid understanding what 's going on . Then the next thing we talked about is actually ,  um , figuring out how to add our own tags , and stuff like that .\nOK . Point number two . I got the , uh , M - three - L for the routes today . Uh , so I got some more . This is sort of the uh ,  um , Hmm . Interesting . It 's just going up , it 's not going back down . So , this is  um , what I got today is  the  the new  um  M - three - L for um ,   the Maps ,\nYep .\nuh , and with some examples  So , this is the XML and this is sort of what it will look like later on , even though it  you can't see it on  on this resolution . And this is what it  sort of is the  the structure of Map requests , um also not very interesting , and here is the more interesting stuff for us , is the routes , route elements , and , again , as we thought it 's really simple . This is sort of the , uh ,   um ,  parameters . We have @ @  simple \" from objects \" and \" to objects \" and so forth , points of interest along the way  And , um , I asked them whether or not we could , um  First of all , I was little bit  It seemed to me that this m way of doing it is sort of a stack a step backwards from the way we 've done it before . t It seems to me that some notions were missing .\nS\nSo these are  these are\nSo these are  these are your friends back at EML .\nYep . Who are doing this .\nSo this is not a complicated negotiation . There 's  there 's not seven committees , or anything , right ?\nNo . No , this is very straightforward .\nGreat . So this is just trying to  It 's a design thing , not a political thing . Once we 've  eh  We can just sort of agree on what oughta be done .\nYeah .\nGood .\nExactly . And , um  And , uh  However , the , uh  e So that you understand , it is really simple . Uh  You  you have a route , and you cut it up in different pieces . And every  every element of that e r r f of that  Every segment we call a \" route element \" . And so , from A to B we cut up in three different steps , and every step has a \" from object \" where you start , a \" to object \" where y where  you sort of end , and some points of interest along the way . What w I was sort of missing here , and uh , maybe it was just me being too stupid , is ,  I didn't sort of get the  the notion of the global goal of the whole route . Really , s was not straightforward visibly for me . And some other stuff . And I  suggested that they should n be  k uh , kind enough to do s two things for us , is one , um ,   Also allocating , uh , some tags for our Action Schema Enter - Vista - Approach , and  And also , um , since you had suggested that  that , um , we figure out if we ever , for a demo reason , wanted to shortcut directly to the g GIS and the Planner , of how we can do it . Now , what 's the state of the art of getting to entrances , um , what 's the syntax for that , how get getting to  vista points and calculating those on the spot . And the Approach mode , anyhow , is the default . That 's all they do it these days . Wherever you 'll find a route planner it n does nothing but get to the closest point where the street network is  at minimal distance to the geometric center .\nMm - hmm .\nSo .\nSo , well , let  Now , this is important . Let , uh  I want a a Again , outside of m almost managerial point , um  You 're in the midst of this , so you know better . But it seems to me it 's probably a good idea to li uh  minimize the number of uh , change requests we make of them . So it seemed to me , what we ought to do is get our story together . OK ? And think about it some , internally , before asking them to make changes .\nMm - hmm .\nOh . Does this  does this make sense to you guys ? It  I mean you 're  you 're doing the  the interaction but it seemed to me that  what we ought to do is come up with a  uh , something where you , um  And I  I don't know who 's mok working most closely on it . Probably Johno . OK . Uh , take what they have , send it to everybody saying \" this is what they have , this is what we think we should add \" , OK ? and then have a d a  an iteration within our group saying \" Hmm , well  \" OK ? And get our best idea of what we should add .\nMm - hmm .\nAnd then go back to them . Is i or , I don't know does this make sense to you ? Or\nYeah .  Especially if we want  Sort of , what I  my feeling was eh we  we sort of reserved something that has a r eh an OK label . That 's  th that was my th first sort of step .\nMm - hmm .\nI w No matter how we want to call it ,  this is sort of our playground .\nRight .\nAnd if we get something in there that is a structure elaborate and  and  and  and  and complex enough to  to  to maybe enable a whole simulation , one of these days , that would be  u the  the perfect goal .\nRight . That 's right . So . So , Yeah . The problem isn't the short ra range optimization . It 's the sort of  o one or two year kind of thing . OK . What are the thl class of things we think we might try to do in a year or two ? How  how would we try to characterize those and what do we want to request now  that 's leave enough space to do all that stuff ?\nMm - hmm .\nRight .\nYep .\nAnd that re that requires some thought .\nYep .\nAnd  so that sounds like a great thing to do  as the priority item um , as soon as we can do it .\nYep .", "topic_id": 2, "keywords": "parser, syntax, parsed, actions, xml", "dialogue_id": 42}, {"text": "So y so you guys will  send to the rest of us um   a version of um , this , and  the  uh , description\nWith sugge yeah , suggested improvements and\nWell b Yeah . So , the  the  uh  Not everyone uh , reads German , so if you 'd um\nMmm .\ntu uh , tur change the description to , uh , English\nOK .\nand , um , Then  then , yeah . Then , with some sug s suggestions about where  where do we go from here ?\nOK .\nUh , this  and this , of course , was just the   action end . Uh , at some point we 're going to have to worry about the language end . But for the moment just  uh , t for this class of  of things , we might want to try to encompass . And\nThen the scope of this is beyond  Approach and Vis - or Vista . Yeah , yeah .\nOh , yeah , yeah yeah yeah . This is  this is everything that  that , um ,   you know , um  we might want to do in the next couple years .\nYeah , yeah . So what would\nHmm ?\nOK .\nWe don't  I mean , that 's an issue . We don't know what , entirely .\nUh , yeah . but I 'm just  But the  Yeah , OK . So I just  this XML stuff here just has to do with Source - Path - Goal type stuff , in terms of traveling through Heidelberg .\nHmm .\nOr travel , specifically .\nRight .\nSo , but this O Is the domain greater than that ?\nNo .\nOK .\nI think  I think the i the idea is  that  Oh . It 's beyond Source - Path - Goal , but I think we don't need to get beyond it @ @   tourists in Heidelberg .\nOK .\nIt seems to me we can get  all the complexity we want in actions and in language without going outside of tourists in Heidelberg . OK ? But you know , i depending on what people are interested in , one could have ,  uh , tours , one could have  um , explanations of why something is  is , you know , why  why was this done , or  I mean , no  there 's no end to the complexity you can build into the   uh , what a tourist in Heidelberg might ask .\nMmm .\nSo , at least  unless somebody else wants t to suggest otherwise I think  the general domain we don't have t to uh , broaden . That is , tourists in Heidelberg . And if there 's something somebody comes up with that can't be done that way , then , sure . W we 'll  we 'll look at that , but  uh I 'd be s I I 'd be surprised at  if there 's any   important issue that  that  And , um  I mean if  if you want to  uh , push us into reference problems , that would be great .\nOK .\nOK , so this is  his specialty is  reference ,\nMm - hmm .\nand  you know , what  what are these things referring to ? Not only  anaphora , but , uh , more generally the , uh  this whole issue of , uh , referring expressions , and , what is it that they 're actually dealing with in the world ?\nMm - hmm .\nAnd , again , this is li in the databa this is also pretty well formed because there is an ontology , and the database , and stuff . So it isn't like ,  um , you know , the Evening Star or stuff like that .\nRight .\nI i it  All the entities do have concrete reference . Although th the  To get at them from a language may not be trivial .\nRight .\nThere aren't really deep mysteries about um , what w what things the system knows about .\nRight . Right . And you have both proper names and descriptions\nAll those things .\nand y and you can ask for it .\nYeah . You have proper names , and descriptions .\nMm - hmm .\nRight .\nAnd a l and a lot  and  and anaphora , and pronouns ,\nNuh .\nOK . Right .\nand  all those things .\nRight .\nNow , we hav the  the whole  Unfortunately , the whole database is , uh ,  in German . We have just commissioned someone to translate some bits of it , IE the e the shortest k the  the more general descriptions of all the objects and , um , persons and events . So , it 's a relational database with persons , events ,  and , um , objects . And it 's  it 's quite , um ,  there . But did y I  uh  I think there will be great because the reference problem really is not trivial , even if you have such a g well - defined world .\nHe knows .\nAh - he you are not , uh , throwing uh , uh , carrying owls to Athens .\nCould you give me an example of a reference problem ? so  so l I can make it more concrete ?\nWell   How do I get to the Powder - Tower ? We sort of t think that our bit in this problem is interesting , but , just to get from Powder - Tower to an object I ID in a database is also not really trivial .\nOr  or if you take something even more scary , um , \" how do I get to the third building after the Tower ? the Ple - Powder - Tower ? \"\nMmm .\nUh , you need some mechanism for\nYeah . Or , you know , the church across from City Hall , or\nOr the re the restaurant where they wear lederhosen ?\nOr the\nRight .\nOr is that\nYeah , that would be fine .\nOK .\nRight .\nYeah .\nO or  or tower , or this tower , or that building , or\nRight .\nUniquely .\nhmm ?\nOK . Trying to\nOr you can say \" how  \" you know , \" how do I get back ? \"\nYeah , yeah .\nOK . And , again , it 's just a question of which of these things , uh , people want to  dive into . What , uh , I think I 'm gonna try to do , and I guess , pwww ! let 's say that by the end of spring break , I 'll try to come up with some  general story about , um , construction grammar , and what constructions we 'd use and how all this might fit together . There 's this whole framework problem that I 'm feeling really uncomfortable about . And I haven't had a chance to  think about it seriously . But I  I want to  I want to do that early , rather than late . And you and I will probably have to talk about this some .\nu u u u That 's what strikes me , that we sort of  the de g uh , small  Something , uh , maybe we should address one of these days , is to   That most of the work people actually always do is look at some statements , and  and analyze those . Whether it 's abstracts or newspapers and stuff like this .\nHmm .\nBut the whole  i is it  is it really relevant that we are dealing mostly with , sort of , questions ?\nOh , yeah ?\nUh , you know\nWell , I mean yeah , I d\nAnd this is  It seems to me that we should maybe at least spend a session or  or brainstorm a little bit about whether that l this is special case in that sense .\nMm - hmm .\nUm , I don't know . You know  Did we ever find m metaphorical use in  in questions in  in that sense , really ?\nYeah .\nYou will .\nAnd how soon ,\nOh , yeah .\nI don't know .\nI mean , uh , we could take all the standard metaphor examples and make question versions of them . OK .\n\" Who got kicked out of France ? \"\nMuh\nYeah , or , you know . \" Wh - why is he  why is he pushing for promotion ? \"\nNuh .\nRight .\nor , \" who 's pushing proof \"\nNuh .\ner , just pick  pick any of them and just  do the  eh\nMm - hmm .\nSo I don't  I don't think ,  uh , it 's at all difficult  Uh , to convert them to question forms that really exist and people say all the time , um  And  sort of  we don't know how to handle them , too . Right ? I mean , it 's  I d It  We don't know how to handle the declarative forms , @ @  really , and , then , the interrogative forms , ah - oh . Uh . Yeah .\nOoo !\nNancy , it looked like you were s\nOh . it 's just that  that the goals are g very different to cases  So we had this problem last year when we first thought about this domain , actually , was that  most of the things we talked about are our story understanding .\nRight .\nUh , we 're gonna have a short discourse and  the person talking is trying to , I don't know , give you a statement and tell you something . And here ,  it 's th\nHelp you create a mental model , blah - blah - blah . Yeah .\nYea - eh  y Yeah , I guess so .\nYes .\nAnd then here , y you are j uh , the person is getting information and they or may not be following some larger plan ,  you know , that we have to recognize or , you know , infer . And th th the  their discourse patterns probably {nonvocalsound} don't follo follow quite as many  logical connec\nRight . No , I think that 's one of things that 's interesting , is  is in this sort of over - arching story we  we worked it out for th as you say , this  the storytelling scenario .\nYeah . Mm - hmm .\nAnd I think it 's really worth thinking through   what it looks like .\nMm - hmm .\nWhat is the simspec mean , et cetera .\nMm - hmm . M Right . Cuz for a while we were thinking , \" well , how can we change the ,  um , data to sort of illicit tha  illicit , um , actions that are more like what we are used to ? \" But obviously we would rather , you know , try to figure out what 's  what 's , you know\nWell , I don't know . I mean , maybe  maybe that 's what we 'll do is  is s u e We can do anything we want with it . I mean , once we have fulfilled these requirements ,\nYep . Mmm  Mm - hmm . Mm - hmm .\nOK , and the one for next uh , summer is just half done and then the other half is this , um , \" generation thing \" which we think isn't much different .\nMm - hmm .\nSo once that 's done , then all the rest of it is , uh , sort of , you know , what we want to do for the research . And we can  w we can do all sorts of things that don't fit into their framework at all . Th - there 's no reason why we 're c we 're constrained to do that .\nMm - hmm .\nIf we can use all the , uh , execution engines , then we can ,  you know , really {nonvocalsound} try things that would be too  too much pain to do ourselves .\nMm - hmm .\nBut there 's no obligation on any of this . So , if we want to turn it into u understan standing stories about Heidelberg , we can do that . I mean , that would just be a t a um\nOr , as a matter of fact , we need   and if we if we ' r eh  take a ten year perspective , we need to do that , because w e w a Assuming we have this , um , we we ta in that case we actually do have these wonderful stories , and historical anecdotes ,\nYeah .\nand knights jumping out of windows ,\nMmm .\nand - and - and    tons of stuff . So , th the database is huge , and if we want to answer a question on that , we actually have to go one step before that , and understand that . In order to e do sensible information extraction .\nMm - hmm . Yeah . Mm - hmm .\nYou might , yeah .\nAnd so , um , this has been a  a  a Deep Map research issue that was  is  is part of the unresolved , and to - do 's , and something for the future , is  how can we sort of run our our text , our content , through a machine  that will enable us , later , to retrieve or answer e questions more sensibly ?\nMwa Mm - hmm .\nMm - hmm . Mmm .\nRight . Anyway . S Who 's going ?\nSo , uh  So , uh , I was just going to ask , um ,  so , what is the  the basic thing that  that you are , um , obligated to do , um , uh , by the summer before w uh y c we can move\nAh ! OK . So  eh  Yeah . So , what happened is , there 's this , eh , uh  Robert was describing the  There 's two packages there 's a , uh , quote parser , there 's a particular piece  of this big system , which , in German , uh , takes these t sentence templates and produces XML structures . And one of our jobs was to make the English equivalent of that .\nRight .\nThat , these guys did in a  in a day .\nRight . Right .\nThe other thing is , at the other end , roughly at the same level , there 's something that takes , uh , X M L structures , produces an output XML structure which is instructions for the generator .\nRight .\nOK ? And then there 's a language generator , and then after that a s a synthesizer that goes from an XML structure to , uh , language generation , to actual specifications for a synthesizer . Eh , but again , there 's one module in which there 's one piece  that we have to convert to English .\nRight . Right . Got it .\nIs that  OK . And that  But as I say , this is  all along was viewed as a kind of   a m a minor thing , necessary , but  but not\nRight .\nOK ?\nRight .\nAnd much more interesting is the fact that ,  as part of doing this , we  we are , you know , inheriting this system that does all sort of these other  things .\nThat 's great ! Right .\nNot precisely what we want , and that 's   that 's wh where it  it gets difficult . And I  I don't pretend to understand yet what I think we really ought to do .\nOK . So , e enough of that , but I , uh , um , mmm , the e sort of , Johno and I will take up that responsibility , and , um , get a first draft of that . Now , we have um just , I think two more short things .\nOK .\nUm , y you guys sort of started fighting , uh , on the Bayes - net \" Noisy - OR \" front ?\nHmm . Yeah , I thought I should , um , talk a little bit about that , because that might be a good , uh , sort of architecture to have , in general for , uh , problems with ,  you know , multiple inputs to a node .\nGood ! OK . Good . And what 's the other one ? so that  just we know what the d agenda is ?\nUm , the Wu paper , I think maybe\nOh , yeah . I 've got a couple new Wu papers as well . Uh , so I  I 've been in contact with Wu , so , probably let 's put that off till I  I  till I understand better ,  uh , what he 's doing . It 's just a little embarrassing cause all this was in his thesis and I was on his thesis committee , and , so ,  I r really knew this at one time .\nUgh .\nBut , I  I  It 's not only uh Is  Part of what I haven't figured out yet is  is how all this goes together . So I 'll dig up some more stuff from Dekai . And  so why don't we just do the , uh\nOK . So  should I  Is there a white board here that I can use ?\nYeah . You could\nUh\nYeah .\nsquealing sound ?\nOr shall I just use this ?\nIt 's probably just as easy . I\nYeah .\nYeah .\nYou can put the microphone in your pocket .\nHey !\nI was envying you and your pocket cause I don't have one .\nIt was a quick one , huh ?\nThat 's why they invented \" pocket T 's \" .\nexactly\nThey have clips !\nYeah .\nHuh .\nSo , um   Recall that , uh , we want to have this kind of structure in our Bayes - nets . Namely , that , um    You have these nodes that have several bands , right ? So  Does I mean , they sort of  the typical example is that , um , these are all a bunch of cues for something , and this is a certain effect that we 'd like to conclude . So , uh  Like , let 's just look at the case when , um , this is actually the  the final action , right ? So this is like , uh ,  you know , touch ,\nY\nor\nE - EVA\nSorry . Uh\nYeah , E -  EVA , right ?\nYeah .\nEnter , V View , Approach , right ?\nW what was this ? It  i i i ehhh ,  i ehhh .\nWri - write it out for for\nSo , this is  Yeah . Enter ,\nI mean\nView , Approach .\nOK . Right .\nRight . So , I mean , we 'd like to  take all these various cues , right ?\nLike the army .\nSo this one might be , say , uh\nNew terminology ?\nYeah .\nHmm ?\nWell , let me pick a random one\nI haven't heard that before .\nand say , uh  I don't know , it could be , like   This isn't the way it really is , but let me say  that , suppose someone mentioned , uh , admission fees Ah , it takes too long . Try  let me just say \" Landmark \" . If the thing is a landmark , you know ,  um  then there 's another thing that says if   um  if it 's closed or not , at the moment . Alright , so you have nodes . Right ? And the , uh , problem that we were having was that , you know , given N - nodes , there 's \" two to the N \" Given N - nodes , and furthermore , the fact that there 's three things here , we need to specify \" three times \" , uh , \" two to the N \" probabilities . Right ? That 's assuming these are all binary , which f they may not be . For example , they could be \" time of day \" , in which case we could , uh , say , you know , \" Morning , afternoon , evening , night \" . So , this could be more So , it 's a lot , anyway . And , that 's a lot of probabilities to put here , which is kind of a pain . So  Noisy - ORs are a way to , uh ,  sort of deal with this . Um Where should I put this ? So , the idea is that , um ,  Let 's call these , uh , C - one , C - two , C - three , and C - four , and E , for Cause and Effect , I guess . The idea is to have these intermediate nodes . Right . Well , actually , the idea , first of all , is that each of these things has a  quote - unquote distinguished state , which means that this is  the state in which we don't really know anything about it . So  right ? So , for example , if we don't really know  if the thing is a landmark or not , Or , i if that just doesn't seem relevant , then that would be th sort of the Disting - the Distinguish state . It 's a really , you know ,  if there is something for the person talking about the admission fee , you know , if they didn't talk about it , that would be the Distinguish state .\nS so , this is a fanciful way of saying \" default \" ?\nSo  Yeah , yeah .\nOK .\nThat 's just what they  the word they used in that paper .\nMm - hmm .\nSo , the idea is that , um ,  you have these intermediate nodes , right ? E - one , E - two , E - three and E - four ?\nSo , this is the Heckerman paper you 're working with ? Good .\nYeah . So  The idea is that , each of these EI  is   represents what this would be  if all the other ones were in the distinguish state . Right ? So , for example , suppose that the person  I mean , suppose the thing that they talked about is a landmark . But none of the other   sort of cues really apply . Then ,  this would be  W The  this would just represent the probability distribution of this , assuming that this cue is turned on and the other ones just didn't apply ? So , you know , if it is a landmark , and no none of the other things really ap applicable , then  this would represent the probability distribution . So maybe in this case   Maybe we just t k Maybe we decide that , if the thing 's a landmark and we don't know anything else , then we 're gonna conclude that , um   They want to view it with probability , you know , point four . They want to enter it with probability , uh  with probability point five and they want to approach it probability point one , say  Right ? So we come up with these l little tables for each of those OK . And the final thing is that , um    this is a deterministic function of these , so we don't need to specify any probabilities . We just have to , um , say what function this is , right ? So we can let this be , um   G of E - one comma E - two . E - three , E - four . Right ? and our example G would be , um ,  a majority vote ? Right ?\nWell . OK , so th so the important point  is  W not what the G function is . The important point is  that  Um  There is a  a  a general kind of idea of shortcutting the full CPT . Th - c the full conditional probability table  with some function . OK ? Which y w you choose appropriately for each case . So , depending on  what your situation is , there are different functions which are most appropriate . And  So I gave  eh  Bhaskara a copy of this , eh  sort of \" ninety - two \"  paper . D and you got one , Robert .\nMm - hmm .\nI don't know who else has seen it .\nThere 's  I mean  yeah . it 's Heckerman and Breese .\nIt 's short . It 's short .\nYeah .\nSo , I u w Um , yo uh  you  Have you read it yet ?\nUh , you can  Yeah , you should take a look at it , I guess .\nOK\nOK , so you should take a look . Nancy , I 'm sure you read it at some point in life .\nI  yeah . I  I think so , yeah .\nOK . And  so , you other guys can decide how interested\nYeah , @ @ .\nAnyway . So the paper isn't th isn't real hard .\nOK .\nAnd   Uh  One of the questions just come at Bhaskara is , \" How much of this does JavaBayes support ? \"\nYeah , it 's a good question . Um   {nonvocalsound} The  so what we want , is basically JavaBayes to support deterministic , uh , functions .\nRight .\nAnd , um   In a sense it sup we can make it supported by , um ,  manually , uh , entering , you know , probabilities that are one and zeros , right ?\nRight . So the little handout that  The little thing that I sent  I sent a message saying , uh , here is a way to take  One thing you could do , which is kind of s in a way , stupid , is take this deterministic function , and use it to build the CPT . So , if Ba - JavaBayes won't do it for you ,\nMmm .\nthat you can convert all that into what the CPT would be . Um  and , what I sent out about a week ago , was an idea of how to do that , for , um , evidence combination . So one of  one function that you could use as your \" G function \" is an e e Evidence - Combining . So you just take  the  uh , if each of th if each of the ones has its own little table like that ,  then you could take the , uh , strength of each of those , times its little table , and you 'd add up the total evidence for \" V \" , \" E \" , and \" A \" .\nMmm . I don't think you can do this , because   G is a function from  that  to that .\nMm - hmm .\nYep . Right .\nRight ? So there 's no numbers . There 's just  quadruplets of  well , N - duplets of , uh , E Vs .\nI i i No , no  But I 'm saying is  There    There is a w I mean , if y if  if you decide what 's  what is appropriate , is probablistic evidence combination , you can write a function that does it . It 's a pui it 's actually one of the examples he 's got in there . But , anyway , s skipping  skipping the question of exactly which functions  now is it clear that you might like to be able to shortcut the whole conditional probability table .\nI mean , in some  it seems very plausible in some sense , where we will be likely to not be  observe some of the stuff . Cuz we don't have the a access to the information .\nOops ,  sorry .\nRight . That 's one of the problems , is , W Is  is , Where would th Where would it all come from ?\nYeah . So .\nIs  Oh , right . W would not be ab able to observe\nMmm .\nWhat ?\nI if it 's a  a  a discar Discourse Initial Phrase , we will have nothing in the discourse history . So , if  if we ever want to wonder what was mention\nOh  Oh . A are you saying that we 'll not be able to observe certain nodes ? That 's fine . That is sort of orthogonal thing .\nYeah , so there 's  there 's two separate things , Robert . The f the  the  the Bayes - nets in general are quite good at saying , \" if you have no current information about this variable just take the prior for that . \" OK ? Th - that 's what they 're real good at . So , if you don't have any information about the discourse , you just use your priors of  of whatever  eh the  discourse  uh , eh , basically whatever w it 's  Probabilistically , whatever it would be . And it 's  it 's sort of not a great estimate ,\nMm - hmm .\nbut  it 's the best one you have , and , so forth . So that , they 're good at . But the other problem is , how do you fill in all these numbers ? And I think that 's the one he was getting at .\nMm - hmm .\nYeah . So , specifically in this case you have to  f have this many numbers ,\nYeah .\nwhereas in this case you just have to have three for this , three for this , three for this . Right ?\nMm - hmm .\nSo you have to have just three N ? So , this is much smaller than that .\nAsymptotically .\nMm - hmm .\nWell , pretty quickly .\nYeah . Right .\nU yeah , yeah .\nI mean\nSo , you don't need da data enough to cover  uh , nearly as much stuff .\nI don't know .\nSo , really , i What a  A Noisy - OR seems to kind of  \" neural - net - acize \" these Bayes - nets ?\nEh  well to some No , no . So , \" Noisy - OR \" is a funny way of referring to this , because  the Noisy - OR is only one instance .\nYeah . This isn't a Noisy - OR anymore .\nThat one actually isn't a Noisy - OR . So we 'll have to think of  of a way t t\nYeah .\nit 's a Noisy - arg - max or a Noisy - whatever .\nYeah , whatever . Yeah . So  Eh   Um\nWell , my point was more that we just  eh  With the neural net , right , eh , things come in , you have a function that combines them and\nYeah , it  it  Tha - that 's true . It is a is also more neural - net - like , although   Uh , it isn't necessarily sum  uh , s you know , sum of weights or anything like that .\nRight .\nI mean i You could have , uh , like the Noisy - OR function , really is one that 's essentially says , uh , take the max .\nWell , the \" OR \" .\nSame .\nRight . I guess you 're right . Yeah .\nUh But anyway . So  And , I thi I think that 's the standard way people get around the  uh There are a couple other ones . There are ways of breaking this up into s to  to subnets and stuff like that . But , um The I think we definitely  I think it 's a great idea tha to  to pursue that .\nYep . So\nWha - still sort of leaves one question . It  I mean you  you can always uh  see easily that  that I 'm not grasping everything correctly , but  what seemed attractive to me in im uh in the last discussion we had , was  that we find out a means of  of getting these point four , point five , point one , of C - four , not because , you know , A is a Landmark or not , but we  we  we label this whatever object type , and if it 's a garden , it 's point three , point four , point two . If it 's a castle , it 's point eight , point one , point one . If it 's ,  uh , a town hall , it 's point two , point three , point five .\nRight .\nAnd so forth . And we don't want to write this down  necessarily every time for something but , uh  let 's see .\nIt 'll be students  Where else would it be stored ? That 's the question .\nWell , in the beginning , we 'll write up a flat file .\nOh .\nWe know we have twenty object types\nYeah .\nand we 'll write it down in a flat file .\nNo . So , i is Well , let me say something , guys , cuz there 's not  There 's a pretty point about this we might as well get in right now . Which is  The hierarchy that s comes with the ontology is just what you want for this .\nMm - hmm .\nSo that   Uh , if you know about it  let 's say , a particular town hall   that , it 's one that is a monument ,  then , that would be stored there . If you don't , you look up the hierarchy , Eh  so , you  you  you may or  So , then you 'd have this little vector of , um , you know , Approach Mode or EVA Mode . Let 's  OK , so we have  the EVA vector for  for various kinds of landmarks . If you know it for a specific landmark you put it there . If you don't , you just go up the hierarchy to the first place you find one .\nOK . So , is the idea to put it in the ontology ?\nAbsolutely .\nOK .\nUh , or , link to  or  but  but in any case  i View it logically as being in the ontology . It 's part of what you know about  a  an object ,  is its EVA vector .\nOK .\nAnd , if yo As I say , if you know about a specific object , you put it there .\nMm - hmm .\nThis is part of what Dekai was doing . So , when we get to Wu , The - e We 'll see w what he says about that .\nRight .\nAnd , then if you  If it isn't there , it 's higher , and if you don't know anything except that it 's a b it 's  it 's a  building , then up at the highest thing , you have the pr what amounts to a prior . If you don't know anything else about a building ,  uh , you just take whatever your crude approximation is up at that level ,\nRight .\nwhich might be equal , or whatever it is .\nYeah .\nSo , that 's a very pretty relationship between these local vectors and the ontology . And it seems to me the obvious thing to do , unless  we find a reason to do something different .\nYeah .\nDoes this make sense to you ?\nSo\nBhask - ?\nYeah . So , we are  but we  we 're not doing the ontology , so we have to get to whoever is doing the  u ultimately ,\nIndeed . So , that 's another thing we 're gonna need to do , is  is , to , either\nwe have to get them to\nWe 're gonna need some way to either get a p tag in the ontology , or add fields , or     some way to associate  Or , w It may be that all we can do is , um , some of our own hash tables that it  Th - the  th you know , there 's always a way to do that . It 's a just a question of\nYeah , hash on object name to , you know , uh , the probabilities or whatever .\ni th Yeah . e Right . And , so , i uh\nBut it 's , uh   Well , it strikes me as a What For If we get the mechanism , that will be sort of the wonderful part . And then ,  how to make it work is  is the second part , in the sense that  I mean , m the guy who was doing the ontology  eh , eh , s ap apologized that i it will take him another through  two to three days because they 're having really trouble getting the upper level straight , and right now . The reason is ,  given the craw bet uh , the  the  the projects that all carry their own taxonomy and , on all history ,  they 're really trying to build one top level ontology ft that covers all the EML projects , and that 's , uh , uh , sort of a tough cookie , a little bit tougher than they  figured . I could have told them s so .\nRight . Yeah .\nUh . But , nevertheless , it 's going to be there by n by , uh , next Monday and I will show you what 's  what some examples  from that for towers , and stuff . And , um , what I don't think is ever going to be in the ontology , is sort of , you know , the likelihood of , eh , people entering r town halls , and looking at town halls , and approaching town halls , especially since we are b dealing with a case - based , not an instance - based ontology . So , there will be nothing on  on that town hall , or on the Berkeley town hall , or on the  Heidelberg town hall , it 'll just be information on town halls .\nWell , they  they  they  How ar What are they gonna do with instances ?\nBut what\nI mean , you  y\nWell , that 's  Hhh . That 's  that 's al different question . I mean , th the  first , they had to make a design question ,  \" do we take ontologies that have instances ? or just one that does not , that just has the types ? \"\nOK .\nAnd , so , since the d decision was on types , on a d simply type - based ,  we now have to hook it up to instances . I mean this is\nBut what i What is SmartKom gonna do about that ?\none\nCuz , they have instances all the time .\nYeah , but the ontology is really not a SmartKom thing , in  in and of itself . That 's more something that  I kicked loose in  in EML . So it 's a completely EML thing .\nBut  Uh  uh  SmartKom 's gonna need an ontology .\nYes , u a w a lot of people are aware of that .\nI understand ,  but is anybody doing anything about it ?\nUm\nOK . It 's a political problem . We won't worry about it .\nNo , but  th the r eh  I th I still think that there is enough information in there . For example , whether  OK . So , th it will know about the twenty object types there are in the world . Let 's assume there are only twenty object types in this world . And it will know if any of those have institutional meanings . So , in a sense , \" I \" used as Institutions for some s in some sense or the other . Which makes them  enterable . Right ? In a sense .\nYeah . Anyway . So we may have to\nYou know .\nThis is with the whole thing ,\nYep .\nwe may have to build another data stru\nYep .\nConceptually , we know what should be done . When we see what people have done , it may turn out that the easiest thing to do  is to build a  a separate thing that  that just pools i i Like , i i it  it may be , that , the  the instance  w That we have to build our own instance , uh , things , that , with their types ,\nYeah , it 's  Right , we can just assume\nand then it goes off to the ontology once you have its type . So we build a little data structure And so what we would do in that case , is , in our instance gadget have  our E V And if we d there isn't one we 'd get the type and then have the E V As for the type . So we 'd have our own little ,  uh , EVA tree . And then , for other , uh , vectors that we need .\nYeah . Right .\nSo , we 'd have our own little  things so that whenever we needed one , we 'd just use the ontology to get the type ,\nMm - hmm .\nand then would hash or whatever we do to say , \" ah !\nMm - hmm .\nIf it 's that type of thing , and we want its EVA vector , pppt - pppt !  it 's that . \" So , I I think we can handle that . And then  But , the combination functions , and whether we can put those in Java Bayes , and all that sort of stuff , is , uh  is the bigger deal .\nYeah .\nI think that 's where we have to get technically clever .\nWe could just steal the classes in JavaBayes and then interface to them with our own code .\nUm\nWell , I me ye {nonvocalsound} eh , yeah , the\nThat requires understanding the classes in JavaBayes , I guess . @ @ .\nYeah , I mean , it 's , uh , e e e e e cute . I mean , you 've been around enough to  I mean  Just ?\nWell , it depends on\nI mean , there 's this huge package which  which may or may not be consistent and  you know . But , yeah , we could look at it .\nWell , I was j OK . Yeah .\nYeah . It 's b It  It 's an inter sort of a kind of a  it  The thing is , it 's kind of an interpreter and i i it expects its data structures to be in a given form , and if you say , \" hey , we 're gonna  make a different kind of data structure to stick in there  \"\nWell , no , but that just means there 's a protocol , right ? That you could\nIt may or may not . I don't know . That 's the question is \" to what extent does it allow us to put in these G functions ? \" And I don't know .\nWell , no , but  I mean  What I uh the  So you could have four different Bayes - nets that you 're running , and then run your own  write your own function that would take the output of those four , and make your own \" G function \" , is what I was saying .\nYeah , that 's fine if it 's  if it comes only at the end . But suppose you want it embedded ?\nWell , then you 'd have to break all of your Bayes - nets into smaller Bayes - nets , with all the\nOh , that  Yeah , that 's a truly horrible way to do d it . One would hope\nYeah , but I 'm just\nMm - hmm .\nYeah , yeah , yeah , yeah , yeah , you bet . But , at that point you may say , \" hey , Java Bayes isn't the only package in town . Let 's see if there 's another package that 's , eh , more civilized about this . \"\nNow , Srini is worth talking to on this ,\nMmm .\ncuz he said that he actually did hack some combining functions into But he doesn't remember  at least when I talked to him , he didn't remember  whether it was an e an easy thing , a natural thing , or whether he had to do some violence to it to make it work .\nAh !\nUh . But he did do it .\nYeah . I don't see why the , uh , combining f functions have to be directly hacked into I mean , they 're used to create tables so we can just make our own little functions that create tables in XML .\nWell , I say that 's one way to do it , is  is to just convert it int into a  into a C P T that you zip  It 's blown up , and is a  it 's , uh  it 's huge , but   it doesn't require any data fitting or complication .\nMm - hmm . Yeah . I don't think  I mean , the fact that it blown u blows up is a huge issue in the sense that  I mean , OK . So say it blows up , right ? So there 's , like , the you know , ten , f ten , fifteen , uh , things . It 's gonna be like , two to the  that , which isn't so bad .\nI I understand . I 'm just saying tha that w That was wi that was my note . The little note I sent said that . It said , \" Here 's the way you 'd take the logical f G function and turn it into a CPT . \"\nMm - hmm . Mm - hmm .\nI mean that  the Max - the Evidence - Combining function . So we could do that . And maybe that 's what we 'll do . But , um don't know . So , I will , e  e before next week , uh , @ @  p push  push some more on  on this stuff that Dekai Wu did , and try to understand it . Uh , you 'll make a couple of more copies of the Heckerman paper to give to people ?\np Sure .\nYeah , I  I would like a copy ,\nOK .\nOK .\ny y yeah .\nAnd , um\nOK .\nI think\nOK . And I I 'll  I 'll think s through this , uh ,  eh  getting EVA vectors dynamically out of ontologies one more time because I s I  I  I 'm not quite sure whether we all think of the same thing or not , here .\nWell , you and I should talk about it .\nYeah , uh - huh . OK .\nAlright , great ! And , Robert , thank you for  coming in under  He  he 's been sick , Robert .\nUnd .\nI was thinking maybe we should just cough into the microphone and see if they can't  th see if they can handle it .\nMm - hmm .\nYep .\nSure .\nUm  is this , uh", "topic_id": 3, "keywords": "language, interpreter, english, constructions, german", "dialogue_id": 42}, {"text": "Is it starting now ?\nYep .\nSo what  what  from  what\nHello ?\nWhatever we say from now on , it can be held against us , right ?\nThat 's right .\nand uh\nIt 's your right to remain silent .\nYeah . So I  I  the  the problem is that I actually don't know how th these held meetings are held , if they are very informal and sort of just people are say what 's going on\nYeah .\nand\nYeah , that 's usually what we do .\nOK .\nWe just sorta go around and people say what 's going on , what 's the latest uh\nYeah . OK . So I guess that what may be a  reasonable is if I uh first make a report on what 's happening in Aurora in general , at least what from my perspective .\nYeah . That would be great .\nAnd  and uh so , I  I think that Carmen and Stephane reported on uh Amsterdam meeting ,\nUh o\nwhich was kind of interesting because it was for the first time we realized we are not friends really , but we are competitors . Cuz until then it was sort of like everything was like wonderful and\nYeah . It seemed like there were still some issues ,\nYeah .\nright ? that they were trying to decide ?\nThere is a plenty of  there 're plenty of issues .\nLike the voice activity detector ,\nWell and what happened was that they realized that if two leading proposals , which was French Telecom Alcatel , and us both had uh voice activity detector . And I said \" well big surprise , I mean we could have told you that  n n n four months ago , except we didn't because nobody else was bringing it up \" .\nRight .\nObviously French Telecom didn't volunteer this information either , cuz we were working on  mainly on voice activity detector for past uh several months\nRight .\nbecause that 's buying us the most uh thing . And everybody said \" Well but this is not fair . We didn't know that . \" And of course uh the  it 's not working on features really . And be I agreed .\nRight .\nI said \" well yeah , you are absolutely right , I mean if I wish that you provided better end point at speech because uh  or at least that if we could modify the recognizer , uh to account for these long silences , because otherwise uh that  that  th that wasn't a correct thing . \" And so then ev ev everybody else says \" well we should  we need to do a new eval evaluation without voice activity detector , or we have to do something about it \" .\nRight .\nAnd in principle I  uh I  we agreed .\nMm - hmm .\nWe said uh \" yeah \" . Because uh  but in that case , uh we would like to change the uh  the algorithm because uh if we are working on different data , we probably will use a different set of tricks .\nRight .\nBut unfortunately nobody ever officially can somehow acknowledge that this can be done , because French Telecom was saying \" no , no , no , now everybody has access to our code , so everybody is going to copy what we did . \" Yeah well our argument was everybody ha has access to our code , and everybody always had access to our code . We never uh  uh denied that . We thought that people are honest , that if you copy something and if it is protected  protected by patent then you negotiate , or something ,\nYeah . Right .\nright ? I mean , if you find our technique useful , we are very happy .\nRight .\nBut  And French Telecom was saying \" no , no , no ,\nMm - hmm .\nthere is a lot of little tricks which uh sort of uh cannot be protected and you guys will take them , \" which probably is also true . I mean , you know , it might be that people will take uh uh th the algorithms apart and use the blocks from that . But I somehow think that it wouldn't be so bad , as long as people are happy abou uh uh uh honest about it .\nYeah .\nAnd I think they have to be honest in the long run , because winning proposal again  uh what will be available th is  will be a code . So the uh  the people can go to code and say \" well listen this is what you stole from me \"\nMm - hmm .\nyou know ?\nRight .\n\" so let 's deal with that \" .\nRight .\nSo I don't see the problem . The biggest problem of course is that f that Alcatel French Telecom cl claims \" well we fulfilled the conditions . We are the best . Uh . We are the standard . \" And e and other people don't feel that , because they  so they now decided that  that  is  the whole thing will be done on well - endpointed data , essentially that somebody will endpoint the data based on clean speech , because most of this the SpeechDat - Car has the also close speaking mike and endpoints will be provided .\nMm - hmm . Ah .\nAnd uh we will run again  still not clear if we are going to run the  if we are allowed to run uh uh new algorithms , but I assume so . Because uh we would fight for that , really . uh but  since uh u u n u  at least our experience is that only endpointing a  a mel cepstrum gets uh  gets you twenty - one percent improvement overall and twenty - seven improvement on SpeechDat - Car\nHmm .\nthen obvious the database  uh I mean the  the  the  uh the baseline will go up . And nobody can then achieve fifty percent improvement .\nRight .\nSo they agreed that uh there will be a twenty - five percent improvement required on  on uh h u m bad mis badly mismatched\nBut wait a minute , I thought the endpointing really only helped in the noisy cases .\nIt uh\nOh , but you still have that with the MFCC .\nY yeah .\nOK .\nYeah but you have the same prob I mean MFCC basically has an enormous number of uh insertions .\nYeah . Right . Yeah . Yeah . Yeah .\nAnd so , so now they want to say \" we  we will require fifty percent improvement only for well matched condition , and only twenty - five percent for the serial cases . \"\nHmm .\nAnd uh  and they almost agreed on that except that it wasn't a hundred percent agreed . And so last time uh during the meeting , I just uh brought up the issue , I said \" well you know uh quite frankly I 'm surprised how lightly you are making these decisions because this is a major decision . For two years we are fighting for fifty percent improvement and suddenly you are saying \" oh no we  we will do something less \" , but maybe we should discuss that . And everybody said \" oh we discussed that and you were not a mee there \" and I said \" well a lot of other people were not there because not everybody participates at these teleconferencing c things . \" Then they said \" oh no no no because uh everybody is invited . \" However , there is only ten or fifteen lines , so people can't even con you know participate . So eh they agreed , and so they said \" OK , we will discuss that . \" Immediately Nokia uh raised the question and they said \" oh yeah we agree this is not good to to uh dissolve the uh uh  the uh  the criterion . \"\nMm - hmm .\nSo now officially , Nokia is uh uh complaining and said they  they are looking for support , uh I think QualComm is uh saying , too \" we shouldn't abandon the fifty percent yet . We should at least try once again , one more round . \"\nMm - hmm .\nSo this is where we are .\nMm - hmm .\nI hope that  I hope that this is going to be a adopted .\nHmm .\nNext Wednesday we are going to have uh another uh teleconferencing call , so we 'll see what uh  where it goes .\nSo what about the issue of um the weights on the  for the different systems , the well - matched , and medium - mismatched and\nYeah , that 's what  that 's a g very good uh point , because David says \" well you know we ca we can manipulate this number by choosing the right weights anyways . \" So while you are right but  uh you know but\nMm - hmm .\nUh yeah , if of course if you put a zero  uh weight zero on a mismatched condition , or highly mismatched then  then you are done .\nMm - hmm .\nBut weights were also deter already decided uh half a year ago . So\nAnd they 're the  staying the same ?\nWell , of course people will not like it . Now  What is happening now is that I th I think that people try to match the criterion to solution .\nMm - hmm .\nThey have solution . Now they want to  make sure their criterion is\nRight .\nAnd I think that this is not the right way .\nYeah .\nUh it may be that  that  Eventually it may ha may ha it may have to happen . But it 's should happen at a point where everybody feels comfortable that we did all what we could .\nMm - hmm .\nAnd I don't think we did .\nMm - hmm .\nBasically , I think that  that this test was a little bit bogus because of the data and uh essentially  there were these arbitrary decisions made , and  and everything . So , so  so this is  so this is where it is . So what we are doing at OGI now is uh uh uh working basically on our parts which we I think a little bit neglected , like noise separation . Uh so we are looking in ways is  in uh which  uh with which we can provide better initial estimate of the mel spectrum basically , which would be a l uh , f more robust to noise , and so far not much uh success .\nHmm .\nWe tried uh things which uh a long time ago Bill Byrne suggested , instead of using Fourier spectrum , from Fourier transform , use the spectrum from LPC model . Their argument there was the LPC model fits the peaks of the spectrum , so it may be m naturally more robust in noise . And I thought \" well , that makes sense , \" but so far we can't get much  much out of it .\nHmm .\nuh we may try some standard techniques like spectral subtraction and\nYou haven't tried that yet ?\nnot  not  not much . Or even I was thinking about uh looking back into these totally ad - hoc techniques\nHmm .\nlike for instance uh Dennis Klatt was suggesting uh the one way to uh deal with noisy speech is to add noise to everything .\nHmm !\nSo .  I mean , uh uh add moderate amount of noise to all data .\nOh !\nSo that makes uh th any additive noise less addi less a a effective ,\nI see .\nright ? Because you already uh had the noise uh in a\nRight .\nAnd it was working at the time . It was kind of like one of these things , you know , but if you think about it , it 's actually pretty ingenious . So well , you know , just take a  take a spectrum and  and  and add of the constant , C , to every  every value .\nWell you 're  you 're basically y Yeah . So you 're making all your training data more uniform .\nExactly . And if  if then  if this data becomes noisy , it b it becomes eff effectively becomes less noisy basically .\nHmm .\nBut of course you cannot add too much noise because then you 'll s then you 're clean recognition goes down , but I mean it 's yet to be seen how much , it 's a very simple technique .\nMm - hmm .\nYes indeed it 's a very simple technique , you just take your spectrum and  and use whatever is coming from FFT ,  add constant ,\nHmm .\nyou know ? on  onto power spectrum . That  that  Or the other thing is of course if you have a spectrum , what you can s start doing , you can leave  start leaving out the p the parts which are uh uh low in energy and then perhaps uh one could try to find a  a all - pole model to such a spectrum . Because a all - pole model will still try to  to  to put the  the continuation basically of the  of the model into these parts where the issue set to zero . That 's what we want to try . I have a visitor from Brno . He 's a  kind of like young faculty . pretty hard - working so he  so he 's  so he 's looking into that .\nHmm .\nAnd then most of the effort is uh now also aimed at this e e TRAP recognition . This uh  this is this recognition from temporal patterns .\nHmm ! What is that ?\nAh , you don't know about TRAPS !\nHmm .\nThe TRAPS sound familiar , I  but I don't\nYeah I mean tha This is familiar like sort of because we gave you the name , but , what it is , is that normally what you do is that you recognize uh speech based on a shortened spectrum .\nMm - hmm . Mm - hmm .\nEssentially L P - LPC , mel cepstrum , uh , everything starts with a spectral slice . Uh so if you s So , given the spectrogram you essentially are sliding  sliding the spectrogram along the uh f frequency axis\nMm - hmm .\nand you keep shifting this thing , and you have a spectrogram .\nMm - hmm .\nSo you can say \" well you can also take the time trajectory of the energy at a given frequency \" , and what you get is then , that you get a p  vector .\nMm - hmm .\nAnd this vector can be a  a  s assigned to s some phoneme . Namely you can say i it  I will  I will say that this vector will eh  will  will describe the phoneme which is in the center of the vector . And you can try to classify based on that .\nHmm .\nAnd you  so you classi so it 's a very different vector , very different properties , we don't know much about it , but the truth is\nHmm . But you have many of those vectors per phoneme ,\nWell , so you get many decisions .\nright ? Uh - huh .\nAnd then you can start dec thinking about how to combine these decisions . Exactly , that 's what  yeah , that 's what it is .\nHmm . Hmm .\nBecause if you run this uh recognition , you get  you still get about twenty percent error  uh twenty percent correct . You know ,\nHmm .\non  on like for the frame by frame basis , so  uh  uh so it 's much better than chance .\nHow wide are the uh frequency bands ?\nThat 's another thing . Well c currently we start  I mean we start always with critical band spectrum . For various reasons . But uh the latest uh observation uh is that you  you  you are  you can get quite a big advantage of using two critical bands at the same time .\nAre they adjacent , or are they s\nAdjacent , adjacent .\nOK .\nAnd the reasons  there are some reasons for that . Because there are some reasons I can  I could talk about , will have to tell you about things like masking experiments which uh uh uh uh yield critical bands , and also experiments with release of masking , which actually tell you that something is happening across critical bands , across bands . And\nWell how do you  how do you uh convert this uh energy over time in a particular frequency band into a vector of numbers ?\nIt 's uh uh uh I mean time T - zero is one number ,  time t\nYeah but what 's the number ? Is it just the\nIt 's a spectral energy , logarithmic spectral energy ,\nit 's just the amount of energy in that band from f in that time interval .\nyeah . Yes , yes . Yes , yes .\nOK .\nAnd that 's what  that 's what I 'm saying then , so this is a  this is a starting vector . It 's just like shortened f  spectrum , or something . But now we are trying to understand what this vector actually represents ,\nMm - hmm .\nfor instance a question is like \" how correlated are the elements of this vector ? \" Turns out they are quite correlated , because I mean , especially the neighboring ones , right ? They  they represent the same  almost the same configuration of the vocal tract .\nYeah . Yeah . Mm - hmm .\nSo there 's a very high correlation . So the classifiers which use the diagonal covariance matrix don't like it . So we 're thinking about de - correlating them .\nHmm .\nThen the question is uh \" can you describe elements of this vector by Gaussian distributions \" , or to what extent ? Because uh  And  and  and so on and so on . So we are learning quite a lot about that . And then another issue is how many vectors we should be using ,\nHmm .\nI mean the  so the minimum is one .\nMm - hmm .\nBut I mean is the  is the critical band the right uh uh dimension ? So we somehow made arbitrary decision , \" yes \" . Then  but then now we are thinking a lot how to  uh how to use at least the neighboring band because that seems to be happening  This I somehow start to believe that 's what 's happening in recognition . Cuz a lot of experiments point to the fact that people can split the signal into critical bands , but then oh uh uh so you can  you are quite capable of processing a signal in uh uh independently in individual critical bands . That 's what masking experiments tell you . But at the same time you most likely pay attention to at least neighboring bands when you are making any decisions , you compare what 's happening in  in this band to what 's happening to the band  to  to  to the  to the neighboring bands . And that 's how you make uh decisions . That 's why the articulatory events , which uh F F Fletcher talks about , they are about two critical bands . You need at least two , basically . You need some relative , relative relation .\nHmm .\nAbsolute number doesn't tell you the right thing .\nHmm .\nYou need to  you need to compare it to something else , what 's happening but it 's what 's happening in the  in the close neighborhood . So if you are making decision what 's happening at one kilohertz , you want to know what 's happening at nine hundred hertz and it  and maybe at eleven hundred hertz , but you don't much care what 's happening at three kilohertz .\nSo it 's really w It 's sort of like saying that what 's happening at one kilohertz depends on what 's happening around it . It 's sort of relative to it .\nTo some extent , it  that is also true . Yeah . But it 's  but for  but for instance ,  th uh  uh what  what uh humans are very much capable of doing is that if th if they are exactly the same thing happening in two neighboring critical bands , recognition can discard it .\nMm - hmm .\nIs what 's happening\nHmm .\nHey !\nHey ! OK , we need us another  another voice here .\nHey Stephane .\nYeah , I think so . Yeah ?\nYep . Sure . Go ahead .\nAnd so so  so for instance if you d if you a if you add the noise that normally masks  masks the uh  the  the signal right ?\nMm - hmm .\nand you can show that in  that if the  if you add the noise outside the critical band , that doesn't affect the  the decisions you 're making about a signal within a critical band .\nHmm .\nUnless this noise is modulated . If the noise is modulated , with the same modulation frequency as the noise in a critical band , the amount of masking is less . The moment you  moment you provide the noise in n neighboring critical bands .\nMmm .\nSo the s m masking curve , normally it looks like sort of  I start from  from here , so you   you have uh no noise then you  you  you are expanding the critical band , so the amount of maching is increasing . And when you e hit a certain point , which is a critical band , then the amount of masking is the same .\nMmm .\nSo that 's the famous experiment of Fletcher , a long time ago . Like that 's where people started thinking \" wow this is interesting ! \" So .\nYeah .\nBut , if you  if you  if you modulate the noise , the masking goes up and the moment you start hitting the  another critical band , the masking goes down . So essentially  essentially that 's a very clear indication that  that  that  cognition can take uh uh into consideration what 's happening in the neighboring bands . But if you go too far in a  in a  if you  if the noise is very broad , you are not increasing much more , so  so if you  if you are far away from the signal  uh from the signal f uh the frequency at which the signal is , then the m even the  when the noise is co - modulated it  it 's not helping you much .\nMm - hmm . Yeah . Mm - hmm .\nHmm .\nSo . So things like this we are kind of playing with  with  with the hope that perhaps we could eventually u use this in a  in a real recognizer .\nMm - hmm .\nLike uh partially of course we promised to do this under the  the  the Aurora uh program .\nBut you probably won't have anything before the next time we have to evaluate ,\nProbably not .\nright ?\nWell , maybe , most likely we will not have anything which c would comply with the rules .\nYeah . Ah .\nlike because uh uh\nLatency and things .\nlatency currently chops the require uh significant uh latency amount of processing ,\nMm - hmm .\nbecause uh we don't know any better , yet , than to use the neural net classifiers , uh and uh  and uh TRAPS .\nYeah .\nMm - hmm .\nThough the  the work which uh everybody is looking at now aims at s trying to find out what to do with these vectors , so that a g simple Gaussian classifier would be happier with it .\nHmm .\nMm - hmm .\nor to what extent a Gaussian classifier should be unhappy uh that , and how to Gaussian - ize the vectors , and\nHmm .", "topic_id": 0, "keywords": "aurora, meeting, meetings, talks, events", "dialogue_id": 43}, {"text": "So this is uh what 's happening . Then Sunil is uh uh uh asked me f for one month 's vacation and since he did not take any vacation for two years , I had no  I didn't have heart to tell him no . So he 's in India .\nWow .\nAnd uh\nIs he getting married or something ?\nUh well , he may be looking for a girl , for  for I don't  I don't  I don't ask . I know that Naran - when last time Narayanan did that he came back engaged .\nRight . Well , I mean , I 've known other friends who  they  they go to Ind - they go back home to India for a month , they come back married ,\nYeah . I know . I know , I know ,\nyou know , huh .\nand then of course then what happened with Narayanan was that he start pushing me that he needs to get a PHD because they wouldn't give him his wife . And she 's very pretty and he loves her and so  so we had to really\nSo he finally had some incentive to finish ,\nOh yeah . We had  well I had a incentive because he  he always had this plan except he never told me .\nhuh ?\nSort of figured that  That was a uh that he uh he told me the day when we did very well at our NIST evaluations of speaker recognition , the technology , and he was involved there .\nOh .\nWe were  after presentation we were driving home and he told me .\nWhen he knew you were happy ,\nYeah . So I  I said \" well , yeah , OK \" so he took another  another three quarter of the year but uh he was out .\nhuh ?\nSo I  wouldn't surprise me if he has a plan like that , though  though uh Pratibha still needs to get out first .\nHmm .\nCuz Pratibha is there a  a year earlier .\nHmm .\nAnd S and Satya needs to get out very first because he 's  he already has uh four years served , though one year he was getting masters . So . So .\nHmm .\nSo have the um  when is the next uh evaluation ? June or something ?\nWhich ? Speaker recognition ?\nNo , for uh Aurora ?\nUh there , we don't know about evaluation , next meeting is in June .\nHmm .\nAnd uh uh but like getting  get together .\nOh , OK . Are people supposed to rerun their systems ,\nNobody said that yet .\nor  ?\nI assume so . Uh yes , uh , but nobody even set up yet the  date for uh delivering uh endpointed data .\nHmm . Wow .\nAnd this uh  that  that sort of stuff . But I uh , yeah , what I think would be of course extremely useful , if we can come to our next meeting and say \" well you know we did get fifty percent improvement . If  if you are interested we eventually can tell you how \" , but uh we can get fifty percent improvement .\nMm - hmm .\nBecause people will s will be saying it 's impossible .\nHmm . Do you know what the new baseline is ? Oh , I guess if you don't have\nTwenty - two  t twenty  twenty - two percent better than the old baseline .\nUsing your uh voice activity detector ?\nu Yes . Yes . But I assume that it will be similar , I don't  I  I don't see the reason why it shouldn't be .\nSimilar , yeah .\nI d I don't see reason why it should be worse .\nMm - hmm .\nCuz if it is worse , then we will raise the objection ,\nYeah .\nwe say \" well you know how come ? \" Because eh if we just use our voice activity detector , which we don't claim even that it 's wonderful , it 's just like one of them .\nMm - hmm .\nYeah .\nWe get this sort of improvement , how come that we don't see it on  on  on  on your endpointed data ?\nYeah . I guess it could be even better ,\nI think so .\nbecause the voice activity detector that I choosed is something that cheating , it 's using the alignment of the speech recognition system ,\nYeah . C yeah uh\nand only the alignment on the clean channel , and then mapped this alignment to the noisy channel .\nand on clean speech data . Yeah .\nOh , OK .\nWell David told me  David told me yesterday or Harry actually he told Harry from QualComm and Harry uh brought up the suggestion we should still go for fifty percent he says are you aware that your system does only thirty percent uh comparing to  to endpointed baselines ? So they must have run already something .\nYeah .\nHmm .\nSo . And Harry said \" Yeah . But I mean we think that we  we didn't say the last word yet , that we have other  other things which we can try . \"\nHmm .\nSo . So there 's a lot of discussion now about this uh new criterion . Because Nokia was objecting , with uh QualComm 's  we basically supported that , we said \" yes \" .\nMm - hmm . Mm - hmm .\nNow everybody else is saying \" well you guys might  must be out of your mind . \" uh The  Guenter Hirsch who d doesn't speak for Ericsson anymore because he is not with Ericsson and Ericsson may not  may withdraw from the whole Aurora activity because they have so many troubles now .\nWow .\nEricsson 's laying off twenty percent of people .\nWow .\nWhere 's uh Guenter going ?\nWell Guenter is already  he got the job uh already was working on it for past two years or three years\nMm - hmm .\nhe got a job uh at some  some Fachschule , the technical college not too far from Aachen .\nHmm !\nSo it 's like professor  u university professor\nMm - hmm .\nyou know , not quite a university , not quite a sort of  it 's not Aachen University , but it 's a good school and he  he 's happy .\nMm - hmm . Hmm !\nAnd he  well , he was hoping to work uh with Ericsson like on t uh like consulting basis , but right now he says  says it doesn't look like that anybody is even thinking about speech recognition .\nMm - hmm .\nThey think about survival .\nWow !\nYeah .\nHmm .\nSo . So . But this is being now discussed right now , and it 's possible that uh  that  that it may get through , that we will still stick to fifty percent .\nMm - hmm .\nBut that means that nobody will probably get this im this improvement . yet , wi with the current system . Which event es essentially I think that we should be happy with because that  that would mean that at least people may be forced to look into alternative solutions\nMm - hmm .\nand\nMm - hmm . But maybe  I  I mean we are not too far from  from fifty percent , from the new baseline .\nUh , but not\nWhich would mean like sixty percent over the current baseline , which is\nYeah . Yes . Yes . We  we getting  we getting there , right .\nWell . We are around fifty , fifty - five .\nYeah .\nSo .\nYeah .\nMm - hmm .\nIs it like sort of  is  How did you come up with this number ? If you improve twenty  by twenty percent the c the f the all baselines , it 's just a quick c comp co computation ?\nYeah . I don't know exactly if it 's\nUh - huh . I think it 's about right .\nYeah , because it de it depends on the weightings\nYeah , yeah .\nand  Yeah . But . Mm - hmm .\nHmm . How 's your documentation or whatever it w what was it you guys were working on last week ?\nYeah , finally we  we 've not finished with this . We stopped .\nMore or less it 's finished .\nYeah .\nMa - nec to need a little more time to improve the English , and maybe s to fill in something  some small detail , something like that ,\nMm - hmm .\nHmm .\nbut it 's more or less ready .\nYeah . Well , we have a document that explain a big part of the experiments ,\nNecessary to  to include the bi the bibliography .\nbut\nMm - hmm .\nit 's not , yeah , finished yet . Mm - hmm .\nSo have you been running some new experiments ? I  I thought I saw some jobs of yours running on some of the machine", "topic_id": 1, "keywords": "narayanan, engaged, married, satya, naran", "dialogue_id": 43}, {"text": "Yeah . Right . We 've fff  done some strange things like removing C - zero or C - one from the    the vector of parameters , and we noticed that C - one is almost not useful at all . You can remove it from the vector , it doesn't hurt .\nReally ? ! That has no effect ?\nUm .\nEh  Is this in the baseline ? or in uh\nIn the  No , in the proposal .\nin  uh - huh , uh - huh .\nSo we were just discussing , since you mentioned that , in  it w\nMm - hmm .\ndriving in the car with Morgan this morning , we were discussing a good experiment for b for beginning graduate student who wants to run a lot of  who wants to get a lot of numbers on something\nMm - hmm .\nwhich is , like , \" imagine that you will  you will start putting every co any coefficient , which you are using in your vector , in some general power .\nIn some what ?\nGeneral pow power . Like sort of you take a s power of two , or take a square root , or something .\nMm - hmm .\nMm - hmm .\nSo suppose that you are working with a s C - zer C - one .\nMm - hmm .\nSo if you put it in a s square root , that effectively makes your model half as efficient . Because uh your uh Gaussian mixture model , right ? computes the mean .\nMm - hmm .\nAnd  and uh i i i but it 's  the mean is an exponent of the whatever , the  the  this Gaussian function .\nYou 're compressing the range ,\nSo you 're compressing the range of this coefficient , so it 's becoming less efficient .\nright ? of that\nRight ?\nMm - hmm .\nSo . So . Morgan was @ @ and he was  he was saying well this might be the alternative way how to play with a  with a fudge factor , you know , uh in the\nOh .\nyou know , just compress the whole vector .\nYeah .\nAnd I said \" well in that case why don't we just start compressing individual elements , like when  when  because in old days we were doing  when  when people still were doing template matching and Euclidean distances , we were doing this liftering of parameters , right ?\nUh - huh .\nbecause we observed that uh higher parameters were more important than lower for recognition . And basically the  the C - ze C - one contributes mainly slope ,\nRight .\nand it 's highly affected by uh frequency response of the  of the recording equipment and that sort of thing ,\nMm - hmm .\nMm - hmm .\nso  so we were coming with all these f various lifters .\nMm - hmm .\nuh Bell Labs had he  this uh uh r raised cosine lifter which still I think is built into H  HTK for reasons n unknown to anybody , but  but uh we had exponential lifter , or triangle lifter , basic number of lifters .\nHmm .\nAnd . But so they may be a way to  to fiddle with the f with the f\nInsertions .\nInsertions , deletions , or the  the  giving a relative  uh basically modifying relative importance of the various parameters .\nMm - hmm .\nThe only of course problem is that there 's an infinite number of combinations and if the  if you s if y\nOh . Uh - huh . You need like a  some kind of a\nYeah , you need a lot of graduate students , and a lot of computing power .\nYou need to have a genetic algorithm , that basically tries random permutations of these things .\nI know . Exactly . Oh . If you were at Bell Labs or  I d d I shouldn't be saying this in  on  on a mike , right ? Or I  uh  IBM , that 's what  maybe that 's what somebody would be doing .\nYeah .\nHmm .\nOh , I mean , I mean the places which have a lot of computing power , so because it is really it 's a p it 's a  it 's  it will be reasonable search\nMm - hmm . Yeah .\nuh but I wonder if there isn't some way of doing this uh search like when we are searching say for best discriminants .\nYou know actually , I don't know that this wouldn't be all that bad . I mean you  you compute the features once ,\nYeah . Yeah .\nright ? And then these exponents are just applied to that\nAbsolutely . And hev everything is fixed .\nSo .\nEverything is fixed . Each  each\nAnd is this something that you would adjust for training ? or only recognition ?\nFor both , you would have to do . Yeah .\nYou would do it on both .\nYou have to do bo both .\nSo you 'd actually\nBecause essentially you are saying \" uh this feature is not important \" .\nMm - hmm .\nOr less important , so that 's  th that 's a  that 's a painful one , yeah .\nSo for each  uh set of exponents that you would try , it would require a training and a recognition ?\nYeah . But  but wait a minute . You may not need to re uh uh retrain the m model . You just may n may need to c uh give uh less weight to  to uh a mod uh a component of the model which represents this particular feature . You don't have to retrain it .\nOh . So if you  Instead of altering the feature vectors themselves , you  you modify the  the  the Gaussians in the models .\nYou just multiply . Yeah . Yep . You modify the Gaussian in the model , but in the  in the test data you would have to put it in the power , but in a training what you c in a training uh  in trained model , all you would have to do is to multiply a model by appropriate constant .\nUh - huh . But why  if you 're  if you 're multi if you 're altering the model , why w in the test data , why would you have to muck with the uh cepstral coefficients ?\nBecause in uh test  in uh test data you ca don't have a model . You have uh only data . But in a  in a tr\nNo . But you 're running your data through that same model .\nThat is true , but w I mean , so what you want to do  You want to say if uh obs you  if you observe something like Stephane observes , that C - one is not important , you can do two things .\nMm - hmm . Mm - hmm .\nIf you have a trained  trained recognizer , in the model , you know the  the  the  the component which  I  I mean di dimension  wh\nMm - hmm . All of the  all of the mean and variances that correspond to C - one , you put them to zero .\nTo the s you  you know it . But what I 'm proposing now , if it is important but not as important , you multiply it by point one in a model .\nYeah .\nBut  but  but\nBut what are you multiplying ? Cuz those are means , right ?\nYou 're multiplying the standard deviation ?\nI mean you 're\nSo it 's\nI think that you multiply the  I would  I would have to look in the  in the math , I mean how  how does the model uh\nI think you\nYeah .\nYeah , I think you 'd have to modify the standard deviation or something , so that you make it  wider or narrower .\nCuz  Yeah .\nYeah .\nYeah .\nEffectively , that 's  that  that 's  I  Exactly . That 's what you do . That 's what you do , you  you  you modify the standard deviation as it was trained .\nYeah .\nEffectively you , you know y in f in front of the  of the model , you put a constant . S yeah effectively what you 're doing is you  is you are modifying the  the  the deviation . Right ?\nThe spread ,\nOop .\nright .\nSorry .\nYeah , the spread .\nIt 's the same  same mean ,\nSo .\nright ?\nAnd  and  and\nSo by making th the standard deviation narrower ,  uh your scores get worse for\nYeah .\nunless it 's exactly right on the mean .\nYour als No . By making it narrower ,\nRight ?\nuh y your\nI mean there 's  you 're  you 're allowing for less variance .\nMm - hmm .\nYes , so you making this particular dimension less important . Because see what you are fitting is the multidimensional Gaussian , right ?\nMm - hmm .\nIt 's a  it has  it has uh thirty - nine dimensions , or thirteen dimensions if you g ignore deltas and double - deltas .\nMm - hmm . Mm - hmm .\nSo in order  if you  in order to make dimension which  which Stephane sees uh less important , uh uh I mean not  not useful , less important , what you do is that this particular component in the model you can multiply by w you can  you can basically de - weight it in the model . But you can't do it in a  in a test data because you don't have a model for th I mean uh when the test comes , but what you can do is that you put this particular component in  and  and you compress it . That becomes uh th gets less variance , subsequently becomes less important .\nCouldn't you just do that to the test data and not do anything with your training data ?\nThat would be very bad , because uh your t your model was trained uh expecting uh , that wouldn't work . Because your model was trained expecting a certain var variance on C - one .\nUh - huh .\nAnd because the model thinks C - one is important . After you train the model , you sort of  y you could do  you could do still what I was proposing initially , that during the training you  you compress C - one that becomes  then it becomes less important in a training .\nMm - hmm .\nBut if you have  if you want to run e ex extensive experiment without retraining the model , you don't have to retrain the model . You train it on the original vector . But after , you  wh when you are doing this parametric study of importance of C - one you will de - weight the C - one component in the model , and you will put in the  you will compress the  this component in a  in the test data . s by the same amount .\nCould you also if you wanted to  if you wanted to try an experiment uh by  leaving out say , C - one , couldn't you , in your test data , uh modify the  all of the C - one values to be um way outside of the normal range of the Gaussian for C - one that was trained in the model ? So that effectively , the C - one never really contributes to the score ?\nMm - hmm .\nNo , that would be a severe mismatch ,\nDo you know what I 'm say\nright ? what you are proposing ? N no you don't want that .\nYeah , someth\nBecause that would  then your model would be unlikely . Your likelihood would be low , right ? Because you would be providing severe mismatch .\nMm - hmm . But what if you set if to the mean of the model , then ? And it was a cons you set all C - ones coming in through your test data , you  you change whatever value that was there to the mean that your model had .\nNo that would be very good match , right ?\nYeah .\nThat you would\nWhich  Well , yeah , but we have several means . So .\nI see what you are sa  saying ,\nRight ?\nSaying .\nbut uh ,  no , no I don't think that it would be the same . I mean , no , the  If you set it to a mean , that would  No , you can't do that . Y you ca you ca Ch - Chuck , you can't do that .\nOh , that 's true , right , yeah , because you  you have\nWait . Which\nBecause that would be a really f fiddling with the data ,\nYeah .\nyou can't do that .\nMm - hmm . Mm - hmm .\nBut what you can do , I 'm confident you ca\nwell , I 'm reasonably confident and I putting it on the record , right ? I mean y people will listen to it for  for centuries now , is  what you can do , is you train the model uh with the  with the original data .\nMm - hmm .\nThen you decide that you want to see how important C  C - one is . So what you will do is that a component in the model for C - one , you will divide it by  by two . And you will compress your test data by square root .\nMm - hmm .\nThen you will still have a perfect m match . Except that this component of C - one will be half as important in a  in a overall score .\nMm - hmm . Mm - hmm .\nThen you divide it by four and you take a square , f fourth root . Then if you think that some component is more  is more important then th th th it then  then uh uh i it is , based on training , then you uh multiply this particular component in the model by  by  by\nYou 're talking about the standard deviation ?\nyeah .\nYeah .\nYeah , multiply this component uh i it by number b larger than one ,\nMm - hmm .\nand you put your data in power higher than one . Then it becomes more important . In the overall score , I believe .\nYeah , but , at the\nBut  don't you have to do something to the mean , also ?\nNo .\nNo .\nYeah .\nNo .\nBut I think it 's  uh the  The variance is on  on the denominator in the  in the Gaussian equation . So . I think it 's maybe it 's the contrary . If you want to decrease the importance of a c parameter , you have to increase it 's variance .\nYes . Right . Yes .\nMultiply .\nExactly . Yeah . So you  so you may want to do it other way around ,\nHmm . That 's right . OK .\nyeah .\nMm - hmm .\nRight .\nBut if your  If your um original data for C - one had a mean of two .\nUh - huh .\nAnd now you 're  you 're  you 're changing that by squaring it . Now your mean of your C - one original data has   is four . But your model still has a mean of two . So even though you 've expended the range , your mean doesn't match anymore .\nMm - hmm .\nLet 's see .\nDo you see what I mean ?\nI think  What I see  What could be done is you don't change your features , which are computed once for all ,\nUh - huh .\nbut you just tune the model . So . You have your features . You train your  your model on these features .\nMm - hmm .\nAnd then if you want to decrease the importance of C - one you just take the variance of the C - one component in the  in the model and increase it if you want to decrease the importance of C - one or decrease it\nYeah .\nYeah .\nRight .\nYeah . You would have to modify the mean in the model . I  you  I agree with you . Yeah . Yeah , but I mean , but it 's  it 's i it 's do - able ,\nWell .\nYeah , so y\nright ? I mean , it 's predictable . Uh . Yeah .\nIt 's predictable , yeah .\nYeah . Yeah , it 's predictable .\nMmm .\nYeah . But as a simple thing , you could just  just muck with the variance .\nJust adjust the model , yeah .\nto get uh this  uh this  the effect I think that you 're talking about ,\nMm - hmm .\nright ?\nIt might be .\nCould increase the variance to decrease the importance .\nMm - hmm .\nMm - hmm .\nYeah , because if you had a huge variance , you 're dividing by a large number ,  you get a very small contribution .\nDoesn't matter\nYeah , it becomes more flat\nRight .\nand\nYeah .\nYeah .\nYeah .\nYeah , the sharper the variance , the more  more important to get that one right .\nHmm .\nMm - hmm .\nYeah , you know actually , this reminds me of something that happened uh when I was at BBN . We were playing with putting um pitch into the Mandarin recognizer .\nMm - hmm .\nAnd this particular pitch algorithm um when it didn't think there was any voicing , was spitting out zeros . So we were getting  uh when we did clustering , we were getting groups uh of features\np Pretty new outliers , interesting outliers , right ?\nyeah , with  with a mean of zero and basically zero variance .\nVariance .\nSo , when ener  when anytime any one of those vectors came in that had a zero in it , we got a great score . I mean it was just , {nonvocalsound} you know , incredibly {nonvocalsound} high score , and so that was throwing everything off .\nMm - hmm .\nSo  if you have very small variance you get really good scores when you get something that matches .\nYeah .\nMm - hmm .\nSo .  So that 's a way , yeah , yeah  That 's a way to increase the  yeah , n That 's interesting . So in fact , that would be  That doesn't require any retraining .\nYeah . No . No .\nNo , that 's right . So it 's\nSo that means it 's just\nYeah .\njust tuning the models and testing , actually .\nrecognitions .\nYeah .\nYeah .\nIt would be quick .\nYou  you have a step where you you modify the models , make a d copy of your models with whatever variance modifications you make , and rerun recognition .\nYeah .\nMm - hmm .\nYeah . Yeah . Yeah .\nAnd then do a whole bunch of those .\nYeah .", "topic_id": 2, "keywords": "fff, computes, computing, pow, exponents", "dialogue_id": 43}, {"text": "Mm - hmm .\nThat could be set up fairly easily I think , and you have a whole bunch of you know\nChuck is getting himself in trouble .\nThat 's an interesting idea , actually . For testing the  Yeah . Huh !\nDidn't you say you got these uh HTK 's set up on the new Linux boxes ?\nThat 's right .\nYeah .\nHey !\nIn fact , and  and they 're just t right now they 're installing uh  increasing the memory on that uh  the Linux box .\nAnd Chuck is sort of really fishing for how to keep his computer busy ,\nRight .\nright ?\nYeah . Absinthe .\nWell , you know , that 's\nAbsinthe . We 've got five processors on that .\nOh yeah .\nthat 's  yeah , that 's a good thing\nThat 's right .\nbecause then y you just write the \" do \" - loops and then you pretend that you are working while you are sort of  you c you can go fishing .\nAnd two gigs of memory .\nYeah .\nYeah .\nPretend , yeah .\nExactly . Yeah .\nGo fishing .\nSee how many cycles we used ?\nYeah . Then you are sort of in this mode like all of those ARPA people are , right ?\nYeah .\nUh , since it is on the record , I can't say uh which company it was , but it was reported to me that uh somebody visited a company and during a  d during a discussion , there was this guy who was always hitting the carriage returns uh on a computer .\nUh - huh .\nSo after two hours uh the visitor said \" wh why are you hitting this carriage return ? \" And he said \" well you know , we are being paid by a computer ty I mean we are  we have a government contract . And they pay us by  by amount of computer time we use . \" It was in old days when there were uh  of PDP - eights and that sort of thing .\nOh , my gosh ! So he had to make it look like\nBecause so they had a  they literally had to c monitor at the time  at the time on a computer how much time is being spent I  i i or on  on this particular project .\nYeah . How  Idle time .\nYeah .\nYeah .\nNobody was looking even at what was coming out .\nHave you ever seen those little um  It 's  it 's this thing that 's the shape of a bird and it has a red ball and its beak dips into the water ?\nYeah , I know , right .\nSo  if you could hook that up so it hit the keyboard\nYeah . Yeah . Yeah . Yeah .\nThat 's an interesting experiment .\nIt would be similar  similar to  I knew some people who were uh that was in old Communist uh Czechoslovakia , right ? so we were watching for American airplanes , coming to spy on  on uh  on us at the time ,\nMm - hmm . Mm - hmm .\nso there were three guys uh uh stationed in the middle of the woods on one l lonely uh watching tower , pretty much spending a year and a half there because there was this service right ? And so they  very quickly they made friends with local girls and local people in the village\nUgh !\nand\nYeah .\nand so but they  there was one plane flying over s always uh uh above , and so that was the only work which they had . They  like four in the afternoon they had to report there was a plane from Prague to Brno Basically f flying there ,\nYeah .\nso they f very q f first thing was that they would always run back and  and at four o ' clock and  and quickly make a call , \" this plane is uh uh passing \" then a second thing was that they  they took the line from this u u post to uh uh a local pub . And they were calling from the pub . And they  but third thing which they made , and when they screwed up , they  finally they had to p the  the p the pub owner to make these phone calls because they didn't even bother to be there anymore . And one day there was  there was no plane . At least they were sort of smart enough that they looked if the plane is flying there , right ? And the pub owner says \" oh my  four o ' clock , OK , quickly p pick up the phone , call that there 's a plane flying . \"\nYeah .\nThere was no plane for some reason ,\nAnd there wasn't ?\nit was downed , or   and  so they got in trouble . But .  But uh .\nHuh ! Well that 's  that 's a really i\nSo . So . Yeah .\nThat wouldn't be too difficult to try .\nYeah .\nMaybe I could set that up .\nYeah .\nAnd we 'll just\nWell , at least go test the s test the uh assumption about C - C - one I mean to begin with . But then of course one can then think about some predictable result to change all of them .\nMm - hmm .\nIt 's just like we used to do these uh  these uh  um the  the uh distance measures . It might be that uh\nYeah , so the first set of uh variance weighting vectors would be just you know one  modifying one and leaving the others the same .\nYeah . Yeah . Yeah . Yeah . Yeah .\nYeah . Maybe .\nAnd  and do that for each one .\nBecause you see , I mean , what is happening here in a  in a  in a  in such a model is that it 's  tells you yeah what has a low variance uh is uh  is uh  is more reliable ,\nThat would be one set of experiment\nright ? How do we\nWh - yeah , when the data matches that , then you get really\nYeah . Yeah . Yeah . Yeah . Yeah .\nYeah . Right .\nHow do we know , especially when it comes to noise ?\nBut there could just naturally be low variance .\nYeah ?\nBecause I  Like , I 've noticed in the higher cepstral coefficients , the numbers seem to get smaller , right ? So d\nThey  t\nI mean , just naturally .\nYeah .\nYeah , th that 's\nThey have smaller means , also . Uh .\nYeah . Exactly . And so it seems like they 're already sort of compressed .\nUh - huh .\nThe range  of values .\nYeah that 's why uh people used these lifters were inverse variance weighting lifters basically that makes uh uh Euclidean distance more like uh Mahalanobis distance with a diagonal covariance when you knew what all the variances were over the old data .\nMm - hmm . Mm - hmm . Hmm .\nWhat they would do is that they would weight each coefficient by inverse of the variance . Turns out that uh the variance decreases at least at fast , I believe , as the index of the cepstral coefficients . I think you can show that uh uh analytically .\nMm - hmm .\nSo typically what happens is that you  you need to weight the  uh weight the higher coefficients more than uh the lower coefficients .\nHmm . Mm - hmm . Hmm .\nSo .\nMmm .", "topic_id": 3, "keywords": "memory, chuck, processors, linux, busy", "dialogue_id": 43}, {"text": "When  Yeah . When we talked about Aurora still I wanted to m make a plea  uh encourage for uh more communication between  between uh  uh different uh parts of the distributed uh  uh center . Uh even when there is absolutely nothing to  to s to say but the weather is good in Ore - in  in Berkeley . I 'm sure that it 's being appreciated in Oregon and maybe it will generate similar responses down here , like , uh\nWe can set up a webcam maybe .\nYeah .\nYeah .\nWhat  you know , nowadays , yeah . It 's actually do - able , almost .\nIs the um  if we mail to \" Aurora - inhouse \" , does that go up to you guys also ?\nI don't think so . No .\nNo .\nOK .\nSo we should do that .\nSo i What is it\nYeah .\nWe should definitely set up\nYeah we sh Do we have a mailing list that includes uh the OGI people ?\nYeah .\nUh no . We don't have .\nUh - huh .\nOh ! Maybe we should set that up . That would make it much easier .\nYeah . Yeah . Yeah , that would make it easier .\nSo maybe just call it \" Aurora \" or something that would\nYeah . Yeah . And then we also can send the  the dis to the same address right , and it goes to everybody\nMm - hmm . Mm - hmm .\nYeah .\nOK . Maybe we can set that up .\nBecause what 's happening naturally in research , I know , is that people essentially start working on something and they don't want to be much bothered , right ? but what the  the  then the danger is in a group like this , is that two people are working on the same thing and i c of course both of them come with the s very good solution , but it could have been done somehow in half of the effort or something .\nMm - hmm .\nOh , there 's another thing which I wanted to uh uh report . Lucash , I think , uh wrote the software for this Aurora - two system . reasonably uh good one , because he 's doing it for Intel , but I trust that we have uh rights to uh use it uh or distribute it and everything . Cuz Intel 's intentions originally was to distribute it free of charge anyways .\nHmm !\nu s And so  so uh we  we will make sure that at least you can see the software and if  if  if  if it is of any use . Just uh\nMm - hmm .\nIt might be a reasonable point for p perhaps uh start converging .\nMm - hmm .\nBecause Morgan 's point is that  He is an experienced guy . He says \" well you know it 's very difficult to collaborate if you are working with supposedly the same thing , in quotes , except which is not s is not the same .\nMm - hmm .\nWhich  which uh uh one is using that set of hurdles , another one set  is using another set of hurdles . So . And  And then it 's difficult to c compare .\nWhat about Harry ? Uh . We received a mail last week and you are starting to  to do some experiments .\nHe got the  he got the software . Yeah . They sent the release .\nAnd use this Intel version .\nYeah . Yeah . Yeah . Yeah .\nHmm .\nYeah because Intel paid us uh should I say on a microphone ? uh some amount of money , not much . Not much I can say on a microphone . Much less then we should have gotten  for this amount of work . And they wanted uh to  to have software so that they can also play with it , which means that it has to be in a certain environment\nHmm .\nthey use actu actually some Intel libraries , but in the process , Lucash just rewrote the whole thing because he figured rather than trying to f make sense uh of uh  including ICSI software uh not for training on the nets\nHmm .\nOh .\nbut I think he rewrote the  the  the  or so maybe somehow reused over the parts of the thing so that  so that  the whole thing , including MLP , trained MLP is one piece of uh software .\nMm - hmm . Wow !\nIs it useful ?\nYe - Yeah .\nYeah ?\nI mean , I remember when we were trying to put together all the ICSI software for the submission .\nOr  That 's what he was saying , right . He said that it was like  it was like just so many libraries and nobody knew what was used when , and  and so that 's where he started and that 's where he realized that it needs to be  needs to be uh uh at least cleaned up ,\nYeah .\nMm - hmm .\nand so I think it  this is available .\nHmm .\nSo\nYeah . Well , the  the only thing I would check is if he  does he use Intel math libraries ,\nuh e ev\nbecause if it 's the case , it 's maybe not so easy to use it on another architecture .\nn not maybe  Maybe not in a first  maybe not in a first ap approximation because I think he started first just with a plain C  C or C - plus - plus or something before\nAh yeah . Mm - hmm .\nI  I can check on that . Yeah .\nYeah .\nHmm .\nAnd uh in  otherwise the Intel libraries , I think they are available free of f freely . But they may be running only on  on uh  on uh Windows .\nYeah .\nOr on  on the\nOn Intel architecture maybe .\nYeah , on Intel architecture , may not run in SUN .\nI 'm  Yeah .\nYeah .\nYeah .\nThat is p that is  that is possible . That 's why Intel of course is distributing it ,\nWell .\nright ? Or   That 's\nYeah . Well there are  at least there are optimized version for their architecture .\nYeah .\nI don't know . I never checked carefully these sorts of\nI know there was some issues that initially of course we d do all the development on Linux but we use  we don't have  we have only three uh uh uh uh s SUNs and we have them only because they have a SPERT board in . Otherwise  otherwise we t almost exclusively are working with uh PC 's now , with Intel . In that way Intel succeeded with us , because they gave us too many good machines for very little money or nothing .\nYeah .\nSo . So . So we run everything on Intel .\nWow !\nAnd\nHmm . Does anybody have anything else ? to  Shall we read some digits ?\nYeah .\nYes . I have to take my glasses\nSo . Hynek , I don't know if you 've ever done this .\nNo .\nThe way that it works is each person goes around in turn ,  and uh you say the transcript number and then you read the digits , the  the strings of numbers as individual digits .\nMm - hmm .\nSo you don't say \" eight hundred and fifty \" , you say \" eight five oh \" , and so forth .\nOK . OK . So can  maybe  can I t maybe start then ?\nUm . Sure .", "topic_id": 4, "keywords": "aurora, mailing, communication, mail, distributed", "dialogue_id": 43}, {"text": "OK .\nUh . Somebody else should run this . I 'm sick of being the one to sort of go through and say , \" Well , what do you think about this ? \" You wanna  ?\nYeah .\nShould we take turns ? You want me to run it today ?\nYeah . Why don't you run it today ? OK .\nOK . OK . Um . Let 's see , maybe we should just get a list of items  things that we should talk about . Um , I guess there 's the usual  updates , everybody going around and saying , uh , you know , what they 're working on , the things that happened the last week . But aside from that is there anything in particular that anybody wants to bring up\nMmm .\nfor today ? No ? OK . So why don't we just around and people can give updates .\nOh .\nUh , do you want to start , Stephane ?\nAlright . Um . Well , the first thing maybe is that the p Eurospeech paper is , uh , accepted . Um . Yeah .\nThis is  what  what do you , uh  what 's in the paper there ?\nSo it 's the paper that describe basically the , um , system that were proposed for the  Aurora .\nThe one that we s we submitted the last round ?\nRight , yeah .\nYeah .\nUh - huh .\nUm  Yeah . So and the , fff  comments seems  from the reviewer are good . So .\nHmm .\nMmm  Yeah .\nWhere  where 's it gonna be this year ?\nIt 's , uh , Aalborg in Denmark . And it 's ,\nOh , OK .\nyeah , September .\nMmm .\nMmm  Yeah . Then , uh , whhh well , I 've been working on  on t mainly on on - line normalization this week . Uh , I 've been trying different  slightly  slightly different approaches . Um , the first thing is trying to play a little bit again with the , um , time constant . Uh , second thing is , uh , the training of , uh , on - line normalization with two different means , one mean for the silence and one for the speech . Um , and so I have two recursions which are controlled by the , um , probability of the voice activity detector . Mmm . This actually don't s doesn't seem to help , although it doesn't hurt . So . But  well , both  on - line normalization approach seems equivalent . Well , they\nAre the means pretty different  for the two ?\nYeah . They can be very different . Yeah . Mm - hmm .\nHmm .\nSo do you maybe make errors in different places ? Different kinds of errors ?\nI didn't look , uh , more closely . Um . It might be , yeah . Mm - hmm . Um . Well , eh , there is one thing that we can observe , is that the mean are more different for  for C - zero and C - one than for the other coefficients . And  Yeah . And  Yeah , it  the C - one is  There are strange  strange thing happening with C - one , is that when you have different kind of noises , the mean for the  the silence portion is  can be different . And\nHmm .\nSo when you look at the trajectory of C - one , it 's  has a strange shape and I was expecting th the s that these two mean helps , especially because of the  the strange C - ze C - one shape , uh , which can  like , yo you can have , um , a trajectory for the speech and then when you are in the silence it goes somewhere , but if the noise is different it goes somewhere else .\nOh .\nSo which would mean that if we estimate the mean based on all the signal , even though we have frame dropping , but we don't frame ev uh , drop everything , but  uh , this can  hurts the estimation of the mean for speech , and  Mmm .  But I still have to investigate further , I think . Um , a third thing is , um ,  that instead of t having a fixed time constant , I try to have a time constant that 's smaller at the beginning of the utterances to adapt more quickly to the r something that 's closer to the right mean . T t um  Yeah . And then this time constant increases and I have a threshold that\nMm - hmm .\nwell , if it 's higher than a certain threshold , I keep it to this threshold to still , uh , adapt , um , the mean when   if the utterance is , uh , long enough to  to continue to adapt after , like , one second\nMm - hmm . Mm - hmm .\nor  Mmm . Uh , well , this doesn't help neither , but this doesn't hurt . So , well . It seems pretty\nWasn't there some experiment you were gonna try where you did something differently for each , um ,  uh  I don't know whether it was each mel band or each , uh , um , FFT bin or someth There was something you were gonna  uh ,  some parameter you were gonna vary depending on the frequency . I don't know if that was\nI guess it was  I don't know . No . u Maybe it 's this  this idea of having different  on - line normalization , um , tunings for the different MFCC 's .\nFor each , uh\nMm - hmm .\nBut  Mm - hmm .\nYeah . I  I thought , Morgan , you brought it up a couple meetings ago . And then it was something about , uh , some and then somebody said \" yeah , it does seem like , you know , C - zero is the one that 's , you know , the major one \" or , uh , s I can't remember exactly what it was now .\nMmm . Yeah . There  uh , actually , yeah . S um , it 's very important to normalize C - zero and  much less to normalize the other coefficients . And , um , actu uh , well , at least with the current on - line normalization scheme . And we  I think , we  kind of know that normalizing C - one doesn't help with the current scheme . And  and  Yeah . In my idea , I  I was thinking that the  the  the reason is maybe because of these funny things that happen between speech and silence which have different means . Um  Yeah . But maybe it 's not so   so easy to\nUm , I I really would like to suggest looking , um , a little bit at the kinds of errors . I know you can get lost in that and go forever and not see too much , but   sometimes ,\nMm - hmm .\nbut  but , um , just seeing that each of these things didn't make things better may not be enough . It may be that they 're making them better in some ways and worse in others ,\nYeah . Mm - hmm .\nor increasing insertions and decreasing deletions , or  or , um , um , you know , helping with noisy case but hurting in quiet case . And if you saw that then maybe you  it would   something would occur to you of how to deal with that .\nMm - hmm . Mm - hmm .\nHmm .\nAlright . Mmm . Yeah . W um , So that 's it , I think , for the on - line normalization . Um  Yeah . I 've been playing a little bit with some kind of thresholding , and , mmm , as a first experiment , I think I Yeah . Well , what I did is t is to take , um   to measure the average  no , the maximum energy of s each utterance and then put a threshold  Well , this for each mel band . Then put a threshold that 's fifteen DB below  well , uh , a couple of DB below this maximum ,\nMm - hmm . Mmm .\nand  Actually it was not a threshold , it was just adding noise .\nMm - hmm .\nSo I was adding a white noise energy , uh , that 's fifteen DB below the maximum energy of the utterance . And  Yeah . When we look at  at the , um , MFCC that result from this , they are  a lot more smoother . Um , when we compare , like , a channel zero and channel one utterance  um , so a clean and , uh , the same noisy utterance  well , there is almost no difference between the cepstral coefficients of the two .\nHmm .\nUm . And  Yeah . And the result that we have in term of speech recognition , actually it 's not  it 's not worse , it 's not better neither , but it 's , um , kind of surprising that it 's not worse\nHmm .\nbecause basically you add noise that 's fifteen DB  just fifteen DB below  the maximum energy .\nSorry .\nAnd at least\nSo why does that m  smooth things out ? I don't  I don't understand that .\nWell , there 's less difference . Right ?\nIt 's  I think , it 's whitening  This  the portion that are more silent ,\nCuz it 's\nas you add a white noise that are  has a very high energy , it whitens everything\nHuh . Oh , OK .\nand  and the high - energy portion of the speech don't get much affected anyway by the other noise . And as the noise you add is the same is   the shape , it 's also the same .\nHmm .\nYeah .\nSo they have  the trajectory are very , very similar . And  and\nSo , I mean , again , if you trained in one kind of noise and tested in the same kind of noise , you 'd  you know , given enough training data you don't do b do badly . The reason that we d that we have the problems we have is because  it 's different in training and test . Even if  the general kind is the same , the exact instances are different . And  and\nMm - hmm .\nso when you whiten it , then it 's like you  the  the only noise  to  to first order , the only th noise that you have is white noise and you 've added the same thing to training and test .\nMm - hmm .\nSo it 's ,\nHmm .\nuh\nSo would that  be similar to , like , doing the smoothing , then , over time or  ?\nMm - hmm .\nWell , it 's a kind of smoothing ,\nI think it 's  I think it 's different .\nbut\nIt 's  it 's something that  yeah , that affects more or less the silence portions because\nMm - hmm .\nWell , anyway , the sp the portion of speech that ha have high energy are not ch a lot affected by the noises in the Aurora database .\nMm - hmm .\nIf  if you compare th the two shut channels of SpeechDat - Car during speech portion , it 's n n n the MFCC are not very different . They are very different when energy 's lower , like during fricatives or during speech pauses . And ,\nYeah , but you 're still getting more recognition errors ,\nuh\nwhich means  that the differences , even though they look like they 're not so big ,  are  are hurting your recognition .\nYe\nRight ?\nYeah . So it distort  the speech . Right .\nYeah .\nUm .\nSo performance went down ?\nNo . It didn't . But\nOh .\nYeah . So , but in this case I  I really expect that maybe the  the two  these two stream of features , they are very different . I mean , and maybe we could gain something by combining them\nWell , the other thing is that you just picked one particular way of doing it .\nor\nUh , I mean , first place it 's fifteen DB , uh ,  down across the utterance . And  maybe you 'd want to have something that was a little more adaptive . Secondly , you happened to pick fifteen DB\nMmm .\nand maybe twenty 'd be better ,\nYeah .\nor  or twelve .\nYeah . Right .\nSo what was the  what was the threshold part of it ? Was the threshold , uh , how far down  ?\nYeah . Well , he  yeah , he had to figure out how much to add . So he was looking  he was looking at the peak value .\nUh - huh .\nRight ? And then\nUh - huh .\nAnd  and so what 's  ho I don't understand . How does it go ? If it  if  if the peak value 's above some threshold , then you add the noise ? Or if it 's below s\nI systematically  add the noise , but the , um , noise level is just  some kind of threshold below the peak .\nOh , oh . I see .\nMmm .\nI see .\nYeah .\nUm . Yeah . Which is not really noise , actually . It 's just adding a constant to each of the mel , uh , energy .\nMm - hmm .\nTo each of the  mel filter bank . Yeah .\nI see .\nSo , yeah , it 's really , uh , white noise . I th\nYeah .\nMm - hmm .\nSo then afterwards a log is taken , and that 's so sort of why the   the little variation tends to go away .\nMm - hmm . Um . Yeah . So may Well , the  this threshold is still a factor that we have to look at . And I don't know , maybe a constant noise addition would   would be fine also , or  Um\nOr  or not constant but  but , uh , varying over time  in fact is another way  to go .\nMm - hmm . Mm - hmm .\nUm .\nYeah . Um\nWere you using the  the normalization in addition to this ? I mean , what was the rest of the system ?\nUm  Yeah . It was  it was , uh , the same system . Mm - hmm .\nOK .\nIt was the same system . Mmm . Oh , yeah . A third thing is that , um ,  I play a little bit with the , um   finding what was different between , um , And there were a couple of differences , like the LDA filters were not the same . Um , he had the France Telecom blind equalization in the system . Um , the number o of MFCC that was  were used was different . You used thirteen and we used fifteen . Well , a bunch of differences . And , um , actually the result that he  he got were much better on TI - digits especially . So I 'm kind of investigated to see what was the main factor for this difference . And it seems that the LDA filter is  is  was hurting . Um ,  so when we put s some noise compensation the , um , LDA filter that  that 's derived from noisy speech is not more  anymore optimal . And it makes a big difference , um ,  on TI - digits trained on clean . Uh , if we use the  the old LDA filter , I mean the LDA filter that was in the proposal , we have , like , eighty - two point seven percent recognition rate , um , on noisy speech when the system is trained on clean speech . But  and when we use the filter that 's derived from clean speech we jumped  so from eighty - two point seven to eighty - five point one , which is a huge leap .\nMm - hmm .\nUm . Yeah . So now the results are more similar , and I don't  I will not , I think , investigate on the other differences , which is like the number of MFCC that we keep and other small things that we can I think optimize later on anyway .\nSure . But on the other hand if everybody is trying different kinds of noise suppression things and so forth , it might be good to standardize on the piece  that we 're not changing . Right ? So if there 's any particular reason to ha pick one or the other , I mean  Which  which one is closer to what the proposal was that was submitted to Aurora ? Are they  they both  ? Well , I mean\nI think  Yeah . I think th th uh , the new system that I tested is , I guess , closer because it doesn't have  it have less of  of France Telecom stuff ,\nYou mean the\nI\nThe  whatever you , uh , tested with recently . Right ?\nMmm ? Yeah .\nYeah ?\nWell , no , I  I 'm  I  Yeah , you 're trying to add in France Telecom .\nBut , we\nTell them about the rest of it . Like you said the number of filters might be  different or something . Right ? Or\nThe number of cepstral coefficients is what ?\nCep\nMm - hmm .\nYeah . So , I mean , I think we 'd wanna standardize there , wouldn't we ?\nYeah , yeah .\nSo , sh you guys should pick something\nYeah .\nand  Well , all th all three of you .\nYeah .\nI think we were gonna work with  with this or this new system , or with\nUh , so the  the  right now , the  the system that is there in the  what we have in the repositories , with  uses fifteen .\nSo  Right . Yeah .\nYeah , so  Yeah , so  Yep .\nBut we will use the  the LDA filters f derived from clean speech . Well , yeah , actually it 's  it 's not the  the LDA filter .\nYeah , yeah . So\nIt 's something that 's also short enough in  in latency .\nYeah . Well .\nSo .\nYeah . So , we haven't  w we have been always using , uh , fifteen coefficients ,\nYeah .\nnot thirteen ?\nMm - hmm .\nYeah . Well , uh , that 's  something 's  Um . Yeah . Then\nI think as long as you guys agree on it , it doesn't matter .\nmmm\nI think we have a maximum of sixty ,  uh , features that we 're allowed . So .\nYeah .\nYeah . Ma - maybe we can  I mean , at least , um , I 'll t s run some experiments to see whether  once I have this   noise compensation to see whether thirteen and fifteen really matters or not .\nMm - hmm . Mm - hmm .\nNever tested it with the compensation , but without ,  uh , compensation it was like fifteen was s slightly better than thirteen ,\nYeah .\nso that 's why we stuck to thirteen .\nYeah . And there is  there is also this log energy versus C - zero .\nSorry , fifteen . Yeah , the log energy versus C - zero .\nWell . W w if  if\nUh , that 's  that 's the other thing . I mean , without noise compensation certainly C - zero is better than log energy . Be - I mean , because the  there are more , uh , mismatched conditions than the matching conditions for testing .\nMm - hmm .\nYou know , always for the matched condition , you always get a  slightly better performance for log energy than C - zero .\nMm - hmm .\nBut not for  I mean , for matched and the clean condition both , you get log energy  I mean you get a better performance with log energy .\nMm - hmm .\nWell , um , maybe once we have this noise compensation , I don't know , we have to try that also , whether we want to go for C - zero or log energy .\nMm - hmm .\nWe can see that .\nYeah .\nHmm .\nMmm .\nSo do you have  more , Stephane , or  ?", "topic_id": 0, "keywords": "eurospeech, stephane, paper, things, updates", "dialogue_id": 44}, {"text": "Uh , that 's it , I think . Mmm .\nDo you have anything , Morgan , or  ?\nUh , no . I 'm just , you know , being a manager this week . So .\nHow about you , Barry ?\nUm ,  still working on my  my quals preparation stuff . Um ,  so I 'm  I 'm thinking about , um , starting some ,  uh , cheating experiments to , uh , determine the , um   the relative effectiveness of , um , some intermediate categories that I want to classify . So , for example , um ,  if I know where voicing occurs and everything , um ,  I would do a phone  um , phone recognition experiment , um , somehow putting in the  the , uh  the perfect knowledge that I have about voicing . So , um , in particular I was thinking ,  um , in  in the hybrid framework , just taking those LNA files ,  and , um ,  setting to zero those probabilities that , um  that these phones are not voicing . So say , like , I know this particular segment is voicing , um ,  I would say , uh , go into the corresponding LNA file and zonk out the  the posteriors for , um , those phonemes that , um , are not voiced ,\nMm - hmm . Mm - hmm .\nand then see what kinds of improvements I get . And so this would be a useful thing , um , to know  in terms of , like , which  which , um  which of these categories are  are good for , um , speech recognition .\nHmm . Mm - hmm .\nSo , that 's  I hope to get those , uh  those experiments done by  by the time quals come  come around in July .\nSo do you just take the probabilities of the other ones and spread them out evenly among the  the remaining ones ?\nYeah . I  I  I was thinking  OK , so just set to  set to some really low number , the  the non - voiced , um , phones .\nMm - hmm .\nRight ? And then renormalize .\nMmm .\nRight . Yeah .\nMm - hmm .\nCool . That will be really interesting to see , you know . So then you 're gonna feed the  those into  some standard recognizer .\nMm - hmm .\nUh , wh are you gonna do digits\nYeah , m Um , well , I 'm gonna f work with TIMIT\nor  ? With TIMIT . OK .\nTIMIT  uh , phone recognition with TIMIT .\nMm - hmm .\nAnd , um\nOh , so then you 'll feed those  Sorry . So where do the outputs of the net go into if you 're doing phone recognition ?\nOh . Um , the outputs of the net go into the standard , h um , ICSI hybrid , um , recognizer . So maybe , um , Chronos\nAn - and you 're gonna  the  you 're gonna do phone recognition with that ?\nor  Phone recognition . Right , right .\nOK , OK . I see .\nSo . And , uh , another thing would be to extend this to , uh , digits or something where I can look at whole words .\nMm - hmm .\nAnd I would be able to see , uh , not just , like , phoneme events , but , um ,  inter - phoneme events . So , like , this is from a stop to  to a vo a vocalic\nMm - hmm .\nsegment . You know , so something that is transitional in nature .\nRight .\nYeah .\nCool . Great .\nSo that 's  that 's it .\nUh  OK .\nYeah .\nUm  Let 's see , I haven't done a whole lot on anything related to this this week . I 've been focusing mainly on Meeting Recorder stuff .\nOh .\nSo , um ,  I guess I 'll just pass it on to Dave .\nUh , OK . Well , in my lunch talk last week I  I said I 'd tried phase normalization and gotten garbage results using that l um , long - term mean subtraction approach . It turned out there was a bug in my Matlab code . So I tried it again , um , and , um , the results  were  were better . I got intelligible speech back . But they still weren't as good as just subtracting the magnitude  the log magnitude means . And also I 've been talking to , um , Andreas and Thilo about the , um , SmartKom language model and about coming up with a good model for , um , far mike use of the SmartKom system . So I 'm gonna be working on , um , implementing this mean subtraction approach in the  far - mike system  for the SmartKom system , I mean . And , um , one of the experiments we 're gonna do is , um , we 're gonna , um , train the  a Broadcast News net , which is because that 's what we 've been using so far , and , um , adapt it on some other data . Um , An - Andreas wants to use , um , data that resembles read speech , like  these digit readings , because he feels that the SmartKom system interaction is not gonna be exactly conversational .\nMm - hmm .\nS so actually I was wondering , how long does it take to train that Broadcast News net ?\nThe big one takes a while . Yeah . That takes two , three weeks .\nTwo , three weeks .\nSo  but , you know , uh , you can get  I don't know if you even want to run the big one , uh , um , in the  in the final system , cuz , you know , it takes a little while to run it . So ,  um , you can scale it down by  I 'm sorry , it was two , three weeks for training up for the large Broadcast News test set  training set . I don't know how much you 'd be training on .\nOh .\nThe full ?\nOK .\nUh , i so if you trained on half as much  and made the net , uh , uh , half as big , then it would be one fourth  the amount of time\nOK .\nand it 'd be nearly as good . So .\nOK .\nYeah . Also , I guess we had  we 've had these , uh , little di discussions  I guess you ha haven't had a chance to work with it too much  about  about , uh  uh , uh m other ways of taking care of the phase . So , I mean , I  I guess that was something I could say would be that we 've talked a little bit about\nMm - hmm .\nyou just doing it all with complex arithmetic and , uh  and not  not , uh , doing the polar representation with magnitude and phase . But  it looks like there 's ways that one could potentially just work with the complex numbers and  and  and in principle get rid of the  effects of the average complex spectrum . But\nAnd , um , actually , regarding the phase normalization  So I did two experiments , and one is  So , phases get added , modulo two pi , and  because you only know the phase of the complex number t t to a value modulo two pi . And so I thought at first , um , that , uh , what I should do is unwrap the phase because that will undo that . Um , but I actually got worse results doing that unwrapping using the simple phase unwrapper that 's in Matlab than I did not unwrapping at all .\nMm - hmm .\nHmm .\nYeah . P So .\nAnd that 's all I have to say .\nHmm .\nYeah . So I 'm  I 'm still hopeful that  that  I mean , we  we don't even know if the phase  is something  the average phase is something that we do want to remove . I mean , maybe there 's some deeper reason why it isn't the right thing to do . But , um , at least in principle it looks like there 's  there 's , uh , a couple potential ways to do it . One  one being to just work with the complex numbers , um , and , uh  in rectangular kind of coordinates . And the other is  to , uh , do a Taylor series  Well . So you work with the complex numbers and then when you get the spectrum  the average complex spectrum  um , actually divide it out , um , as opposed to taking the log and subtracting . So then , um , um , you know , there might be some numerical issues . We don't really know that . The other thing we talked a little bit about was Taylor series expansion . And , um , uh , actually I was talking to Dick Karp about it a little bit , and  and  and , since I got thinking about it , and  and , uh , so one thing is that y you 'd have to do , I think , uh  we may have to do this on a whiteboard , but I think you have to be a little careful about scaling the numbers that you 're  taking  the complex numbers that you 're taking the log of because  the Taylor expansion for it has , you know , a square and a cube , and  and so forth . And  and so if   if you have a  a number that is modulus , you know , uh , very different from one   It should be right around one , if it 's  cuz it 's a expansion of log one  one minus epsilon or o is  is  one plus epsilon , or is it one plus  ? Well , there 's an epsilon squared over two and an epsilon cubed over three ,\nOK .\nand so forth . So if epsilon is bigger than one , then it diverges .\nOh .\nSo you have to do some scaling . But that 's not a big deal cuz it 's the log of   of K times a complex number , then you can just  that 's the same as log of K plus  log of the complex number .\nOh .\nUh , so there 's\nOK .\nconverges . But .", "topic_id": 1, "keywords": "phonemes, classify, hybrid, voicing, lna", "dialogue_id": 44}, {"text": "Hmm . OK . How about you , Sunil ?\nSo , um , I 've been , uh , implementing this , uh , Wiener filtering for this Aurora task . And , uh , I  I actually thought it was  it was doing fine when I tested it once . I it 's , like , using a small section of the code . And then I ran the whole recognition experiment with Italian and I got ,  like , worse results than not using it . Then I  So , I 've been trying to find where the problem came from . And then it looks like I have some problem in the way  there is some  some very silly bug somewhere . And , ugh ! I  I mean , i uh , it actually  i it actually made the whole thing worse . I was looking at the spectrograms that I got and it 's , like  w it 's  it 's very horrible . Like , when I\nI  I missed the v I 'm sorry , I was  I was distracted . I missed the very first sentence . So then , I 'm a little lost on the rest .\nOh , I mean\nWhat  what  what  ?\nOh , yeah . I actually implemented the Wiener f f fil filtering as a module and then tested it out separately .\nYeah , I see . Oh , OK .\nAnd it  it  it gave , like  I just got the signal out and it  it was OK . So , I plugged it in somewhere and then  I mean , it 's like I had to remove some part and then plugging it in somewhere . And then I  in that process I messed it up somewhere .\nOK .\nSo . So , it was real I mean , I thought it was all fine and then I ran it , and I got something worse than not using it . So , I was like  I 'm trying to find where the m m problem came ,\nUh - huh .\nand it seems to be , like , somewhere\nOK .\nsome silly stuff . And , um , the other thing , uh , was , uh , uh  Well , Hynek showed up one  suddenly on one day and then I was t talking wi\nRight . Yeah . As  as he is wont to do . Yeah .\nUh , yeah . So I was actually  that day I was thinking about d doing something about the Wiener filtering , and then Carlos matter of stuff . And then he showed up and then I told him . And then he gave me a whole bunch of filters  what Carlos used for his , uh , uh , thesis and then  that was something which came up . And then , um  So , uh , I 'm actually ,  uh , thinking of using that also in this , uh , W Wiener filtering because that is a m modified Wiener filtering approach , where instead of using the current frame , it uses  adjacent frames also in designing the Wiener filter . So instead of designing our own new Wiener filters , I may just use one of those Carlos filters in  in this implementation\nMm - hmm .\nand see whether it  it actually gives me something better than using just the current f current frame , which is in a way , uh , something like the smoothing  the Wiener filter\nMm - hmm .\nbut @ @  S so , I don't know , I was h I 'm  I 'm  I 'm , like  that  so that is the next thing . Once this  I  once I sort this pro uh , problem out maybe I 'll just go into that also . And the  the other thing was about the subspace approach . So , um , I , like , plugged some groupings for computing this eigen uh , uh , uh , s values and eigenvectors . So just  I just @ @ some small block of things which I needed to put together for the subspace approach . And I 'm in the process of , like , building up that stuff . And , um , uh  {nonvocalsound} Yeah . I guess  Yep . I guess that 's it . And , uh , th th that 's where I am right now . So .\nOh . How about you , Carmen ?\nMmm . I 'm working with VTS . Um , I do several experiment with the Spanish database first , only with VTS and nothing more . Not VAD , no LDA , nothing more .\nWhat  what is VTS again ?\nNew\nEh , Vectorial Taylor Series .\nOh , yes .\nTo remove the noise too .\nRight , right . I think I ask you that every single meeting , don't I ?\nWhat ?\nI ask you that question every meeting .\nYeah .\nSo , that 'd be good from  for analysis .\nIf  Well\nIt 's good to have some , uh , cases of the same utterance at different  different times .\nYeah .\nYeah .\n\" What is VTS ? \"\nVTS . I 'm sor Well , um , the question is that  Well . Remove some noise but not too much . And when we put the  m m the , em , VAD , the result is better . And we put everything , the result is better , but it 's not better than the result that we have without VTS . No , no .\nI see . So that @ @  given that you 're using the VAD also , the effect of the VTS is not  so far\nIs not .\nDo you  How much of that do you think is due to just the particular implementation and how much you 're adjusting it ? Or how much do you think is intrinsic to  ?\nPfft . I don't know because\nAre you still using only the ten first frame for noise estimation\nHhh ,\nor  ? Or i ?\nUh , I do the experiment using only the f onl eh , to use on only one fair estimation of the noise .\nYeah . Hmm .\nAnd also I did some experiment ,  uh , doing , um , a lying estimation of the noise . And , well , it 's a little bit better but not  n\nMaybe you have to standardize this thing also , noise estimation , because all the thing that you are testing use a different  They all need some  some noise  noise spectra\nMmm .\nMmm . No , I do that two  t did two time .\nbut they use  every  all use a different one .\nI have an idea . If  if , uh , uh , y you 're right . I mean , each of these require this . Um , given that we 're going to have for this test at least of  uh , boundaries , what if initially we start off by using  known sections of nonspeech  for the estimation ?\nMm - hmm .\nMm - hmm .\nRight ? S so , e um ,\nYeah . Mm - hmm .\nfirst place , I mean even if ultimately we wouldn't be given the boundaries ,  uh , this would be a good initial experiment to separate out the effects of things . I mean , how much is the poor   you know , relatively , uh , unhelpful result that you 're getting in this or this or this is due to some inherent limitation to the method for these tasks and how much of it is just due to the fact that you 're not accurately  finding enough regions that  that are really  n noise ?\nMmm .\nMm - hmm .\nMm - hmm .\nUm . So maybe if you tested it using that ,  you 'd have more reliable  stretches of nonspeech to do the estimation from and see if that helps .\nYeah . Another thing is the , em  the codebook , the initial codebook . That maybe , well , it 's too clean and\nMm - hmm .\nCuz it 's a  I don't know . The methods  If you want , you c I can say something about the method .\nMm - hmm .\nYeah . In the  Because it 's  a little bit different of the other method . Well , we have  If this  if this is the noise signal , {nonvocalsound} uh , in the log domain , we have something like this . Now , we have something like this . And the idea of these methods is to   n given a , um\nHow do you say ? I will read because it 's better for my English . I i given is the estimate of the PDF of the noise signal when we have a , um , a statistic of the clean speech and an statistic of the noisy speech . And the clean speech  the statistic of the clean speech is  from a  codebook . Mmm ? This is the idea . Well , like , this relation is not linear . The methods propose to develop this in a vectorial Taylor series  approximation .\nI I 'm actually just confused about  the equations you have up there . So , uh , the top equation is  is  is\nNo , this in the  it 's  this is the log domain . I  I must to say that .\nWhich is  which is the log domain ?\nIs the T  is egual   is equal to , uh , log of\nAnd  but Y is what ? Y of  the spectrum\nUh , this  this is this\nor  ?\nand this is this .\nNo , no . The top Y is what ?\nMm - hmm .\nIs that power spectrum ?\nUh , this is the noisy speech .\np s this\nNo , is that power spectrum ? Is it  ?\nYeah . I guess it 's the power spectrum of noisy speech .\nYeah . It 's the power spectrum .\nOh , OK .\nYeah . And\nSo that 's uh\nThis is the noisy  Yeah , it 's\nOK .\nof the value\nYeah , OK . So this  it 's the magnitude squared or something .\nYeah .\nOK , so you have power spectrum added there and down here you have   you  you put the  depends on T , but  b all of this is just  you just mean\nw o Yeah . It 's the same .\nyou just mean the log of the  of the one up above .\nYeah .\nAnd , uh , so that is X times ,\nMm - hmm .\nuh ,\nOne  one plus N by X .\nYeah , maybe\no\nBut , n Well , y we can expre we can put this expression\nX times one plus , uh , N  uh , N  N  N minus X ?\nThe  Yeah .\nAnd then , uh  So that 's log of X plus log of one plus , uh\nAnd the noise signal .\nWell . Is that right ? Log of\nOne plus N by X .\nWell , mmm\nI actually don't see how you get that . Uh .\nWell , if we apply the log , we have E is n\nMmm .\nUh , and\nuh , log  {nonvocalsound} E is equal , oh , to log of X plus N .\nYeah .\nAnd , well ,\nAnd , log of\nuh , we can say that E {nonvocalsound}  is equal to log of , {nonvocalsound} {nonvocalsound} um , exponential of X plus exponential of N .\nUh\nMm - hmm .\nNo .\nNo .\nThat doesn't follow .\nWell , if E restricts  It is y\nWell , this is  this is in the ti the time domain . Well , we have that , um  We have first that , for example , X is equal , uh  Well . This is the frequency domain\nYeah .\nand we can put  u that n the log domain  log of X omega , but , well , in the time domain we have an exponential . No ? No ? Oh , maybe it 's I am  I 'm problem .\nYeah . I mean , just never mind what they are . Uh , it 's just if X and N are variables  Right ?\nWhat is , uh  ?\nThe  the  the log of X plus N is not the same as the log of E to the X plus E to the N .\nYeah . But this i Well , I don't  Well , uh ,\nMaybe we can take it off - line ,\nmaybe\nbut I  I don't know .\nI  I can do this incorrectly . Well , the expression that appear in the  in the paper , {nonvocalsound} is , uh\nThe log  the Taylor series expansion for log one plus N by X is\nOK .\nIs it the first - order expansion ?\nis X\nI i\nYeah , the first one .\nYeah , I guess .\nYeah .\nOK . Yeah . Cuz it doesn't just follow what 's there .\nYeah .\nYeah .\nUh - huh .\nIt has to be some , uh , Taylor series\nY yeah . If  if you take log X into log one plus N by X , and then expand the log one plus N by X into Taylor series\nYeah .\nNow , this is the  and then\nYeah , but the  the second  expression that you put is the first - order expansion of the nonlinear relation between\nNot exactly .\nNo .\nNo , no , no . It 's not the first space . Well , we have  pfft , uh , em  Well , we can put that X is equal  I is equal to log of , uh , mmm\nThat doesn't follow .\nMmm .\nWell , we can put , uh , this ?\nNo .\nThat  I mean , that  the f top one does not  imply the second one . Because  cuz the log of a sum is not the same as  th\nThe top ?\nI mean , as\nYeah , yeah , yeah , yeah , yeah .\nYeah .\nBut we can  uh , we  we know that , for example , the log of  E plus B is equal to log of E plus log to B .\nRight .\nAnd we can say here , it i\nRight . So you could s\nWhat is that ?\nAnd we can , uh , put this inside .\nYeah .\nAnd then we can , uh ,\nN no ,\nyou know\nbut\nYeah .\nI don't see how you get the second expression from the top one .\nUh .\nThe  I mean , just more generally here ,  if you say \" log of , um , A plus B \" , the log of  log of A plus B is not  or A plus B is not the , um , log of E to the A plus E to the B .\nNo , no , no , no , no , no , no . This not .\nRight ? And that 's what you seem to be saying .\nNo . No . It 's not . But this is the same  oh .\nRight ? Cuz you  cuz you  up here you have the A plus B\nNo . I say if I apply log , I have , uh , log of E is equal to log of , uh  in this side , is equal to log of X\nPlus N .\nplus N .\nRight .\nNo ?\nRight .\nRight .\nAnd then how do you go from there to the  ?\nThis is right . And then if I apply exponential , to have here E\nLook . OK , so let 's  I mean , C equals A plus B ,\nIt 's log o of capital Y . Yeah , right .\nand then\nCapital  Y .\nYeah .\nX . X . This is X , inside .\nMm - hmm .\nRight .\nWe have this , no ?\nYeah . That one 's right .\nMm - hmm .\nOne and\nS uh , i th we can put here the set transformation .\nOh . I see .\nNo ?\nI see . OK , I understand now . Alright , thanks .\nYeah . In this case , well , we can put here a {nonvocalsound} Y .\nOK . So , yeah . It 's just by definition  that the individual   that the , uh  So , capital X is by definition the same as E to the little X because she 's saying that the little X is  is the , uh  is the log . Alright .\nNow we can put this .\nYeah .\nNo ?\nAlright .\nAnd here we can multiply by X .\nI think these things are a lot clearer when you can use fonts  different fonts there\nOh , yes .\nso you know which is which . But I  I under I understand what you mean now .\nYeah , yeah . That 's true . That 's true .\nOK .\nBut this  this is correct ?\nSure .\nAnd now I can do it , uh  pfff ! I can put log {nonvocalsound} of EX  plus log\nOh . Yes . I understand now . And that 's where it comes from .\nAnd this is\nYeah .\nYeah . Right .\nRight .\nNow it 's correct .\nRight . OK . Thanks .\nWell . The idea  Well , we have fixed this equa\nOK . So now once you get that  that one , then you  then you do a first or second - order , or something , Taylor  series expansion of this .\nYeah . This is another linear relation that this  to develop this in  vector s Taylor series .\nYeah , sure .\nRight .\nMm - hmm . And for that , well , the goal is to obtain , um    est estimate a PDF for the noisy speech when we have a   a statistic for clean speech and for the noisy speech . Mmm ? And when w the way to obtain the PDF for the noisy speech is  well , we know this statistic and we know the noisy st well , we can apply first order of the vector st Taylor series of the  of the  of  well , the order that we want , increase the complexity of the problem .\nMm - hmm .\nAnd then when we have a expression , uh , for the  mean and variance of the noisy speech , we apply a technique of minimum mean - square estimation\nMm - hmm .\nto obtain the expected value of the clean speech given the  this  statistic for the noisy speech\nMm - hmm .\nthe statistic for clean speech and the statistic of the noisy speech . This only that . But the idea is that\nAnd the  the model of clean speech is a codebook . Right ?\nu Yeah . We have our codebook with different density  Gaussian .\nMm - hmm .\nWe can expre we can put that the  PDF  for the clean test , probability of the clean speech is equal to\nYeah .\nMm - hmm .\nSo , um , how  h how much  in  in the work they reported , how much noisy speech did you need to get , uh , good enough statistics for the  to get this mapping ?\nI don't know exactly .\nYeah .\nI  I need to s\nYeah .\nI don't know exactly .\nCuz I think what 's certainly characteristic of a lot of the  data in this test is that , um , you don't have   the  the training set may not be a  a great estimator for the noise in the test set . Sometimes it is and sometimes it 's not .\nYeah . I  the clean speech  the codebook for clean speech , I am using TIMIT . And I have now , uh , sixty - four {nonvocalsound} Gaus - Gaussian .\nUh - huh . And what are you using for the noisy  ? Y y doing that strictly\nOf the noise  I estimate the noises wi\nMm - hmm .\nWell , for the noises I only use one Gaussian .\nAnd  and you  and you train it up entirely from , uh , nonspeech sections in the test ?\nHmm .\nUh , yes . The first experiment that I do it is solely to calculate the , mmm  well , this value\nYeah .\nuh , the compensation of the dictionary o one time using the  the noise at the f beginning of the sentence .\nMm - hmm .\nThis is the first experiment .\nYeah .\nAnd I fix this for all the  all the sentences . Uh , because  well , the VTS methods  In fact the first thing that I do is to  to obtain , uh , an expression for E  probability e expression of  of E . That mean that the VTS  mmm , with the VTS we obtain , uh  well , we  we obtain the means for each Gaussian  and the variance .\nMm - hmm .\nThis is one . Eh , this is the composition of the dictionary .\nMm - hmm .\nThis one thing . And the other thing that this  with these methods is to , uh , obtain  to calculate this value .\nMm - hmm .\nBecause we can write  uh , we can write that  the estimation of the clean speech is equal at an expected value of the clean speech conditional to , uh , the noise signal   the probability f of the  the statistic of the clean speech and the statistic of the noise .\nMm - hmm . Mm - hmm .\nThis is the methods that say that we 're going obtain this .\nMm - hmm .\nAnd we can put that this is equal to the estimated value of E minus a function that conditional to E to the T  to the noise signal . Well , this is  this function is the  the term  after develop this , the term that we  we take . Give PX and , uh , P the noise .\nX K C noise .\nMmm .\nAnd I can  put that this is equal to  the  noise signal minus  Well , I put before  this name , uh  And I can calculate this .\nWhat is the first variable in that probability ?\nUh , this is the Gaussian .\nNo , no . I 'm sorry . In  in the one you pointed at . What 's that variable ?\nv Uh , this is the\nWeak . So probably it  it would do that .\nlike this ,\nIt 's one mixture of the model . Right ?\nbut conditional . No , it 's condition it 's not exactly this . It 's modify . Uh , if we have clean speech  we have the dictionary for the clean speech , we have a probability f of  our  our weight for each Gaussian .\nOK .\nNo . And now , this weight is different now\nYes .\nbecause it 's conditional . And this I need to  to calcu I know this\nUh - huh .\nand I know this because this is from the dictionary that you have .\nUh - huh .\nI need to calculate this .\nYes .\nAnd for calculate this ,  I have an  I  I can develop an expression that is\nIt 's overlapping .\nthat . I can calculate  I can  I calculated this value ,  uh , with the statistic of the noisy speech that I calculated before with the VTS approximation .\nMm - hmm .\nAnd  well , normalizing . And I know everything . Uh , with the , nnn  when I develop this in s Taylor  Taylor series , I can't , um ,  calculate the mean and the variance  of the  for each of the Gaussian of the dictionary for the noisy speech . Now . And this is fixed .\nMm - hmm .\nIf I never do an estimat a newer estimation of the noise , this mean as  mean and the variance are fixed .\nMm - hmm .\nAnd for each s uh , frame of the speech the only thing that I need to do is to calculate this in order to calculate the estimation of the clean speech given our noisy speech .\nSo , I 'm  I 'm not following this perfectly but , um , I  Are you saying that all of these estimates are done  using , um , estimates of the probability density for the noise that are calculated only from the first ten frames ? And never change throughout anything else ?\nYeah . Never cha This is one of the approximations that I am doing .\nPer  per  per utterance , or per  ?\nPer utterance . Yes .\nPer utterance . OK .\nPer utterance . Yes .\nSo it 's done  it 's done new for each new utterance .\nAnd th\nSo this changes the whole mapping for every utterance .\nYeah . It 's not  Yeah .\nOK .\nYeah . It 's fixed , the dictionary .\nOK .\nAnd the other estimation is when I do the uh on - line estimation , I change the means and variance of th for the noisy speech\nYeah ?\neach time that I detect noise .\nMm - hmm .\nI do it uh again this develop . Estimate the new mean and the variance of the noisy speech . And with th with this new s new mean and variance I estimate again this .\nSo you estimated , uh , f completely forgetting what you had before ? Uh , or is there some adaptation ?\nUm , no , no , no . It 's not completely  No , it 's  I am doing something like an adaptation of the noise .\nOK . Now do we know , either from their experience or from yours , that , uh , just having , uh , two parameters , the  the mean and variance , is enough ? Yeah . I mean , I know you don't have a lot of data to estimate with , but  but , uh , um\nI estimate mean and variance for each one of the Gaussian of the codebook .\nNo , I 'm talking about the noise .\nOh ,\nThere 's only one Gaussian .\num . Well , only one  I am only  using only one .\nRight .\nI don't know i\nAnd you  and  and it 's , uh , uh  right , it 's only  it 's only one  Wait a minute . This is  what 's the dimensionality of the Gaussian ? This is\nUh , it 's in  after the mel filter bank .\nSo this is twenty or something ?\nTwenty - three .\nTwenty ? So it 's  Yeah . So it 's actually forty numbers  that you 're getting . Yeah , maybe  maybe you don't have a\nUh , the original paper say that only one Gaussian for the noise .\nWell , yeah . But , I mean ,  no  no paper is  is a Bible ,\nYeah , maybe isn't the right thing .\nyou know . This is  this is , uh\nYeah , yeah , yeah .\nThe question is , um ,  whether it would be helpful , i particularly if you used  if you had more  So , suppose you did  This is almost cheating . It certainly isn't real - time . But if y suppose you use the real boundaries that  that you were  in fact were given  by the VAD and so forth or I  I guess we 're gonna be given even better boundaries than that . And you look  you take all o all of the nonspeech components in an utterance , so you have a fair amount . Do you benefit from having a better model for the noise ? That would be another question .\nMaybe .\nSo first question would be  to what extent i are the errors that you 're still seeing  based on the fact that you have poor boundaries for the , uh , uh , nonspeech ? And the second question might be , given that you have good boundaries , could you do better if you used more parameters to characterize the noise ? Um . Also another question might be  Um , they are doing  they 're using first term only of the vector Taylor series ?\nYeah .\nUm , if you do a second term does it get too complicated cuz of the nonlinearity ?\nYeah . It 's quite complicated .\nYeah , OK . No , I won't ask the next question then .\nOh , it 's  it 's the  for me it 's the first time that I am working with VTS .\nYeah . No , it 's interesting .\nUh\nUh , w we haven't had anybody work with it before , so it 's interesting to get your  get your feedback about it .\nIt 's another type of approximation because i because it 's a statistic  statistic approximation to remove the noise . I don't know .\nRight .\nGreat . OK . Well , I guess we 're about done . Um , so some of the digit forms don't have digits . Uh ,  we ran out there were some blanks in there , so not everybody will be reading digits . But , um , I guess you 've got some . Right , Morgan ?\nI have some .\nSo , why don't you go ahead and start . And I think it 's  just us down here at this end that have them .\nS\num\nSo .\nUh , OK .\nS so , we switch off with this\nWhenever you 're ready .\nor n ?\nUh , leave it on ,\nNo . OK .\nuh ,\nThey prefer to have them on\nand the\njust so that they 're continuing to get the distant , uh , information .\nYeah .\nOK . OK .\nOK .\nOK . S", "topic_id": 2, "keywords": "wiener, computing, spectrograms, filtering, distracted", "dialogue_id": 44}, {"text": "Sorry . Mental  mental Palm Pilot . Right . Hence  no problem .\nLet 's see . So . What ? I 'm supposed to be on channel five ? Her . Nope . Doesn't seem to be ,\nHello  I 'm channel one .\nyeah .\nWhat does your thing say on the back ?\nTesting .\nNnn , five . Alright , I 'm five .\nSibilance . Sibilance .   Three , three . I am three .\nEh .\nSee , that matches the seat up there . So .\nYeah , well , I g guess  it 's coming up then , or\nCuz it 's  That starts counting from zero and these start counting from one . Ergo , the classic off - by - one error .\nBut mine is correct .\nIs it ?\nNo .\nIt 's one . Channel one .\nYour mike  number  is what we 're t\nLook at the back .\nOh , oh , oh ! Oh .\nHo !\nSo\nI 've bested you again , Nancy .\nBut your p No , but the paper 's correct .\nThe paper is correct .\nLook at the paper .\nI didn't det I was saying the microphone , not the paper .\nNnn ,\nOh .\nit 's n\nOK .\nIt 's always offset . Yeah .\nYes , you 've bested me again . That 's how I think of our continuing interaction . Damn ! Foiled again !\nSo is Keith showing up ? He 's talking with George right now . Uh , is he gonna get a rip  uh  rip himself away from  from that ?\nHe 'll probably come later .\nWhat  He - he he 's probably not , is my guess .\nOh , then it 's just gonna be the five of us ?\nYeah .\nWell , he  he was very affirmative in his way of saying he will be here at four . But  you know , that was before he knew about that George lecture probably .\nRight . This  this is not  It 's not bad for the project if Keith is talking to George . OK . So my suggestion is we just\nForge ahead .\nForge ahead , yeah .\nCool .\nAre you in charge ?\nSure . Um . Well , I sort of had informal talks with most of you . So , Eva just reported she 's really happy about the  CBT 's being in the same order in the XML as in the um  be Java declaration format\nYeah . The e\nso you don't have to do too much in the style sheet transversion .\nUh , yeah . Yeah , so .\nThe  uh , Java  the embedded Bayes  wants to take input  uh , uh , a Bayes - net  in  in some Java notation and Eva is using the Xalan style sheet processor to convert the XML that 's output by the Java Bayes for the  into the , uh , E Bayes input .\nMmm .\nActually , maybe I could try , like , emailing the guy and see if he has any something already .\nSure .\nHmm .\nThat 'd be weird , that he has both the Java Bayes and the embedded Bayes in\nBut that 's some sort of conversion program ?\nYeah . Yeah . And put them into different  formats . Oh\nI think you should demand things from him .\nYep , he could do that , too .\nHe charges so much . Right .\nYeah .\nNo , I think it 's a good idea that you may as well ask . Sure .\nYeah .", "topic_id": 0, "keywords": "error, pilot, channel, counting, number", "dialogue_id": 45}, {"text": "And , um , well  pretty mu pretty much on t on the top of my list , I would have asked Keith how the \" where is X ? \"  hand parse is standing . Um .  But we 'll skip that . Uh , there 's good news from Johno . The generation templates are done .\nSo the trees  for  the XML trees for the  for the gene for the synthesizer are written . So I just need to  do the , uh  write a new set of  tree combining rules . But I think those 'll be pretty similar to the old ones . So . Just gonna be  you know\nOh ! You were gonna send me a note about hiring\nYes .\nI didn't finish the sentence but he understood it .\nI know what he 's talking about .\nOK . But Nancy doesn't .\nHiring somebody .\nWe  w um\nThe guy .\nOK , so  natural language generation  produces not a  just a surface string that is fed into a text - to - speech but , a  surface string with a syntax tree that 's fed into a concept - to - speech .\nNo .\nYeah . Mm - hmm . Better .\nNow and this concept - to - speech module has  certain rules on how  if you get the following syntactic structure , how to map this onto prosodic rules .\nMm - hmm . Sure . Mm - hmm .\nAnd Fey has foolheartedly agreed to rewrite uh , the German concept uh syntax - to - prosody rules\nI didn't know she spoke German .\nNo , she doesn't .\nOh , OK .\nBut she speaks English .\nOh . Rewrite the German ones into English . OK , got it .\nInto English . And um therefore  the , uh  if it 's OK that we give her a couple of more hours per week , then  she 'll do that .\nOK , got it .\nWhat  language is that  written i Is that that Scheme thing that you showed me ?\nYeah . That 's the LISP - type scheme .\nShe knows how to program in Scheme ? I hope ?\nNo , I  My guess is  I  I asked for a commented version of that file ? If we get that , then it 's  doable , even without getting into it , even though the Scheme li uh , stuff is really well documented in the  Festival .\nWell , I guess if you 're not used to functional programming , Scheme can be completely incomprehensible . Cuz , there 's no  Like  there 's lots of unnamed functions\nSyntax . Yeah .\nand\nMm - hmm .\nYou know ?\nAnyway , it  We 'll sort this out . Um . But anyway , send me the note and then I 'll - I 'll check with , uh , Morgan on the money . I  I don't anticipate any problem but we have to  ask . Oh , so this was  {nonvocalsound} You know , on the generation thing , um if  sh y she 's really going to do that , then we should be able to get prosody as well . So it 'll say it 's nonsense with perfect intonation .\nAre we gonna  Can we change the voice of the  of the thing , because right now the voice sounds like a murderer .\nYep . We ha we have to change the voice .\nWh - Which one ?\nThe  the little Smarticus  Smarticus sounds like a murderer .\nOh .\nThat 's good to know .\n\" I have your reservations . \"\nBut I will not give them to you unless you come into my lair .\nIt is  Uh , we have the choice between the , uh , usual Festival voices , which I already told the SmartKom people we aren't gonna use because they 're really bad .\nFestival ?\nIt 's the name of some program ,\nOh , oh . Got it . OK .\nthe  the synthesizer .\nYou know , the usual party voices .\nBut , um\nYeah , I know . That doesn't sound ,  exactly right either .\nOGI has , uh , crafted a couple of diphone type voices that are really nice and we 're going to use  that . We can still , um , d agree on a gender , if we want . So we still have male or female .\nI think  Well , let 's just pick whatever sounds best .\nHmm ?\nWhatever sounds best .\nUh .\nUnfortunately , probably male voices , a bit more research on .\nDoes OGI stand for  ?  Original German Institute ?\nOrego\nSo .\nOr\nOregon .\nOregon Graduate Insti\nOregon @ @  Graduate Institute\nOh .\nTry Oregon .\nAh .\nIt turns out there 's the long - standing links with these guys in the speech group .\nHmm !\nVery long .\nHmm !\nHmm .\nIn fact , there 's this guy who 's basically got a joint appointment , Hynek  Hermansky . He 's - spends a fair amount of time here . Anyway . Leave it . Won't be a problem .\nOK . And it 's probably also absolutely uninteresting for all of you to , um learn that as of twenty minutes ago , David and I , per accident , uh managed to get the whole SmartKom system running on the  uh , ICSI Linux machines with the ICSI NT machines thereby increasing the number of running SmartKom systems in this house from  one on my laptop to three .\nMmm , that 's good .\nHow was this by accident ?\nYeah , I know . Tha - that 's the part I didn't understand .\nUm , I suggested to try something that was really kind of  even though against better knowledge shouldn't have worked , but it worked .\nHmm !\nIntuition .\nYeah .\nWill it work again ,\nMaybe  maybe  maybe a bit for the AI i intuition thing .\nor  ?\nYeah .\nOK . And , um , we 'll never found out why . It - it 's just like why  why the generation ma the presentation manager is now working ?\nHmm ! This is something you ha you get used to as a programmer , right ?\nWhich\nYou know ,  and it 's cool , it works out that way .\nHmm . So ,  the  the people at Saarbruecken and I decided not to touch it ever again . Yeah , that would work . OK . Um  I was gonna ask you where something is and what we know about that .\nWhere  OK .\nWhere the \" where is \" construction is .\nWhat  what thing is this ?\nWhere is X ?\nOK .\nOh , but by  Uh , we can ask , uh , did you get to read all four hundred words ?\nI did .\nWas it OK ? Was it ?\nYeah .\nI  I wa I was looking at it . It doesn't follow logically . It doesn't  The first paragraph doesn't seem to have any link to the second paragraph .\nAnd so on .\nYeah .\nYeah .\nHmm . That\nYou know , i Yeah , it\nEach paragraph is good , though . I li\nI i Yeah . Well , it it 's fine .\nIt was written by committee .\nAnyway . Um . But c the meeting looks like it 's , it 's gonna be good . So . I think it 's uh\nYeah .", "topic_id": 1, "keywords": "syntactic, syntax, speech, synthesizer, tree", "dialogue_id": 45}, {"text": "Yeah , I didn't know about it until  Robert told me , like ,\nYeah , I  I ra I ran across it in  I don't even know where , you know  some just  some weird place . And , uh , yeah , I I 'm surprised I didn't know about it\nY yeah . Well , yeah . I was like , why didn't Dan tell me ?\nsince we know all the invited speakers , an\nRight .\nRight , or some Anyway . So  But anyway , yeah . I so I  I did see that . Oh wha Yeah . Before we get started on this st so I also had a nice email correspondence with Daphne Kohler , who said yes indeed she would love to work with us on the , um ,  you know , using these structured belief - nets and stuff but  starting in August , that she 's also got a new student working on this and that we should get in touch with them again in August and then we 'll figure out a way for you  uh  you to get seriously connected with , um their group . So that 's , uh  looks pretty good . And um  Yeah , I 'll say it now . So , um  And it looks to me like  we 're now at a good point to do something  start working on something really hard . We 've been so far working on things that are easy .\nOh !\nUh , w Which is  mental spaces and uh  and - or\nHmm !\nIt 's hard . Yeah , it 's hard .\nHuh ?\nYeah .\nYeah .\nIt 's a hard puzzle . But the other part of it is the way they connect to these , uh , probabilistic relational models . So  there 's all the problems that the linguists know about , about mental spaces , and the cognitive linguists know about , but then there 's this problem of the belief - net people have only done a moderately good job of dealing with temporal belief - nets . Uh , which they call dynamic  they incorrectly call dynamic belief - nets .\nMmm .\nSo there 's a term \" dynamic belief - net \" , doesn't mean that . It means time slices . And Srini used those and people use them . Uh . But one of the things I w would like to do over the next , uh , month , it may take more ,  is to st understand to what extent we can not only figure out the constructions for them for multiple worlds and uh sort of what the formalism will look like and where the slots and fillers will be , but also what that would translate into in terms of belief - net and the inferences . So the story is that if you have these probabilistic relational models , they 're set up , in principle , so that you can make new instances and instances connect to each other , and all that sort of stuff , so it should be feasible to set them up in such a way that if you 've got the past tense and the present tense and each of those is a separate  uh , belief structure that they do their inferences with just the couplings that are appropriate . But that 's g that 's , as far as I can tell , it 's  it 's putting together two real hard problems . One is the linguistic part of what are the couplings and  and when you have a certain , uh , construction , that implies certain couplings and other couplings , you know , between let 's say between the past and the present , or any other one of these things and then we have this inference problem of exactly technically how does the belief - net work if it 's got um , let 's say one in  in , you know , different tenses or my beliefs and your beliefs , or any of these other ones of  of multiple models . So um you know , in the long run we need to solve both of those and my suggestion is that we start digging into them both , uh , in a way we that , you know , th hopefully turns out to be consistent , so that the  Um . And sometimes it 's actually easier to solve two hard problems than one\nYeah .\nbecause they constrain each other . I mean if you 've got huge ra huge range of possible choices um  We 'll see . But anyway , so that 's , um\nOh yeah , like uh , I solved the  the problem of um  we were talking about how do you  various issues of how come a plural noun gets to quote \" count as a noun phrase \" , you know , occur as an argument of a higher construction , but a bare singular stem doesn't get to act that way .\nRight .\nUm , and it would take a really long time to explain it now , but I 'm about to write it up this evening . I solved that at the same time as \" how do we keep adjectives from floating to the left of determiners and how do we keep all of that from floating outside the noun phrase \" to get something like \" I the kicked dog \" . Um . Did it  did it at once .\nThat 's great .\nSo maybe  maybe it 'll be a similar thing .\nCool .\nYeah . No , I know , I th I I think that is gonna be sort of the key to this wh to th the big project of the summer of  of getting the constructions right is that people do manage to do this so there probably are some , uh , relatively clean rules , they 're just not context - free trees .\nRight .\nAnd if we  if the formalism is  is good , then we should be able to have , you know , sort of moderate scale thing . And that by the way is  is , Keith , what I encouraged George to be talking with you about . Not the formalism yet\nMm - hmm .\nbut the phenomena .\nYeah .\nThe p And  Oh , another thing , um there was this , uh thing that Nancy agreed to in a  in a weak moment this morning that\nHmm !\nI was really strong .\nHmm !\nHmm .\nUh , sorry . In a  in a friendly moment .\nSame thing .\nAnyway , uh , that we were  that we 're gonna try to get a uh , first cut at the revised formalism by the end of next week .\nAlright .\nOK ? Probably skipping the mental spaces part .\nSeems\nRight . I do .\nUh , just trying to write up essentially what  what you guys have worked out so that everybody has something to look at . We 've talked about it , but only the innermost inner group currently , uh ,\nMm - hmm . Knows .\nknows , uh\nOK .\nYeah , and  and not even all of them really do .\nYeah .\nBut like\nRight .\nThere 's  The group as a whole knows but no individual member kno\nWell that that  yeah th there 's one of the advantages of a document , right ? ,\nYeah .\nis  is that it actually transfers from head to head .\nRight .\nOK .", "topic_id": 2, "keywords": "talking, linguistic, email, member, talked", "dialogue_id": 45}, {"text": "So anyway . So um\nAh , communication !\nHuh ?\nCommunication .\nHunh !\nCommunication , documentation and stuff . Anyway , so , uh , with a little luck  Uh  l let 's , let 's have that as a goal anyway .\nSo , uh , what was the date there ?\nAnd\nMonday or  ? It 's a Friday .\nNo , no , no . No , w uh  we 're talking about a week fr e end of next week .\nEnd of next week .\nBut , uh , but  but the two of us will probably talk to you at well before th\nI thought you said beginning of n Yeah .\nI mean . Anyway , w let 's talk separately about how t\nYeah , I have a busy weekend but after that    Yeah , gung - ho .\nOK . Yeah , so  so someti sometime next week .\nGreat ,\nNow if it turns out that that effort leads us into some big hole that 's fine .\nMm - hmm . OK .\nYou know , if you say we 're  we 're dump  dump  dump . There 's a really hard problem we haven't solved yet  that , that 's just fine .\nOK .\nMm - hmm .\nBut at  at least sort of try and work out what the state of the art is right now .\nRight , t t if  to the extent that we have it , let 's write it\nOK .\nand to the extent we don't , let 's find out what we need to do .\nOK .\nSo , uh\nCan we  ?  Is it worth  thinking of an example out of our tourism thing domain , that involves a  a  a decent mental  space shift  or setting up\nI think it is , but  uh  but I interrupted before Keith got to tell us what happened with \" where is the Powder - Tower ? \" or whatever\nRight .\nWell . Uh , what was supposed to happen ? I 've sort of been actually caught up in some other ones , so , um , you know , I don't have a write - up of  or I haven't elaborated on the ideas that we were already talking about which were\nHmm , yeah . I think  I think we already came to the conclusion that we have two alternative  paths that we  two alternative ways of representing it . One is sort of a  has a um\nIt 's gone .\num\nThe question of whether the polysemy is sort of like in the construction or pragmatic .\nOne of them was th Right .\nor comes\nRight .\nis resolved later . Yeah .\nI think it has to be the  the second case .\nYeah .\nUm , so d ' you  Is it clear what we 're talking about here ?\nI agree .\nThe question is whether the construction is semantic or like ambiguous between asking for location and asking for path .\nUh\nSo you might be  yeah , y And asking for directions .\nIt 's\nUm or  or whether the construction semantically , uh , is clearly only asking for location\nShould we have a  a  a\nUh\nbut pragmatically that 's construed as meaning \" tell me how to get there \" .\nMm - hmm . Yep .\nSo  assume these are two , uh , nodes we can observe in the Bayes - net .\nYeah .\nRight .\nSo these are either true or false and it 's also just true  or false . If we encounter a phrase such as \" where is X ? \" , should that set this to true and this to true , and the Bayes - net figures out which under the c situation in general is more likely ? Um , or should it just activate this , have this be false , and the Bayes - net figures out whether this actually now means  ?\nUh w that 's a s\nSlightly different .\nOK , so that 's a  that 's a separate issue .\nOK .\nSo I a I I th I agree with you that , um , it 's a disaster to try to make separate constructions for every uh , pragmatic reading ,\nMm - hmm .\nalthough there are some that will need to be there .\nGood . Mm - hmm .\nRight .\nRight .\nI mean , there there 's some that\nOr have every construction list all the possible pragmatic implications of the same one .\nYou can't do that either .\nRight . Yeah .\nYeah . But , you know , c um  almost certainly \" can you pass the salt \" is a construction worth noting that there is this th this  this  this  uh\nYeah .\nRequest .\nMm - hmm . Yeah .\nVery yeah .\nSo right , this one is maybe in the gray area . Is it  is it like that or is it just sort of obvious from world knowledge that no one  you wouldn't want to know the location without wanting to know how to get there or whatever .\nMmm .\nRi Yeah .\nOne Or in some cases , it 's  it 's quite definitely\nYeah .\ns so that you just know  wanna know where it is .\nYeah . Well the question is basically , is this conventional or conversational implicature ?\nExactly . Yeah .\nMight be , yeah .\nAnd I guess , see , the more important thing at this stage is that we should be able to know how we would handle it in ei f in the short run it 's more important to know how we would treat  technically what we would do if we decided A and what we would do if we decided B , than it is t to decide A or B r right now .\nOK , right .\nRight . Right .\nWhich of that is .  Yeah , OK\nWhich one it is .\nHmm .\nCuz there will be other k examples that are one way or the other . Right .\nW we know for sure that we have to be able to do both .\nYeah .\nSo I guess  In the short run , let 's  let 's be real clear on h what the two alternatives would be .\nOK .\nAnd then the  we had another idea floating around um , which we wanted to , uh , get your input on , and that concerns the  But the nice thing is w we would have a person that would like to work on it , and that 's Ir - Irina Gurevich from EML  who is going to be visiting us , uh , the week before , uh , August and a little bit into August . And she would like to  apply the  ontology that is , um  being crafted at EML . That 's not the one I sent you . The one I sent you was from GMD , out of a European CRUMPET .\nIt was terrible .\nAgreed . Um , and one of the reas one of the  those ideas was , so , back to the old Johno observation that if y if you have a dialogue history  and it said the word \" admission fee \" was uh , mentioned um , it 's more likely that the person actually wants to enter  than just take a picture of it from the outside . Now what could imagine  to , you know , have a list for each construction of things that one should look up in the discourse history , yeah ? That 's the really stupid way . Then there is the  really clever way that was suggested by Keith and then there is the , uh , middle way that I 'm suggesting and that is you  you get X , which is whatever , the castle . The ontology will tell us that castles have opening hours , that they have admission fees , they have whatever . And then , this is  We go via a thesaurus and look up  certain linguistic surface structures  that are related to these concepts and feed those through the dialogue history and check dynamically for each e entity . We look it up check whether any of these were mentioned and then activate the corresponding nodes on the discourse side . But Keith suggested that a  a much cleaner way would be  is , you know , to keep track of the discourse in such a way that you  if you know that something like that ha has been mentioned before , this just a continues to add up , you know , in th in a\nSo if someone mentions admission f fees , that activates an Enter schema which sticks around for a little while in your rep in the representation of what 's being talked about . And then when someone asks \" where is X ? \" you 've already got the  the Enter schema activated\nKind of a priming\nMm - hmm .\nand you 're able to  to conclude on it .\nYeah .\npriming a spreading activation\nYeah .\nRight . Yeah . So that 's certainly  more  realistic .\nRight .\nI m I mean psychologically . Now technically\nYeah .\nUm\nWell , uh , is it  doesn't it seem like if you just managed the dialogue history with a  a thread , that you know , kept track of ho of the activity of  I mean , cuz it would  the  the thread would know what nodes  like , needed to be activated , so it could just keep track of  how long it 's been since  something 's been mentioned , and  automatically load it in .\nYeah . You could do that . Um . But here 's  here 's a way  in th in the bl Bayes - net you could  you could think about it this way , that if um  at the time \" admissions fee \" was mentioned  you could increase the probability  that someone wanted to enter .\nTurn prior on .\nWe - yeah  th th that 's what I wa I wasn't  I was  I wasn't thinking in terms of Enter schemas . I was just\nFair enough , OK , but , but , in terms of the c c the current implementation  right ? so that um\nIt would already be higher in the  context .\nth that th the  the  the conditional probability that someone  So at the time you mentioned it  This is  this is essentially the Bayes - net equivalent of the spreading activation .\nMm - hmm . Yeah .\nIt 's  In some ways it 's not as good but it 's  the implementation we got .\nYeah , sure . No , I mean\nWe don't have a connectionist implementation . Now  Now my guess is that it 's not a question of time but it is a question of whether another  intervening object has been mentioned .\nYeah , relevance .\nYeah .\nYeah .\nI mean , we could look at dialo this is  Of course the other thing we ha we do is , is we have this data coming\nYeah .\nwhich probably will blow all our theories ,\nYeah , right .\nbut   but skipping that  so  so  but my guess is what  what 'll probably will happen , Here 's a  here 's a proposed design .  is that there 're certain constructions which , uh , for our purposes do change the probabilities of EVA decisions and various other kinds and th that the , uh , standard way that  that the these contexts work is sort of stack - like or whatever , but that 's sort of the most recent thing . And so it could be that  when another uh , en tourist entity gets mentioned , you\nRenew\nre re essentially re - initiali you know , re - i essentially re - initialize the  state .\nMmm .\nYeah .\nMm - hmm .\nAnd of course i if we had a fancier one with multiple worlds you could have  uh , you could keep track of what someone was  uh saying about this and that .\nYeah .\nYou know , \" I wanna go  in the morning\n\" Here 's my plan for today .\nI wanna  \"\nHere 's my plan for tomorrow . \"\nYeah , or  Yeah , in the morning morning I I 'm planning t to go shopping ,\nhypothetically .\nin the afternoon to the Powder - Tower\nYeah .\nUh , tal so I 'm talking about shopping and then you say , uh , you know , well , um \" What 's it cost ? \" or something .\nMm - hmm .\nOr  Anyway . So one could well imagine , but not yet .\nYeah .\nBut I do th think that the   It 'll turn out that it 's gonna be  depend pretty much on whether there 's been an override .\nYeah , I mean , if  if you ask \" how much does a train ride and  and cinema around the vineyards cost ? \" and then somebody tells you it 's sixty dollars and then you say \" OK How much is , uh  I would like to  visit the  \"  whatever , something completely different , \" then I go to , you know , Point Reyes \" ,\nYeah .\nit  it 's not more likely that you want to enter anything , but it 's , as a matter of fact , a complete rejection of entering by doing that .\nRight .\nYeah .\nRight .\nRight .\nSo when you admit have admission fee and it changes something , it 's only for that particular  It 's relational , right ? It 's only for that particular object .\nYeah , I th th Yeah . Well , and  and  and the simple idea is that it 's on it 's only for m for the current uh , tourist e entity of instre interest .\nYeah .\nYeah .\nRight .\nYeah . But that 's  I mean this  this function , so , has the current object been mentioned in  in  with a question about  concerning its\nNo , no . It 's  it  It goes the other d it goes in the other direction . Is  When th When the  this is mentioned ,  the uh probability of  of , let 's say , entering changes\nOf that object . For  But\nchanges .\nRight .\nYou could just hav uh , just basically , ob it  It observes an  er , it sets the  a node for \" entered \" or \" true \" or something ,\nYeah . Yeah . Now , uh  But I think Ro - Robert 's right , that to determine that , OK ? you may well want to go through a th thesaurus\n\" discourse enter \" .\nand  and  So , if the issue is , if  so now th this construction has been matched and you say \" OK . Does this actually have any implications for our decisions ? \" Then there 's another piece of code  that presumably  does that computation .\nSo , sort of forward chaining in a way , rather than  backward .\nYeah . Yeah .\nOK .\nBut  but what 's Robert 's saying is  is , and I think he 's right ,  is you don't want to try to build into the construction itself all the synonyms and all  you know , all the wo Uh maybe . I 'll have to think about that .\nHmm .\nI don't know . I mean it  th  I can thi I can think of arguments in either direction on that . But somehow you want to do it .\nMm - hmm . Well , it 's just another , sort of , construction side is how to get at the possible inferences we can draw from the discourse history or changing of the  probabilities , and - or\nGuess it 's like  I g The other thing is , whether you have a m m user model that has , you know , whatever , a current plan , whatever , plans that had been discussed , and I don't know , I mean\nWhat  uh , what 's the argument for putting it in the construction ? Is it just that  the s synonym selection is better , or  ?\nOh , wel Well , the ar the  The argument is that you 're gonna have the  If you 've recognized the word , you 've recognized the word , which means you have a lexical construction for it , so you could just as well tag the lexical construction with the fact that it 's a uh , you know , thirty percent increase in probability of entering . You  So you could  you could  you could invert  invert the whole thing , so you s you tag that information on to  the lexicon\nMmm . Oh , I see .\nsince you had to recognize it anyway . That  that 's the argument in the other direction . at  at  Yeah , and this is\nEven though uh the lexical construction itself  out  out of context , uh , won't do it . I mean , y you have to keep track whether the person says\nYeah .\n\" But I but I 'm not interested in the opening times \" is sort of a more a V type .\nYeah there 's , yeah ther there 's that as well .\nYep . Hmm . So . But , we 'll  uh , we have time to  This is a s just a sidetrack , but uh I think it 's also something that people have not done before , is um , sort of abuse an ontology for these kinds of , uh , inferences , on whether anything relevant to the current something has been   uh , has crept up in the dialogue history already , or not . And , um I have the , uh  If we wanted to have that function in the dialogue hi dialogue module of SmartKom , I have the written consent of Jan to put it in there .\nGood . OK .   Well , this  this is highly relevant to someone 's thesis .\nYes , um . That 's  uh , I 'm  I 'm keeping on good terms with Jan .\nYou 've noticed that . OK .\nYeah .\nSo the point is , it 's very likely that Robert 's thesis is going to be along these lines ,\nOh , s\nand the local rules are if it 's your thesis , you get to decide how it 's done . OK . So if , you know  if this is  seriously , if this becomes part of your thesis , you can say , hey we 're gonna do it this way , that 's the way it 's done .\nMmm .\nYay , it 's not me . It 's always me when it 's someone 's thesis .\nNo , no , no ! No , no . We 've got a lot  we 've got a lot of theses going .\nThere 's a few of us around now .\nNow it 's not . Yay ! I know it is .\nYeah . Right .\nWell , let 's  let 's talk after Friday the twenty - ninth . Then we 'll see how f f\nRight . So h he 's got a th he 's got a meet meeting in Germany with his thesis advisor .\nYeah , he said he 's gonna f finish his thesis by then .\nOh yeah .\nYeah . I should try to finish it by then . Yeah .\nOh , right .\nSo .\nUm . Yeah . So I think  in fact , That 's the other thing . uh , this is  this is , speaking of hard problems ,  this is a very good time um , to start trying to make explicit where construal comes in and  you know , where c where the construction per - se ends  and where construal comes in ,\nMm - hmm .\nMm - hmm .\nYeah , we 've  we 've done quite a bit of that .\ncuz this is clearly part of th\nYeah .\nWe 've been doing quite a bit of that .\nHuh ?\nYeah .\nWell I said . But that 's part of what the f\nWe have many jobs for you , Ro - Robert .\nYeah . Well , he 's gonna need this .\nYeah , it seems to always land in your category .\nThe conclusion .\nYou 're lucky .\nYeah .\nRight . So .  Right . So thing  That 's part of why we want the formalism ,\nYeah .\nis  is because th it is gonna have implicit in it\nWas I ? In the room ?\nNo , you weren't there  on purpose . Like\nYeah .\nMade it much easier to make these decisions .\nObviously .\nUh .\nYeah .\nRight . Well I  That 's tentative .\nYeah . Right , right , right .\nThey aren't decisions , they 're ju they 're just proposals .\nYes .  Excuse me .\nNo , they 're decisions . OK .\nYeah , that  That 's the point , is  is th\nYeah .\nConstraints . Let 's call them constraints , around which one has to\nYeah .\nActually , yeah .  There 's a problem with that word , too , though .\nYeah .   Anyway . But so that 's that 's w Yeah .\nYeah , but it  he the decisions I made wer had to do with my thesis . So consequently don't I get to decide then that it 's Robert 's job ?\nNo .\nAnyhow .\nUh .\nWell , I 'll just pick a piece of the problem and then just push the hard stuff into the center  and say it 's Robert 's . Like .\nI 've always been  completely in favor of consensus decisions ,\nI can\nRight .\nso we 'll  we 'll find a way .\nWell , we  we  we will , but um\nI haven't .  OK .\nnot\nIt  it might even be  interesting then to  say that I should be forced to um , sort of pull some of the ideas that have been floating in my head out of the , uh  out of the top hat\nYes .\nand , um\nAlways good .\nRight . So\nThat metaphor is not going anywhere , you know .\nYeah .\nRi - No . Absolutely . So , uh , wh you had  you know you ha You had done one draft .\nYes , and , um , it 's  Ha - None of that is basically still around ,\nI didn't get\nAnd a another draft OK .\nbut it 's\nD i\nThat 's normal .\nI i\nOh , I guess it 's good I didn't read it .\nI  this is  I 'm shocked . This is the first time I 've seen a thesis proposal change . Right . Anyway , uh .  So .\nReally ?\nBut , yeah , a second  that would be great . So , uh , a sec I mean you 're gonna need it anyway .\nHmm .\nand\nYeah , and I would like to d discuss it and , you know , get you guys 's input\nRight .\nand make it sort of bomb - proof .\nBomb proof !\nYep .\nGood .\nBullet - proof .\nOh ! Oh , OK .\nThat 's the word I was looking for .\nBoth proof .\nEither way .\nBoth .\nRight .\nGood luck .  Really .\nUh So that , so th thi this  I mean , so this is the point , is we  we 're going to have to cycle through this ,\nYeah .\nbut th the draft of the p proposal on the constructions is  is going to tell us a lot about  what  we think needs to be done by construal . And , um , we oughta be doing it .\nOK . Yeah , we need  we need some  Then we need to make some dates . Um .\nMeeting  regular meeting time for the summer , we really haven't found one . We did  Thursdays one for a while . I just talked to Ami . It 's - it 's a coincidence that he can't do  couldn't do it today  here .\nUsually , he can .\nUsually he has no real constraints .\nAnd the NTL meeting moved to Wednesday ,\nSo\ncuz of  of , uh\nYeah , it was just an exception .\nYeah , you weren't here , but  but  but  s uh ,  And so , if that 's OK with you ,\nIt 's i Is it staying basically at the Wednesday noon ?\nyou would\nOK . It was th off this week ,\nYeah . I always thought it was staying .\nYeah , it was th\nyeah .\nYeah , I thought it was just this week that we were changing it .\nRight .\nMmm .  Yeah .\nOK .\nAnd , um . How do we feel about doing it Wednesdays ? Because it seems to me that this is sort of a time where when we  have things to discuss with other people , there  they seem to be s tons of people around .\nThe only disadvantage  is that it may interfere with other\nOr  subgroup meetings\ns you know , other  other  No , you  Uh , people in this group connecting with  with\nThose people who  happen to be around .\nthose people  who  who might not be around so much . Uh , I don't care . I I uh you know I have no fixed\nTo tell you the truth , I 'd rath I 'd , I 'd  would like to avoid more than one ICSI meeting per day , if possible . But   I mean . I don't know .\nOK .\nWhatever .\nNo , that 's fine . I mean that\nThe  I 'd like to have them all in one day ,\nYeah , I can understand that .\nWell p\nso package them up and then\npeople  people differ in their tastes in this matter .\nYeah .\nI  I 'm neutral .\nYeah .\nYeah .  I 'm always here anyway ,\nIt 's OK , that\nso  It doesn't matter .\nYeah . @ @ That 's  Me too . I 'm basically  I 'm here . So .\nWell , if  one  sort of thing is , this room is taken at  after three - thirty pr pretty much every day by the data collection .\nOh .\nSo we have subjects anyway  Except for this week , we have subjects in here .\nOh .\nThat 's why it was one .\nOK .\nSo we just knew i\nSo did you just say that Ami can't make one o '\nNo , he can .\nOh .\nOh , OK .\nSo let 's say Thursday one . But for next week , this is a bit late . So  I would suggest that we need to  to talk\nOh , oh , OK .\nOK . About the c the  th\nCould we do Thursday at one - thirty ? Would that  that be horrible ?\nNo . Yes .\nOh really ?\nBecause , uh , this room is again taken at two - thirty by Morgan .\nOh , OK . OK . You didn't tell me that . OK , that 's fine .\nAnd the  s meeting recorder meeting meeting meeting recording on meeting meetings\nOK , OK , OK . OK .  Yeah .\nSo .\nAh , yeah .\nInteresting . So you 're proposing that we meet Tuesday .\nHow about that ?\nNext week .\nWell , we 're meeting Tuesday .\nI  I could\nI mean we usually meet Tuesday  or l like , linguists  um , at two .\nWould it\nThat 's right .\nSo . Do you want to meet again here bef\nAnd the s Is the Speech - Gen meeting still at  on Tuesdays ?\nI mean w Well , actually we w we we did scrap our Monday time just because Bhaskara couldn't come Monday .\nHhh .  Maybe I do need a Palm Pilot .\nSo there 's  Nothing 's impeding Monday anymore  either .\nThat doesn't apply to a\nAlthough I thought you wanted to go camping on Monday  er , take off Mondays a lot so you could go camping .\nGet a fresh start  Yeah , that 's another s thing . Yeah . But , um . I mean , there are also usually then holidays anyways . I mean  like   Sometimes  it works out that way .\nUsually ?\nSo . Hmm !\nWell , I mean , the linguists ' meeting  i happens to be at two , but I think that 's  I mean .\nThat should be relatively flexible be\npretty flexible , I think .\nYeah . There 's just  sort of the two to four of us .\nSo . The multiple meetings\nRight ? Yeah . So .\nyeah .\nAnd , you know , of course Nancy and I are just sort of always talking anyway and sometimes we do it in that room .\nRight . Yeah .\nSo , you know , I mean .\nOK , so  l forget about the b the camping thing . So let 's  eh , any other problems w w w ? But , I suggested Monday . If that 's a problem for me then I shouldn't  suggest it .\nHa - ha - ha .\nOK .\nSo .\nUm , all of the proposed times sound fine with me .\nSame here .\nMonday ?\nOK , whate I mean  What I think Robert 's saying is that\nEarlier in the week\nearlier we  At least for next week , there 's a lot of stuff we want to get done ,\nMm - hmm . Yeah .\nso why don't we plan to meet Monday\nMmm .\nand  we 'll see if we want to meet any more than that .\nOK .\nWhat time ?\nOK .\nAt o o o o one , two , three  ?\nOne , two , three ? Three 's too late .\nOh , I i  Yeah , I actually  Two is the earliest I can meet on Monday .\nTwo - thirty ? OK , two .\nHere I 'm blissfully agreeing to things and realizing that I actually do have some stuff scheduled on Monday .\nSure . Sounds great . Uh , so that 's the eighteenth .\nYou guys will still remind me , right ?\nNo way !\nY you 'll come and take all the   the headph the good headphones first and then remind me .\nW why do you  ?\nYeah , exactly . Sorry , two PM .\nAnd\nWhy do I have this unless I 'm gonna write ?\ndo I get to see th uh , your formalism before  that ?\nFine . Yes . Uh . Would you like to ?\nMm - hmm .\nOK . I was actually gonna work on it for tomorrow  like this  this weekend .\nI wo I would like  I would sort of  get a  get a notion of what  what you guys have in store for me .\nYeah .\nWell m @ @ you know , w maybe Mond - Maybe we can put  This is part of what we can do Monday , if we want .\nYeah . I OK .\nAlright .\nI mean , I  I  I\nIs some  some version\nOK .\nYeah , so there was like , you know , m m in my head the goal to have like an intermediate version , like , everything I know .\nMm - hmm .\nAnd then , w I would talk to you and figure out everything you know , that  you know , see if they 're consistent .\nYeah . OK . Why don't w Maybe you and I should meet sort of more or less first thing Monday morning and then we can work on this .\nYes . Yeah . That 's f fine with me .\nOK .\nSo . I might  I might  um ,\nYou - y\ns You said you 're busy  over th until the weekend , right ?\nYeah , sort of through the weekend because Kate has a photography show .\nThat 's fine . So we might continue our email thing\nYeah .\nand that might be fine , too . So , maybe I 'll send you some\nUm , if you have time after this I 'll show you the noun phrase thing .\nOK . That would be cool . So . OK , and we 'll  You wanna m\nSo the idea is on Monday at two we 'll  we 'll see an intermediate version of the formalism for the constructions ,\nYeah .\nSo that 's OK for you\nand do an on - line merging with my construal  ideas .\nSure , sure .\nAlright .\nOK .\nThat 's OK .\nSo it won't be , like , a for semi - formal presentation of my  proposal . It 'll be more like towards  finalizing that proposal .\nOK .\nCuz then you 'll find out more of what we 're making you do .\nOK , that 's fine . Yep , and then\nYeah .\nHmm , hmm .\nYikes .\nOy ,  deadlines .\nWe 'll make a presentation of your propo  of your proposal .\nPerfect . Can you also write it up ?\nIt 's like , \" this is what we 're doing .\nAbso\nAnd the complement is Robert . \"\nI 'll  I 'll send you  I 'll  I 'll send you a style file , right ?\nOK .\nYou just\nI already sent you my fi  my bib file . So .\nOK . And , um . Sounds good .\nSomeday we also have to  we should probably talk about the other side of the \" where is X \" construction , which is the issue of , um , how do you simulate questions ? What does the simspec look like for a question ?\nYeah .\nBecause  it 's a little different .\nMm - hmm .\nYeah .\nYeah , now , we we w\nWe had to  we had an idea for this which seemed like it would probably work .\nGreat . OK . Yeah . Simspec may need  we may n need to re - name that .\nYeah .\nI  Yeah . I\nOK ? So let 's think of a name for  for whatever the  this intermediate structure is . Oh , we talked about semspec , for \" semantic spec specification \"\nMmm .\nand that seems  Um .\nIt 's more general\nYou know , so it 's a m minimal change .\nOnly have to change one vowel . That 's great .\nYeah . Just\nAll the old like  graphs ,\nRight .\njust change the  just , like , mark out the\nCool .\nRight , a little substi substi You know , that 's what text substitution uh macros are for .\nYeah . It 's good for you .\nYeah .\nAnyway , uh , so let 's  let 's for the moment call it that until we think of something better .\nOK .\nAnd , yeah , we absolutely need to find  Part of what was missing were markings of all sorts that weren't in there , incl including the questions\nMm - hmm .\nWe didn't  we never did figure out how we were gonna do emphasis in  in uh , the semspec .\nYeah .\nYeah , we 've talked a little bit about  that , too , which  uh , uh , it 's hard for me to figure out with sort of our general linguistic issues , how they map onto this particular one ,\nYeah .\nbut  OK , yeah , understood .\nBut that 's part of the formalism  is got to be uh , how things like that get marked .\nMm - hmm .\nW do you have data , like the  the  You have preliminary  data ? Cuz I know , you know , we 've been using this one easy sentence and I 'm sure you guys have  uh , maybe you are the one who 've been looking at  the rest of it\nUm , I\nit 'd  it 'd be useful for me , if we want to  have it a little bit more data oriented .\nTo tell you the truth , what I 've been looking at has not been the data so far ,\nYeah . Mm - hmm  mm - hmm .\nI just sort of said \" alright let 's see if I can get noun phrases and , uh , major verb co uh , constructions out of the way first . \" And I have not gotten them out of the way yet .\nMm - hmm .\nSurprise . So , um .\nYeah .\nSo , I have not really approached a lot of the data , but I mean obviously like these  the  the question one , since we have this idea about the indefinite pronoun thing and all that , you know , I ca can try and , um run with that , you know , try and do some of the sentence constructions now . It would make sense .\nOK . Do you wanna run the indefinite pronoun idea past Jerry ?\nOK .\nOh yeah , the basic idea is that um , uh  you know  Uh ,  let 's see  if I can  formulate this .\nSo  Mary fixed the car with a wrench .\nYeah .\nSo you perform the mental sum and then , you know , \" who fixed the car with a wrench ? \" You  basically are told , to  to do this In the  in  analogously to the way you would do \" someone fixed the car with a wrench \" . And then you hand it back to your hippocampus and find out  what that , you know ,\nMeans .\nmeans , and then  come up with that  so who that someone was .\nThe WH question has this as sort of extra thing which says \" and when you 're done , tell me who fills that slot \" or w you know .\nMm - hmm .\nSo , um . And , you know , this is sort of a nice way to do it , the idea of sort of saying that you treat  from the simulation point of view or whatever  you treat , uh , WH constructions similarly to uh , indefinite pronouns like \" someone fixed the car \" because  lots of languages , um , have WH questions with an indefinite pronoun in situ or whatever ,\nUse actually the same one .\nand you just get intonation to tell you that it 's a question . So it makes sense\nAlright , which is\num\nSkolemization .\nHmm ?\nMmm .\nIn  in logic , it 's  it 's  @ @  it 's actual Huh ?\nRight .  Let 's put a Skolem   Skolem constant in ,\nYeah . shko\nWhat ?\nSure .\nyeah . Yeah .  Right .\nOK .\nThat - that 's not  that 's not saying it 's bad ,\nRight . Right . No . Of course .\nit 's just that\nMmm .\nthat  that  the logicians have  have , uh\nThat 's right . It makes sense from that point of view , too , which is actually better .\ncome up with this\nSo yeah , um . Anyway , but just that kind of thing and we 'll figure out exactly how to write that up and so on , but\nGood .\nUh , no , all the focus stuff . We sort of just dropped that cuz it was too weird and we didn't even know , like , what we were talking about  exactly , what the object of study was .\nUm - mmm .\nSo .\nYeah . Well , if  if  I mean , i part of  of what the exercise is , t by the end of next week , is to say what are the things that we just don't have answers for yet .\nYeah . Yep .\nThat 's fine . I mean\nMm - hmm .\nWell , if you  if you do wanna discuss focus  background and then get me into that because  I mean , I wo I w scientifically worked on that for  for almost two years .\nYeah . OK , then certainly we will . Good .\nYeah , you should definitely , um be on on that  maybe  maybe by  after Monday we 'll  y you can see what things we are and aren't\nYeah . w We should figure out what our questions are , for example ,  to ask you .\nYeah . Yeah .\nSo .\nOK .\nOK .\nWel - then t Hans . Has  I haven't seen Hans Boas ?\nHe 's been around .\nYeah .\nJust maybe not today .\nOK . So has he been  been involved with this , or  ?\nEh . with us ?\nYeah .\nYeah .\nYeah .\nI would say that tha that those discussions have been primarily , um , Keith and  Keith and me , but um like in th the meeting  I mean , he sort of  I thin like the last meeting we had , I think we were all very much part of it\nYeah .\nbut  um\nSometimes Hans has been sort of coming in there as sort of like a  devil 's advocate type role or something ,\nbut different perspec Yeah .\nlike  \" This make  you know , I 'm going to pretend I 'm a linguist who has nothing to do with this . This makes no sense . \" And he 'll just go off on parts of it which  definitely need fixing\nRight .\nbut aren't where we 're at right now , so it 's\nLike  like what you call certain things ,\nYeah .\nwhich we decided long ago we don't care that much right now .\nRight .\nBut in a sense , it 's good to know that he  of all people\nOK .\nyou know , like maybe a lot of people would have m much stronger reactions , so , you know , he 's like a relatively friendly linguist\nYeah . Yeah .\nand yet a word like \" constraint \" causes a lot of problems . And , so .  Right . So .\nOK . This is consistent with um the role I had suggested that he  he play ,\nAh .\nMm - hmm .\nOK , which was  that o one of the things I would like to see happen is a paper that was tentatively called \" Towards a formal cognitive semantics \" which was addressed to these linguists  uh  who haven't been following  this stuff at all .\nYeah .\nSo  it could be that he 's actually , at some level , thinking about how am I going to  communicate this story\nYeah . Yeah .\nSo , internally , we should just do  whatever works ,\nYeah .\ncuz it 's hard enough .\nYeah .\nBut  if he g if he turns  is  is really gonna turn around and help t to write this version that does  connect with as many as possible of the  other linguists in the world um  then  then it becomes important to  use terminology that doesn't make it hard\nMm - hmm .\nMm - hmm .\nYeah . Yeah .\nMm - hmm .  Sure .\nI mean , it 's gonna be plenty hard for  for people to understand it as it is ,\nYeah .\nbut y y you don't want to make it worse .\nYeah . No , right . I mean , tha that role is  is , uh , indispensable\nSo .\nbut that 's not where sort of our heads were at in these meetings .\nRight .\nIt was a little strange .\nYeah , yeah .  No , that 's fine . I just wanted t to I have to catch up with him , and I wanted t to get a feeling for that . OK .\nYeah .\nMm - hmm .\nSo I don't know what his take will be on these meetings exactly , you know .\nOK . Good .\nCuz sometimes he sort of sounds like we 're talking a bunch of goobledy - gook from his point of view .\nI think it 's good when we 're  when we 're into data and looking at the  some specific linguistic phenomenon  in  in English or in German , in particular , whatever , that 's great ,\nYeah .\nMm - hmm .\nand Ben and  and Hans are , if  if anything , more  you know , they have more to say than , let 's say , I would about some of these things .\nRight .\nBut when it 's like , well , w how do we capture these things , you know , I think it 's definitely been Keith and I who have d you know , who have worried more about the\nMm - hmm .\nWell , that 's good . That 's  I I I think that should be the  the core group\ns Which is fine .\nYeah .\nMm - hmm .\nand  um that 's , you know , I think  very close to the maximum number of people working together that can get something done .\nYeah .\nYes . Yeah . We actually have  I think we have been making progress ,\nYeah .\nand its sort of surprising .\nI  I  I  I definitely get that impression . Yeah .\nYou know , like\nYep .\nThat 's great .\nYeah . So anyone else would like uh  ruin the balance of  Anyway .\nWell , but  Well . But th th then w then we have to come back to the bigger group .\nYeah .\nRight .\nYeah .   Great . And then we 're gon we 're gonna  because of this other big thing we haven't talked about is  actually implementing this stuff ? So that I guess the three of us are gonna connect tomorrow about that .\nYeah , we could talk tomorrow . I was just gonna say , though , that , for instance , there was  you know , out of a meeting with Johno  came the suggestion that \" oh , could it be that the  meaning  constraints really aren't used for selection ? \" which has sort of been implicit  in the parsing  strategy we talked about .\nRight .\nIn which case we w we can just say that they 're the effects or the bindings . Which  uh , so far , in terms of like putting up all the constraints as , you know , pushing them into type constraints , the  when I 've , you know , propo then proposed it to linguists who haven't yet given me  you know , we haven't yet thought of a reason that that wouldn't work . Right ? As long as we allow our type constraints to be reasonably  complex .\nWell , it\nSo  Anyway , to be  to talk about later .\nYeah , it has to in the sense that you 're gonna use them eventu it 's  you know , it 's sort of a , um , generate and test kind of thing ,\nMm - hmm .  Mm - hmm .\nand if you over - generate then you 'll have to do more . I mean , if there are some constraints that you hold back and don't use uh , in your initial matching then you 'll match some things\nMm - hmm .  Mm - hmm .\nI mean , I  I d I don't think there 's any way that it could completely fail . It  it could be that uh , you wind up  I mean  The original bad idea of purely context - free grammars died because  there were just vastly too many parses . You know , exponentially num num many parses . And so th the concern might be that  not that it would totally fail , but that\nMm - hmm . Mm - hmm . That it would still generate too many .  Right ? So by just having semantic even bringing semantics in for matching just in the form of j semantic types , right ?\nit would still genera\nLike \" conceptually these have to be construed as this , this , and this \" might still give us quite a few possibilities\nYeah .\nthat , you know  And  and it certainly helps a lot .\nWe don't know , but , yeah .\nI mean , le let 's put it that way . So .\nNo question . Yeah . And I think it 's a  it 's a perfectly fine place to start . You know , and say , let let 's see how far we can go this way .\nMm - hmm .  Mm - hmm .\nAnd , uh\nWell it definitely makes the problem easier .\nI 'm  I 'm in favor of that . Uh , cuz I think i I think it 's  As you know , I think it 's real hard and if w if we  Right .\nSo  Friday , Monday\nYeah .\nMonday .\nYeah .\nSo . OK , that 's  Tuesday .\nYeah .\nLike   th that 's the conclusion . OK .\nYeah .\nSo , you your dance card is  completely filled now ?\nShoot .\nMm - hmm .\nYeah , and I have nothing to do this weekend but work .\nWhy don't\nNo , that 's not really true ,\nBummer .\nbut like\nWhat about  What about DDR ?\nIt 's almost true .\nOh , I don't have it this weekend , so , tsk  don't have to worry about that .\nMmm .\nDDR , he asked ?\nSpeaking of dance , Dance Dance Revolution I can't believe I 'm  It 's a  it 's like a game , but it 's for , like , dancing . Hard to  It 's like karaoke , but for dancing , and they tell you what  It 's amazing . It 's so much fun . Yeah , it 's so good . My friend has a home version and he brought it over , and we are so into it . It 's so amazing . Well , y you know of it ? I i i it 's one of your hobbies ? It 's great exercise , I must say . I can't wait to hear this . Uh - huh . Oh , definitely . They have , like , places  instead of like  Yeah , instead of karaoke bars now that have , like , DDR , like  Yeah , yeah , I didn't until I started hanging out with this friend , who 's like \" Oh , well , I can bring over the DDR if you want . \" Oh , oh , Dance Dance Revolution  OK . He actually brought a clone called Stepping Selection , but it 's just as good . So . Anyw", "topic_id": 3, "keywords": "weekend, talk, talking, busy, communicate", "dialogue_id": 45}, {"text": "And we already got the crash out of the way . It did crash , so I feel much better , earlier .\nYeah .\nInteresting . Hmm .\nWill you get the door , and  ?\nOK , so um .\nOK . You collected an agenda , huh ?\nI did collect an agenda . So I 'm gonna go first . Mwa - ha - ha ! It shouldn't take too long .\nYeah .\nUm , so we 're pretty much out of digits . We 've gone once through the set . Um , so the only thing I have to do\nNo there 's only ten .\nYeah , that 's right . so I  I just have to go through them\nWell , OK .\nand uh pick out the ones that have problems , and either correct them or have them re - read . So we probably have like four or five more forms to be read , to be once through the set . I 've also extracted out about an hour 's worth . We have about two hours worth . I extracted out about an hour 's worth which are the f digits with  for which whose speaker have speaker forms , have filled out speaker forms . Not everyone 's filled out a speaker form . So I extracted one for speakers who have speaker forms and for meetings in which the \" key \" file and the transcript files are parsable . Some of the early key files , it looks like , were done by hand , and so they 're not automatically parsable and I have to go back and fix those . So what that means is we have about an hour of transcribed digits that we can play with . Um , Liz\nSo you think two  you think two hours is the  is the total that we have ?\nYep , yeah .\nAnd you think we th uh , I  I didn't quite catch all these different things that are not quite right , but you think we 'll be able to retrieve the other hour , reasonably ?\nYes , absolutely .\nOK .\nSo it 's just a question of a little hand - editing of some files and then waiting for more people to turn in their speaker forms . I have this web - based speaker form , and I sent mail to everyone who hadn't filled out a speaker form , and they 're slowly s trickling in .\nSo the relevance of the speaker form here , s\nIt 's for labeling the extracted audio files .\nOh , OK .\nBy speaker ID and microphone type .\nWasn't like whether they were giving us permission to use their digits or something .\nNo , I spoke with Jane about that and we sort of decided that it 's probably not an issue that  We edit out any of the errors anyway . Right ? So the there are no errors in the digits ,\nYeah .\nyou 'll always read the string correctly . So I can't imagine why anyone would care . So the other topic with digits is uh , Liz would like to elicit different prosodics , and so we tried last week with them written out in English . And it just didn't work at all because no one grouped them together . So it just sounded like many many more lines instead of anything else . So in conversations with Liz and uh Jane we decided that if you wrote them out as numbers instead of words it would elicit more phone number , social security number - like readings . The problem with that is it becomes numbers instead of digits . When I look at this , that first line is \" sixty one , sixty two , eighteen , eighty six , ten . \" Um , and so the question is does anyone care ? Um , I 've already spoken with Liz and she feels that , correct me if I 'm wrong , that for her , connected numbers is fine ,\nMm - hmm .\nas opposed to connected digits . Um , I think two hours is probably fine for a test set , but it may be a little short if we actually wanna do training and adaptation and all that other stuff .\nYeah Um , do um you want different prosodics , so if you always had the same groupings you wouldn't like that ? Is that correct ?\nWell , we actually figured out a way to\nYeah , the  the\nthe  the groupings are randomly generated .\nNo but , I was asking if that was something you really cared about because if it wasn't , it seems to me if you made it really specifically telephone groupings that maybe people wouldn't , uh , go and do numbers so much . You know if it if it 's\nUh\nI think they may still do it , um ,\nMaybe some , but I probably not so much .\nWhat about putting a hyphen between the numbers in the group ?\nAnd\nRight ? So if you  if  if you have uh\nSix dash one , you mean ?\nif you go six six six uh dash uh two nine three one .\nI  well OK  I  it might help , I would like to g get away from having only one specific grouping .\nThat 's what I was asking , yeah .\nUm , so if that 's your question ,\nYeah .\nbut I mean it seems to me that , at least for us , we can learn to read them as digits\nYeah .\nif that 's what people want . I  I 'm\nYeah .\ndon't think that 'd be that hard to read them as single digits .\nI agree .\nUm , and it seems like that might be better for you guys since then you 'll have just more digit data ,\nRight .\nand that 's always a good thing .\nYep .\nIt 's a little bit better for me too because the digits are easier to recognize . They 're better trained than the numbers .\nSo we could just , uh , put in the instructions \" read them as digits \" .\nRight .\nRight . Right , read them as single digits , so sixty - one w is read as six one ,\nMm - hmm .\nand if people make a mistake we\nHow about \" O \" versus \" zero \" ?\nI mean , the other thing is we could just bag it because it 's  it 's  it 's - I 'm not worrying about it I mean , because we do have digits training data that we have from uh from OGI . I 'm sorry , digits  numbers training that we have from OGI , we 've done lots and lots of studies with that . And um .\nBut it 's nice to get it in this room with the acous\nYeah .\nI mean  for  it 's\nNo , no , I guess what I 'm saying is that\nJust let them read it how they read it .\nto some extent maybe we could just read them  have them read how  how they read it and it just means that we have to expand our  our vocabulary out to stuff that we already have .\nRight . Well that 's fine with me as long as  It 's just that I didn't want to cause the people who would have been collecting digits the other way to not have the digits .\nYeah . We can go back to the other thing later .\nSo\nI mean we s we  we 've  We can do this for awhile\nOK .\nand then go back to digits for awhile , or um . Do yo I mean , do you want  do you want this  Do you need training data or adaptation data out of this ?\nOK .\nHow much of this do you need ? with uh the\nIt 's actually unclear right now . I just thought well we 're  if we 're collec collecting digits , and Adam had said we were running out of the TI forms , I thought it 'd be nice to have them in groups , and probably , all else being equal , it 'd be better for me to just have single digits\nOK .\nsince it 's , you know , a recognizer 's gonna do better on those anyway , um , and it 's more predictable . So we can know from the transcript what the person said and the transcriber , in general .\nOK , well if you pre\nBut if they make mistakes , it 's no big deal if the people say a hundred instead of \" one OO \" . and also w maybe we can just let them choose \" zero \" versus \" O \" as they  as they like because even the same person c sometimes says \" O \" and sometimes says \" zero \" in different context ,\nYeah .\nand that 's sort of interesting . So I don't have a Specific need cuz if I did I 'd probably try to collect it , you know , without bothering this group , but If we can try it\nOK so  so I can just add to the instructions to read it as digits not as connected numbers .\nMm - hmm .\nRight , and you can give an example like , you know , \" six  sixty - one would be read as six one \" .\nRight .\nMm - hmm . And i actually it 's no more artificial than what we 've been doing with words .\nAnd I think people will get it .\nI 'm sure people can adapt to this , read it single .\nRight , right .\nThe spaces already bias it toward being separated .\nIt 's just easier to read .\nAnd I know I 'm gonna find this easier than words .\nRight .\nOh yeah , absolutely , cognitively it 's much easier .\nOK I also had a hard  hard time with the words ,\nYeah .\nbut then we went back and forth on that . OK , so let 's give that a try\nOK . And is the spacing alright or do you think there should be more space between digits and groups ?\nOK .\nand\nOr is that alright ?\nI mean what do other people think cuz you guys are reading  them .\nI think that i it 's fine .\nOK .\nI it  it  to me it looks like you 've got the func the idea of grouping and you have the grou the idea of separation\nOK .\nand , you know , it 's just a matter of u i the instructions , that 's all .\nGreat . OK .\nAnd I think there are about ten different gouping patterns\nLet 's try it .\nWell let 's give it a try .\nisn't that right , Liz ? That we did .\nRigh - right , and you just  they 're randomly {nonvocalsound} generated and randomly assigned to digits .\nI did  Mm - hmm .\nSo we have\nGo ahead .\nSorry , I  I was just gonna say , so we have in the vicinity of forty hours of  of recordings now . And you 're saying two hours , uh , is digits , so that 's roughly the ratio then ,\nYep .\nsomething like twenty  twenty to one . Which I guess makes  makes sense . So if we did another forty hours of recordings then we could get another couple hours of this .\nRight .\nUm , yeah like you say , I think a couple hours for a  for a  for a test  test set 's OK . It 'd be nice to get , you know , more later because we 'll  we might use  use this up , uh , in some sense ,\nMm - hmm .\nRight .\nbut  but uh\nYeah , I also would like to argue for that cuz it  it seems to me that , um , there 's a real strength in having the same test replicated in  a whole bunch of times and adding to that basic test bank .\nRight .\nHmm ? Cuz then you have , you know , more and more , u chances to get away from random errors . And I think , um , the other thing too is that right now we have sort of a stratified sample with reference to dialect groups , and it might be  there might be an argument to be made for having uh f for replicating all of the digits that we 've done , which were done by non - native speakers so that we have a core that totally replicates the original data set , which is totally American speakers , and then we have these stratified additional language groups overlapping certain aspects of the database .\nRight . I think that uh trying to duplicate , spending too much effort trying to duplicate the existing TI - digits probably isn't too worthwhile because the recording situation is so different .\nYeah .\nIt 's gonna be very hard to be comparable .\nExcept that if you have the stimuli  comparable , then it says something about the  the contribution of setting\nNo it 's  it 's not the same .\nand\nA little bit , but the other differences are so major .\nYeah I mean read versus not .\nOK .\nThey 're such major sources of variance that it 's  it 's  it 's uh\nWhat 's an example of a  of m some of the other differences ? Any other a difference ?\nWell i i individual human glottis  is going to be different for each one ,\nOK .\nyou know , it 's just  There 's so many things .\nWell , and not just that ,\nOK .\nit 's  it  and  and enunciation .\nI mean the uh the corpus itself . I mean , we 're collecting it in a read digit in a particular list , and I 'm sure that they 're doing more specific stuff . I mean if I remember correctly it was like postman reading zipcodes and things like that .\nTI - digits was ?\nI thought so .\nI thought  I thought it was read .\nWas it read ?\nYeah , I think the reading zipcode stuff you 're thinking of would be OGI .\nOh , I may well be .\nYeah , no TI - digits was read in th in read in the studio I believe .\nI haven't ever listened to TI - digits . So I don't really know how it compares .\nYeah . Yeah .\nBut  but regardless it 's gonna  it 's hard to compare cross - corpus .\nBut it  but  It - it 's different people  is the  is the core thing .\nSo .\nOK , fine .\nAnd they 're different circumstances with different recording environment and so forth , so it 's  it 's  it 's really pretty different . But I think the idea of using a set thing was just to give you some sort of framework , so that even though you couldn't do exact comparisons , it wouldn't be s valid scientifically at least it 'd give you some kind of uh frame of reference . Uh , you know it 's not\nHey Liz , What  what do the groupings represent ?\nOK .\nYou said there 's like ten different groupings ?\nRight , just groupings in terms of number of groups in a line , and number of digits in a group , and the pattern of groupings .\nMm - hmm . Are the patterns  like are they based on anything or\nUm , I  I just roughly looked at what kinds of digit strings are out there , and they 're usually grouped into either two , three , or four , four digits at a time .\nOh .\nAnd they can have , I mean , actually , things are getting longer and longer . In the old days you probably only had three sequences , and telephone numbers were less , and so forth . So , there 's between , um  Well if you look at it , there are between like three and five groups , and each one has between two and four groupings and  I purposely didn't want them to look like they were in any kind of pattern .\nMmm .\nSo\nAnd which group appears is picked randomly , and what the numbers are are picked randomly .\nMm - hmm .\nSo unlike the previous one , which I d simply replicated TI - digits , this is generated randomly .\nRight .\nOh OK .\nMmm , oh , OK .\nBut I think it 'd be great i to be able to compare digits , whether it 's these digits or TI - digits , to speakers , um , and compare that to their spontaneous speech , and then we do need you know a fair amount of  of digit data because you might be wearing a different microphone\nMm - hmm .\nand , I mean  so it 's  it 's nice to have the digits you know , replicated many times . Especially for speakers that don't talk a lot .\nYeah .\nSo  um , for adaptation . No , I 'm serious ,\nYeah .\nYeah all we have for some people is digits .\nYeah .\nso we have a problem with acoustic adaptation , and we 're not using the digit data now , but you know\nOh , you 're not .\nNot for adaptation , nope . v W we 're not  we were running adaptation only on the data that we ran recognition on and I 'd  As soon as someone started to read transcript number , that 's read speech and I thought \" well , we 're gonna do better on that ,\nOh I see .\nthat 's not fair to use \" .\nOh yeah that 's true , absolutely .\nOK .\nBut , it might be fair to use the data for adaptation , so . So those speakers who are very quiet ,  shy\nThat would be interesting to see whether that helps .\nr Right\nLike Adam ?\nDo you think that would help adapting on  Yeah . Yeah , I have a real problem with that .\nYeah .\nWell , it sh I mean it 's the same micropho see the nice thing is we have that in the  in the same meeting ,\nRight . Same  same acoustics ,\nYeah .\nand so you don't get\nsame microphone ,\nYeah .\nsame channel .\nRight , and so I still like the idea of having some kind of  digit data .\nOK . Good .\nYeah I mean , for the  for the um acoustic research , for the signal - processing , farfield stuff , I see it as  as  as the place that we start . But , th I mean , it 'd be nice to have twenty hours of digits data , but  but uh the truth is I 'm hoping that we  we through the  the stuff that  that you guys have been doing as you continue that , we get , uh , the best we can do on the spontaneous stuff uh , uh nearfield , and then um , we do a lot of the testing of the algorithms on the digits for the farfield , and at some point when we feel it 's mature and we understand what 's going on with it then we  we have to move on to the spontaneous data with the farfield . So .\nGreat .\nThe only thing that we don't have , I know this sounds weird , and maybe it 's completely stupid , but we don't have any overlapping digits .\nYeah , we talked about that a couple times .\nAn - yea I know it 's weird , but um\nOverlapping digits !\nThe  the problem I see with trying to do overlapping digits is the cognitive load .\nAlright everybody 's laughing . OK .\nDueling digits .\nNo it 's  it 's not stupid , it 's just  I mean , try to do it .\nI 'm just talkin for the stuff that like Dan Ellis is gonna try ,\nI mean , here , let 's try it .\nyou know , cross - talk cancellation .\nYou read the last line , I 'll read the first line .\nLet 's try it .\nOK .\nOh !\nWait  oh it  these are all the same forms .\nSixty - one .\nOK  So but\nSo  so you read the last line , I 'll read the first line .\nNo , I 'll p\nSo you plu you plug your ears .\nOh I guess if you plug you 're ears you could do it , but then you don't get the  the same effects .\nYeah .\nWell , what I mean is actually no not the overlaps that are well - governed linguistically , but the actual fact that there is speech coming from two people\nYeah .\nand the beam - forming stuf all the acoustic stuff that like Dan Ellis and  and company want to do .\nOh I see .\nDigits are nice and well behaved , I mean\nI guess we could try .\nAnyway , it 's just a thought .\nWe could try doing some .\nIt  it would go faster .\nParallel .\nIt would take one around  amount of ti\nIt 's the P - make of digit reading .\nWell  Well OK . Well let 's try it .\nThat 's right . I  I mea I 'm  I was sort of serious , but I really , I mean , I 'm  I don't feel strongly enough that it 's a good idea ,\nSee , y\nYou do the last line , I 'll do the first line .\nso .\nOK .\nO .  That 's not bad .\nNo , I can do it .\nI couldn't understand a single thing you guys were saying .\nA and that prosody was great , by the way .\nI think it was numbers , but I 'm not sure .\nIt  it sort of sounded like a duet , or something .\nYeah .\nPerformance art .\nAlright , let 's try three at once you  you pick one in the middle .\nThe Aurora theater .\nOK .\nGo .\nI 'm sorry . I 'm mean I think it 's doable ,\nThe poor transcribers\nI 'm just\nthey 're gonna hate us .\nSo , we  we could have a round like where you do two at a time , and then the next person picks up when the first guy 's done , or something .\nSo pairwise .\nOh like a round , yeah , like in a  a\nLike a ,\nYeah , just pairwise ,\nyeah .\nwhat do you call it ?\nor yeah .\nRound .\nA round .\nRow , row , row your boat .\nLi - a r like\nMm - hmm .\nYeah .\nyeah , like that .\nOK .\nIt 's gonna require some coordination .\nThen it would go like h twice as fast , or  a third as fast .\nYou have to have a similar pace .\nAnyway , it 's just a thought .\nYeah .\nI 'm actually sort of serious if it would help people do that kind o but the people who wanna work on it we should talk to them .\nI don't think we 're gonna collect vast amounts of data that way ,\nSo .\nMmm .\nbut I think having a little bit might at least be fun for somebody like Dan to play around with ,\nOK .\nI think maybe if we wanted to do that we would do it as a separate session ,\nyeah .\nYeah .\nsomething like that rather than doing it during a real meeting and you know , do two people at a time then three people at a time and things like that . So .\nCan try it out .\nSee  see what Dan thinks .\nIf we have nothing  if we have no agenda we could do it some week .\nYeah , right .\nYeah , yeah . Spend the whole time reading digits with different qu quantities .\nOK .\nI thought this was gonna be fast .\nc c Can I can I have an another  another question w about this ?\nOh well .\nSo , um , there are these digits , which are detached digits , but there are other words that contain the same general phon phoneme sequences . Like \" wonderful \" has \" one \" in it and  and Victor Borge had a  had a piece on this where he inflated the digits . Well , I wonder if there 's , um , an if there would be a value in having digits that are in essence embedded in real words to compare in terms of like the articulation of \" one \" in \" wonderful \" versus \" one \" as a digit being read .\nThat 's \" two \" bad . Yeah .\nI 'm all \" four \" it .\nThere you go .\nNot after I \" eight \" though .\nUh , they don't all work as well , do they ? Hmm . What does nine work in ?\nNein !\nUh .\nUh ,\nYou scream it .\nNein ! You have to be German ,\nOh . In German ,\nThat 's German , yeah .\nIt 's great for the Germans .\nyeah .\nyeah .\nOh , oh !\nNein .\nThat 's right !\nYeah .\nOh !\nIt only sounds w good when you scream it , though . So .\nI think everybody 's a little punchy here  today .\nWell , I mean , I just wanted to offer that as a possible task\nYes .\nbecause , you know , if we were to each read his embedded numbers words in sent in sentences cuz it 's like an entire sketch he does and I wouldn't take the inflated version . So he talks about the woman being \" two - derful \" , and  and  a But , you know , if it were to be deflated , just the normal word , it would be like a little story that we could read .\nMm - hmm .\nI don't know if it would be useful for comparison , but it 's embedded numbers .\nI think for something like that we 'd be better off doing like uh TIMIT .\nWell I don't know . Well I think the question is what the research is , so I mean , I presume that the reason that you wanted to have these digits this way is because you wanted to actually do some research looking at the prosodic form here .\nHmm .\nYeah OK .\nRight , yeah .\nSo if somebody wanted to do that , if they wanted to look at the  the  the difference of the uh phones in the digits in the context of a word versus uh the digits  a  a non - digit word versus in digit word , uh that would be a good thing to do , but I think someone would have to express interest in that .\nI see . OK .\nI think , to  I mean if you were interested in it then we could do it , for instance .\nOK , thank you .\nOK , are we done with digits ?\nHuh .", "topic_id": 0, "keywords": "meetings, meeting, agenda, forms, processing", "dialogue_id": 46}, {"text": "Um , We have ASR results from Liz , transcript status from Jane , and disk space and storage formats from Don . Does  do we have any prefer preference on which way we wanna  we wanna go ?\nWell I was actually gonna skip the ASR results part , in favor of getting the transcription stuff talked about\nMm - hmm .\nsince I think that 's more important to moving forward , but I mean Morgan has this paper copy and if people have questions , um , it 's pretty preliminary in terms of ASR results because we didn't do anything fancy , but I think e just having the results there , and pointing out some main conclusions like it 's not the speaking style that differs , it 's the fact that there 's overlap that causes recognition errors . And then , the fact that it 's almost all insertion errors , which you would expect but you might also think that in the overlapped regions you would get substitutions and so forth , um , leads us to believe that doing a better segmentation , like your channel - based segmentation , or some kind of uh , echo cancellation to get basically back down to the individual speaker utterances would be probably all that we would need to be able to do good recognition on the  on the close - talking mikes .\nSo these\nUm , why don't you , if you have a hard copy , why don't you email it to the list .\nSo , that 's about the summary  But this is  Morgan has this paper .\nYeah , yeah .\nOh it 's in the paper .\nYeah , so it 's the same thing ?\nI mean he  he\nIt 's the same thing I mailed to every everybody that w where it was ,\nit  it 's that paper .\nOK .\nYeah , yeah .\nOK then , it 's already been mailed .\nSo , we basically , um , did a lot of work on that\nyeah .\nand it 's  Let 's see , th I guess the other neat thing is it shows for sure w that the lapel , you know within speaker is bad .\nHorrible ?\nAnd it 's bad because it picks up the overlapping speech .\nSo , your  your ASR results were run on the channels synchronized ,\nYes , cuz that 's all that w had been transcribed at the time ,\nOK . OK . OK .\num but as we  I mean I wanted to here more about the transcription . If we can get the channel asynchronous or the\nYeah .\nthe closer t that would be very interesting for us\nSo if\nbecause we\nYeah , that 's  that 's why I only used the part from use\nYeah .\nwhich we had uh about uh about the alt over all the channels\nYeah .\nRight . That 's\nYeah sure . Yeah .\nor mixed channel\nYeah .\nrather mixed signal .\nSo if there was a segment of speech this long\ncuz\nYeah .\nand oh and someone said \" oh , \" the whole thing was passed to the recognizer ?\nAnd someone said \" oh \" in the front  in the middle .\nThere were several speakers in it , yeah .\nThat 's right . In fact I  I pulled out a couple classic examples in case you wanna u use them in your talk of\nThat 's why there 's so many insertion errors ?\nMm - hmm .\nChuck on the lapel , so Chuck wore the lapel three out of four times .\nMmm .\nI noticed that Chuck was wearing the lapel a lot .\nEarly on , yeah .\nUm , yeah , and I wore the lapel once , and for me the lapel was OK . I mean I still  and I don't know why . I 'm  But um ,\nProbably how you wear it  wore it I would guess .\nfor you it was  Or who was next to me or something like that .\nYeah , where you were sitting probably affected it .\nYeah .\nRight , but when Chuck wore the lapel and Morgan was talking there 're a couple really long utterances where Chuck is saying a few things inside , and it 's picking up all of Morgan 's words pretty well and so the rec you know , there 're error rates because of insertion  Insertions aren't bounded , so with a one - word utterance and ten insertions you know you got huge error rate .\nUh - huh .\nYeah .\nAnd that 's  that 's where the problems come in . So I this is sort of what we expected , but it 's nice to be able to  to show it .\nRight .\nAnd also I just wanted to mention briefly that , um , uh Andreas and I called up Dan Ellis who 's still stuck in Switzerland , and we were gonna ask him if  if there 're  you know , what 's out there in terms of echo cancellation and things like that . Not that we were gonna do it , but we wanted to know what would need to be done .\nAnd he said , \" Lots lots lots lots . \"\nAnd he  We 've given him the data we have so far , so these sychronous cases where there are overlap .\nYep .\nAnd he 's gonna look into trying to run some things that are out there and see how well it can do\nSo\nbecause right now we 're not able to actually report on recognition in a real paper , like a Eurospeech paper , because it would look sort of premature .\nSo  So the idea is that you would take this big hunk where somebody 's only speaking a small amount in it , and then try to figure out where they 're speaking  based on the other peopl\nRight . Or who 's  At any point in time who 's the foreground speaker , who 's the background speaker .\nSo yeah\nI thought we were just gonna move the boundaries in .\nYeah , should it\nSo .\nWell that 's with the hand stuff .\nSo there 's like\nBut how would you do that automatically ?\nWell ther there 's\nUh , I 've actually done some experiments with cross - correlation\nRight .\nand it seems to work pretty well to  to get rid of those  those overlaps ,\nI mean that that 's the sort of thing that you would do .\nMm - hmm .\nYeah .\nyeah .\nSo .\nYeah . Exactly , so it 's  it 's a\nSo why do you want to do echo cancellation ?\nUm , it would be techniques used from adaptive  adaptive echo cancellation which I don't know enough about to talk about .\nUh - huh .\nIt  just  it just to r to remove cross - talk .\nUm .\nYeah .\nYeah .\nBut , right , um , and that would be similar to what you 're also trying to do , but using um , you know , more than energy\nYeah .\nI  I don't know what exactly would go into it .\nYeah , sure .\nSo it would be\nSo the idea is to basically run this on the whole meeting . and get the locations , which gives you also the time boundaries of the individual speak\nOK . So do sort of what he 's already  what he 's trying to do .\nRight . Except that there are many techniques for the kinds of cues , um , that you can use to do that .\nYeah , in another way ,\nOK , I s I see .\nyeah . Yeah .\nYeah . I see .\nYeah , Dave  Dave uh is , um , also gonna be doin usin playing around with echo cancellation for the nearfield farfield stuff ,\nSo .\nso we 'll be\nAnd I guess Espen ? This  is  uh  is he here too ?\nYeah .\nMay also be working  So it would just be ver that 's really the next step because we can't do too much , you know , on term in terms of recognition results knowing that this is a big problem\nMm - hmm .\num , until we can do that kind of processing . And so , once we have some  some of yours ,\nOK . Yeah I 'm working on it .\nand @ @ we 'll move on .\nI think this also ties into one of the things that Jane is gonna talk about too .\nUm ,\nOK .\nI also wanted to say I have done all this chopping up of digits ,\nMm - hmm . Mm - hmm .\nso I have some naming conventions that we should try to agree on . So let 's do that off - line ,\nOh right .\nwe don't need to do it during the meeting .\nYeah .\nOK .\nRight . Definitely\nAnd  and I have scripts that will extract it out from \" key \" files\nUh , and Don should\nand  and do all the naming automatically ,\nOK .\nAlright .\nso you don't have to do it by hand .\nGreat .\nYou 've compiled the list of , uh , speaker names ?\nSo that that 's it for the\nMm - hmm .\nSpeakers and  OK .\nNot names , but I Ds .\nYep . Yeah , names  names in the  names to I Ds ,\nOK .\nso you\nGreat .\nand it does all sorts of matches because the way people filled out names is different on every single file so it does a very fuzzy sort of match .\nRight .\nCool .\nSo at this point we can sort of finalize the naming , and so forth ,\nMm - hmm .\nYep .\nand we 're gonna basically re rewrite out these waveforms that we did because as you notice in the paper your \" M O in one meeting and \" M O - two \" in another meeting and it 's  we just need to standardize the\nYeah . That was my fault .\num , no it 's  it 's\nNo , I didn't notice that actually .\num , that 's why those comments are s  are in there .\nYeah . Then disregard it then .\nYep . So th I now have a script that you can just say basically look up Morgan ,\nSo\nYeah .\nRight . OK .\nand it will give you his ID .\nGreat , great .\nOK .\nSo . Um ,\nTerrific .\nalright . Do we  Don , you had disk space and storage formats . Is that something we need to talk about at the meeting , or should you just talk with Chuck at some other time ?\nUm , I had some general questions just about the compression algorithms of shortening waveforms and I don't know exactly who to ask . I thought that maybe you would be the  the person to talk to . So , is it a lossless compression  when you compress ,\nMm - hmm .\nso\nEntropy coding .\nIt just uses entropy coding ?\nSo .\nOK . So , I mean , I guess my question would be is I just got this new eighteen gig drive installed . Um , yeah , which is\nAnd I assume half of it is scratch and half of it is  ?\nI 'm not exactly sure how they partitioned it .\nProbably , yeah .\nBut um ,\nThat 's typical , huh .\nyeah , I don't know what 's typical here , but um , it 's local though , so\nThat doesn't matter .\nBut\nYou can access it from anywhere in ICSI . N\nOK . Alright . How do you do that ?\nIn fact , this is an eighteen gig drive ,  or is it a thirty six gig drive with eighteen\nN\nEighteen .\nEigh - eighteen . It was a spare that Dave had around\nSlash N slash machine name , slash X A in all likelihood .\nOh OK .\nOh I see . OK . Alright , I did know that .\nUm , so the  the only question is how much of it  The distinction between scratch and non - scratch is whether it 's backed up or not .\nMm - hmm . Right .\nSo what you wanna do is use the scratch for stuff that you can regenerate .\nOK .\nSo , the stuff that isn't backed up is not a big deal because disks don't crash very frequently ,\nRight .\nas long as you can regenerate it .\nRight . I mean all of this stuff can be regenerated ,\nYeah it 's\nit 's just a question\nThen put it all on scratch\nWell the\nbecause we 're  ICSI is  is bottlenecked by backup .\nMm - hmm , very good point .\nYeah .\nOK .\nSo we wanna put\nWell I 'd leave all the  All the transcript stuff shouldn't  should be backed up ,\nMm - hmm .\nbut all the waveform   Sound files should not be backed up ,\nYeah , I guess  Right .\nthe ones that you write out .\nOK . So , I mean , I guess th the other question was then , should we shorten them , downsample them , or keep them in their original form ? Um\nIt just depends on your tools . I mean , because it 's not backed up and it 's just on scratch , if your sc tools can't take shortened format , I would leave them expanded ,\nRight .\nso you don't have to unshorten them every single time you wanna do anything .\nOK .\nWe can downsample them ,\nDo you think that 'd be OK ?\nso .\nTo downsample them ?\nYeah . Yeah , we get the same performance .\nOK .\nI mean the r the front - end on the SRI recognizer just downsamples them on the fly ,\nYeah , I guess the only argument against downsampling is to preserve just the original files in case we want to experiment with different filtering techniques .\nso  So that 's\nI  I  I 'm sorry\nYeah , if\nYeah , l I mean over all our data , we  we want to not downsample .\nfe You 'd  you wanna not . OK .\nYeah .\nSo we 're  what we 're doing is we 're writing out  I mean , this is just a question . We 're writing out these individual segments , that wherever there 's a time boundary from Thilo , or  or Jane 's transcribers , you know , we  we chop it  there .\nYeah . Mm - hmm .\nAnd the reason is so that we can feed it to the recognizer ,\nMm - hmm .\nand throw out ones that we 're not using and so forth .\nYeah .\nAnd those are the ones that we 're storing .\nYeah , as I said , since that 's  it 's regeneratable , what I would do is take  downsample it ,\nSo  Yeah .\nand compress it however you 're e the SRI recognizer wants to take it in .\nYeah .\nye\nSo we can't shorten them ,\nRight .\nbut we can downsample them .\nYeah , I mean  yeah , I 'm sorry .\nSo .\nAs  yeah , as long as there is a  a form that we can come from again , that is not downsampled ,  then ,\nr Yeah .\nOh yeah th\nYeah those are gonna be kept .\nYeah . Yeah . That  that 's why we need more disk space\nuuu\ncuz we 're basically duplicating the originals , um\nYeah .\nRight .\nThen it 's fine . But for  for  fu future research we 'll be doing it with different microphone positions and so on\nOh yeah .\nRight .\nYep .\nNo . We always have the original long ones .\nwe would like to\nSo the SRI front - end won't take a uh  an  an  a large audio file name and then a  a list of segments to chop out  from that large audio file ?\nYeah .\nThey actually have to be chopped out already ?\nUm , it 's better if they 're chopped out ,\nUh - huh .\nand  and it  it will be  yeah , y we could probably write something to do that , but it 's actually convenient to have them chopped out cuz you can run them , you know , in different orders . You c you can actually move them around .\nAnd that 's the whole point about the naming conventions\nUh , you can get rid of\nis that you could run all the English speaking ,\nYeah , it it 's a lot faster .\nall the native speakers , and all the non - native speakers ,\nRight . You can grab everything with the word \" the \" in it ,\nand all the men , and all the women . Yeah .\nand it 's  That 's a lot quicker than actually trying to access the wavefile each time , find the time boundaries and  So in principle , yeah , you could do that ,\nI don't  I don't think that 's really right .\nbut it 's  but it 's um\n\" That 's just not right , man . \" The  the point\nThese are long  These are long\nSo  so s For example , what if you wanted to run  run all the native speakers .\nYou know . This is an hour of speech .\nRight , so if  if you did it that way you would have to generate a program that looks in the database somewhere , extracts out the language , finds the time - marks for that particular one , do it that way . The way they 're doing it , you have that already extracted and it 's embedded in the file name . And so , you know , you just say\nWe - yeah that 's  so that 's part of it\ny so you just say you know \" asterisk E asterisk dot wave \" , and you get what you want .\nis  Right . And the other part is just that once they 're written out it  it is a lot faster to  to process them .\nRather than doing seeks through the file .\nSo . Otherwise , you 're just accessing\nThis is all just temporary access , so I don't  I think  it 's all just  It 's fine . You know . Fine to do it however is convenient .\nRight .\nI mean it just depends how big the file is . If the file sits in memory you can do extremely fast seeks\nRight . The other thing is that , believe it or not  I mean , we have some\nbut .\nYeah and they don't . Two gig ?\nSo we 're also looking at these in Waves like for the alignments and so forth . You can't load an hour of speech into X Waves .\nYeah .\nYou need to s have these small files , and in fact , even for the Transcriber program Um\nYes you can .\nYeah , you  you can give Waves a start and an end time . And middle .\nYeah , if you try to load s really long waveform into X Waves , you 'll be waiting there for\nNo , I  I 'm not suggesting you load a long wave file ,\nOh\nI 'm just saying you give it a start and an end time . And it 'll just go and pull out that section .\nI th w The transcribers didn't have any problem with that did they Jane ?\nWhat 's th u w in what respect ?\nLoading the long\nNo , with the Transcriber tool , it 's no problem .\nThey loaded  they loaded the long long files into X Waves .\nIt takes a very long ti\nYeah just to load a transcription\nIn the  in Mm - hmm .\nRight .\ntakes a long time ,\nIt takes a l very long time .\nbut not for the wavefile . The wavefile is there immediately .\nMm - hmm . Yeah .\nAre you talking about Transcriber or X Waves ?\nHuh .\nYeah . Oh , I 'm tr talking about Transcriber .\nActually , you 're talking about Transcriber , right ?\nYeah .\nBecause  because i we used X Waves to do the digits .\nIt was also true of the digits task which was X Waves .\nAnd they were loading the full mixed files then ,\nYeah . Very quickly .\nand it didn't seem to be any problem .\nI agree .\nHuh . Well we  we have a problem with that , you know , time - wise on a  It - it 's a lot slower to load in a long file ,\nHmm . Seemed really fast .\nand also to check the file , so if you have a transcript , um ,\nWell regardless , it 's\nYeah .", "topic_id": 1, "keywords": "transcription, utterances, transcribed, asr, transcribers", "dialogue_id": 46}, {"text": "I mean it 's  I  I think overall you could get everything to work by accessing the same waveform and trying to find two  you know , the begin and end times . Um , but I think it 's more efficient , if we have the storage space , to have the small ones .\nand , it 's no problem , right ?\nYeah , it 's\nBecause it 's not backed up .\nYeah .\nSo we just\nIt 's  it 's just\nIf we don't have a spare disk sitting around we go out and we buy ourselves an eighty gigabyte drive and make it all scratch space . You know , it 's not a big deal .\nYou 're right about the backup being  a bottleneck .\nRight .\nIt 's good to think towards scratch .\nYeah , so these wouldn't be backed up , the\nYeah .\nYep .\nRight .\nSo remind me afterward\nAnd\nand I 'll  and we 'll look at your disk and see where to put stuff .\nOK . Alright . I mean , I could just u do a DU on it right ? And just see which  how much is on each  So .\nYep . Each partition . And you wanna use , either XA or scratch .\nOK .\nWell X question mark , anything starting with X is scratch .\nOK .\nWith two  two digits .\nTwo digits , right , XA , XB , XC . OK ?\nSo , @ @ .\nJane ?\nOK . So I got a little print - out here . So three on this side , three on this side . And I stapled them . OK . Alright so , first of all , um , there was a  an interest in the transcribe transcription , uh , checking procedures and   and I can  tell you first , uh , to go through the steps although you 've probably seen them . Um , as you might imagine , when you 're dealing with , um , r really c a fair number of words , and uh , @ @  natural speech which means s self - repairs and all these other factors , that there 're lots of things to be , um , s standardized and streamlined and checked on . And , um , so , I did a bunch of checks , and the first thing I did was obviously a spell - check . And at that point I discovered certain things like , um , \" accommodate \" with one \" M \" , that kind of thing . And then , in addition to that , I did an exhaustive listing of the forms in the data file , which included n detecting things like f faulty punctuation and things\nI 'm  I 'm sorry to interrupt\nYeah ?\nyou could  could I just back up a little bit\nSure , please ,\nand\nyeah , please , please .\nSo you 're doing these  So  the whole process is that the transcribers get the conversation\nYeah , yeah , yeah .\nand they do their pass over it .\nYes .\nAnd then when they 're finished with it , it comes to you ,\nThat 's right .\nand you begin these sanit these quality checks .\nExactly . I do these checks .\nOK .\nUh - huh .\nOK .\nExactly . Yeah . Thank you . And so , uh , I do a  an exhaustive listing of the forms  Actually , I will go through this in  in order , so if  if we could maybe wait and stick keep that for a second cuz we 're not ready for that .\nSo on the fifth page , seven down\nYeah , yeah , yeah , yeah . Exactly ! Exactly ! Alright so ,  a spelling check first then an exhaustive listing of the , uh  all the forms in the data with the punctuation attached and at that point I pick up things like , oh , you know , word followed by two commas . And th and then another check involves , uh , being sure that every utterance has an identifiable speaker . And if not , then that gets checked . Then there 's this issue of glossing s w so - called \" spoken - forms \" . So there  mo for the most part , we 're keeping it standard wo word level transcription . But there 's  w And that that 's done with the assumption that  pronunciation variants can be handled . So for things like \" and \" , the fact that someone doesn't say the \" D \" , uh that 's not important enough to capture in the transcription because a  a good pronunciation , uh , you know , model would be able to handle that . However , things like \" cuz \" where you 're lacking an entire very prominent first syllable , and furthermore , it 's a form that 's specific to spoken language , those are r reasons  f for those reasons I  I kept that separate , and used the convention of using \" CUZ \" for that form , however , glossing it so that it 's possible with the script to plug in the full orthographic form for that one , and a couple of others , not many . So \" wanna \" is another one , \" going  \" uh , \" gonna \" is another one , with just the assumption , again , that this  th these are things which it 's not really fair to a c consider  expect that  a pronunciation model , to handle . And Chuck , you in you indicated that \" cuz \" is  is one of those that 's handled in a different way also , didn't you ? Did I\nI don't remember .\nOK . So  so it might not have been   It might not have been you ,\nHmm .\nbut someone told me that in fact \" cuz \" is treated differently in , um , i u in this context because of that r reason that , um , it 's a little bit farther than a pronunciation variant . OK , so after that , let 's see ,\nSo that was part of the spell - check ,  or was that  that was after the spell - check ?\num . Well so when I get the exhau So the spell - check picks up those words because they 're not in the dictionary .\nUh - huh .\nSo it gets \" cuz \" and \" wanna \" and that\nAnd then you gloss them ?\nYeah , mm - hmm . Run it through  I have a sed  You know , so I do sed script saying whenever you see \" gonna \" you know , \" convert it to gonna \" , you know , \" gloss equals quote going - to quote \" , you know . And with all these things being in curly brackets\nMm - hmm .\nso they 're always distinctive . OK , I also wrote a script which will , um , retrieve anything in curly brackets ,  or anything which I 've classified as an acronym , and  a pronounced acronym . And the way I tag ac pronounced acronyms is that I have underscores between the components . So if it 's \" ACL \" then it 's \" A \" underscore \" C \" underscore \" L \" .\nAnd so  so your list here , are these ones that actually occurred in the meetings ?\nAnd the th Yes . Uh - huh , yeah .\nWhew !\nOK , so now . Uh and  a\nWe are acronym - loaded .\nUm , can I ask a question about the glossing , uh before we go on ?\nYeah .\nSo , for a word like \" because \" is it that it 's always predictably \" because \" ? I mean , is \" CUZ \" always meaning \" because \" ?\nYes , but not the reverse . So sometimes people will say \" because \" in the meeting , and if  if they actually said \" because \" , then it 's written as \" because \" with no  w \" cuz \" doesn't even figure into the equation .\nBut  but in our meetings people don't say \" hey cuz how you doing ? \"\nBeca - because  Right .   Right .\nExcept right there .\nYeah .\nYeah .\nUm , so , I guess  So , from the point of view of\nThat 's a good point .\nThe  the only problem is that with  for the recognition we  we map it to \" because \" ,\nWell ,\nand so if we know that \" CUZ \"\nThat 's fine .\nbut they have the gloss .\nWell Don has a script .\nYeah .\nbut , we don't\nYou have the gloss form so you always replace it .\nExactly .\nIf that 's how  what you wanna do .\nUh - huh . And Don knows this ,\nYeah .\nand he 's bee he has a glo he has a script that\nI replace the \" cuz \" with \" because \" if it 's glossed .\nS Right . But , if it 's  OK .\nAnd\nBut then there are other glosses that we don't replace , right ? Because\nYes . And that 's why there 're different tags on the glosses ,\nOK . So , then it 's fine .\non the different  on the different types of comments , which we 'll  which we 'll see in just a second .\nRight .\nOK .\nSo the pronounceable acronyms get underscores , the things in curly brackets are viewed as comments . There 're comments of four types . So this is a good time to introduce that . The four types . w And maybe we 'll expand that\nUm\nbut the  but the comments are , um , of four types mainly right now . One of them is , um , the gloss type we just mentioned .\nCan  ca\nAnother type is , um\nSo a are we done with acronyms ? Cuz I had a question on what  what this meant .\nI 'm still doing the overview . I haven't actually gotten here yet .\nOh I 'm sorry .\nOK so , gloss is things like replacing the full form u with the , um , more abbreviated one to the left . Uh , then you have if it 's  uh , there 're a couple different types of elements that can happen that aren't really properly words , and wo some of them are laughs and breathes , so we have  uh that 's prepended with a v a tag of \" VOC \" .\nWhew !\nAnd the non - vocal ones are like door - slams and tappings , and that 's prepended with a no non - vocalization .\nSo then it  just an ending curly brace there , or is there something else in there .\nOh yeah , so i e this would\nA comment , basically .\nLet 's just take one example .\nOh , oh , oh .\nAnd then the no non - vocalization would be something like a door - slam . They always end . So it 's like they 're paired curly brackets . And then the third type right now ,  uh , is  m things that fall in the category of comments about what 's happening . So it could be something like , you know , \" referring to so - and - so \" , \" talking about such - and - such \" , uh , you know , \" looking at so - and - so \" .\nSo on the m\nYeah .\non the middle t So , in the first case that gloss applies to the word to the left . But in the middle two  Th - it 's not applying to anything , right ?\nYeah , and this gets substituted here .\nThey 're impulsive .\nOK .\nHuh - uh . No , they 're events .\nOK .\nWell the \" QUAL \" can be  The \" QUAL \" is applying to the left .\nThey 're actually  They have the status of events .\nRight , I just meant the middle two ones , yeah .\nYep .\nWell , and actually , um , it is true that , with respect to \" laugh \" , there 's another one which is \" while laughing \" ,\n\" While laughing \" .\nand that is , uh , i i An argument could be made for this  tur turning that into a qualitative statement because it 's talking about the thing that preceded it , but at present we haven't been , um , uh , coding the exact scope of laughing , you know , and so to have \" while laughing \" , you know that it happened somewhere in there which could well mean that it occurred separately and following , or , you know , including some of the utterances to the left . Haven't been awfully precise about that , but I have here , now we 're about to get to the  to this now , I have frequencies . So you 'll see how often these different things occur . But , um , uh , the very front page deals with this , uh , final c pa uh , uh , aspect of the standardization which has to do with the spoken forms like \" mm - hmm \" and \" mm - hmm \" and \" ha \" and \" uh - uh \" and all these different types . And , um , uh , someone pointed out to me , this might have been Chuck ,  about , um  about how a recognizer , if it 's looking for \" mm - hmmm \" with three M 's ,  and it 's transcribed with two M 's ,  that it might  uh , that it might increase the error rate which is  which would really be a shame because um , I p I personally w would not be able to make a claim that those are dr dramatically different items . So , right now I 've standardized across all the existing data with these spoken forms .\nOh good .\nI  I should say\nSo it 's a small list .\nall existing data except thirty minutes which got found today . So , I 'm gonna   I 'm gonna   I 'm gonna check\nThat  that 's known as \" found data \" .\nYeah , yeah . Acsu - actually yeah . I got  It was stored in a place I didn't expect ,\nIt 's like the z Zapruder Film .\nso  and  and um , w we , uh , sh yea reconstructed how that happened .\nI wanna work with lost data .\nYeah . It 's much easier .\nAnd this is  this 'll be great . So I 'll  I 'll be able to get through that tonight , and then everyth i well , actually later today probably .\nHmm .\nAnd so then we 'll have everything following these conventions . But you notice it 's really rather a small set of these kinds of things .\nYeah .\nAnd I made it so that these are , um , with a couple exceptions but , things that you wouldn't find in the spell - checker so that they 'll show up really easily . And , um\nJane , can I ask you a question ? What 's that very last one correspond to ?\nSure .\nI don't even know how to pronounce that .\nWell , yeah . Now that  that s only occurs once ,\nYeah .\nand I 'm thinking of changing that .\nRight .\nUh , is that like someone 's like burning or some such thing ?\nSo - c I haven't listened to it so I don't know .\nLike their hair 's on fire ?\nI haven't heard it actually . I n I need to listen to that one .\nAh !\nIt 's the Castle of Ah !\nActually we  we gave this to our pronunciation person ,\nUh , it looks like that .\nshe 's like , \" I don't know what that is either \" . So .\nDid she hear the th did she actually hear it ? Cuz I haven't heard it .\nNo , we just gave her a list of words that , you know , weren't in our dictionary and so of course it picked up stuff like this , and she just didn't listen so she didn't know . We just  we 're waiting on that  just to do the alignments .\nYeah . Yeah I 'm curious to se hear what it is , but I didn't know  wanna change it to something else until I knew .\nRight .\nMaybe it 's \" argh \" ?", "topic_id": 2, "keywords": "backup, storage, disk, bottleneck, partition", "dialogue_id": 46}, {"text": "Well , sss ,  you know\nBut that 's not really like\nHhh .\nNo one really says \" argh , \" you know ,\nYeah . Right , no one say\nit 's not\nWell , you just did .\nExcept for now !\nWell , there 's another  there 's another word error .\nYeah . That 's right .\nYes , that 's right . We 're gonna have a big problem when we talk about that .\nCha - ching .\nAh .\nWe 're gonna never recognize this meeting .\nIn Monty Python you say \" argh \" a lot .\nOK .\nOh yeah ?\nSo . Well , or if you 're a C programmer .\nMmm .\nYou say arg - C and arg - V all the time .\nYeah , that 's right .\nYeah .\nThat 's right .\nThat 's true .\nYeah .\nYeah\nBut it has a different prosody .\nArg .\nIt does .\nMm - hmm .\nArg  arg - max , arg - min , yeah .\nAh !\nUh ,\nSo , Jane , what 's the  d\nMaybe he died while dictating .\nso .\nI have one question about the the \" EH \" versus like the \" AH \" and the \" UH \" .\nThat 's partly a nonnative - native thing ,\nOK .\nbut I have found \" EH \" in native speakers too .\nBut it 's mostly non - native\nH\nThat 's \" eh \" versus \" ah \" ?\nS OK .\nEh .\nEh ?\n\" Eh , \" yeah right , cuz there were  were some speakers that did definite \" eh 's \"\nMm - hmm .\nbut right now we\nThey were the Canadians , right ?\nCanadians , yeah , yeah , yeah .\nThat 's right .\nSo , it  it 's actually probably good for us to know the difference between the real \" eh \" and the one that 's just like \" uh \" or transcribed \" aaa \"\nExactly .\ncuz in  like in Switchboard , you would see e all of these forms , but they all were like \" uh \" .\nYou mean just the single letter \" a \"  as in the particle ?\nThe transcription or\nArticle .\nNo , no , I mean like the  the \" UH \" ,\n\" UH \" .\nOh .\nor  the \" UH \" , \" EH \" , \" AH \" were all the same . And then , we have this additional non - native version of  uh , like \" eeh \" .\nAll the \" EH \" 's I 've seen have been like that . They 've been like \" eh \" like that have bee has been transcribed to \" EH \" . And sometimes it 's stronger ,\nMm - hmm , that 's right .\nlike \" eeh \"  which is like closer to \" EH \" .\nMmm .\nRight .\nBut .\nI 'm just  these poor transcribers , they 're gonna hate this meeting .\nYeah .\nI know . We should go off - line .\nWell ,  we 're not doing  We 're not doing length .\nQuick Thilo , do a  do a filled pause for us .\nYeah , that 's right .\nOoo  no .\nBut you 're a native German speaker so it 's not a  not a issue for\nYeah .\nIt 's only\nThem Canadians .\nOnl yeah . No , only if you don't have lax vowels , I guess .\nOh .\nRight .\nThis makes sense .\nSo it 's  like Japanese and Spanish\nYeah I  I think you 've  uh - huh , yeah .\nOh I see .\nUh - huh .\nand\nI didn't get that ,\nThat makes sense .\nOK .\nYeah , and so , you know , I mean , th th I have  there are some , um , Americans who  who are using this \" eh \" too , and I haven't listened to it systematically , maybe with some of them , uh , they 'd end up being \" uh 's \" but , uh , I my spot - checking has made me think that we do have \" eh \" in also , um , American e e data represented here . But any case , that 's the  this is reduced down from really quite a long a much longer list ,\nYeah this is great .\nMm - hmm .\nYeah , it 's good ,\nand this is\nyeah .\nThis is really really helpful .\nfunctionally pretty , you know , also  It was fascinating , I was listening to some of these , uh , I guess two nights ago , and it 's just hilarious to liste to  to do a search for the \" mm - hmm 's \" . And you get \" mm - hmm \" and diff everybody 's doing it .\nAnd just listen to them ? Yeah .\nJust  I wanted to say  I w think it would be fun to make a montage of it because there 's a \" Mm - hmm . Mm - hmm .\nPerformance art ,\nMm - hmm . \"\njust extract them all .\nRight .\nIt 's really  it 's really fun to listen to .\nMorgan can make a song out of it .\nAll these different vocal tracts , you know , but it 's  it 's the same item . It 's very interesting . OK . Uh , then the acronyms y and the ones in parentheses are ones which the transcriber wasn't sure of ,\nOh I see .\nand I haven't been able to listen to to  to clarify , but you can see that the parenthesis convention makes it very easy to find them\no How about question mark ?\ncuz it 's the only place where  where they 're used .\nThe question marks , yeah . What are those ?\nQuestion mark is punctuation . So it  they said that @ @\nMm - hmm .\nOh .\num , \" DC ? \"\nAh .\nSo they  so it 's \" PLP ? \"\nExactly . Exactly . Yeah , so the only  Well , and I do have a stress marker here . Sometimes the contrastive stress is showing up , and , um\nI 'm sorry , I  I got lost here . What - w what 's the difference between the parenthesized acronym and the non - parenthesized ?\nThe parenthesized is something that the transcriber thought was ANN , but wasn't entirely sure . So I 'd need to go back or someone needs to go back , and say , you know , yes or no ,\nAh .\nand then get rid of the parentheses .\nRight .\nBut the parentheses are used only in that context in the transcripts , of of noti noticing that there 's something uncertain .\nYeah , P - make is\nYeah I mean cuz they  they have no idea ,\nThat 's a good one . That 's correct .\nright . If you hear CTPD , I mean , they do pretty well\nYeah .\nMm - hmm .\nbut it 's\nI  I don't recognize a lot of these .\nyou know how are  how are they gonna know ?\nYeah .\nI know ! I  I was saying that I think a lot of them are the Networks meeting .\nI\nI think that 's true .\nMaybe .\nYeah , absolutely .\nI see a few .\nNSA ,\nYeah .\na lot of these are  are coming from them . I listened to some of that .\nYeah , we don't have that many acronyms comparatively in this meeting .\nAlthough I see  I see plenty of uh\nYeah . Yeah . I agree .\nIt 's not so bad .\nRight .\nAnd Robustness has a fair amount ,\nYeah .\nMmm .\nbut the NSA group is just very very many .\nThe recognizer , it is funny . Kept getting PTA for PDA .\nYeah , that 's pretty close .\nYeah .\nThis is close , right ,\nThat 's not bad .\nand the PTA was in these , uh , topics about children ,\nYeah .\nso , anyway .\nThat 's interesting .\nIs the P - PTA working ?\nRight and sometimes , I mean , you see a couple of these that are actually \" OK 's \" so it 's  it 's  may be that they got to the point where  I mean it was low enough understandable  understandability that they weren't entirely sure the person said \" OK . \" You know , so it isn't really necessarily a an undecipherable acronym ,\nThere 's a lot of \" OK 's \" .\nbut just n needs to be double checked . Now we get to the comments . This\nThe number to the left is the number of incidences ?\nCount . Yep .\nNumber of times out of the entire database ,\nUh - huh .\nw except for that last thirty minutes I haven't checked yet .\nSo CTS is really big here ,\nYeah , I wonder what it is .\nyeah . Yeah .\nSo what is the difference between \" papers rustling \" and \" rustling papers \" ?\nIP , I know what IP is .\nI 'd have to listen . I  I I agree . I w I 'd like to standardize these down farther but , um , uh , uh , to me that sounds equivalent .\nYeah .\nBut , I  I 'm a little hesitant to  to collapse across categories unless I actually listen to them .\nSeems so .\nOK .\nOh I 'm sure we 've said XML more than five times .\nWell , then , at least now .\nNow it 's at least six times , yeah .\nS s six now , yeah .\nYeah . Six . OK well\nWh - the self - referential aspect of these  these p\nI 'm wai\nYeah .\nYes , it 's very bad .\nWell this is exactly how people will prove that these meetings do differ because we 're recording , right ?\nYes .\nY no normally you don't go around saying , \" Now you 've said it six times .\nYeah  that 's right .\nNow you 've said \"\nBut did you notice that there were seven hundred and eighty five instances of \" OK \" ?\nSeven hundred eighty - five instances .\nAnd that 's just without the  without punc punctuation .\nYeah .\nYep .\nNo , I didn't . Yeah .\nAnd that 's an underestimate\nExtra forty one if it 's questioned .\nWhere 's that ?\ncuz they 're Yep .\nSo th\nOn the page two of acronyms .\nIs this after  like did you do some uh replacements for all the different form of \" OK \" to this ?\nYeah . Seven hundred eighty .\nYeah . Of \" OK \" , yes .\nOK .\nMm - hmm . So that 's the single existing convention for \" OK \" .\nWait a minute , w s\nSo now we 're up to seven hundred and eighty eight .\nYeah that 's\nAlthough , what 's  there 's one with a slash after it . That 's kind of disturbing .\nYeah .\nYeah , we 'll have to look at it you know .\nThat 's  that 's  I looked for that one .\nYeah .\nAnyway .\nI actually explicitly looked for that one ,\nMm - hmm .\nand I think that , um , I  I 'm not exactly sure about that .\nWas that somewhere where they were gonna say \" new speaker \" or something ?\nNo , I looked for that , but that doesn't actually exist . And it may be , I don't  I can't explain that .\nThat 's alright . I 'm just pointing that out .\nI i it 's the only\nThere 's\nit 's the only pattern that has a slash after it , and I think it 's  it 's an epiphenomenon .\nWell there 's not @ @ .\nSo I 'll just  I was just looking at the bottom of page three there , is that \" to be \" or \" not to be \" .\nYeah .\nThere 's no tilde in front of it ,\nOh that 's cute .\nso .\nThat 's funny . Yeah .\nOK anyways , sorry .\nOK .\n\" Try to stay on topic , Adam . \"\nThere is th one  Y well , no , that 's r that 's legitimate . So now , uh , comments , you can see they 're listed again , same deal , with exhaustive listing of everything found in everything except for these final th thirty minutes .\nOK so , um , on some of these QUALs ,\nYeah .\nare they really QUALs , or are they glosses ? So like there 's a \" QUAL TCL \" .\n\" TCL \" . Where do you see that ?\nUh\nOh , oh . The reason is because w it was said \" tickle \" .\nWhat 's a QUAL ?\nOh I see , I see .\nHmm .\nSo it 's not gloss . OK , I see .\nYep .\nSh - shouldn't it be \" QUAL TICKLE \" or something ?\nIt wasn't said \" TCL \" . Of course .\nLike  it 's not\nOn the  in the actual script  in the actual transcript , I s I  So this  this happens in the very first one .\nMm - hmm .\nI actually wrote it as \" tickle \" .\nOK .\nBecause we  they didn't say \" TCL \" , they said \" tickle \" .\nYeah .\nAnd then , following that is \" QUAL TCL \" .\nRight .\nOh I see . OK .\nI f I forget , what 's QUAL ?\nQual - qualifier .\nIt 's just comment about what they said .\nYeah .\nComment .\nIt 's not something you wanna replace  with\nComment or contextual comment .\nSo they didn't mean \" tickle \" as in Elmo ,\nbut\nTickle ?\nYeah .\nthey meant \" tickle \" as in\nYeah .\nHuh .\nRight .\nBut at some point  I mean , we probably shoul\nWe 'll probably add it to the language model .\nBut we should add it to the dictionar\nYeah .\nNo , to the pronunciation model .\nWhat did I say ?\nTo the language model  model .\nLanguage , uh\nWell both .\nAdd what , Liz ?\nWe can go on lan lan add it to both dictionary and language model .\nOh lan Oh OK - we OK\nYeah .\nit 's in the language model , w yeah , but it so it 's the pronunciation model that has to have a pronunciation of \" tickle \" .\nWell \" tickle \" was pronounced \" tickle \" . Right ?\n\" tickle \" is pronounced \" tickle \" ?\nWhat are you saying ?\nIt 's pronounced the same  it 's pronounced the same as the verb .\nI 'm sorry !\nSo I think it 's the language model that makes it different .\nOh , sorry . What I meant is that there should be a pronunciation \" tickle \" for TCL as a word .\nYeah .\nOh I see .\nAnd that word in the  in , you know , it stays in the language model wherever it was .\nMm - hmm .\nRight . Right .\nRight .\nYeah you never would put \" tickle \" in the language model in that form ,\nRight .\nyeah . Right . There 's actually a bunch of cases like this with people 's names and\nSo how w there 'd be a problem for doing the language modeling then with our transcripts the way they are .\nYes . Yeah . Yeah so th th there there 's a few cases like that where the um , the word needs to be spelled out in  in a consistent way as it would appear in the language , but there 's not very many of these . Tcl 's one of them .\nAnd  and you 'll ha you 'll have to do it sychronously .\nUm , y yeah .\nRight , so y so , whoever 's creating the new models , will have to also go through the transcripts and change them synchronously .\nIt 's just disturbing .\nRight .\nHmm .\nRight . We have this  there is this thing I was gonna talk to you about at some point about , you know , what do we do with the dictionary as we 're up updating the dictionary , these changes have to be consistent with what 's in the  Like spelling people 's names and so forth . If we make a spelling correction to their name , like someone had Deborah Tannen 's name mispelled , and since we know who that is , you know , we could correct it ,\nYou can correct it . Yeah .\nbut  but we need to make sure we have the mispel If it doesn't get corrected we have to have a pronunciation as a mispelled word in the dictionary .\nMm - hmm .\nThings like that .\nThese are so funny to read .\nWell , of course now the  the Tannen corre the spelling c change .\nSo .\nUh , that 's what gets  I  I picked those up in the frequency check .\nRight . Right . So if there 's things that get corrected before we get them , it 's  it 's not an issue ,\nMm - hmm .\nbut if there 's things that um , we change later , then we always have to keep our  the dictionary up to date . And then , yeah , in the case of \" tickle \" I guess we would just have a , you know , word \" TCL \" which\nMm - hmm .\nYou add it to the dictionary .\nwhich normally would be an acronym , you know , \" TCL \"\nRight .\nbut just has another pronunciation .\nYep .\n\" ICSI \" is  is one of those that sometimes people pronounce and sometimes they say \" ICSI . \"\nMm - hmm .\nSo , those that are l are listed in the acronyms , I actually know\nOh yeah .\nthey were said as letters . The others , um , e those really do need to be listened to cuz I haven't been able to go to all the IC ICSI things ,\nRight , exactly .\nand   and until they 've been listened to they stay as \" ICSI \" .\nMm - hmm .\nRight .\nDon and I were just noticing , love this one over on page three , \" vocal  vocal gesture mimicking sound of screwing something into head to hold mike in place . \"\nThat 's great .\nIt 's this , \" rrre - rrre - rrre \" . It was me .\nIt was ! In fact , it was ! Yeah !\nA lot of these are me the  the \" beep is said with a high pit high pitch and lengthening . \"\nHe  he s he said  he said get\nTo head .\nThat was the  I was imitating uh , beeping out\nYeah , that 's it .\nBeep .\nPerfect . Yeah that 's it .\nYeah .\nOh there is something spelled out \" BEEEEEEP \"\nUm\nThat 's it .\nYeah .\nYeah , that 's  that 's been changed .\nin the old  Thank you . Because he was saying , \" How many E 's do I have to allow for ? \"\nYou need a lot of\nWhat I meant was \" beep \" .\nYou need a lot of qualification Adam .\nI guess so .\nThat 's been changed . So , exactly , that 's where the lengthening comment c came in .\nSubtext .\nAnyway .\ns chan brought it down .\nRight , thanks , yeah .\nSo they 're vocalization ,\nRight .\nAnd those of course get  get picked up in the frequency check\nglosses .\nbecause you see \" beep \"\nRight .\nand you know  I mean it gets kicked out in the spelling , and it also gets kicked out in the , uh , freq frequency listing .\nRight . Right .\nI have the  there 're various things like \" breathe \" versus \" breath \" versus \" inhale \" and , hhh , you know , I don't know . I  I think they don't have any implications for anything else so it 's like I 'm tempted to leave them for now an and  It 's easy enough to find them when they 're in curly brackets . We can always get an exhaustive listing of these things and find them and change them .\nYeah .\n\" Sings finale - type song \"\nYeah , that was in the first meeting .\nthat 's  that 's good .\nYeah .\nUm ,\nYeah , but I don't actually remember what it was . But that was  Eric did that .\nYeah .\nSo on\nYeah .\nTah - dah ! I don't know .\nI think maybe something like that .\nSomething like that maybe , yeah .\nWell , that 'd qualify .\nOn the glosses for numbers ,\nYeah .\nit seems like there are lots of different ways it 's being done .\nOK . Interesting question .\nThere 's a\nYes . OK , now first of all  Ooo - ooo ! Very important .\n\" Ooo - ooo . \"\nUh Chuck  Chuck led to a refinement here which is to add \" NUMS \" if these are parts of the read numbers . Now you already know i that I had , uh , in places where they hadn't transcribed numbers , I put \" numbers \" in place of any kind of numbers , but there are places where they , um , it  th this convention came later an and at the very first digits task in some transcripts they actually transcribed numbers . And , um , d Chuck pointed out that this is read speech , and it 's nice to have the option of ignoring it for certain other prob uh p uh , things . And that 's why there 's this other tag here which occurs a hundred and five  or three hundred and five times right now which is just  well n n \" NUMS \" by itself\n\" NUMS \" , yeah .\nwhich means this is part of the numbers task . I may change it to \" digits \" . I mean , i with the sed command you can really just change it however you want because it 's systematically encoded , you know ?\nYep .\nHave to think about what 's the best for  for the overall purposes , but in any case , um , \" numbers \" and \" NUMS \" are a part of this digits task thing . Um , now th Then I have these numbers that have quotation marks around them . Um , I didn't want to put them in as gloss comments because then you get the substitution . And actually , th um ,  the reason I b did it this way was because I initially started out with the other version , you have the numbers and you have the full form and the parentheses , however sometimes people stumble over these numbers they 're saying . So you say , \" Seve - seventy eight point two \" , or whatever . And there 's no way of capturing that if you 're putting the numbers off to the side . You can't have the seven and\nSo what 's to the left of these ?\nThe left is i so example the very first one ,\nMm - hmm .\nit would be , spelled out in words , \" point five \" .\nOK , that 's what I was asking . Right .\nOnly it 's spelled out in words .\nPoint FIVE , yeah .\nSo i this is also spelled out in  in words . \" Point five . \"\nGood .\nAnd then , in here , \" NUMS \" , so it 's not going to be mistaken as a gloss . It comes out as \" NUMS quote dot five \" .\nOK now , the other example is , in the glosses right there ,\nThank you .\n\" gloss one one one dash one three zero \" .\nRight .\nWhat  what 's to the left of that ?\nWell now  In that case it 's people saying things like \" one one one dash so - and - so \" or they 're saying uh \" two  I mean zero \" whatever .\nOK .\nAnd in that case , it 's part of the numbers task , and it 's not gonna be included in the read digits anyway ,\nSo there will be a \" NUMS \" tag on those lines ?\nso  I m in the uh  There is .\nYeah .\nYeah . I 've added that all now too .\nThere 's a \" numbers \" tag\nGood .\nI 'm sorry I 'm  I didn't follow that last thing .\nWait .\nSo , so gloss  in the same line that would have \" gloss quote one one one dash one thirty \" , you 'd have a gloss at the end of the line saying , uh , \" curly bracket NUMS curly bracket \" .\nRight .\nSo if you  if you did a , uh , a \" grep minus V nums \"\nOh , so you could do \" grep minus V nums \" .\nand you get rid of anything that was read .\nSo that 's the  yeah .\nOK .\nSo there wouldn't be something like i if somebody said something like , \" Boy , I 'm really tired , OK . \" and then started reading that would be on a separate line ?\nYes .\nOK great . Cuz I was doing the \" grep minus V \" quick and dirty and looked like that was working OK ,\nMm - hmm . Good .", "topic_id": 3, "keywords": "arg, dictating, pronunciation, argh, pronounce", "dialogue_id": 46}, {"text": "but\nYep .\nGreat . Now why do we  what 's the reason for having like the point five have the \" NUMS \" on it ? Is that just like when they 're talking about their data or something ?\nThis is more because\nOr\nYeah . Oh these are all these , the \" NUMS point \" , this all where they 're saying \" point \" something or other .\nThese are all like inside the spontaneous\nAnd the other thing too is for readability of the transcript . I mean if you 're trying to follow this while you 're reading it it 's really hard to read , you know  eh , \" so in the data column five has \" , you know , \" one point five compared to seventy nine point six \" , it 's like when you see the words it 's really hard to follow the argument . And this is just really a  a way of someone who would handle th the data in a more discourse - y way to be able to follow what 's being said .\nLabel it .\nOh OK .\nSo this is where Chuck 's , um , overall h architecture comes in ,\nI see .\nwhere we 're gonna have a master file of the channelized data . Um , there will be scripts that are written to convert it into these t these main two uses and th some scripts will take it down th e into a f a for ta take it to a format that 's usable for the recognizer an uh , other scripts will take it to a form that 's usable for the  for linguistics an and discourse analysis . And , um , the implication that  that I have is that th the master copy will stay unchanged . These will just be things that are generated ,\nRight\nand e by using scripts .\nOK .\nMaster copies of superset .\nWhen things change then the  the script will cham change but the  but there won't be stored copies of  in different versions of things .\nGood .\nSo , I guess I 'd have one request here which is just , um , maybe to make it more robust , th that the tag , whatever you would choose for this type of \" NUMS \"  where it 's inside the spontaneous speech , is different than the tag that you use for the read speech .\nRight . Right . That would argue for changing the other ones to be \" digits \" or something .\nUm , that way w if we make a mistake parsing , or something , we don't see the \" point five \" , or  or it 's not there , then we\nMm - hmm .\na Just  an And actually for things like \" seven eighths \" , or people do fractions too I guess , you  maybe you want one overall tag for sort of that would be similar to that ,\nExcept\nor  As long as they 're sep as they 're different strings that we  that 'll make our p sort of processing more robust .\nWell\nCuz we really will get rid of everything that has the \" NUMS \" string in it .\nI suppose what you could do is just make sure that you get rid of everything that has \" curly brace NUMS curly brace \" .\nWell  Ex - exactly .\nI mean that would be the\nExactly . That was  that was my motivation . And i these can be changed , like I said .\nYeah .\nYou know , I mean , as I said I was considering changing it to \" digits \" . And , it just  i you know , it 's just a matter of deciding on whatever it is , and being sure the scripts know .\nRight .\nIt would probably be safer , if you 're willing , to have a separate tag just because um , then we know for sure . And we can also do counts on them without having to do the processing . But you 're right , we could do it this way , it  it should work . Um ,\nYeah , and it makes it  I guess the thing about\nbut it it 's probably not hard for a person to tell the difference\nYeah .\nbecause one 's in the context of a  you know , a transcribed word string ,\nRight .\nThe other thing is you can get really so minute with these things\nand  So\nand increase the size of the files and the re and decrease the readability to such an extent by simply something like \" percent \" . Now I  I could have adopted a similar convention for \" percent \" , but somehow percent is not so hard , you know ?\nHmm .\ni It 's just when you have these points and you 're trying to figure out where the decimal places are  And we could always add it later . Percent 's easy to detect . Point however is  is uh a word that has a couple different meanings . And you 'll find both of those in one of these meetings , where he 's saying \" well the first point I wanna make is so - and - so \" and he goes through four points , and also has all these decimals .\nSo Liz , what does the recognizer do ,\nSo .\nuh ,\nHmm .\nwhat does the SRI recognizer output for things like that ? \" seven point five \" . Does it output the word\n\" Seven point five \" .\nRight , the word \" seven \" ?\nWell , the numbers ?\nThe number \" seven \" ?\nThe word .\nThe word \" seven \" , OK .\nYeah .\nYeah .\nSo I 'd  so \" I 'd like  I 'd like to talk about point five \" .\nAnd  and actually , you know the language\nYeah .\nit 's the same point , actually , the  the p you know , the word \" to \" and the word y th \" going to \" and \" to go to \" those are two different \" to 's \" and so there 's no distinction there .\nMm - hmm .\nIt 's just  just the word \" point \" has  Yeah , every word has only one , yeah e one version even if  even if it 's  A actually even like the word \" read \"  and \" read \" Those are two different words . They 're spelled the same way , right ?\nMm - hmm .\nAnd they 're still gonna be transcribed as READ .\nMm - hmm .\nRight .\nSo , yeah , I  I like the idea of having this in there , I just  I was a little bit worried that , um , the tag for removing the read speech  because i What if we have like \" read letters \" or , I don't know ,\nWe might wanna  just a separate tag that says it 's read .\nlike \" read something \" like \" read \"\nMm - hmm .\nyeah , basically . But other than that I it sounds great .\nYeah . OK ? Are we done ?\nWell I wanted to say also regarding the channelized data ,\nOh , I guess we 're not done .\nYeah .\nthat , um , Thilo requested , um , that we ge get some segments done by hand to e e s reduce the size of the time bins wh like was Chuc - Chuck was mentioning earlier that , um , that , um , if you  if you said , \" Oh \" and it was in part of a really long , s complex , overlapping segment , that the same start and end times would be held for that one\nWell\nas for the longer utterances ,\nWe did that for one meeting , right ,\nand\nso you have that data don't you ?\nYeah , that 's the training data .\nAnd he requested that there be , uh , similar , uh , samples done for five minute stretches c involving a variety of speakers and overlapping secti sections .\nYeah .\nHe gave me  he did the  very nice , he  he did some shopping through the data and found segments that would be useful . And at this point , all four of the ones that he specified have been done . In addition the I 've  I have the transcribers expanding the amount that they 're doing actually .\nOh great .\nSo right now , um , I know that as of today we got an extra fifteen minutes of that type , and I 'm having them expand the realm on either side of these places where they 've already started .\nOh great . OK .\nBut if  if  you know , and I  and he 's gonna give me some more sections that  that he thinks would be useful for this purpose .\nYeah . Yeah .\nBecause it 's true , I mean , if we could do the  the more fine grained tuning of this , uh , using an algorithm , that would be so much more efficient . And , um . So this is gonna be  useful to expand this .\nSo I  I thought we  we sh we sh perhaps we should try to  to start with those channelized versions just to  just to try it . Give it  Give one tr transcriber the  the channelized version of  of my speech - nonspeech detection and look if  if that 's helpful for them , or just let them try if  if that 's better or If they  if they can\nYou mean to start from scratch f in a brand new transcript ?\nYeah . Yeah . Yeah .\nThat 'd be excellent . Yeah , that 'd be really great . As it stands we 're still in the phase of sort of , um , cleaning up the existing data getting things , uh , in i m more tight tightly time  uh , aligned . I also wanna tell  um , I also wanted to r raise the issue that  OK so , there 's this idea we 're gonna have this master copy of the transcript , it 's gonna be modified by scripts t into these two different functions . And actually the master\nTwo or more . Two or more different functions .\nTwo  two or more . And that the master is gonna be the channelized version .\nRight .\nSo right now we 've taken this i initial one , it was a single channel basically the way it was input . And now , uh , thanks to the advances made in the interface , we can from now on use the channelized part , and , um , any changes that are made get made in the channelized version kind of thing . But I wanted to get all the finished  all the checks\nYeah , so that has implications for your script .\nYeah . So , uh , have those  e e the vis the ten hours that have been transcribed already , have those been channelized ? And I know  I 've seen @ @  I 've seen they 've been channelized ,\nYes , they have .\nAll ten hours ?\nbut\nExcept for the missing thirty minutes .\nhave they uh  have they been  has the time  have the time markings been adjusted , uh , p on a per channel\nGreat .\nUh , for  for a total of like twenty m f for a total of  Let 's see , four times  total of about an   thirty minutes . That 's  that 's been the case .\nSo ,\nAnd plus the training , whatever you have .\nI guess , I mean , I don't know if we should talk about this now , or not , but I\nWell it 's just we 're  missing tea .\nYeah , I know .\nSo .\nNo , but I mean my question is like should I wait until all of those are processed , and channelized , like the time markings are adjusted before I do all the processing , and we start like branching off into the  into the  our layer of uh transcripts .\nWell , you know the problem  the problem is that some  some of the adjustments that they 're making are to bring  are to combine bins that were  time bins which were previously separate . And the reason they do that is sometimes there 's a word that 's cut off .\nRight .\nAnd so , i i i it 's true that it 's likely to be adjusted in the way that the words are more complete . And ,\nOK . No I know  I know that adjusting those things are gonna  is gonna make it better .\nso I  it 's gonna be a more reliable thing and I 'm not sure\nI mean I 'm sure about that ,\nYeah .\nbut do you have like a time frame when you can expect like all of it to be done , or when you expect them to finish it , or\nWell partly it depends on how  um , how e effective it will be to apply an algorithm because i this takes time ,\nYeah . Yeah .\nyou know , it takes a couple hours t to do , uh , ten minutes .\nYeah , I don't doubt it . Um , so .\nSo right now the  what you 're doing is you 're taking the  uh , the o original version and you 're sort of channelizing yourself , right ?\nYeah . I 'm doing it myself . I mean i if the time markings aren't different across channels , like the channelized version really doesn't have any more information .\nMm - hmm .\nSo , I was just  I mean , originally I had done before like the channelized versions were coming out .\nRight . Right .\nUm ,\nSo I  I th I think probably the way it 'll go is that , you know , when we make this first general version and then start working on the script , that script @ @ that will be ma you know primarily come from what you 've done , um , we 'll need to work on a channelized version of those originals .\nand so it 's a question of like what  Mm - hmm . Mm - hmm .\nMm - hmm .\nAnd so it should be pretty much identical to what you have t except for the one that they 've already tightened the boundaries on .\nYep . Mm - hmm .\nRight .\nUm , So\nYeah , I mean\nuh , and then probably what will happen is as the transcribers finish tightening more and more , you know , that original version will get updated\nyeah .\nand then we 'll rerun the script and produce better uh versions .\nOK .\nBut the  I guess the ef the effect for you guys , because you 're pulling out the little wave forms into separate ones , that would mean these boundaries are constantly changing you 'd have to constantly re rerun that ,\nI know .\nso , maybe\nRight .\nBut that\nBut that  that 's not hard .\nMm - hmm .\nNo .\nI I think the harder part is making sure that the transc the transcription\nOK .\nSo if you b merge two things , then you know that it 's the sum of the transcripts , but if you split inside something , you don't where the word  which words moved .\nMm - hmm . Mm - hmm .\nAnd that 's wh that 's where it becomes a little bit  uh , having to rerun the processing .\nMm - hmm .\nThe cutting of the waveforms is pretty trivial .\nYeah . I mean as long as it can all be done automatically , I mean , then that 's not a concern .\nMm - hmm .\nYou know , if I just have to run three scripts to extract it all and let it run on my computer for an hour and a half , or however long it takes to parse and create all the reference file , that 's not a problem .\nRight .\nYeah . Uh - huh . Mm - hmm .\nUm , so yeah . As long as we 're at that point . And I know exactly like what the steps will work  what 's going on , in the editing process ,\nYeah .\nso . OK .\nSo that 's  I I mean I could  there were other checks that I did , but it 's  I think that we 've  unless you think there 's anything else , I think that I 've covered it .\nYeah .\nI can't think of any of the  other ones .\nOK . Great .\nOK .\nOop ! Man !", "topic_id": 4, "keywords": "transcripts, transcript, utterances, nums, discourse", "dialogue_id": 46}, {"text": "Nice .\nOK .\nto  to handle .\nIs that good ?\nRight . Yeah , I 've have never handled them .\nGoats eat cans , to my understanding . Tin cans .\nDid we need to do these things ?\nWow .\nOK .\nCould I hit  hit F - seven to do that ? on the  Robert ?\nI 'm\nOh , the remote will do it OK .\nOK .\nCuz I 'm already up there ?\nin control here .\nYou are in control . Already ?\nWow , we 're all so high tech here . Yet another p PowerPoint presentation .\nI  Well it makes it easier  to do\nCertainly does .\nSo ,  we were  Ah !\nJohno , where are you ?\nOK . So , Let 's see . Which one of these buttons will do this for me ? Aha ! OK .\nShould you go back to the first one ?\nDo I wanna go back to the first one ?\nWell\nOK .\nI 'm sorry I\nWell , I mean ,  just to\nOK . Introduce .\nOK .\nYeah , um  Well , \" the search for the middle layer \" . It 's basically uh talks about uh   It just refers to the fact that uh  one of main things we had to do was to  decide what the intermediate sort of nodes were ,\nI can read ! I 'm kidding .\nyou know , because\nMm - hmm .\nBut if you really want to find out what it 's about you have to  click on the little  light bulb .\nAlthough I 've  I 've never  I don't know what the light bulb is for . I didn't i install that into my  PowerPoint presentation .\nIt opens the Assistant that tells you that the font type is too small .\nAh .\nDo you wanna try ?\nAch u\nI 'd prefer not to .\nOK . Continue .\nIt 's a needless good idea . Is that the idea ?\nWhy are you doing this in this mode and not in the presentation mode ?\nOK .\nBecause I 'm gonna switch to the JavaBayes program\nOh ! OK . Of course . Mm - hmm .\nand then  if I do that it 'll mess everything up .\nI was wondering .\nIs that OK ?\nYeah , it 's OK .\nSure .\nCan you maximize the window ?\nProceed .\nYou want me to  Wait , what do you want me to do ?\nCan you maximize the window so all that stuff on the side isn't  doesn't appear ?\nNo , It 's OK . It 's  It 'll work .\nWell I can do that , but then I have to end the presentation in the middle so I can go back to open up\nOK , fine .\nHere , let 's see if I can\nAlright .\nVery nice .\nIs that better ? OK .\nYeah .\nUh  I 'll also get rid of this \" Click to add notes \" . OK .", "topic_id": 0, "keywords": "handle, buttons, handled, proceed, control", "dialogue_id": 47}, {"text": "Perfect .\nSo then the features we decided  or we decided we were  talked about , right ? Uh the  the prosody , the discourse ,  verb choice . You know . We had a list of things like \" to go \" and \" to visit \" and what not . The \" landmark - iness \" of uh  I knew you 'd like that .\nNice coinage .\nThank you . uh , of a  of a building . Whether the and this i we actually have a separate feature but I decided to put it on the same line  for space . \" Nice walls \"  which we can look up because I mean if you 're gonna  get real close to a building in the Tango mode , right , there 's gotta be a reason for it . And it 's either because you 're in route to something else or you wanna look at the walls . The context , which in this case we 've limited to  \" business person \" , \" tourist \" , or  \" unknown \" , the time of day , and \" open to suggestions \" , isn't actually a feature . It 's  \" We are open to suggestions . \"\nRight . can I just ask the nice walls part of it is that  uh , in this particular domain  you said  be  i it could be on two different lines but are you saying that in this particular domain it happens the  that landmark - iness cor is correlated with\nOh\nNo . We have a separate\nThey 're separate things .\nfeature .\ntheir being nice w\nYeah .\nOK .\nI either could put \" nice walls \" on its own line or \" open to suggestions \" off the slide .\nLike you could have a p\nAnd  and  By \" nice \" you mean\nYou  Like you could have a post office with uh  you know , nice murals or something .\nRight .\nOK .\nOr one time I was at this\nSo \" nice walls \" is a stand in for like architecturally it , uh  significant\nBut see the thing is , if it 's\nArchitecturally appealing from the outside .\nor something like that . OK .\nYeah but if it 's architecturally significant you might be able to see it from  Like you m might be able to \" Vista \" it ,\nMm - hmm .\nright ? And be able to\nAppreciate it .\nMm - hmm .\nYeah , versus , like , I was at this place in Europe where they had little carvings of , like , dead people on the walls or something .\nMm - hmm .\nI don't remember w\nUh - huh .\nIt was a long time ago .\nThere 's a lot of those .\nBut if you looked at it real close , you could see the  the in intricacy of the  of the walls .\nOK . So that count as  counts as a nice wall .\nMm - hmm .\nRight .\nThe  OK . Right .\nThe\nSomething you want to inspect at close range  because it 's interesting .\nExactly .\nOK .\nHmm .\nRobert ?\nWell there  there is a term  that 's often used . That 's \" saliency \" , or the \" salience \" of an object . And I was just wondering whether that 's the same as what you describe as \" landmark - iness \" . But it 's really not . I mean an object can be very salient\nHmm .", "topic_id": 1, "keywords": "landmark, walls, wall, features, architecturally", "dialogue_id": 47}, {"text": "but not a landmark at all .\nNot a landmark at all . There 's landmark for um , touristic reasons and landmark for I don't know navigational reasons or something .\nYep .\nRight .\nYeah , we meant , uh , touristic reasons .\nYeah .\nOK .\nHmm .\nRight .\nOK . but you can imagine maybe wanting the oth both kinds of things there for different um , goals .\nHmm .\nYeah .\nRight .\nRight ?\nBut  Yeah . Tourist - y landmarks also happen to be  Wouldn't  couldn't they also be  They 're not exclusive groups , are they ? Like  non - tourist - y landmarks and\nOr it can be als\ndirect navigational\nThey 're not mutually exclusive ?\nYeah .\nRight .\nOK .\nRight . Definitely .\nOK , So our initial idea was not very satisfying ,  because  uh our initial idea was basically all the features pointing to the output node . Uh .\nSo , a big flat structure .\nRight .\nRight ?\nYep .\nAnd uh , so we  Reasons being , you know , it 'd be a pain to set up all the probabilities for that . If we moved onto the next step and did learning of some sort , uh according Bhaskara we 'd be handicapped . I don't know belief - nets very well .\nWell usually , I mean , you know , N  If you have N features , then it 's two to the N   or exponential in N .\nAnd they wouldn't look pretty . So .\nYeah , they 'd all be like pointing to the one node .\nMm - hmm .\nUh . So then our next idea was to add a middle layer , right ? So the thinking behind that was  we have the features that we 've drawn  from the communication of some  Like , the someone s The person at the screen is trying to communicate some abstract idea , like \" I 'm  \" the  the abstract idea being \" I am a tourist I want to go  to this place . \" Right ? So we 're gonna set up features along the lines of where they want to go and  what they 've said previously and whatnot . And then we have  the means  that they should use . Right ? but the middle thing , we were thinking along the lines of maybe trying to figure out , like , the concept of whether they 're a tourist  or  whether they 're running an errand or something like that along those lines . Or  Yes , we could things we couldn't extract the  from the data , the hidden variables . Yes , good . So then the hidden variables  hair variables we came up with were whether someone was on a tour , running an errand , or whether they were in a hurry , because we were thinking uh , if they were in a hurry there 'd be less likely to  like  or th\nWant to do Vista ,\nRight .\nright ? Because  if you want to view things you wouldn't be in a hurry .\nOr they might be more likely to be using the place that they want to go to as a  like a  navigational point to go to another place .\nMm - hmm .\nWhether the destination was their final destination , whether the destination was closed . Those are all  And then \" Let 's look at the belief - net \"  OK . So that means that I should switch to the  other program . Um right now it 's still kind of  in a toy  version of it , because we didn't know the probabilities of   or  Well I 'll talk about it when I get the picture up .\nNo one knows it .\nOK . So this right  what we  Let 's see . What happens if I maximize this ? There we go . But uh  So . The mode  basically has three different  outputs . The probability  whether the probability of a Vista , Tango , or Enter . Um  The \" context \" , we simplified . Basically it 's just the businessman , the tourist , unknown . \" Verb used \" is actually personally amusing mainly because it 's  it 's just whether the verb is a Tango verb , an Enter verb , or a  Vista verb .\nYeah , that one needs a lot of\nAnd are those mutually exclusive sets ?\nNo .\nNot at all . That 's  that  that needs a lot of work .\nRight .\nBut uh   that would 've made the probably significantly be more complicated to enter ,\nGot it . Uh - huh .\nso we decided that for the purposes of this  it 'd be simpler to just have three verbs .\nYeah . Simple .\nYeah .\nStab at it . Yep .\nRight . Um  Why don't you mention things about this , Bhaskara , that I am  not  that are not coming to my mind right now .\nOK , so  Yeah , so note the four nodes down there , the  sort of , the things that are not directly extracted . Actually , the five things . The \" closed \" is also not directly extracted I guess , from the uh\nWell i it 's\nHmm .\nFrom the  utterance ?\nit 's so it sort of is\nActually , no , wait .\nbecause it 's  because have the  the time of day\nIt is . OK , \" closed \" sort of is .\nand the close it just had the  er and what time it closed .\nRight , so f Right , but the other ones , the final destination , the whether they 're doing business , whether they 're in a hurry , and whether they 're tourists , that kind of thing is all uh  sort of  you know probabilistically depends on the other things .\nInferred from the other ones ?\nYeah .\nOK .\nAnd the mode , you know , depends on all those things only .\nYeah the   the actual parse is somewhere up around in here .\nYeah . So we haven't uh , managed  Like we don't have nodes for \" discourse \" and \" parse \" , although like in some sense they are parts of this belief - net .\nMm - hmm .\nBut uh   The idea is that we just extract those features from them , so we don't actually have a node for the entire parse ,\nMm - hmm .\nRight .\nbecause we 'd never do inference on it anyway , so .\nSo some of the  the top row of things  What 's  what 's \" Disc admission fee \" ?\nwhether they discuss the admission fees . So we looked at the data and in a lot of data people were saying things like  \" Can I get to this place ? \"\nOh .\n\" What is the admission fee ? \" . So that 's like a huge uh clue that they 're trying to Enter the place rather than uh to Tango or Vista ,\nUh - huh .\nRight .\nOK .\nso .\nI see .\nThere were  there 'd be other things besides just the admission fee , but  you know ,  we didn't have\nMm - hmm .\nThat was like our example .\nMm - hmm .\nThat was the  initial one that we found .\nOK . So there are certain cues that are very strong  either lexical or topic - based um , concept cues\nFrom the discourse that  Yeah .\nfor one of those . And then in that second row  or whatever that row of Time of Day through that  So all of those  Some of them come from the utterance and some of them are sort of  either world knowledge or situational  things .\nRight .\nRight ? So that you have no distinction between those and OK .\nOne , uh  Uh .  Um , anything else you want to say Bhaskara ?\nUm .\n\" Unmark @ @ Time of Day \"\nYeah , I m I mean\nYeah . They 're  they 're are a couple of more things .\nOne thing  uh\nI mean Uh . I would actually suggest we go through this one more time so we  we all uh , agree on what  what the meaning of these things is at the moment and maybe  what changes we\nYeah , th OK . so one thing I  I 'm you know unsure about , is how we have the discus uh  the \" admission fee \" thing set up . So one  thing that we were thinking was  by doing the layers like this , Uh  we kept um  things from directly affecting the mode  beyond the concept , but you could see perhaps discus the \" admission fee \" going directly to the mode pointing at \" Enter \" ,\nMm - hmm .\nright ? Versus pointing to just at \" tourist \" ,\nMm - hmm .\nOK ?\nMm - hmm .\nBut we just decided to keep all the things we extracted  to point at the middle and then  down .\nMm - hmm . Why is the landmark  OK . The landmark is facing to the tourists . That 's because we 're talking about landmarks as touristic landmarks not as possible um\nRight .\nYeah .\nNavigational landmarks ,\nNavigational cue .\nnavigational landmarks\nyeah .\nso Mm - hmm . Then\nYeah , that would be  whatever building they referred to .\nProsody .\nRight . So let 's see . The variables .\nMm - hmm .\nDisc - \" admission fee \" is a binary thing , \" time of day \" is like morning , afternoon , night . Is that the deal ? Yeah .\nThat 's how we have it currently set up ,\nYep .\nbut it could be ,  you know , based upon hour\nYeah . Yeah .\nWhatever granularity .\nor  dis we could discrete it  des descret - ize it .\nYeah .\nUh - huh .\nYeah .\nMm - hmm .\nYeah . Normally context will include a huge amount of information , but um , we are just using the particular  part of the context which consists of the switch that they flick to indicate whether they 're a tourist or not , I guess .\nYep .\nOK . So that 's given in their input .\nRight .\nSo  Right ,\nRight ?\nso it 's not really all of context . Similarly prosody is not all of prosody but simply  for our purposes whether or not they appear tense or relaxed .\nMm - hmm . that 's very nice , huh ?\nOK .\nThe  the  So the context is a switch between tourist or non - tourist ?\nand\nOr also unknown ?\nOr un  unknown ,\nOK .\nyeah .\nYeah . Unknown , right ?\nSo final dest So it seems like that would really help you for doing business versus tourist ,\nWhich is th Which one ?\nbut OK . so the the context being um , e I don't know if that question 's sort of in general , \" are you  \" I mean the  ar ar are do they allow business people to be doing non - business things at the moment ?\nYeah , it does .\nOK . So then you just have some probabilities over\nEverything is probablistic , and  There 's always\nOK .  over which which of those it is .\nYeah . Um , right . So then landmark is  Oh , sorry . \" Verb used \" is like , right now we only have three values , but in general they would be a probability distribution over all verbs .\nMm - hmm .\nRather , let me rephrase that . It  it can take values  in the set of all verbs , that they could possibly use .\nMm - hmm .\nUm \" nice walls \" is binary , \" closed \" is binary \" final destination \" , again  Yeah , all those are binary I guess . And \" mode \" is one of three things .\nSo , the  the middle layer is also binary ? No .\nYeah , anything with a question mark after it in that picture is a binary node .\nUh . It  Yeah . But all those things without question marks are also binary . Right ?\nWhich things ?\nNice walls ?\nWi\nMm - hmm .\nOh . \" Nice walls \" is uh  something that we extract from our world knowledge .\nMm - hmm .\nYeah , a Oh yeah . Sorry . It is binary .\nIt is binary but it doesn't have question mark because it 's extracted .\nThat 's true . Yeah . OK , I see your point .\nYeah . OK .\nYeah .\nI  I gotcha .\nUh - huh .\nYeah , similarly \" closed \" , I guess .\nSo we can either be in a hurry or not , but we cannot be in a medium hurry at the moment ?\nWell , we To do that we would add another uh  value for that .\nMm - hmm . OK .\nAnd that would require s updating the probability distribution for \" mode \" as well .\nMm - hmm .\nBecause it would now have to like uh  take that possibility into account .\nMm - hmm . Take a conti\nMm - hmm .\nSo um , of course this will happen when we think more about the kinds of verbs that are used in each cases\nYeah , yeah .\nYeah .\nbut you can imagine that it 's verb plus various other things that are also not in the bottom layer that would  that would help you  Like it 's a conjunction of , I don't know , you know , the verb used and some other stuff that  that would   determine\nRight . Other syntactic information you mean ?\nYeah . Exactly .\nYeah .\nUm .\nwell the  the  sort of the landmark is  is sort of the object right ? the argument in a sense ?\nUsually . I  I don't know if that 's always the case I  I guess haven't looked at the data as much as you guys have . So . Um .\nthat 's always warping on something  some entity ,\nMm - hmm . Mm - hmm .\nand um  Uh maybe at this stage we will  we do want to  uh sort of get  uh modifiers in there\nHmm . Yeah .\nbecause they may also tell us whether the person is in a hurry or not\nI want to get to the church quickly ,\nYeah .\nMm - hmm .\nand uh\nYeah , right .\nThat would be a cue .\nwhat 's the fastest way\nYeah , correct .\nMm - hmm . Um . OK .\nRight . Excellent . Do we have anything else to say about this ?\nWe can do a little demo .\nOh the Yeah , we could . But the demo doesn't work very well .\nNo , then it wouldn't be a demo I was just gonna s\nI mean  We can do a demo in the sense that we can um ,  just ob observe the fact that this will , in fact do inference .\nObserve nodes .\nSo we can , you know , set some of the uh nodes and then try to find the probability of other nodes .\nYeah . Go ahead .\nOK . Dat - dat - dah . What should I observe ?\nJust se set a few of them . You don't have to do the whole thing that we did last time . Just like uh ,  maybe the fact that they use a certain verb\nOK .\nActually forget the verb .\nOK .\njust uh  I don't know , say they discussed the admission fee\nOK .\nand uh   the place has nice walls\nI love nice walls , OK ? I 'm a big fan .\nand it 's night .\nit 's starting to grow on me\nAnd the time of day is night ?\nYeah , no wait . That  that doesn't uh  it 's not really consistent . They don't discuss the admission fee . Make that false .\nAlright .\nAnd it 's night .\nOh , they  OK . Oh whoops . I forgot to uh\nThat didn't work .\nAch !\nI 'd like to do that again .\nOne thing that bugs me about JavaBayes is you have to click that and do this .\nYeah . That seems kind of redundant but .\nOK .\nThat all you want ?\nYes .\nOK . So let 's see . I want  to query ,\n\" Go \" and , right , \" query \" .\nright ? the mode . OK , and then on here  So let 's see .\nSo that  is the probability that they 're Entering , Vista - ing or Tango - ing .\nMm - hmm .\nYeah .\nAnd uh\nSo slightly  biased  toward \" Tango \" ing\nYeah .\nIf it 's night time ,  they have not discussed admission fee , and the n walls are nice .\nOK .\nSo , yeah . I guess that  sort of makes sense . The reason I say the  demo doesn't work very well is yesterday we uh   observed everything in favor of  taking a tour , and it came up as \" Tango \" , right ? Over and over again . We couldn't  we couldn't figure out how to turn it off of \" Tango \" .\nSo . Uh - huh .\nIt loves the Tango .\nHuh ! Um .\nWell , that 's obviously just to do with our probabilities .\nYeah , yeah .\nLike ,  we totally hand - tuned the probabilities ,\nYeah .\nright . We were like  \" hmm , well if the person does this and this and this , let 's say forty percent for this ,\nOK .\nfifty per \" Like , you know . So obviously that 's gonna happen .\nYeah .\nRight .\nYeah but it  it\nMaybe the bias toward \" Tango \" ing was yours , then ?\nYeah ,\nYeah .\nthat 's  that 's at\nIt 's  So we have to like fit the probabilities .\nSpent my youth practicing the tango de la muerte .\nSo , the real case ?\nHowever you know , it  The purpose was not really , at this stage , to come up with meaningful probabilities but to get thinking about that hidden middle layer . And so th\nMm - hmm .\nAnd\nWe would actually  I guess once we look at the data more we 'll get more hidden  nodes ,\nMm - hmm .\nYeah .\nbut I 'd like to see more . Not because it would  expedite the probabilities , cuz it wouldn't . It would actually slow that down tremendously .\nUm . Well , yeah , I guess .\nBut .\nNot that much though . Only a little early .\nNo , I think we should have uh  exponentially more  middle nodes than features we 've extracted . I 'm ju I 'm just jo\nOK .\nSo . Are \" doing business \" versus \" tourist \"  They refer to your current task . Like  like current thing you want to do at this moment .\nUm . Yeah , well   That 's  that 's an interesting point . Whether you 're  It 's whether  It 's not\nAnd are th\nI think it 's more like \" Are you are tourist ? are you in Ham - like Heidelberg for a  \"\nOh , so , I thought that was directly given by the context  switch .\nThat 's a different thing . What if the context , which is not set , but still they say things like , \" I want to go  uh , see the uh  the  the castle and uh , et cetera . \"\nIs it\nWell the I kind of  thought of \" doing business \" as more of running an errand type thing .\nYeah . Business on the other hand is , uh , definitely what you 're doing .\nSo if you run out of cash as a tourist , and  and  and you need to go to the AT\nSo  i wi th\nOK . Oh , I see , you may have a task . wh you have to go get money and so you are doing business at that stage .\nMmm .\nRight .\nYeah .\n\" How do I get to the bank ? \"\nI see . Hmm .\nAnd that 'll affect whether you want to enter or you if you  kinda thing .\nOK . So the \" tourists \" node  should be  um , very consistent with the context node . Right ? If you say that 's more their  in general what their background is .\nYeah , I think this context node is a bit of a  I don't know , like in d Uh  Do we  wanna have  Like it 's\nAre you assuming that or not ? Like is that to be  I mean if that 's accurate then that would determine tourist node .\nIf the context were to set one way or another , that like strongly uh um , says something about whether  whether or not they 're tourists .\nMm - hmm .\nSo what 's interesting is when it 's not  when it 's set to \" unknown \" .\nMm - hmm . Mm - hmm .\nWe - what set the  they set the context to \" unknown \" ?\nOK .\nOK .\nRight now we haven't observed it , so I guess it 's sort of averaging over all those three possibilities .\nMm - hmm .\nMm - hmm .\nRight .\nBut yes , you can set it to un \" unknown \" .\nAnd if we now do  leave everything else as is the results should be the same ,\nOops .\nright ?\nNo .\nWell no , because we  Th - the way we set the probabilities  might not have  Yeah , it 's  it 's an  it 's an issue , right ? Like\nPretty much the same ?\nYeah , it is . So the issue is that um in belief - nets , it 's not common to do what we did of like having , you know , a d bunch of values and then \" unknown \" as an actual value . What 's common is you just like don't observe the variable ,\nYeah .\nYep .\nright , and then just marginalizes\nYeah .\nBut uh   We didn't do this because we felt that there 'd  I guess we were thinking in terms of a switch that actually\nWe were thi Yeah ,\nMm - hmm .\nWe were th\nBut uh  I don't know y what the right thing is to do for that . I 'm not  I don't know if I totally am happy with  the way it is .\nWhy don't we  Can we , um  How long would it take to  to add another  node on the observatory and , um , play around with it ?\nAnother node on what ?\nUh , well it depends on how many things it 's linked to .\nLet 's just say make it really simple . If we create  something that for example would be um  So th some things can be landmarks in your sense but  they  can never be entered ? So for example s a statue .\nGood point .\nYeah ?\nRight .\nMm - hmm .\nSo  maybe we wanna have \" landmark \"  meaning now \" enterable landmark \" versus , um something that 's simply just a vista point , for example .\nYeah , that 's true .\nYeah ? uh , a statue or um\nSo basically it 's addressing a variable that 's \" enterable or not \" . So like an \" enterable , question mark \" .\nAlso   you know , didn't we have a  size as one ? The size of the landmark .\nWhat ?\nCuz if it 's\nUm . Not when we were doing this ,\nYeah .\nbut I guess at some point we did .\nFor some reason I had that  OK , that was a thought that I had at one point but then went away .\nSo you want to have a  a node for like whether or not it can be entered ?\nWell , for example , if we include that , yeah ?\nYeah .\num , accessibility or something , yeah ? \" Is it  Can it be entered ? \"\nHmm .\nthen of course , this is  sort of binary as well .\nYeah .\nAnd then um , there 's also the question whether it may be entered . In the sense that , you know , if it 's  Tom  the house of Tom Cruise , you know , it 's enterable but you may not enter it . You know ? You 're not allowed to .\nYeah .\nUnless you are , whatever , his  his divorce lawyer or something .\nYeah .\nYeah ? and um  And these are very observable sort of from the  from the ontology sort of things .\nWay Does it actually help to distinguish between those two cases though ? Whether it 's practically speaking enterable , or actually physically enterable  or not ?\ny y If  If you 're running an errand you maybe more likely to be able to enter places that are usually not  al w you 're not usually  not allowed to uh m\nIt seems like it would for uh , uh  determining whether they wanna go into it or not .\nWell I can see why\nCuz they\nLet 's get this uh b clearer . S so it 's matrix between if it 's not enterable , period .\nWhether it 's a  Whether it 's a public building , and whether it 's  actually has a door .\nYeah , exactly .\nOK .\nThis is sort of uh\nSo Tom Cruise 's house is  not a public building\nMm - hmm .\nbut it has a door . But the thing is\nMm - hmm .\nRight .\nOK , sh explain to me why it 's necessary  to distinguish between whether something has a door and is  not public . Or , if something  It seems like it 's equivalent to say that it doesn't have a door a  and it\nMm - hmm .\nOr \" not public \" and \" not a door \" are equivalent things ,\nYeah .\nit seems like in practice .\nRight . Yeah . So we would have  What does it mean , then , that we have to  we have an object type statue . That really is an object type . So there is  there 's gonna be a bunch of statues .\nRight .\nAnd then we have , for example , an object type ,  hmm , that 's a hotel . How about hotels ?\nOK .\nSo , the most famous building in Heidelberg is actually a hotel . It 's the hotel Zum Ritter , which is the only Renaissance building in Heidelberg that was left after  the big destruction and for the Thirty Years War , blah - blah - blah .\nHmm . Does it have nice walls ?\nIt has wonderful walls . Um - And lots of detail , c and carvings , engravings and so forth ,\nExcellent .\nso . But , um , it 's still an unlikely candidate for the Tango mode I  must say . But . Um . So  s So if you are a d Well it 's very tricky . So I guess your question is  so far I have no really arg no real argument why to differentiate between statues as  statues and houses of celebrities , from that point of view . Huh . OK . Let  Let 's do a  Can we add , just so I can see how it 's done , uh , a \" has door \"  property or  ?\nOK .\nWhat would it , uh , connect to ? Like , what would , uh , it affect ?\nUm , I think , um , it might affect  Oh actually it 's  it   it wouldn't affect any of our nodes , right ?\nWhat I was thinking was if you had a  like\nOh it 's  it affects th The \" doing business \" is certainly not .\nYou could affect   Theoretically you could affect \" doing business \" with \" has door \" .\nYeah . OK .\nHmm .\nIt should , um , inhibit that ,\nRight .\nLet 's see .\nright ?\nYeah , I don't know if JavaBayes is nice about that . It might be that if you add a new thing pointing to a variable , you just like  it just overwrites everything . But  you can check .\nWell ,  we have it saved . So .  We can rel open it up again .\nOK . It 's true .\nThe  safety net .\nI think you could just add it . I mean , I have before OK . Whew !\nWell that 's fine , but we have to see the function now . Has it become all point fives or not ?\nOh , right .\nLet 's see . So this is \" has door \" Uh , true , false . That 's acceptable . And I want to edit the function going to that , right ? Oh no .\nNo . This is fine ,\nRight . It was fine .\nthis business .\nadded this one .\nYep .\nThis\nWhat would be nice if it  is if it just like kept the old function for either value but . Nope . Didn't  do it .\nOh .\nOh wait , it might be  Did we w Yes , that 's not good .\nThat 's  kind of annoying .\nOK , so just dis dismiss everything . Close it and  and load up the old state so  it doesn't screw  screw that up .\nLet 's see . Oops .\nHmm .\nMaybe you can read in ?\nHa - So have you used JavaBayes a lot ?\nYes . Really  I ha I 've  I haven't used it a lot and I haven't used it in the last you know many months so\nOK .\num , uh , we can ask someone .\nIt might be worth uh  asking around .\nUm .\nLike , we looked at sort of uh  a page that had like a bunch of\nYeah . Srini\nOK . Yeah , S I guess he 'd be the person .\nSrini 's the one to ask I would say .\nYeah .\nUm . He might know .\nCuz  Yeah .\nAnd .\nI mean in a way this is a lot of good features in Java it 's cra has a GUI and it 's uh\nMm - hmm .\nI guess those are the main two things . It does learning , it has\nMm - hmm .\nNo it doesn't , actually .\nYeah .\nI didn't think it did learning .\nWhat ?\nMaybe it did a little bit of learning ,\nOK .\nI don't remember .\nOh right . Maybe you 're right . OK . Right . But uh  it 's free .\nWhich is w quite positive , yeah .\nBut uh , yeah . Maybe another thing that uh  But I mean its interface is not the greatest . So .\nBut actually it had an interface .\nMm - hmm .\nA lot of them were like , you know .\nYep .\nCommand line .\nHuh .\nWhat is the c code ? Can w can we see that ? How do you write the code\nThe c\nor do you actually never have to write any code there ?\nYeah . There is actually a text file that you can edit . But it 's  You don't have to do that .\nThere 's like an XML format for  Bayes - nets .\nIs it XML ?\nThe - there is one . I don't know if this uses it .\nOh , I see . No this doesn't use it .\nBut it\nI didn't think it did .\nYeah , the  the\nYou can look at the text file .\nYeah .\nBut do you have it here ?\nUh , yes I do actually .\nWell , maybe you don't .\nLet me see .\nOh yes , of course .\nOh man ,\nLike , there 's the\nI didn't n  Is there an ampersand in DOS ?\nNope . Just s l start up a new DOS .\nWe - That 's alright . I can probably double cli click on it .\nOr  Yeah , right .\nn uh\nLet 's see .\nYep .\nLet 's see , come on .\nIt 'll ask you what you  what it wants  what you want to open it with and see what BAT , I guess .\nOne of these days , it should open this , theoretically .\nGo  Right mouse . Open with .\nOh there we go .\nThat 's  Oh !\nMaybe it was just\nOh .\nOh ! W Ah , it was dead . To the world .\nGod !\nOK .\nThrough the old Notepad . That 's my favorite editor .\nI like  I like Word Pad because it has the uh  the returns ,\nWordpad ? I\nthe carriage returns on some of them .\nMm - hmm . OK .\nYou know how they get \" auto - fills \" I guess ,\nMmm - hmm .\nor whatever you call it .\nAnyway , there it is .\nSo this is sort of LISP - y ? No .\nUh , Yeah .\nIt just basically looks like it just specifies a bunch of\nMm - hmm .\nYeah . That 's how actual probability tables are specified .\nYeah .\nAs , like , lists of numbers .\nMm - hmm .\nSo theoretically you could edit that .\nMm - hmm .\nIt just that  it 's\nBut  they 're not very friendly .\nMm - hmm .\nYeah the ordering isn't very clear on\nSo you 'd have to like figure out  Like you have to go and\nRight . The layout  of the table .\nYeah .\nYeah .\nActually we could write a program that could generate this .\nWell I  Yeah . I think so .\nYeah you could .\nYou could .\nit 's not\nWe were doing it\nYeah we can maybe write an interface th for uh entering probability distributions easily , something like  like a little script . That might  be worth it .\nAnd that might do .\nYeah . I actually seem to recall Srini complaining about something to do with Entering probability so this is probably\nThe other thing is it is in Java\nYeah , it 's  Yeah .\nso .\nWe could  manipulate the source  itself ?\nYeah .\nOr\nDo you have the true source files or just the class ?\nI don't know if he actually\nYeah . Uh , yeah . we do\nDoes he\nI  I saw directory called \" source \" ,\nOh .\nMm - hmm .\nI didn't e\nor  Yeah . Go up one ?\nUp one . Ah yes , good .\nYeah .\n\" Source \" . That 's  that 's quite nice .\nI don't know if it actually manipulate the source , though . That might be a bit complicated .\nMm - hmm .\nI think it might  it might be simpler to just  have a script that , you know  It 's , like , friendly ,\nThe d the data tables .\nit allows you enter things well .\nYeah .\nRight .\nBut if th if there is an XML  file that  or format that it can also read  I mean it just reads this , right ? When it starts .\nMm - hmm .\nYeah I know there is an  I was looking on the we web page and he 's updated it for an XML version of I guess Bayes - nets . There 's a Bayes - net spec for  in XML .\nMm - hmm .\nHe 's  Like this guy has ?\nYeah .\nThe JavaBayes guy ? So  but , e he doesn't use it . So in what sense has he updated it ?\nWell th you can either  you ca or you can read both .\nOh . I see .\nTo my understanding .\nOK . That would be awesome .\nOh .\nBecause uh  Well at least the  uh  I could have misread the web page , I have a habit of doing that , but .\nOK , wonderful .\nOK .\nSo you got more slides ?\nDo I have more slides ? Um yes , one more . \" Future Work \" . I think every presentation have a should have a \" Future Work \" slide . But uh it 's basically  we already talked about all this stuff , so .\nUm . The additional thing is I guess learning the probabilities ,  also . E That 's maybe , I don't know   If\nUh that 's future future work .\nDoes  That 's  Yeah .\nRight .\nVery future .\nMm - hmm .\nAnd of course if you have a presentation that doesn't  have something that doesn't work at all , then you have \" What I learned \" , as a slide .\nCan't you have both ?\nYou could . My first approach failed .\nRight .\nWhat I learned . OK , so I think that uh our presentation 's finished .\nGood .\nI know what I like about these meetings is one person will nod , and then the next person will nod , and then it just goes all the way around the room .\nSo the uh\nI missed my turn .\nNo I  Earlier I went {nonvocalsound} and Bhaskara went {nonvocalsound} and you did it . You did it .\nIt 's like yawning .\nIt 's like yawning .\nAnd this announcement was in stereo .\nHa .\nOK . So this means um\nShould I pull up the  net again ?\nYeah . Could you put the  the um , net up again ?\nYes . There we go .\nThanks .\nAnd actually I was  cuz I got a wireless mike on .\nSo a more general thing than \" discussed admission fee \" um , could be  I  I 'm just wondering whether the context , the background context of the discourse  might be  I don't know , if there 's a way to define it or maybe you know generalize it some way um , there might be other cues that , say , um , in the last few utterances there has been something that has strongly associated with say one of the particular modes uh , I don't know if that might be\nMm - hmm . I think we\nuh , and  and into that node would be various  various things that  that could have specifically come up .\nI think a  a sort of general strategy here  You know , this is  this is excellent because  um it gets you thinking along these terms  is that maybe we ob we could observe a couple of um discourse phenomena such as the admission fee , and something else and something else , that happened in the discourse before .\nMm - hmm . Right .\nAnd um  let 's make those four . And maybe there are two um  So maybe this could be sort of a separate region of the net ,  which has two   has it 's own middle layer . Maybe this , you know , has some  kind  of um , funky thing that di if this and this may influence these hidden nodes of the discourse which is maybe something that is uh , a more general version of the actual  phenomenon that you can observe . So things that point towards\nSo instead of single node , for  like , if they said the word \" admission fee \"\nExactly .\n\" admission fee \" , or maybe , you know , \" how much to enter \"\nYeah .\nor you know something , other cues .\nOpening hours or something like that .\nExactly . That would all f funnel into one node that would  constitute entrance requirements or something like that .\nSo \" pay a visit \"\nMm - hmm .\nuh uh d\nSure .\nYeah ?\nYeah .\nI mean it sort of get into plan recognition kinds of things in the discourse . I mean that 's like the bigger um , version of it .\nExactly . Yeah ? And then maybe there are some discourse acts if they happened before , um it 's more for um a cue that the person actually wants to get somewhere else and that you are in a  in a  in a route um , sort of proceeding past these things , so this would be just something that  where you want to pass it . Hmm ? Is that it ? However these are of course then the  the nodes , the observed nodes , for your middle layer . So this  again points to \" final destination \" , \" doing business \" , \" tourist hurry \" and so forth .\nMm - hmm .\nOK .\nYeah ? And so then we can say , \" OK . we have a whole  region  \"  in a e\nThat 's a whole set of discourse related cues to your middle layer .\nYeah , exactly . And this is just  then just one .\nRight ?\nSo e because at the end the more we um  add , you know , the more spider - web - ish it 's going to become in the middle and the more of hand editing . It 's going to get very ugly . But with this way we could say \" OK , these are the  discourse phenomena . They ra may have there own hidden layer  that points to some of  the  the real hidden layer , um or the general hidden layer .\nSure .\nAnd the same we will be able to do for syntactic information , the verbs used , the object types used , modifiers . And maybe there 's a hidden layer for that .\nYep .\nAnd so forth and so forth . Then we have context .\nYeah . So essentially a lot of those nodes can be expanded into little Bayes - nets of their own .\nYep .\nMm - hmm .\nPrecisely . So .\nOne thing that 's kind of been bugging me when I  more I look at this is that the  I guess , the fact that the  there 's a complete separation between the  observed features and in the output .\nYeah .\nI mean , it makes it cleaner , but then uh  I mean .\nThat 's true .\nFor instance if the discourse does\nWhat do you mean by that ?\nwell for instance , the \" discourse admission fee \"  node seems like it should point directly to the\nUh - huh .\nor increase the probability of \" enter  directly \" versus \" going there via tourist \" .\nYeah . Or we could like add more , uh , sort of middle nodes . Like we could add a node like do they want to enter it , which is affected by admission fee and by whether it 's closed and by whether it has a door .\nMm - hmm .\nRight .\nSo it 's like  There are  Those are the two options . Either like make an arrow directly or put a new node .\nYeah ,\nHmm .\nthat makes sense .\nYeah . And if it  if you do it  If you could connect it too hard you may get such phenomenon that  like \" So how much has it cost to enter ? \" and the answer is two hundred fifty dollars , and then the persons says um \" Yeah I want to see it . \" Yeah ? meaning \" It 's way out of my budget \" um\nThere are places in Germany where it costs two hundred fifty dollars to enter ?\nUm , nothing comes to mind . Without thinking too hard . Um , maybe , yeah of course , um opera premiers .\nReally ?\nSo you know .\nHmm .\nOr  or any good old Pink Floyd concert .\nI see . If you want to see \" The Magic Flute \" or something .\nYeah .\nOr maybe um , a famous restaurant . or , I don't know . There are various things that you might w not want to eat a  meal there but  your own table .\nThe Spagos of Heidelberg .\nI think that the h I mean nothing beats the  the admission charge prices in Japan . So there , two hundred dollars is  is moderate for getting into a discotheque . You know . Then again , everything else is free then once you 're ins in there .\nReally .\nFood and drink and so forth . So . I mean . But i you know , i we can  Something  Somebody can have discussed the admission fee and u the answer  is s if we  um , you know , um  still , based on that result is never going to enter that building .\nHmm .\nYou know ? Because it 's just too expensive .\nOh yeah , I think I see . So the discourse refers to \" admission fee \" but it just turns out that they change their mind in the middle of the discourse .\nYeah . you have to have some notion of not just  I mean there 's a  there 's change across several turns of discourse\nRight .\nMm - hmm .\nso  I don't know how  if any of this was discussed  but how i if it all this is going to interact with  whatever general  uh , other  other discourse processing that might be happen .\nMm - hmm .\nYeah .  {nonvocalsound} Yeah .\nI mean .\nWhat sort of discourse  processing is uh  are the  How much is built into SmartKom and\nIt works like this . The uh , um  I mean . The first thing we get is that  already the intention is sort of t They tried to figure out the intention , right ? simply by parsing it . And this um  m won't differentiate between all modes , yeah ? but at least it 'll tell us \" OK here we have something that  somebody that wants to go someplace , now it 's up for us to figure out what kind of going there is  is   is happening , and um , if the discourse takes a couple of turns before everything  all the information is needed , what happens is you know the parser parses it and then it 's handed on to the discourse history which is , um o one of the most elaborate  elaborate modules . It 's  it 's actually the  the whole memory of the entire system , that knows what  wh who said what , which was  what was presented . It helps an an anaphora resolution and it  and it fills in all the structures that are omitted , so ,  um , because you say \" OK ,  how can I get to the castle ? \" Oh , how  how much is it ? \" and um \" yeah I would like uh  um  to g let 's do it \" and so forth . So even without an a ana  anaphora somebody has to make sure that information we had earlier on is still here .\nMm - hmm .\nBecause not every module keeps a memory of everything that happened . so  whenever the uh , um person is not actually rejecting what happened before , so as in \" No I really don't want to see that movie . I 'd rather stay home and watch TV \" um  What movie was selected in what cinema in what town is  is going to be sort of added into the disc into the representations every di at each dialogue step , by the discourse model  discourse  model , Yeah , that 's what it 's called . and , um , it does some help in the anaphora resolution and it also helps in coordinating the gesture screen issues . So a person pointing to something on the screen , you know , the discourse model actually stores what was presented at what location on the s on the screen\nHmm .\nso it 's a  it 's a rather huge   huge thing but um    um    we can  sort of  It has a very clear interface . We can query it whether admission fees were discussed in the last turn and  and the turn before that or you know how  deep we want to search\nOK .\num  which is a question . How deep do we want to sear , you know ? Um  but we should  try to keep in mind that , you know , we 're doing this sort of for research , so we  we should find a limit that 's reasonable and not go , you know , all the way back to Adam and Eve . You know , did that person ever discuss admissions fee  fees in his entire life ? And the dialogues are pretty  pretty you know  concise and  Anyway .\nSo one thing that might be helpful which is implicit in the  use of \" admission fee discussion \" as a cue for entry ,   is thinking about the plans that various people might have . Like all the different  sort of general schemas that they might be following OK . This person is um , finding out information about this thing in order to go  in as a tourist or finding out how to get to this place  in order to do business . Um , because then  anything that 's a cue for one of the steps  would be slight evidence for that overall plan . Um , I don't know . They 're  in  in non in sort of more traditional AI kinds of plan recognition things you sort of have   you know , some idea at each turn of agent doing something , \" OK , wha what plans is this a  consistent with ? \" and then get s some more information and then you see  \" here 's a sequence that this sort of roughly fits into \" . It  it might be useful here too .\nMm - hmm .\nI  I don't know how you know you 'd have to   figure out what knowl what knowledge representation would work for that .\nI mean the   u u\nHmm .\nIt 's in the  these  these  these plan schemas . I mean there are some  some of them are extremely elaborate , you know . \" What do you need  need to buy a ticket ? \"\nMm - hmm .\nYou know ? and it  it 's fifty steps ,\nMm - hmm . Mm - hmm .\nhuh ? just for buying a ticket  at a ticket counter , you know , and  and maybe that 's helpful to look at it  to look at those . It 's amazing what human beings can do . W when we talked uh we had the example , you know , of you being uh  a s a person on a ticket counter working at railway station and somebody r runs up to you with a suitcase in his hands , says  New York and you say Track seven , huh ? And it 's because you know that that person actually is following , you know  You execute a whole plan of going through a hundred and fifty steps , you know , without any information other than \" New York \" , huh ? inferring everything from the context . So , works . Um , even though there is probably no train from here to New York , right ?\nMmm . Not direct .\nYou 'd uh probably have to transfer in Chicago .\nMm - hmm . But uh  it 's possible . Um , no you probably have to transfer also somewhere else . Right ? Is that t San Francisco , Chicago ?\nI think\nIs that possible ?\nOne time I saw a report on trains , and I think there is a l I don't know if  I thought there was a line that went from somewhere , maybe it was Sacramento to Chicago ,\nMm - hmm .\nbut there was like a California to Chicago line of some sort .\nHmm .\nI could be wrong though . It was a while ago .\nThe Transcontinental Railroad , doesn't that ring a bell ?\nYeah but I don't know if it 's still\nI think it has to exist somewhere .\nThey might have blown it up .\nWell it never went all the way , right ? I mean you always had to change trains at Omaha ,\nWell most of the way .\nright ? One track ended there and the other one started at  five meters away from that\nUh . Mm - hmm . Yeah .\nand  sort of\nWell .  You seem to know better than we do so .\nyeah ? Has anybody ever been on an Amtrak ?\nI have . But not transcontinentally .\nI 'm frightened by Amtrak myself .\nWhat ? Why ?\nI just  They seem to have a lot of accidents on the Amtrak .\nReally ?\nTheir reputation is very bad .\nYeah . Yeah .\nhuh ? It 's not maybe reality .\nIt 's not like German trains . Like German trains are really great so .\nBut  you know , I don't know whether it 's  which ones are safer , you know , statistically .\nUm , but they 're faster .\nYeah .\nMuch faster . Mm - hmm .\nAnd there 's much more of them . Yeah , they 're Yeah , it 's  way better\nyeah I used  um Amtrak quite a bit on the east coast and I was surprised . It was actually OK .\nMm - hmm .\nYou know , on Boston New York ,\nYeah .\nNew York Rhode Island ,\nYeah .\nwhatever ,\nI 've done that kind of thing .\nBoston .\nMm - hmm .\nYeah . But  That 's  a different issue .\nThis is going to be an interesting transcript .\nHmm ?\nI  I want to see what it does with uh \" landmark - iness \" . That 's\nYeah .\nLet 's all say it a few more times .\nIt 'd help it figure it out .\nSo .\nJust kidding . Right .\nYeah .\nSo by the way tha that structure  that Robert drew on the board was like more um ,   cue - type - based , right , here 's like we 're gonna  segment off a bit of stuff that comes from discourse and then  some of the things we 're talking about here are more  you know , we mentioned maybe  if they talk about  um , I don't know , entering or som you know like they might be more task - based .\nHmm .\nSo I  I don't know if there  There 's obviously some  m more than one way of organizing  the variables into something\nI think that um  What you guys did is really nicely sketching out different tasks , and maybe some of their conditions .\nso . Mm - hmm .\nOne task is more likely you 're in a hurry when you do that kind of s doing business ,\nMm - hmm .\nand  and less in a hurry when uh  you 're a tourist Um   tourists may have  never have final destinations , you know because they are eternally traveling around so  maybe what  what  what happened  what might happen is that we do get this sort of task - based middle layer ,\nMm - hmm .\nand then we 'll get these sub - middle layers , that are more cue - based .\nMm - hmm . That feed into those ?\nNah ?\nMm - hmm .\nMight be  might be a nice dichotomy of  of the world . So , um I suggest w to  for  to proceed with this in  in the sense that  maybe throughout this week the three of us will  will talk some more about maybe segmenting off different regions , and we make up some   some toy a observable \" nodes \"  is that what th\nRefined y re just refine the\nWhat 's the technical term ?\nOK . For which ?\nFor the uh  nodes that are observable ? The \" outer layer \" ?\nJust observable nodes ,\nThe features ,\nevidence nodes ?\nI don't know , whatever you\nFeature ma make up some features for those  Identify  four regions ,\nYeah .\nmaybe make up some features for each region and uh   and uh , uh  and uh  middle layer for those . And then these should then connect somehow to the more plan - based deep space\nYeah .\nBasically just refine  some of the more general nodes .\nYep . The - they  they will be aud ad - hoc for  for  for some time to come .\nYeah , this is totally like  The probabilities and all are completely ad - hoc . We need to look at all of them . I mean but , they 're even like   I mean like , close to the end we were like , uh , you know we were like uh  really ad - hoc .\nIt 's a even distribution . Like , whatever .\nRight ? Cuz if it 's like , uh  If it 's four things coming in , right ? And , say , some of them have like three possibilities and all that . So you 're thinking like  like a hundred and forty four or something  possible things  numbers to enter ,\nAnd  That 's terrible .\nright ? So .\nSome of them are completely absurd too , like   they want to enter , but it 's closed ,\nThat 's uh   Well\nit 's night time , you know there are tourists and all this weird stuff happens at the line up and you 're like\nYeah , the only like possible interpretation is that they are like  come here just to rob the museum or  something to that effect .\nconfused .\nIn which case you 're supposed to alert the authorities ,  and see appropriate action .\nYeah .\nYeah . Yeah , another thing to do , um , is also to , um  I guess to ask around people about other Bayes - net packages . Is Srini gonna be  at the meeting tomorrow , do you know ?\nMaybe .\nThe day after tomorrow .\nWait\nQuite possibly .\nWednesday .\nDay after tomorrow .\nOh , oh , sorry .\nYeah .\nSorry , Wednesday ,\nWho 's talking on Wednesday ?\nMaybe we can ask him about it .\nyeah . Mmm .\nI haven't  J Jerry never sent out a  sent out an email , did he , ever ?\nNo . But he mentioned at the last meeting that someone was going to be talking , I forget who .\nOh , isn't Ben ?\nUh .\nBen ?\nBen , then ,\nI think it 's Ben actually ,\nBen .\nAh !\nyeah , um , giving his job talk I think . um , Sorry . I was just reading the screen .\nOK .\nYeah .\nOh .\nSo the uh  That will be one  one thing we could do . I actually uh , have  Um , also we can uh , start looking at the SmartKom tables and I will\nRight .\nI actually wanted to show that  to you guys now but um .\nDo you want to  trade ?\nUm , no I  I actually made a mistake because it  it fell asleep and when Linux falls asleep on my machine it 's  it doesn't wake up ever , so I had to reboot\nOh , no .\nAnd if I reboot without a network , I will not be able to start SmartKom , because I need to have a network .\nUh\nSo we 'll do that t maybe uh\nBut . OK . But once you start  sart start SmartKom you can be on  You don't have to be on a network anymore . Is that the deal ?\nYep .\nAh , interesting .\nWhy does SmartKom need a network ?\nUm   it looks up some stuff that ,  you know , is  is that  is in the  written by the operating system only if it  if you get a DHCP request , so it  you know , my computer does not know its IP address , you know ?\nAh .\nYou know . So . Unless it boots up with networking .\nIt 's plugged in . Yeah .\nAnd I don't have an IP address , they can't look up  they don't know who localhost is , and so forth and so forth .\nHmm .\nAlways fun . But it 's a , um , simple solution . We can just um , go downstairs and  and  and look at this , but maybe not today . The other thing um  I will  oh yeah , OK , I have to report  um , data collection . We interviewed Fey ,\nMm - hmm .\nShe 's willing to do it , meaning be the wizard for the data collection , also  maybe transcribe a little bit , if she has to , but also recruiting subjects , organizing them , and so forth . So that looks good . Jerry however suggested that we should uh have a trial run with her , see whether she can actually do all the uh spontaneous , eloquent and creativeness that we uh expect of the wizard . And I talked to Liz about this and it looks as if Friday afternoon will be the time when we have a first trial run for the data .\nSo who would be the subject  of this trial run ?\nPardon me ?\nWho  Will there be a  Is one  Is you  one of you gonna be the subject ? Like are you\nUm Liz also volunteered to be the first subject ,  which I think might be even better than us guys .\nGood .\nOne of us , yeah .\nIf we do need her for the technical stuff , then of course one of you has to sort of uh  jump in .\nI like how we 've  you guys have successfully narrowed it down . \" Is one of you going to be the subject ? \" Is one of you  jump in .\nReference . I haven't done it yet .\nWell I just figured it has to be someone who 's , um , familiar enough with the data to cause problems for the wizard , so we can , uh , see if they 're you know good .\nOh plants ? e u someone who can plant difficult things .\nYeah . I mean that 's what we wanna  check , right ?\nUm ,\nWell , in this case it 's a p it 's a  sort of testing of the wizard rather than of the subject .\nIsn't that what it is ?\nIt 's uh\nyes w we  we would like to test the wizard , but  you know , if we take a subject that is completely unfamiliar with the task , or any of the set up , we get a more realistic\nI guess that would be reasonable .\nYeah .\nyou know , set up as\nYeah . I know . That 's probably a good enough test of\nUh - huh .\nYeah .\nSort of having an actively antagonistic , uh\nYeah . That might be a little unfair . Um .\nYeah .\nI 'm sure if we uh ,  You think there 's a chance we might need Liz for , whatever , the technical side of things ? I 'm sure we can get  other people around who don't know anything  um , if we want another subject .\nYeah , yeah .\nYou know . Like I can drag Ben into it or something . Although he might cause problems but . So , is it a experimental setup for the um , data collection  totally  ready  determined ?\nI like that . \" Test the wizard . \" I want that on a T - shirt .\nUm  I think it 's  it 's  it 's  I mean  experimental setup u on the technical issue yes , except we st I think we still need uh  a recording device for the wizard , just a tape recorder that 's running in a room .\nMm - hmm .\nBut um  in terms of specifying the scenario ,  um  uh  uh  we 've gotten a little further\nMm - hmm .\nbut um  we wanted to wait until we know who is the wizard , and have the wizard partake in the  ultimate  sort of definition probe . So  so if  if on Friday it turns out that she really likes it and  and we really like her , then nothing should stop us from sitting down next week and   getting all the details completely figured out .\nMm - hmm .\nAnd um\nOK . So the ideal task um ,  will have  whatever I don't know how much the structure of the evolving Bayes - net   will af affect  Like we wanna  we wanna be able to collect  as much of the variables that are needed for that ,\nMmm - yea - some .\nright ? in the course of the task ? Well not all of them but you know .\nBu - e e e I 'm even  This  this Tango , Enter , Vista is sort of , itself , an ad - hoc scenario .\nMm - hmm . Mm - hmm .\nThe  the basic u um idea behind the uh  data collection was the following . The data we get from Munich is  very command line , simple linguistic stuff .\nMm - hmm .\nHardly anything complicated . No metaphors whatsoever .\nMm - hmm .\nNot a rich language . So we wanted just to collect data , to get  that  that  that  elicits more , uh , that elicits richer language .\nMm - hmm .\nAnd we actually did not want to constrain it too much ,\nMm - hmm .\nyou know ? Just see what people say . And then maybe we 'll discover the phenomenon  the phenomena that we want to solve , you know , with  whatever engine we  we come up with . Um . So this  this  this is a parallel track , you know , there  they hopefully meet ,\nOK . So in other words this data collection is  more general .\nbut since\nIt could  it could  be used for not just this task .\nIt should tell us , you know , what kind of phenomenon could occur , it should tell us also maybe something about the difference between people who think they speak to a computer versus people who think they speak to a human being\nMm - hmm .\nand the sort of differences there . So it may get us some more information on the human - machine pragmatics , um , that no one knows anything about , as of yesterday . And uh   nothing has changed  since then , so . Uh . And secondly , now that of course we have sort of started to lick blood with this , and especially since um   Johno can't stop Tango - ing ,  we may actually include , you know , those  those intentions . So now I think we should maybe have at least one navigational task with  with sort of explicit  uh\nMm - hmm .\nnot ex it 's implicit that the person wants to enter ,\nMm - hmm .\nand maybe some task where it 's more or less explicit that the person wants to take a picture ,\nMm - hmm .\nor see it or something . So that we can label it . I mean , that 's how we get a corpus that we can label .\nMm - hmm . Exactly .\nWhereas , you know , if we 'd just get data we 'd never know what they actually wanted , we 'd get no cues . Yep .\nAlrighty .\nOK .\nThat was that .\nSo is this the official end of the meeting now ?\nYep .\nLooks like it .\nSo what 's \" Economics , the fallacy \" ?\nMa\nI just randomly  label things . So that has nothing to do with economics or anything .\nOh , really ?\nMaybe we ought to switch off these things before we continue .\nOK .", "topic_id": 2, "keywords": "landmarks, landmark, touristic, navigational, tourist", "dialogue_id": 47}, {"text": "OK . Switching o", "topic_id": 3, "keywords": "switching, ok", "dialogue_id": 47}, {"text": "OK , we 're recording .\nWe can say the word \" zero \" all we want ,\nI 'm doing some\nbut just\nsquare brackets , coffee sipping , square brackets .\nThat 's not allowed , I think .\nCur - curly brackets .\nIs that voiced or unvoiced ?\nCurly brackets .\nCurly brackets .\nCurly brackets .\nRight .\nOops .\nWell , correction for transcribers .\nMmm !   Gar - darn !\nYeah .\nChannel two .\nDo we use square brackets for anything ?\nYeah . Uh\nThese poor transcribers .\nu\nNot ri not right now . I mean  No .\nThere 's gonna be some zeros from this morning 's meeting because I noticed that\nu\nBarry , I think maybe you turned your mike off before the digits were  Oh , was it during digits ? Oh , so it doesn't matter .\nYeah .\nIt 's still not a good idea .\nSo it 's not  it 's not that bad if it 's at the end , but it 's  in the beginning , it 's  bad .\nYeah . Yeah .\nYeah , you wanna  you wanna keep them on so you get  good noise  noise floors , through the whole meeting .\nThat 's interesting . Hmm .\nUh , I probably just should have left it on . Yeah I did have to run , but\nIs there any way to change that in the software ?\nChange what in the software ?\nWhere like you just don't  like if you  if it starts catching zeros , like in the driver or something  in the card , or somewhere in the hardware  Where if you start seeing zeros on w across one channel , you just add some  random , @ @  noise floor  like a small noise floor .\nI mean certainly we could do that , but I don't think that 's a good idea . We can do that in post - processing if  if the application needs it .\nYeah .\nManual post - processing .\nWell , I  u I actually don't know what the default  is anymore as to how we 're using the  the front - end stuff but  for  for  when we use the ICSI front - end ,\nAs an argument .\nbut um , there is an  there is an o an option in  in RASTA , which , um ,  in when I first put it in , uh , back in the days when I actually wrote things , uh ,  I  did actually put in a random bit or so that was in it ,\nOK .\nbut  then I realized that putting in a random bit was equivalent to adding uh  adding flat spectrum ,\nRight .\nand it was a lot faster to just add a constant to the   to the spectrum . So then I just started doing that\nMmm . OK .\ninstead of calling \" rand \"  or something ,\nRight .\nso . So it d it does that . Gee ! Here we all are !\nUh , so the only agenda items were Jane  was Jane wanted to talk about some of the IBM transcription process .\nThere 's an agenda ?\nI sort of  condensed the three things you said into that . And then just  I only have like , this afternoon and maybe tomorrow morning to get anything done before I go to Japan for ten days . So if there 's anything that n absolutely , desperately needs to be done , you should let me know now .\nUh , and you just sent off a Eurospeech paper , so .\nRight . I hope they accept it .", "topic_id": 0, "keywords": "transcribers, recording, transcription, brackets, voiced", "dialogue_id": 48}, {"text": "Right .\nI mean , I  both actu as  as a submission and   you know , as a paper . Um  but\nWell yeah , you sent it in  late .\nYeah , I guess you  first you have to do the first one ,\nYeah .\nand then  Yeah .\nWe actually exceeded the delayed deadline by o another day , so .\nOops .\nOh they  they had some extension that they announced or something ?\nWell yeah . Liz had sent them a note saying \" could we please  have another \"   I don't know , \" three days \" or something , and they said yes .\nAnd then she said \" Did I say three ?\nOh ,\nI meant four . \"\nthat was the other thing uh ,\nBut u\nuh , Dave Gelbart sent me email , I think he sent it to you too ,  that um , there 's a special topic , section in si in Eurospeech on new , corp corpors corpora . And it 's not due until like May fifteenth .\nOh this isn't the Aurora one ?\nNo .\nIt 's another one ?\nIt 's a different one .\nNo it 's  Yeah . Yeah .\nHuh !\nAnd uh ,\nOh !\nI got this mail from\nI s forwarded it to Jane as I thought being the most relevant person . Um  So , I thought it was highly relevant\nYeah I 'm\nThat 's\nhave you  did you look at the URL ?\nYeah . I think so too . Um , I haven't gotten over to there yet ,\nMm - hmm .\nbut what  our discussion yesterday , I really  I  I wanna submit one .\nWas this  SmartKom message ? I think  Christoph Draxler sent this ,\nYeah . And , you offered to  to join me , if you want me to .\nI 'll help ,\nyeah .\nbut obviously I can't , really do , most of it ,\nYeah . Yeah , that 's right .\nI think several people  sent this ,\nso .\nYeah .\nUh - huh .\nyeah .\nBut any  any help you need I can certainly provide .\nWell ,\nYeah .\nthat 's  that 's a great idea .\nWell  there  there were some interesting results in this paper , though . For instance that Morgan  uh , accounted for fifty - six percent of the Robustness meetings in terms of number of words .\nWow .\nIn  in terms of what ? In term\nNumber of words .\nOne ? Wow ! OK .\nThat 's just cuz he talks really fast .\nDo you mean ,\nn No .\nI know\nOh . Short words .\nbecause  is it partly , eh , c correctly identified words ? Or is it  or just overall volume ?\nNo . Well , according to the transcripts .\nBut re well regardless . I think it 's  he 's  he 's in all of them ,\nOh . OK .\nYeah .\nI mean , we didn't mention Morgan by name\nand he talks a lot .\nwe just\nOne participant .\nWell  we have now , but\nWe  we  we  something about\nDid you identify him as a senior  member ?\nNo , we as identify him as the person dominating the conversation .\nWell .\nYeah .\nOK .\nI mean I get these AARP things , but I 'm not se really senior yet , but\nRight\nUm ,\nHmm .\nbut uh , other than that delightful result , what was the rest of the paper about ?\nUm , well it was about  it had three sections\nYou sent it to me but I haven't seen it yet .\nuh  three kinds of uh results , if you will . Uh , the one was that the  just the  the amount of overlap\nThe good , the bad , and the ugly .\num , s in terms of  in terms of number of words and also we computed something called a \" spurt \" , which is essentially a stretch of speech with uh , no pauses exceeding five hundred milliseconds . Um , and we computed how many overlapped i uh spurts there were and how many overlapped words there were .  Um , for four different  corpora , the Meeting Recorder meetings , the Robustness meetings Switchboard and CallHome , and , found  and sort of compared the numbers . Um , and found that the , uh , you know , as you might expect the Meeting Recorder  meetings had the most overlap uh , but next were Switchboard and CallHome , which both had roughly the same , almost identical in fact , and the Robustness meetings were  had the least , so  One sort of unexpected result there is that uh two - party telephone conversations have  about the same amount of overlap ,\nI 'm surprised .\nsort of in gen you know  order of magnitude - wise as , uh  as face - to - face meetings with multiple\nI have  I had better start changing all my slides !\nYeah . Also , I  in the Levinson , the pragmatics book ,  in you know , uh , textbook ,  there 's  I found this great quote where he says  you know  you know , how people  it talks about how uh  how  how people are so good at turn taking ,\nMm - hmm . Yeah . Yeah .\nand  so  they 're so good that  generally , u the overlapped speech does not  is less than five percent .\nOh , that 's interesting . Yeah .\nSo , this is way more than five percent .\nDid he mean face  like face - to - face ? Or  ?\nWell , in real conversations ,\nHmm .\neveryday conversations .\nMm - hmm .\nIt 's s what these conversation analysts have been studying for years and years there .\nMm - hmm .\nBut\nWell , of course , no , it doesn't necessarily go against what he said , cuz he said \" generally speaking \" . In order to  to go against that kind of a claim you 'd have to big canvassing .\nHmm .\nAnd in f\nWell , he  he made a claim\nWell\nWell\nBut\nYeah , we  we have pretty limited sample here .\nFive percent of time or five percent of what ?\nYeah , I was gonna ask that too .\nYeah .\nYeah .\nExactly .\nWell it 's time .\nYeah , so\nIt 's  i it 's not against his conclusion ,\nSo   but still  but still  u\nit just says that it 's a bi bell curve , and that ,  you have something that has a nice range , in your sampling .\nYeah . So there are slight  There are differences in how you measure it , but still it 's   You know , the difference between um  between that number and what we have in meetings , which is more like ,  you know , close to  in meetings like these , uh  you know , close to twenty percent .\nMm - hmm . Mm - hmm .\nBut what was it like , say , in the Robustness meeting , for instance ?\nThat\nBut\nRobustness meeting ? It was  about half of the r So ,  in terms of number of words , it 's like seventeen or eigh eighteen percent for the Meeting Recorder meetings and  about half that for ,  uh , the Robustness .\nMaybe ten percent ?\nBut I don't know if that 's really a fair way of comparing between , multi - party , conversations and two - party conversations . Yeah . I  I  I don't know .\nThen  then  then you have to\nI mean that 's just something\nYeah , I just wonder if you have to normalize by the numbers of speakers or something .\nYeah .\nThen  Yeah , then normalize by  by something like that ,\nYeah , that 's a good point .\nWell , we didn't get to look at that ,\nyeah .\nYeah .\nbut this obvious thing to see if  if there 's a dependence on the number of uh  participants .\nGood idea .\nI mean  I bet there 's a weak dependence . I 'm sure it 's  it 's not a real strong one .\nYeah .\nRight .\nRight ? Because you\nCuz not everybody talks .\nRight .\nRight .\nYeah .\nYou have a lot of  a lot of two - party , subsets within the meeting .\nRight .\nUh - huh .\nWell regardless  it 's an interesting result regardless .\nSo  Right .\nYes , that 's right .\nAnd  and  and then  and we also d computed this both with and without backchannels ,\nMm - hmm .\nso you might think that backchannels have a special status because they 're essentially just\nUh - huh . So , did  we all said \" uh - huh \" and nodded at the same time ,\nR right .\nso .\nBut , even if you take out all the backchannels  so basically you treat backchannels l as nonspeech , as pauses ,\nMm - hmm .\nMm - hmm .\nyou still have significant overlap . You know , it goes down from maybe  For Switchboard it goes down from  I don't know  f um   I don't know  f fourteen percent of the words to maybe  uh I don't know , eleven percent or something  it 's  it 's not a dramatic change ,\nMm - hmm .\nso it 's  Anyway , so it 's uh  That was  that was one set of  results , and then the second one was just basically the   the stuff we had in the  in the HLT paper on how overlaps effect the  recognition performance .\nHmm .\nNope . Right .\nMm - hmm .\nAnd we rescored things um , a little bit more carefully . We also fixed the transcripts in  in numerous ways . Uh , but mostly we added one  one number , which was what if you  uh , basically score ignoring all  So  so the  the conjecture from the HLT results was that  most of the added recognition error is from insertions  due to background speech . So , we scored  all the recognition results ,  uh , in such a way that the uh\nOh by the way , who 's on channel four ? You 're getting a lot of breath .\nYeah . I j was just wondering .\nThat 's\nYeah .\nThat 's me .\nuh , well Don 's been working hard .\nThat 's right .\nOK , so   so if you have the foreground speaker speaking here , and then there 's some background speech , may be overlapping it somehow , um , and this is the time bin that we used , then of course you 're gonna get insertion errors here and here .\nRight .\nRight ? So we scored everything , and I must say the NIST scoring tools are pretty nice for this , where you just basically ignore everything outside of the ,  uh , region that was deemed to be foreground speech . And where that was we had to use the t forced alignment , uh , results from s for  so  That 's somewhat  that 's somewhat subject to error , but still we  we   Uh , Don did some ha hand - checking and  and we think that  based on that , we think that the results are you know , valid , although of course , some error is gonna be in there . But basically what we found is after we take out these regions  so we only score the regions that were certified as foreground speech ,   the recognition error went down to almost  uh , the  level of the non - overlapped  speech . So that means that  even if you do have background speech , if you can somehow separate out or find where it is ,  uh , the recognizer does a good job ,\nThat 's great .\nYeah .\neven though there is this back\nYeah , I guess that doesn't surprise me , because , with the close - talking mikes , the  the signal will be so much stronger .\nRight . Right .\nMm - hmm .\nMm - hmm . Um ,\nWhat  what sort of normalization do you do ?\nso  Uh , well , we just  @ @  we do  u you know , vit\nI mean in you recognizer , in the SRI recognizer .\nWell , we do uh , VTL   vocal tract length normalization , w and we uh  you know , we  we uh ,  make all the features have zero mean and unit variance .\nOver an entire utterance ?\nAnd\nOr windowed ?\nOver  over the entire c over the entire channel .\nDon't  train\nOver the\nHmm .\nbut you know . Um , now we didn't re - align the recognizer for this . We just took the old  So this is actually a sub - optimal way of doing it ,\nRight .\nRight .\nright ? So we took the old recognition output and we just scored it differently . So the recognizer didn't have the benefit of knowing where the foreground speech  a start\nWere you including the  the lapel  in this ?\nYes .\nAnd did the  did  did the la did the  the problems with the lapel go away also ? Or\nUm , it  Yeah .\nfray for  for insertions ?\nIt u not per  I mean , not completely , but yes ,\nLess so .\ndramatically . So we have to um\nI mean , you still\nWell I should bring the  should bring the table with results . Maybe we can look at it  Monday .\nI would presume that you still would have somewhat higher error with the lapel for insertions than\nYes . It 's  It 's\nYeah .\nYes . Yeah .\nCuz again , looking forward to the non - close miked case , I think that we s still\nMm - hmm .\nI 'm not looking forward to it .\ni it 's the high signal - to - noise ratio\nRight .\nhere that  that helps you .\nu s Right . So  so that was number  that was the second set of  uh , the second section . And then ,  the third thing was , we looked at ,   uh , what we call \" interrupts \" , although that 's  that may be  a misnomer , but basically  we looked at cases where  Uh , so we  we used the punctuation from the original transcripts and we inferred the beginnings and ends of sentences . So , you know\nDi - did you use upper - lower case also , or not ?\nUm\nU upper lower case or no ?\nHmm ?\nOK .\nNo , we only used , you know , uh periods , uh , question marks and  exclamation . And we know that there 's th that 's not a very g I mean , we miss a lot of them ,\nYeah . That 's OK but\nbut  but it 's f i i\nComma also or not ?\nNo commas . No . And then  we looked at locations where , uh , if you have overlapping speech and someone else starts a sentence , you know , where do these  where do other people start their  turns  not turns really , but you know , sentences ,\nAh .\num  So we only looked at cases where there was a foreground speaker and then at the to at the  so the  the foreground speaker started into their sentence and then someone else started later .\nSomewhere in between the start and the end ?\nOK ? And so what\nOK .\nSorry ?\nSomewhere in between the start and the end of the foreground ?\nYes . Uh , so that such that there was overlap between the two sentences .\nYeah .\nSo , the  the question was how can we  what can we say about the places where the second or  or actually , several second speakers ,  um  start their  \" interrupts \" , as we call them .\nThree words from the end .\nAt pause boundaries .\nw And we looked at this in terms of um\nOn T - closures , only .\nSo  so we had   we had um u to  for  for the purposes of this analysis , we tagged the word sequences , and  and we time - aligned them . Um , and we considered it interrupt  if it occurred in the middle of a word , we basically  you know , considered that to be a interrupt as if it were at  at the beginning of the word . So that ,  if any part of the word was overlapped , it was considered an interrupted  word .\nMm - hmm .\nAnd then we looked at the  the locatio the ,  um , you know , the features that  the tags because we had tagged these word strings ,   um , that  that occurred right before these  these uh , interrupt locations .\nTag by uh\nAnd the tags we looked at are  the spurt tag , which basically says  or actually  Sorry . End of spurt . So   whether there was a pause essentially here , because spurts are a  defined as being you know , five hundred milliseconds or longer pauses , and then we had things like discourse markers , uh , backchannels , uh , disfluencies . um , uh , filled pauses  So disfluen the D 's are for ,  um ,  the interruption points of a disfluency , so , where you hesitate , or where you start the repair there . Uh , what else do we had . Uh , repeated  you know , repeated words is another of that kind of disfluencies and so forth . So we had both the beginnings and ends of these  uh so , the end of a filled pause and the end of a discourse marker . And we just eyeballed  I mean  we didn't really hand - tag all of these things . We just  looked at the distribution of words , and so every  \" so yeah \" , and \" OK \" , uh , and \" uh - huh \" were  were the  were deemed to be backchannels and  \" wow \" and \" so \" and  uh \" right \" , uh were um   Not \" right \" . \" Right \" is a backchannel . But so , we sort of  just based on the lexical   um , identity of the words , we  we tagged them as one of these things . And of course the d the interruption points we got from the original transcripts . So , and then we looked at the disti so we looked at the  distribution of these different kinds of tags , overall uh , and  and  and particularly at the interruption points . And uh , we found that there is a marked difference so that for instance after  so at the end after a discourse marker or after backchannel or after filled pause , you 're much more likely to be interrupted  than before . OK ? And also of course after spurt ends , which means basically in p inside pauses . So pauses are always an opportunity for  So we have this little histogram which shows these distributions and ,  um ,\nI wonder\nyou know , it 's  it 's  it 's not  No big surprises , but it is  sort of interesting from\nIt 's nice to actually measure it though .\nYeah .\nI wonder about the cause and effect there . In other words uh  if you weren't going to pause you  you will because you 're g being interrupted .\nWell we 're ne\nUh\nRight . There 's no statement about cause and effect .\nYeah , right . No , no , no .\nThis is just a statistical correlation ,\nRight , I  I see . Yeah .\nyeah .\nBut he  yeah , he 's  he 's right , y I mean maybe you weren't intending to pause at all , but   You were intending to stop for fifty - seven milliseconds ,\nRight .\nbut then Chuck came in\nRight .\nYeah .\nand so you  paused for a second\nRight . Anyway .  So ,\nor more .\nuh , and that was basically it . And  and we  so we wrote this and then ,  we found we were at six pages , and then we started  cutting furiously\nOops .\nand  threw out half of the  material again , and uh played with the LaTeX stuff and\nMade the font smaller and the narrows longer .\nuh , and  until it fi\nFont smaller , yeah .\nNo , no . W well , d you couldn't really make everything smaller\nPut the abstract end .\nbut we s we put  Oh , I  I\nTook out white space .\nyou know the  the gap between the two columns is like ten millimeters ,\nYeah .\nso I d shrunk it to eight millimeters and that helped some . And stuff like that .\nWasn't there  wasn't there some result , Andreas\nYeah\nI  I thought maybe Liz presented this at some conference a while ago about  uh , backchannels\nMm - hmm . Mm - hmm .\nuh , and that they tend to happen when uh  the pitch drops . You know you get a falling pitch . And so that 's when people tend to backchannel .\nYeah . Well\nUh - i i do you rem\ny We didn't talk about , uh , prosodic , uh , properties at all ,\nRight . Right . But\nalthough that 's  I  I take it that 's something that uh Don will  will look at\nYeah , we 're gonna be looking at that .\nnow that we have the data and we have the alignment , so . This is purely based on you know the words\nMm - hmm .\nand\nI have a reference for that though . Uh - huh .\nOh you do .\nYeah .\nSo am I recalling correctly ?\nAnyway , so .\nWell , I didn't know about Liz 's finding on that ,\nAbout\nbut I know of another paper that talks about something\nUh - huh .\nthat\nHmm .\nI 'd like to see that reference too .\nOK .\nIt made me think about a cool little device that could be built to uh  to handle those people that call you on the phone and just like to talk and talk and talk . And you just have this little detector that listens for these  drops in pitch and gives them the backchannel . And so then you  hook that to the phone and go off\nYeah . Uh - huh .\nand do the   do whatever you r wanna do ,\nOh yeah . Well\nwhile that thing keeps them busy .\nThere 's actually  uh there 's this a former student of here from Berkeley , Nigel  Nigel Ward .\nUh - huh . Sure .\nDo you know him ?\nYeah .\nHe did a system uh , in  he  he lives in Japan now , and he did this backchanneling , automatic backchanneling system .\nRight .\nIt 's a very\nOh !\nSo , exactly what you describe ,\nHuh .\nbut for Japanese . And it 's apparently  for Japa - in Japanese it 's really important that you backchannel . It 's really impolite if you don't , and  So .\nHuh . Actually for a lot of these people I think you could just sort of backchannel continuously and it would  pretty much be fine .\nIt wouldn't matter ? Yeah .\nYeah . That 's w That 's what I do .\nRandom intervals .\nThere was  there was of course a Monty Python sketch with that . Where the barber who was afraid of scissors was playing a  a tape of clipping sounds , and saying \" uh - huh \" , \" yeah \" , \" how about them sports teams ? \"\nAnyway . So the paper 's on - line and y I  I think I uh  I CC ' ed a message to Meeting Recorder with the URL so you can get it .\nYep .\nYeah .\nPrinted it out , haven't read it yet .\nYeah .\nUm , uh one more thing . So I  I 'm actually   about to send Brian Kingbury an email saying where he can find the  the s the m the material he wanted for the s for the speech recognition experiment , so  but I haven't sent it out yet because actually my desktop locked up , like I can't type anything . Uh b so if there 's any suggestions you have for that I was just gonna send him the\nIs it the same directory that you had suggested ?\nI made a directory . I called it um\nHe still has his Unix account here , you know .\nWell this isn't\nYeah .\nHe does ?\nAnd he  and he 's\nYeah but  but  but he has to\nI 'd hafta add him to Meeting Recorder , I guess ,\nhe prefe he said he would prefer FTP\nbut  OK .\nand also , um , the other person that wants it  There is one person at SRI who wants to look at the  um , you know , the uh  the data we have so far ,\nOK .\nand so I figured that FTP is the best  approach . So what I did is I um    @ @  I made a n new directory after Chuck said that would c that was gonna be a good thing . Uh , so it 's \" FTP   pub\nPub real .\nreal \"  Exactly . MTGC  What is it again ? CR\nAsk Dan Ellis .\nu R D  RDR , yeah .\nOr  Yeah . Right ? The same  the same as the mailing list ,\nYeah ,\nand\nthe   No vowels .\nYeah . Um ,\nYeah\nand then under there  Um actually  Oh and this directory ,  is not readable . It 's only uh , accessible . So ,  in other words , to access anything under there , you have to  be told what the name is .\nRight .\nSo that 's sort of a g  quick and dirty way of doing access control .\nMm - hmm .\nSo  uh , and the directory for this I call it I \" ASR zero point one \" because it 's sort of meant for recognition .\nSo anyone who hears this meeting now knows the\nBeta ?\nAnd then  then in there I have a file that lists all the other  files , so that someone can get that file and then know the file names and therefore download them . If you don't know the file names you can't\nIs that a dash or a dot in there ?\nI mean you can\nDon't  don't  don't say .\nDash . Anyway . So all I  all I was gonna do there was stick the  the transcripts after we  the way that we munged them for scoring , because that 's what he cares about , and  um , and also  and then the  the  waveforms that Don segmented . I mean , just basically tar them all up f I mean  w for each meeting I tar them all into one tar file and G - zip them and stick them there .\nI uh , put digits in my own home directory  home FTP directory ,\nAnd so .\nbut I 'll probably move them there as well .\nOh , OK .\nSo we could point Mari to this also for her  March O - one request ?\nOK . Yeah . March O - one .\nOr\nOh !\nYou n Remember she was\nOh she wanted that also ?\nWell she was saying that it would be nice if we had  they had a  Or was she talking  Yeah . She was saying it would be nice if they had eh  the same set , so that when they did experiments they could compare .\nRight , but they don't have a recognizer even .\nYeah .\nUm  I\nBut yeah , we can send  I can CC Mari on this so that she knows\nYeah . So , for the thing that\nThat 's good .\nWe need to give Brian the beeps file ,\nRight .\nso I was gonna probably put it\nWe can put it in the same place . Just put in another directory .\nYeah , it I 'll make another directory .", "topic_id": 1, "keywords": "deadline, mailing, delayed, mail, submission", "dialogue_id": 48}, {"text": "Well , make ano make another directory .\nYeah . Exactly .\nYou don't n m\nYeah .\nYeah .\nAnd , Andreas , um , sampled ?\nYeah . They are ?\nI think so . Yeah . Um , so either we should regenerate the original  versions ,   or um , we should just make a note of it .\nOK . Oh . Beca - Well  OK , because in one directory there 's two versions .\nYeah , that 's the first meeting I cut both versions . Just to check which w if there is a significant difference .\nOK . And so I  but  OK so  but for the other meetings it 's the downsampled version that you have .\nThey 're all downsampled , yeah .\nOh , OK . Oh that 's th important to know , OK so we should probably  uh  give them the non - downsampled versions .\nYeah . So\nOK . Alright , then I 'll hold off on that and I 'll wait for you um\nProbably by tomorrow\ngen\nI can  I 'll send you an email .\nOK . Alright . OK . Yeah , definitely they should have the full bandwidth version ,\nYeah , because I mean  I I think Liz decided to go ahead with the  downsampled versions cuz we can  There was no s like , r significant difference .\nyeah . OK . Well , it takes  it takes up less disk space , for one thing .\nIt does take up less disk space , and apparently it did even better  than the original  than the original versions ,\nYeah . Yeah .\nwhich you know , is just , probably random .\nRight . Yeah , it was a small difference\nBut , um  they probably w want the originals .\nbut yeah . Yeah . OK . OK , good . Good that  Well , it 's a good thing that\nOK , I think we 're losing , Don and Andreas at three - thirty , right ? OK .\nHey mon hafta booga .\nYeah .\nSo , that 's why it was good to have Andreas , say these things but  So , we should probably talk about the IBM transcription process stuff that\nOK . So , um you know that Adam created um , a b a script to generate the beep file ?\nHmm .\nTo then create something to send to IBM . And , um , you  you should probably talk about that . But  but you were gonna to use the  originally transcribed file because I tightened the time bins and that 's also the one that they had already  in trying to debug the first stage of this . And uh , my understanding was that , um  I haven't   I haven't listened to it yet ,\nMm - hmm .\nbut it sounded very good and  and I understand that you guys  were going to have a meeting today , before this meeting .\nIt was just to talk about how to generate it . Um , just so that while I 'm gone , you can regenerate it if you decide to do it a different way . So uh , Chuck and Thilo should , now more or less know how to generate the file\nExcellent . OK .\nand ,  the other thing Chuck pointed out is that , um ,  since this one is hand - marked ,  there are discourse boundaries . Right ? So  so when one person is speaking , there 's breaks .\nMm - hmm .\nWhereas Thilo 's won't have that . So what  what we 're probably gonna do is just write a script , that if two , chunks are very close to each other on the same channel we 'll just merge them .\nOh ! OK . Ah , interesting . Yeah . Yeah . Oh , sure . Yeah , sure . Makes sense .\nSo , uh , and that will get around the problem of , the ,  you know \" one word beep , one word beep , one word beep , one word beep \" .\nYeah . Ah ! Clever . Yes . Clever . Yeah . Excellent .\nYeah , in fact after our meeting uh , this morning Thilo came in and said that  um , there could be  other differences between  the uh  already transcribed meeting with the beeps in it and one that has  just r been run through his process .\nAnd that 's the purpose . Yeah .\nSo tomorrow ,  when we go to make the um  uh , chunked file  for IBM , we 're going to actually compare the two . So he 's gonna run his process on that same meeting ,\nGreat idea !\nand then we 're gonna do the beep - ify on both , and listen to them and see if we notice any real differences .\nBeep - ify !\nOK , now one thing that prevented us from apply you  you from applying  Exactly . The training  So that is the training meeting . OK .\nYeah , w and we know that . Wel - uh we just wanna if  if there 're any major differences between  doing it on the hand\nUh - huh . Oh , interesting . Ah !\nHmm .\nOK . Interesting idea . Great .\nSo this training meeting , uh w un is that uh  some data where we have uh very um ,  you know , accurate  time marks ? for\nI went back and hand - marked the  ba the bins , I ment I mentioned that last week .\nOK , yeah .\nBut the  but there 's  yeah , but there is this one issue with them in that there 're   there are time boundaries in there that occur in the middle of speech .\nBecause\nSo  Like when we went t to um  When I was listening to the original file that Adam had , it 's like you  you hear a word then you hear a beep  and then you hear the continuation of what is the same sentence .\nThat 's on the other channel . That 's because of channel overlap .\nWell , and  and so the  th\nHmm .\nIt 's  i\nSo there are these chunks that look like uh   that have uh\nI mean that 's not gonna be true of the foreground speaker . That 'll only be if it 's the background speaker .\nRight . So you 'll  you 'll have a chunk of , you know , channel  A which starts at zero and ends at ten , and then the same channel starting at eleven , ending at fifteen , and then again , starting at sixteen , ending at twenty . Right , so that 's three chunks where  actually we w can just make one chunk out of that which is A , zero , twenty .\nMm - hmm .\nYeah .\nThat 's what I just said ,\nSure . Sure .\nyeah .\nYeah . So I just wanted to make sure that it was clear .\nYeah , I thought that was\nSo  if you were to use these , you have to be careful not to pull out these individual\nYeah .\nOh ! I mean it  Right , I mean w I mean what I would  I was interested in is having   a se having time marks for the beginnings and ends of speech by each speaker .\nWell , that 's definitely a problem .\nUh , because we could use that to fine tune our alignment process\nBattery .\nYeah .\nto make it more accurate .\nBattery ?\nMm - hmm .\nSo  uh , it  I don't care that you know , there 's actually abutting segments that we have to join together . That 's fine .\nOK .\nBut what we do care about is that  the beginnings and ends um  are actually close to the speech  inside of that\nYeah , I think Jane tightened these up by hand .\nuh\nOK .\nYeah .\nOK , so what is the  sort of how tight are they ?\nUh , it looks much better .\nYeah . Looks good .\nThey were , um , reasonably tight , but not excruciatingly tight .\nOh .\nThat would 've taken more time . I just wanted to get it so tha So that if you have like \" yeah \"  in a  swimming in a big bin , then it 's\nNo , no ! I don\nLet me make a note on yours .\nactually I  I\nYeah .\nI  it 's f That 's fine because we don't want to  th that 's perfectly fine . In fact it 's good . You always want to have a little bit of pause or nonspeech around the speech , say for recognition purposes . Uh , but just  just u w you know get an id I just wanted to have an idea of the   of how much extra you allowed um  so that I can interpret the numbers if I compared that with a forced alignment segmentation .\nI can't answer that ,\nSo .\nbut  but my main goal was  um , in these areas where you have a three - way overlap  and one of the overlaps involves \" yeah \" ,  and it 's swimming in this huge bin ,  I wanted to get it so that it was clo more closely localized .\nMm - hmm . Mm - hmm . Right . But are we talking about , I don't know ,  a   tenth of a second ? a  ? You know ? How  how much  how much extra would you allow at most\nI  I wanted to  I wanted it to be able to  l he be heard normally ,\nMm - hmm .\nso that if you  if you play  back that bin and have it in the mode where it stops at the boundary ,  it sounds like a normal word .\nOK .\nIt doesn't sound like the person  i it sounds normal . It 's as if the person could 've stopped there .\nMm - hmm .\nAnd it wouldn't have been an awkward place to stop .\nOK .\nNow sometimes you know , it 's  these are involved in places where there was no time . And so ,   there wouldn't be  a gap afterwards because\nOK .\nI mean some cases , there 're some people  um , who  who have very long  segments of discourse where ,  you know , they 'll  they 'll breath  and then I put a break .\nMm - hmm .\nBut other than that , it 's really pretty continuous and this includes things like going from one sentence into the  u one utterance into the next , one sentence into the next , um , w without really stopping . I mean  i they , i you know in writing you have this  two spaces and a big gap\nMm - hmm .\nyou know .\nRight .\nBut  but uh   i some people are planning and , you know , I mean , a lot  we always are planning  what we 're going to say next .\nOK .\nBut uh , in which case , the gap between  these two complete syntactic units ,  um , which of course n spoken things are not always complete syntactically , but   but it would be a shorter p shorter break  than  maybe you might like .\nMm - hmm .\nBut the goal there was to  not have  the text be so  so crudely  parsed in a time bin . I mean , because  from a discourse m purpose  it 's   it 's more   it 's more useful to be able to see  and also you know , from a speech recognition purpose my impression is that  if you have too long a unit , it 's  it doesn't help you very much either , cuz of the memory .\nWell , yeah . That 's fine .\nSo , that means that  the amount of time after something is variable depending partly on context , but my general goal  when there was  sufficient space , room , pause  after it  to have it be  kind of a natural feeling  gap .\nOK .\nWhich I c I don't know what it would be quantified as . You know , Wally Chafe says that  um ,  in producing narratives , the spurts that people use  tend to be ,  uh , that the  the  what would be a pause might be something like two  two seconds .\nMmm .\nAnd um , that would be , you know one speaker . The discourse   the people who look at turn taking often do use\nMm - hmm .\nI was interested that you chose uh ,  you know um ,  the  you know that you use cuz I think that 's a unit that would be more consistent with sociolinguistics . Yeah .\nWell we chose um , you know , half a second because  if  if you go much larger , you have a  y you know , your  your statement about how much overlap there is becomes less ,  um , precise ,\nMm - hmm .\nbecause you include more of actual pause time into what you consider overlap speech . Um , so , it 's sort of a compromise ,\nYeah .    Yeah , I also used I think something around zero point five seconds for the speech - nonspeech detector\nand   it 's also based  I mean Liz suggested that value based on  the distribution of pause times that you see in Switchboard and  and other corpora .\nMm - hmm .\nUm  So\nfor the minimum silence length .\nMm - hmm . I see .\nSo .\nYeah .\nMm - hmm .\nOK .\nIn any case , this  this uh , meeting  that I hand  I  I hand - adjusted two of them I mentioned before ,\nMm - hmm .\nand I sent  I sent email ,\nOK ,\nso\nSo  so at some point we will try to fine - tune our forced alignment\nAnd I sent the   path .\nmaybe using those as references because you know , what you would do is you would play with different parameters . And to get an object You need an objective  measure of how closely you can align the models to the actual speech . And that 's where your your data would be  very important to have . So , I will  Um\nYeah and hopefully the new meetings  which will start from the channelized version will  will have better time boundaries  and alignments .\nMm - hmm . Right .\nBut I like this idea of  uh , for our purposes for the  for the IBM preparation ,  uh , n having these  joined together ,\nYeah . Yeah .\nand uh  It makes a lot of sense . And in terms of transcription , it would be easy to do it that way .\nYeah .\nThe way that they have with the longer units ,\nYeah .\nnot having to fuss with adding these units at this time .\nYeah . Whi - which could have one drawback . If there is uh a backchannel in between those three things ,\nRight .\nMm - hmm .\nthe  the n the backchannel will  will occur at the end of  of those three .\nYes .\nAnd  and in  in the  in the previous version where in the n which is used now ,  there , the backchannel would  would be in - between there somewhere , so .\nI see .\nThat would be more natural\nYeah . Well ,\nbut\nthat 's  that 's right , but you know , thi this brings me to the other f stage of this which I discussed with you earlier today ,\nYeah .\nwhich is  the second stage is  um , w what to do  in terms of the transcribers adjustment of these data . I discussed this with you too . Um , the tr so the idea initially was , we would get  uh , for the new meetings , so the e EDU meetings , that  Thilo ha has now presegmented all of them for us , on a channel by channel basis . And um , so , I 've assigned  I 've  I 've assigned them to our transcribers and um , so far I 've discussed it with one , with uh  And I had a  about an hour discussion with her about this yesterday , we went through  uh EDU - one , at some extent . And it occurred to me that  um  that  basically what we have in this kind of a format is  you could consider it as a staggered mixed file , we had some discussion over the weekend a about  at  at this other meeting that we were all a at  um ,  about whether the tran the IBM transcribers should hear a single channel audio , or a mixed channel audio . And um ,  in  in a way , by  by having this  this chunk and then the backchannel  after it , it 's like a stagal staggered mixed channel . And um ,  it occurred  to me in my discussion with her yesterday that um , um , the   the  the maximal gain , it 's  from the IBM  people , may be in long stretches of connected speech . So it 's basically a whole bunch of words  which they can really do , because of the continuity within that person 's turn . So , what I 'm thinking , and it may be that not all meetings will be good for this ,  but  but what I 'm thinking is that  in the EDU meetings , they tend to be  driven by a couple of dominant speakers . And , if the chunked files focused on the dominant speakers ,  then , when  when it got s patched together when it comes back from IBM , we can add the backchannels . It seems to me  that  um , you know , the backchannels per - se wouldn't be so hard , but then there 's this question of the time  @ @  uh , marking , and whether the beeps would be  uh y y y And I 'm not exactly sure how that  how that would work with the  with the backchannels . And , so um  And certainly things that are  intrusions of multiple words ,  taken out of context and displaced in time from where they occurred ,  that would be hard . So , m my  thought is  i I 'm having this transcriber go through  the EDU - one meeting , and indicate a start time {nonvocalsound} f for each dominant speaker , endpoi end time for each dominant speaker , and the idea that  these units would be generated for the dominant speakers ,  and maybe not for the other channels .\nYeah the only , um , disadvantage of that is , then it 's hard to use an automatic method to do that . The advantage is that it 's probably faster to do that than it is to use the automated method and correct it . So .\nWell , it\nWe 'll just have to see .\nOK . I think   I  I think um , you know , the original plan was that the transcriber would adjust the t the boundaries , and all that for all the channels but ,  you know , that is so time - consuming , and since we have a bottleneck here , we want to get IBM things that are usable s as soon as possible , then this seemed to me it 'd be a way of gett to get them a flood of data , which would be useful when it comes back to us . And um\nYeah .\nOh also , at the same time she  when she goes through this , she 'll be  uh  If there 's anything that  was encoded as a pause , but really has something transcribable in it ,  then she 's going to  uh , make a mark  w uh , so you know , so  that  that bin would be marked as it  as double dots and she 'll just add an S . And in the other  in the other case , if it 's marked as speech ,  and really there 's nothing transcribable in it , then she 's going to put a s dash , and I 'll go through and it  and um , you know , with a    with a substitution command , get it so that it 's clear that those are the other category . I 'll just , you know , recode them . But um ,  um , the transcribable events  that um , I 'm considering in this ,  uh , continue to be  laugh , as well as speech , and cough and things like that , so I 'm not stripping out anything , just  just you know , being very lenient in what 's considered speech . Yeah ?\nJane ? In terms of the  this new procedure you 're suggesting ,  um , u what is the\nIt 's not that different .\nSo I 'm a little confused , because how do we know where to put beeps ? Is it  i d y is it\nOh , OK .\nTranscriber will do it .\nSo what it  what it  what it involves is  is really a s uh ,  uh , the original pr procedure , but  only applied to  uh , a certain  strategically chosen  s aspect of the data .\nWe pick the easy parts of the data basically ,\nSo\nand transcriber marks it by hand .\nYou got it .\nAnd because\nBut after we 've done Thilo 's thing .\nNo .\nYes !\nOh , after . Oh , OK ,\nYes !\nI didn't  I didn't understand that .\nOh yeah !\nOK .\nSo , I 'm @ @  now I 'm confused .\nOK . We start with your presegmented version\nOK , and I 'm leaving .\nYeah , I have to go as well .\nSo , um\nOK , leave the mikes on , and just put them on the table .\nOK . Thanks .\nWe start with the presegmented version\nLet me mark you as no digits .\nYou start with the presegmentation , r  yeah ?\nYeah . And then um ,  the transcriber ,  instead of going painstakingly through all the channels and moving the boundaries around , and deciding if it 's speech or not , but not transcribing anything . OK ? Instead of doing that , which was our original plan ,  the tra They focus on the dominant speaker\nMm - hmm . They just  do that on  the main channels .\nYeah . So what they do is they identify who 's the di dominant speaker , and when the speaker starts .\nOK .\nYeah ? OK .\nSo I mean , you 're still gonna\nAnd you just\nSo we 're  It 's based on your se presegmentation , that 's the basic  thing .\nand you just use the s the segments of the dominant speaker then ? For  for sending to  to IBM or  ?\nYeah . Exactly .\nSo , now Jane , my question is  when they 're all done adjusting the w time boundaries for the dominant speaker ,  have they then also erased the time boundaries for the other ones ?\nMm - hmm . Uh No . No , no . Huh - uh . S\nSo how will we know who\nYeah .\nThat 's  that 's why she 's notating the start and end points of the dominant speakers . So , on a  you know , so  i in EDU - one , i as far as I listened to it , you start off with a  a s section by Jerry . So Jerry starts at minute so - and - so , and goes until minute so - and - so . And then Mark Paskin comes in . And he starts at  minute such - and - such , and goes on till minute so - and - so . OK . And then  meanwhile , she 's listening to   both of these guys ' channels , determining if there 're any cases of misclassification of speech as nothing , and nothing as speech ,\nMm - hmm . OK .\nand  a and adding a tag if that happens .\nSo she does the adjustments on those guys ?\nBut you know , I wanted to say , his segmentation is so good , that  um , the part that I listened to with her yesterday  didn't need any adjustments of the bins .\nOn that meeting .\nMm - hmm .\nSo far we haven't . So this is not gonna be a major part of the process , at least  least not in  not on ones that  that really\nSo if you don't have to adjust the bins , why not just do what it  for all the channels ?\nMm - hmm ?\nWhy not just throw all the channels to IBM ?\nWell there 's the question o of  whether  Well , OK . She i It 's a question of how much time we want our transcriber to invest here  when she 's gonna have to invest that when it comes back from IBM anyway .\nMm - hmm .\nSo if it 's only inserting \" mm - hmm \"s here and there , then , wouldn't that be something that would be just as efficient to do at this end , instead of having it go through I B M , then be patched together , then be double checked here .\nMm - hmm . Right .\nYeah . But  But then we could just use the  the output of the detector , and do the beeping on it , and send it to I B\nWithout having her check anything .\nYeah .\nRight .\nWell , I guess\nI think we just  we just have to listen to it and see how good they are .\nFor some meetings , I 'm  I 'm sure it  i n\nI 'm  I 'm open to that , it was\nYeah , if it 's working well ,\nThat 's  And some  on some meetings it 's good .\nthat sounds like a good idea since as you say you have to do stuff with the other end anyway .\nYeah .\nWell yea OK , good . I mean the detector , this\nYeah , I mean we have to fix it when it comes back anyhow .\nYeah .\nNow , you were saying that they  they differ in how well they work depending on channel s sys systems and stuff .\nYeah . So we should perhaps just select meetings on which the speech - nonspeech detection works well ,\nBut EDU is great .\nand just use ,  those meetings to  to  to send to IBM and , do the other ones .\nRelease to begin with .\nHow interesting . You know\nWhat 's the problem  the l I forget . Is the problem the lapel , or  or\nUh , it really depends . Um , my  my  my impression is that it 's better for meetings with fewer speakers , and it 's better for   for meetings where nobody is breathing .\nOh ,\nYeah ,\nthe dead meetings .\nget  That 's it .\nSo in fact this might suggest an alternative sort of a  a c a hybrid between these two things .\nNo , the undead meeting , yeah .\nYeah . Yeah ?\nSo the  the one suggestion is you know we   we run Thilo 's thing and then we have somebody go and adjust all the time boundaries\nYeah .\nYeah ?\nand we send it to IBM . The other one is  we just run his thing and send it to IBM .\nYeah .\nThere 's a  a another possibility if we find that there are some problems ,\nYeah . Yeah .\nand that is  if we go ahead and we  just run his , and we generate the beeps file , then we have somebody listen beeps file .\nYeah . And erase\nAnd they listen to each section and say \" yes , no \" whether that section is\nYeah .\nIs intelligible .\ni i intelligible or not . And it just  You know , there 's a little interface which will  for all the \" yes \" - es it  then that will be the final  beep file .\nYeah .\nBlech .\nThat 's interesting ! Cuz that 's  that 's directly related to the e end task .\nStress test .\nMm - hmm .\nHow interesting !\nYeah . I mean it wouldn't be that much fun for a transcriber to sit there , hear it , beep , yes or no .\nNope .\nI  I  I don't know .\nBut it would be quick .\nIt would be  kind of quick but they 're still listening to everything .\nBut there 's no adjusting . And that 's what 's slow . There 's no adjusting of time boundaries .\nWell ,  eh , listening does take time too .\nYeah .\nYeah . I don't know , I  I think I 'm  I 'm really tending towards\nOne and a half times real time .\nI mean ,  what 's the worst that happens ? Do the transcribers  I mean as long as th on the other end they can say there 's  there 's something  conventions so that they say \" huh ? \"\nYeah . Right . They  they\nand then we can flag those later .\nYeah . That 's true .\ni i It  i\nWe can just catch it at the  catch everything at this side .\nYeah .\nWell maybe that 's the best way to go ,\nHow interesting !\njust\nI mean it just depends on how\nWell EDU\nYeah ,\nSorry , go ahead .\nu u u\nSo I was gonna say , EDU - one is good enough ,\nYeah .\nmaybe we could include it in this  in this set of uh , this stuff we send .\nYeah there 's  I  I think there are some meetings where it would  would  It 's possible like this .\nYeah I  I think , we won't know until we generate a bunch of beep files automatically , listen to them and see how bad they are .\nYeah . Yeah .\nYeah .\nMm - hmm .\nWe won't be able to s include it with this first thing ,\nIf\nHmm . Oh , OK .\nbecause there 's a part of the process of the beep file which requires knowing the normalization coefficients .\nOh , I see .\nAnd   So a\nThat 's not hard to do . Just  it takes  you know , it just takes five minutes rather than , taking a second .\nOK\nYeah .\nSo . I just hand  hard - coded it .\nRight , except I don't think that  the c the instructions for doing that was in that directory , right ? I  I didn't see where you had gener\nNo , but it 's easy enough to do .\nWhat\nBut I  but I have a\nDoing the gain ? It 's no problem . Adjusting the gain ?\nn Doing th No , getting the coefficients , for each channel .\nYeah , that 's no problem .\nKnow what numbers .\nOK . So we just run that one\nThere are lots of ways to do it .\nWe can do that .\nI have one program that 'll do it . You can find other programs .\nYeah . I  I used it , so .\nWe just run that\nYep .\nYeah .\nJ - sound - stat ? OK .\nYeah .\nMinus D , capital D .\nYeah .\nBut  but  but I  I  I have  another suggestion on that , which is ,  since , really what this is , is  is  is trying to in the large , send the right thing to them and there is gonna be this  this post - processing step , um , why don't we check through a bunch of things by sampling it ?\nMm - hmm .\nRight ? In other words , rather than , um , uh , saying we 're gonna listen to everything\nI didn't mean listen to everything , I meant , just see if they 're any good .\nYeah . So y you do a bunch of meetings , you listen to  to a little bit here and there ,\nYeah .\nif it sounds like it 's almost always right and there 's not any big problem you send it to them .\nSend it to them .\nYeah .\nOK .\nAnd , you know , then they 'll send us back what we  w what  what they send back to us ,\nOh , that 'd be great .\nand we 'll  we 'll fix things up and  some meetings will cost more time to fix up than others .\nWe should  Yeah .\nYeah .\nAnd we should just double - check with Brian on a few simple conventions on how they should mark things .\nSure .\nOK . When they  when there 's either no speech in there ,\nYeah . Yeah .\nor  something they don't understand ,\nYeah . Mm - hmm .\nthings like that .\nYeah , cuz @ @ uh what I had originally said to Brian was well they 'll have to mark , when they can't distinguish between the foreground and background ,\nYeah .\nbecause I thought that was gonna be the most prevalent . But if we send them without editing , then we 're also gonna hafta have m uh , notations for words that are cut off ,\nMm - hmm .\nYeah .\nMm - hmm .\nand other sorts of , uh , acoustic problems .\nYeah .\nThey do already .\nAnd they may just guess at what those cut - off words are ,\nYeah .\nbut w I mean we 're gonna adjust  everything when we come back\nBut what  what we would like them to do is be conservative so that they should only write down the transcript if they 're sure .\nYeah .\nAnd otherwise they should mark it so that we can check .\nMark it . Sure . Yeah . Yeah .\nMm - hmm .\nWell , we have the unintelligibility  convention .\nMm - hmm .\nAnd actually they have one also ,\nRight .\nwhich\ni Can I maybe have  have an order of  it 's probably in your paper that I haven't looked at lately , but\nCertainty .\nUh , an order of magnitude notion of  of how  on a good meeting , how often uh , do you get segments that come in the middle of words and so forth , and uh  in a bad meeting how  often ?\nUh .\nWas is it in a  in a  what  what is the t\nWell he 's saying , you know , that the  the EDU meeting was a good  good meeting ,\nIn a good meeting , what ?\nYeah .\nYeah .\nright ?\nOh I see ,\nUh , and so  so  so it was almost  it was almost always doing the right thing .\nthe characteristics .\nSo I wanted to get some sense of what  what almost always meant . And then , uh in a bad meeting ,  or p some meetings where he said oh he 's had some problems , what does that mean ?\nUh - huh . OK .\nSo I mean does one of the does it mean one percent and ten percent ? Or does it mean  five percent and fifty percent ?\nOK .\nUh\nSo\nOr  Maybe percentage isn't the right word ,\nJust\nYeah th\nbut you know how many  how many per minute , or  You know .\nYeah , the  the problem is that , nnn , the numbers Ian gave in the paper is just uh , some frame error rate . So that 's  that 's not really   What will be effective for  for the transcribers , is  They have to  yeah , in in they have to insure that that 's a real s spurt or something . And  but ,  the numbers  Oops . Um\nHmm !\nLet me think . So the  speech  the amount of speech that is missed by the  detector , for a good meeting , I th is around  or under one percent , I would say . But there can be  Yeah . For  yeah , but there can be more  There 's  There 's more amount speech  uh , more amount of  Yeah well , the detector says there is speech , but there is none . So that  that can be a lot when  when it 's really a breathy channel .\nBut I think that 's less of a problem .\nYeah .\nThey 'll just listen . It 's just wasted time .\nYeah .\nAnd th and that 's for a good meeting . Now what about in a meeting that you said we 've  you 've had some more trouble with ?\nI can't  really  hhh ,   Tsk .  I  don't have really representative numbers , I think . That 's really  I  I did  this on  on four meetings and only five minutes of  of every meet of  of these meetings so ,  it 's not  not that representative , but , it 's perhaps , Fff . Um  Yeah , it 's perhaps then  it 's perhaps five percent of something , which s uh the  the frames  speech frames which are  which are missed , but um , I can't  can't really tell .\nRight . So I   So i Sometime , we might wanna go back and look at it more in terms of  how many times is there a spurt that 's  that 's uh , interrupted ?\nYeah . Yeah . Yeah .\nSomething like that ?\nThe other problem is , that when it  when it uh d i on the breathy ones , where you get   breathing , uh , inti indicated as speech .\nAnd\nSo\nAnd I guess we could just indicate to the transcribers not to  encode that if they  We could still do the beep file .\nYeah again I  I think that that is probably less of a problem because if you 're  if there 's   If  if a  if a word is  is split , then they might have to listen to it a few times to really understand that they can't quite get it .\nOK . OK .\nBut\nOK .\nWhereas if they listen {nonvocalsound} to it and there 's  don't hear any speech I think they 'd probably just listen to it once .\nYeah .\nSo there 'd  you 'd think there 'd be a  a factor of three or four in  in , uh , cost function ,\nOK .\nyou know , between them or something .\nYeah , so  but I think that 's  n that really doesn't happen very often that  that  that a word is cut in the middle or something . That 's  that 's really not  not normal .\nSo  so what you 're saying is that nearly always what happens when there 's a problem is that  is that uh , there 's  some uh , uh nonspeech that uh  that is b interpreted as speech .\nThat is marked as speech . Yeah . Yeah .\nWell then , we really should just send the stuff .\nThat would be great .\nRight ? Because that doesn't do any harm .\nYeah , it 's\nYou know , if they  they hear you know , a dog bark and they say what was the word , they  you know , they\nYeah , I als I\nRuff ruff !\nYeah I also thought of  there  there are really some channels where it is almost  um , only bre breathing in it . And to  to re - run 's\nYeah ?\nEh , um . Yeah . I 've got a  a  P - a  method with loops into the cross - correlation with the PZM mike , and then to reject everything which  which seems to be breath .\nUh - huh .\nSo , I could run this on those breathy channels , and perhaps throw out\nThat 's a good idea .\nWow , that 's a great idea .\nYeah . But I think  I th Again , I think that sort of  that that would be good ,\nYeah .\nand what that 'll do is just cut the time a little further .\nYeah .\nMm - hmm .\nBut I think none of this is stuff that really needs somebody doing these  these uh , uh , explicit markings .\nYeah .\nExcellent . Oh , I 'd be delighted with that , I  I was very impressed with the  with the result . Yeah .\nYeah , cuz the other thing that was concerning me about it was that it seemed kind of specialized to the EDU meeting , and  and that then when you get a meeting like this or something ,\nYeah .\nand   and you have a b a bunch of different dominant speakers\nOh yeah , interesting .\nyou know , how are you gonna handle it .\nOh yeah .\nWhereas this sounds like a more general solution\nOh yeah , I pr I much prefer this ,\nis\nI was just trying to find a way  Cuz I  I don't think the staggered mixed channel is awfully good as a way of handling overlaps .\nYeah . Uh - huh .\nBut  but uh\nWell good . That  that really simplifies thing then .\nYeah .\nAnd we can just , you know , get the meeting , process it , put the beeps file , send it off to IBM .\nMm - hmm .\nYou know ?\nYeah .\nWith very little  work on our side .\nProcess it , hear into it . I would\nDo what ?\nUm ,  listen to it , and then\nOr at least sample it .\nYeah .\nWell , sample it .\nYeah .\nSample it .\nI  I would just use some samples ,\nYeah . Yeah .\nmake sure you don't send them three hours of \" bzzz \"  or something .\nYeah .\nNo .\nYeah . Right .\nThat won't be good .\nYeah .\nYeah . Yeah that would be very good .\nYeah .\nAnd then we can you know\nYeah .\nThat 'll oughta be a good way to get the pipeline going .\nOh , I 'd be delighted . Yeah .\nAnd there 's  there 's one point which I  uh   yeah , which  which I r  we covered when I  when I r listened to one of the EDU meetings ,\nGreat .\nand that 's  that somebody is playing sound from his laptop .\nUh - huh\nAnd i  the speech - nonspeech detector just assigns randomly the speech to  to one of the channels , so . Uh - I haven't - I didn't think of  of s of  this before ,\nWhat can you do ?\nbut what  what shall we do about s things like this ?\nWell you were suggesting  You suggested maybe just not sending that part of the meeting .\nYep . Mmm .\nBut\nBut , sometimes the   the  the laptop is in the background and some  somebody is  is talking , and ,  that 's really a little bit confusing , but\nIt 's a little bit confusing .\nThat 's life .\nYeah .\nI mean ,  what 're we gonna do ?\nYeah .\nEven a hand - transcription would\nOK .\nDo you\nYeah .\na hand - transcriber would have trouble with that .\nYeah ,\nSo .\nthat 's  that 's a second question , \" what  what will different transcribers do with  with the laptop sound ? \"\nWould you  would\nWhat was the l what was the laptop sound ?\nYeah , go ahead .\nI mean was it speech ,\nYeah .\nor was it\nIt 's speech .\nGreat .\nWell , so  I mean  So my standard approach has been if it 's not someone close - miked , then , they don't end up on one of the close - miked channels . They end up on a different channel . And we have any number of channels available ,\nUh - huh .\nYeah .\nI mean it 's an infinite number of channels .\nBut ,\nSo just put them on some other channel .\nwhen thi when this is sent to  to the I M - eh , I B M transcribers , I don't know if  if they can tell that 's really\nYeah , that 's right .\nYeah cuz there will be no channel on which it is foreground .\nYeah . Yeah .\nUh\nWell , they have a convention , in their own procedures ,  which is for a background  sound .\nRight , but , uh , in general I don't think we want them transcribing the background , cuz that would be too much work .\nYeah .\nRight ? For it  because in the overlap sections , then they 'll\nWell I don't think Jane 's saying they 're gonna transcribe it , but they 'll just mark it as being  there 's some background stuff there ,\nBut that 's gonna be all over the place .\nYeah .\nright ?\nHow w how will they tell the difference between that sort of background and the dormal  normal background of two people talking at once ?\nYeah .\nOh , I think  I think it 'd be easy to to say \" background laptop \" .\nHow would they know that ?\nBut wait a minute , why would they treat them differently ?\nYeah .\nWell because one of them\nBecause otherwise it 's gonna be too much work for them to mark it . They 'll be marking it all over the place .\nYeah .\nOh , I s background laptop or , background LT   wouldn't take any time .\nSure , but how are they gonna tell bet the difference between that and two people just talking at the same time ?\nAnd\nYeah .\nOh , you can tell . Acoustically , can't you tell ?\nIt 's really good sound , so\nOh is it ? Oh !\nWell , I mean , isn't there a category something like uh , \" sounds for someone for whom there is no i close mike \" ?\nYeah that would be very important ,\nBut how do we d how do we do that for the I B M folks ?\nYeah .\nyeah .\nHow can they tell that ?\nWell we may just have to do it when it gets back here .\nYes , that 's my opinion as well .\nYeah .\nSo we don't do anything for it  with it .\nOK .\nYeah .\nThat sounds good .\nAnd they 'll just mark it however they mark it ,\nThat sounds good .\nYeah .\nand we 'll correct it when it comes back .\nSo th\nYeah .\nthere was a category for @ @  speech .\nOK .\nYeah , the default .\nYeah , s a\nNo , not default .\nOK .\nWell , as it comes back , we have a uh  when we can use the channelized interface for encoding it , then it 'll be easy for us to handle .\nYeah .\nBut   but if  if out of context , they can't tell if it 's a channeled speak uh , you know , a close - miked speaker or not ,  then that would be confusing to them .\nOK .\nRight .\nOK .\nI don't know , I  it doesn't  I don't  Either way would be fine with me , I don't really care .\nYeah . So . Shall we uh , do digits and get out of here ?\nYep .\nI have o I have one question . Do you think we should send the um  that whole meeting to them and not worry about pre - processing it ?\nYes ma '\nOr  Uh , what I mean is  we  we should  leave the  part with the audio in the uh , beep file that we send to IBM for that one , or should we  start after the  that part of the meeting is over in what we send .\nWhich part ?\nWith\nSo , the part where they 're using sounds from their  from their laptops .\nwith the laptop sound , or  ? just\nw If we have speech from the laptop should we just uh , excise that from what we send to IBM , or should we  i give it to them and let them do with it what they can ?\nI think we should just  it  it 's gonna be too much work if we hafta  worry about that I think .\nOK , that 'd be nice to have a  a uniform procedure .\nYeah , I think if we just  m send it all to them . you know .\nWorry about it when we get back .\nGood . And see how well they do .\nLet  Yeah , worry about it when we get back in .\nAnd give them freedom to   to indicate if it 's just not workable .\nYeah .\nYeah ,\nYeah .\nOK ,\nYeah .\nexcellent .\nCuz , I wouldn't  don't think we would mind  having that  transcribed , if they did it .\nI think\nYeah , e\nAs I say , we 'll just have to listen to it and see how horrible it is .\nYeah , yeah .\nYeah .\nSample it , rather .\nOK . Alright .\nI think that  that will be a little bit of a problem\nYeah .\nThat 's great .\nas it really switches around between  two different channels , I think .\nMm - hmm , and  and they 're very  it 's very audible ? on the close - talking channels ?\nWhat  what I would  Yeah .\nOh well . I mean , it 's the same problem as the lapel mike .\nYeah .\nYeah .\nBut\nOh , interesting .\nComparable , yeah .\nYeah .\nOK .\nOK , alright . Digits .\nLet 's do digits .\nOK , so we read the transcript number first , right ?\nAre we gonna do it altogether or separately ?\nSo  What time is it ?\nUh ,  why don't we do it together ,\nUh , quarter to four .\nOh , OK .\nthat 's  that 's a nice fast way to do it .\nMm - hmm .\nOne , two , three , go !\nIt 's kind of interesting if there 're any more errors in these ,  than we had the first set .\nNnn , yeah , I think there probably will be .\nYeah .\nDo you guys plug your ears when you do it ?\nI do .\nNo .\nI usually do .\nI do .\nI don't .\nI didn't this time .\nYou don't ?\nNo .\nI haven't been ,\nHow can you do that ?\nno .\nI  I\nUh , concentration .\nPerhaps there are  lots of errors in it\nGah !\nTotal concentration . Are you guys ready ?\nYou hate to have your ears plugged ?\nYeah .\nReally ?", "topic_id": 2, "keywords": "downsampled, versions, sampled, files, version", "dialogue_id": 48}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 49}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 49}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 49}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 49}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 49}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 50}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 50}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 50}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 50}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 50}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 51}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 51}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 51}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 51}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 51}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 52}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 52}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 52}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 52}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 52}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 53}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 53}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 53}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 53}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 53}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 54}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 54}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 54}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 54}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 54}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 55}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 55}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 55}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 55}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 55}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 56}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 56}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 56}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 56}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 56}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 57}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 57}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 57}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 57}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 57}, {"text": "Let 's see . Test ? Test ? Yeah . OK .\nHello ?\nChannel one .\nHello ?\nTest .\nI was saying Hynek 'll be here next week , uh , Wednesday through Friday  uh , through Saturday , and , um , I won't be here Thursday and Friday . But my suggestion is that , uh , at least for this meeting , people should go ahead , uh , cuz Hynek will be here , and , you know , we don't have any Czech accent yet , uh ,  as far as I know , so  There we go .\nOK .\nUm . So other than reading digits , what 's our agenda ?\nI don't really have , uh , anything new . Been working on  Meeting Recorder stuff . So .\nOK . Um . Do you think that would be the case for next week also ? Or is  is , uh  ? What 's your projection on  ?\nUm .\nCuz the one thing  the one thing that seems to me we really should try , if you hadn't tried it before , because it hadn't occurred to me  it was sort of an obvious thing  is , um , adjusting the , uh , sca the scaling and , uh , insertion penalty sorta stuff .\nI did play with that , actually , a little bit . Um . What happens is , uh ,  when you get to the noisy stuff , you start getting lots of insertions .\nRight .\nAnd , um , so I 've tried playing around a little bit with , um , the insertion penalties and things like that .\nYeah .\nUm . I mean , it  it didn't make a whole lot of difference . Like for the well - matched case , it seemed like it was pretty good . Um .  I could do more playing with that , though . And , uh\nBut you were looking at mel cepstrum .\nand see . Yes .\nRight .\nOh , you 're talking about for th  for our features .\nRight . So , I mean , i it it 's not the direction that you were working with that we were saying what 's the  uh , what 's the best you can do with  with mel cepstrum . But , they raised a very valid point ,\nMmm .\nwhich , I guess  So , to first order  I mean , you have other things you were gonna do , but to first order , I would say that the conclusion is that if you , um , do , uh , some monkeying around with , uh , the exact HTK training and @ @  with , uh , you know , how many states and so forth , that it  it doesn't particularly improve the performance . In other words , that even though it sounds pretty dumb , just applying the same number of states to everything , more or less , no matter what language , isn't so bad . Right ? And I guess you hadn't gotten to all the experiments you wanted to do with number of Gaussians ,\nRight .\nbut , um , let 's just  If we had to  if we had to draw a conclusion on the information we have so far , we 'd say something like that . Right ?\nMm - hmm .\nUh , so the next question to ask , which is I think the one that  that  that Andreas was dre addressing himself to in the lunch meeting , is , um , we 're not supposed to adjust the back - end , but anybody using the system would .\nYeah .\nSo , if you were just adjusting the back - end , how much better would you do , uh , in noise ? Uh , because the language scaling and insertion penalties and so forth are probably set to be about right for mel cepstrum .\nMm - hmm .\nBut , um , they 're probably not at all set right for these things , particularly these things that look over , uh , larger time windows , in one way or another with  with LDA and KLT and neural nets and  all these things . In the fa past we 've always found that we had to increase the insertion penalty to  to correspond to such things . So , I think that 's , uh , @ @  that 's kind of a first - order thing that  that we should try .\nSo for th so the experiment is to , um , run our front - end like normal , with the default , uh , insertion penalties and so forth , and then tweak that a little bit and see how much of a difference it makes\nSo by \" our front - end \" I mean take , you know , the Aurora - two s take some version that Stephane has that is , you know , our current best version of something .\nif we were  Mm - hmm .\nUm . I mean , y don't wanna do this over a hundred different things that they 've tried but , you know , for some version that you say is a good one . You know ? Um . How  how much , uh , does it improve if you actually adjust that ?\nOK .\nBut it is interesting . You say you  you have for the noisy  How about for the  for the mismatched or  or  or  or the  or the medium mismatched conditions ? Have you  ? When you adjusted those numbers for mel cepstrum , did it  ?\nUh , I  I don't remember off the top of my head . Um . Yeah . I didn't even write them down . I  I  I don't remember . I would need to  Well , I did write down , um  So , when I was doing  I just wrote down some numbers for the well - matched case .\nYeah .\nUm . Looking at the  I wrote down what the deletions , substitutions , and insertions were , uh , for different numbers of states per phone .\nYeah .\nUm , but , uh , that  that 's all I wrote down .\nOK .\nSo . I  I would  Yeah . I would need to do that .\nOK . So\nI can do that for next week .\nYeah . And , um  Yeah . Also , eh , eh , sometimes if you run behind on some of these things , maybe we can get someone else to do it and you can supervise or something . But  but I think it would be  it 'd be good to know that .\nOK . I just need to get , um ,  front - end , uh , stuff from you\nHmm .\nor you point me to some files  that you 've already calculated .\nYeah . Alright .\nOK . Uh .\nI probably will have time to do that and time to play a little bit with the silence model .\nMm - hmm .\nSo maybe I can have that for next week when Hynek 's here .\nYeah .\nMm - hmm .\nYeah . Cuz , I mean , the  the other  That , in fact , might have been part of what , uh , the difference was  at least part of it that  that we were seeing . Remember we were seeing the SRI system was so much better than the tandem system .\nHmm .\nPart of it might just be that the SRI system , they  they  they always adjust these things to be sort of optimized ,\nIs there  ?\nand\nI wonder if there 's anything that we could do  to the front - end that would affect the insertion\nYes . I think you can .\nWhat could you do ?\nWell , um  uh , part of what 's going on , um , is the , uh , the range of values . So , if you have something that has a much smaller range or a much larger range , and taking the appropriate root .\nOh . Mm - hmm .\nYou know ? If something is kind of like the equivalent of a bunch of probabilities multiplied together , you can take a root of some sort . If it 's like seven probabilities together , you can take the seventh root of it or something , or if it 's in the log domain , divide it by seven .\nMm - hmm .\nBut  but , um , that has a similar effect because it changes the scale of the numbers  of the differences between different candidates from the acoustic model\nOh , right .\nas opposed to what 's coming from the language model .\nSo that w Right . So , in effect , that 's changing the value of your insertion penalty .\nYeah . I mean , it 's more directly like the  the language scaling or the , uh  the model scaling or acoustic scaling ,\nThat 's interesting .\nbut you know that those things have kind of a similar effect to the insertion penalty\nMm - hmm .\nanyway . They 're a slightly different way of  of handling it .\nRight .\nSo , um\nSo if we know what the insertion penalty is , then we can get an idea about what range our number should be in ,\nI think so .\nso that they  match with that .\nYeah . Yeah . So that 's why I think that 's another reason other than curiosity as to why i it would in fact be kinda neat to find out if we 're way off . I mean , the other thing is , are aren't we seeing  ? Y y\nMm - hmm .\nI 'm sure you 've already looked at this bu in these noisy cases , are  ? We are seeing lots of insertions . Right ? The insertion number is quite high ?\nYeah .\nI know the VAD takes pre care of part of that ,\nYeah .\nYeah .\nbut\nI 've seen that with the mel cepstrum . I don't  I don't know about  the Aurora front - end , but\nI think it 's much more balanced with , uh  when the front - end is more robust . Yeah . I could look at it  at this . Yeah . Mm - hmm .\nYeah . Wha - what 's a typical number ?\nI don't  I don't know .\nDo we  ? Oh , you  oh , you don't know .\nI don't have this in\nOK . I 'm sure it 's more balanced ,\nMm - hmm .\nbut it  it  it wouldn't surprise me if there 's still\nMm - hmm .\nI mean , in  in the  the  the old systems we used to do , I  I  uh , I remember numbers kind of like insertions being half the number of deletions , as being  and both numbers being  tend to be on the small side comparing to  to , uh , substitutions .\nMm - hmm .\nWell , this  the whole problem with insertions was what I think , um , we talked about when the guy from OGI came down  that one time and  and that was when people were saying , well we should have a , uh , uh , voice activity detector\nRight .\nthat , because all that stuff  that we 're getting thr the silence that 's getting through is causing insertions . So .\nMmm .\nRight .\nI 'll bet you there 's still a lot  of insertions .\nMm - hmm .\nYeah . And it may be less of a critical thing . I mean , the fact that some get by may be less of a critical thing if you , uh , get things in the right range .\nMm - hmm .\nSo , I mean , the insertions is  is a symptom . It 's a symptom that there 's something , uh , wrong with the range .\nRight .\nBut there 's  uh , your  your  your substitutions tend to go up as well . So , uh , I  I  I think that ,\nMm - hmm .\nuh , the most obvious thing is just the insertions , @ @ . But  Uh  um . If you 're operating in the wrong range  I mean , that 's why just in general , if you  change what these  these penalties and scaling factors are , you reach some point that 's a  that 's a minimum . So . Um . Um . We do have to do well over a range of different conditions , some of which are noisier than others . Um . But , um , I think we may get a better handle on that if we  if we see  Um , I mean we ca it 's if we actually could pick a  a  a more stable value for the range of these features , it , um , uh , could  Uh  Even though it 's  it 's  it 's true that in a real situation you can in fact adjust the  these  these scaling factors in the back - end , and it 's ar artificial here that we 're not adjusting those , you certainly don't wanna be adjusting those all the time . And if you have a nice front - end that 's in roughly the right range\nHmm .\nI remember after we got our stuff more or less together in the previous systems we built , that we tended to set those scaling factors at kind of a standard level , and we would rarely adjust them again , even though you could get a\nMm - hmm .\nfor an evaluation you can get an extra point or something if you tweaked it a little bit . But , once we knew what rou roughly the right operating range was , it was pretty stable , and  Uh , we might just not even be in the right operating range .\nSo , would the  ? Uh , would a good idea be to try to map it into the same range that you get in the well - matched case ? So , if we computed what the range was in well - matched , and then when we get our noisy conditions out we try to make it have the same range as  ?\nNo . You don't wanna change it for different conditions . No . No . I  I  I  What  what I 'm saying\nOh , I wasn't suggesting change it for different conditions . I was just saying that when we pick a range , we  we wanna pick a range that we map our numbers into\nYeah .\nwe should probably pick it based on the range that we get in the well - matched case . Otherwise , I mean , what range are we gonna choose to  to map everything into ?\nWell . It depends how much we wanna do gamesmanship and how much we wanna do  I mean , i if he it  to me , actually , even if you wanna be  play on the gamesmanship side , it can be kinda tricky . So , I mean , what you would do is set the  set the scaling factors , uh , so that you got the best number for this point four five times the   you know , and so on .\nMm - hmm .\nBut they might change that  those weightings .\nYeah .\nUm . So  Uh  I just sorta think we need to explore the space . Just take a look at it a little bit .\nMm - hmm .\nAnd we  we  we may just find that  that we 're way off .\nOK . Mm - hmm .\nMaybe we 're not . You know ? As for these other things , it may turn out that , uh ,  it 's kind of reasonable . But then  I mean , Andreas gave a very reasonable response , and he 's probably not gonna be the only one who 's gonna say this in the future  of , you know , people  people within this tight - knit community who are doing this evaluation  are accepting , uh , more or less , that these are the rules . But , people outside of it who look in at the broader picture are certainly gonna say \" Well , wait a minute . You 're doing all this standing on your head , uh , on the front - end ,\nYeah .\nwhen all you could do is just adjust this in the back - end with one s one knob . \"\nMm - hmm .\nAnd so we have to at least , I think , determine that that 's not true , which would be OK , or determine that it is true , in which case we want to adjust that and then continue with  with what we 're doing . And as you say  as you point out  finding ways to then compensate for that in the front - end  also then becomes a priority for this particular test ,\nRight .\nand saying you don't have to do that .\nMm - hmm .", "topic_id": 0, "keywords": "meeting, czech, hynek, accent, talking", "dialogue_id": 58}, {"text": "So . OK . So , uh  What 's new with you ?\nUh . So there 's nothing  new . Um .\nUh , what 's old with you that 's developed ?\nI 'm sorry ?\nYou  OK . What 's old with you that has developed over the last week or two ?\nMmm . Well , so we 've been mainly working on the report and  and  Yeah .\nMainly working on what ?\nOn the report  of the work that was already done .\nOh .\nUm . Mm - hmm . That 's all .\nHow about that  ? Any - anything new on the thing that , uh , you were working on with the , uh  ?\nI don't have results yet .\nNo results ? Yeah .\nWhat was that ?\nThe  the , uh ,\nVoicing thing .\nvoicing detector .\nI mean , what what 's  what 's going on now ? What are you  doing ?\nUh , to try to found , nnn , robust feature for detect between voice and unvoice . And we  w we try to use  the variance  of the es difference between the FFT spectrum and mel filter bank spectrum .\nYeah .\nUh , also the  another parameter is  relates with the auto - correlation function .\nUh - huh .\nR - ze energy and the variance a also of the auto - correlation function .\nUh - huh . So , that 's  Yeah . That 's what you were describing , I guess , a week or two ago .\nYeah . But we don't have res we don't have result of the AURO for Aurora yet .\nSo .\nWe need to train the neural network\nMm - hmm .\nand\nSo you 're training neural networks now ?\nNo , not yet .\nSo , what  wha  wh wha what what 's going on ?\nWell , we work in the report , too , because we have a lot of result ,\nUh - huh .\nthey are very dispersed , and was necessary to  to look in all the directory to  to  to give some more structure .\nYea\nSo . B So  Yeah . I if I can summarize , basically what 's going on is that you 're going over a lot of material that you have generated in furious fashion , f generating many results and doing many experiments and trying to pull it together into some coherent form to be able to see wha see what happens .\nHm - hmm .\nUh , y yeah . Basically we we 've stopped , uh , experimenting ,\nYes ?\nI mean . We 're just writing some kind of technical report . And\nIs this a report that 's for Aurora ? Or is it just like a tech report for ICSI ,\nNo .\nYeah .\nFor ICSI .\nor  ? Ah . I see .\nYeah .\nJust summary of the experiment and the conclusion and something like that .\nYeah .\nMm - hmm .\nOK . So , my suggestion , though , is that you  you not necessarily finish that . But that you put it all together so that it 's  you 've got  you 've got a clearer structure to it . You know what things are , you have things documented , you 've looked things up that you needed to look up .\nMm - hmm .\nSo that , you know  so that such a thing can be written . And , um  When  when  when do you leave again ?\nUh , in July . First of July .\nFirst of July ? OK . And that you figure on actually finishing it in  in June . Because , you know , you 're gonna have another bunch of results to fit in there anyway .\nMm - hmm .\nMm - hmm .\nAnd right now it 's kind of important that we actually go forward with experiments .\nIt 's not .\nSo  so , I  I think it 's good to pause , and to gather everything together and make sure it 's in good shape , so that other people can get access to it and so that it can go into a report in June . But I think  to  to really work on  on fine - tuning the report n at this point is  is probably bad timing , I  I  think .\nMm - hmm . Yeah . Well , we didn't  we just planned to work on it one week on this report , not  no more , anyway . Um .\nBut you ma you may really wanna add other things later anyway\nYeah . Mm - hmm .\nbecause you\nMmm .\nThere 's more to go ?\nYeah . Well , so I don't know . There are small things that we started to  to do . But\nAre you discovering anything , uh , that makes you scratch your head as you write this report , like why did we do that , or why didn't we do this ,\nUh .\nor  ?\nYeah . Yeah . And  Actually , there were some tables that were also with partial results . We just noticed that , wh while gathering the result that for some conditions we didn't have everything .\nMmm .\nBut anyway . Um . Yeah , yeah . We have , yeah , extracted actually the noises from  the SpeechDat - Car . And so , we can train neural network with speech and these noises . Um . It 's difficult to say what it will give , because when we look at the Aurora  the TI - digits experiments , um , they have these three conditions that have different noises , and apparently this system perform as well on the seen noises  on the unseen noises and on the seen noises . But , I think this is something we have to try anyway . So  adding the noises from  from the SpeechDat - Car . Um .\nThat 's  that 's , uh  that 's permitted ?\nUh . Well , OGI does  did that . Um . At some point they did that for  for the voice activity detector .\nUh , for a v VAD .\nRight ? Um .\nCould you say it again ? What  what exactly did they do ?\nThey used some parts of the , um , Italian database to train the voice activity detector , I think . It\nYeah . I guess the thing is  Yeah . I guess that 's a matter of interpretation . The rules as I understand it , is that in principle the Italian and the Spanish and the English  no , Italian and the Finnish and the English ?  were development data\nYeah . And Spanish , yeah .\non which you could adjust things . And the  and the German and Danish were the evaluation data .\nMm - hmm .\nAnd then when they finally actually evaluated things they used everything .\nYeah . That 's right . Uh\nSo  Uh , and it is true that the performance , uh , on the German was  I mean , even though the improvement wasn't so good , the pre the raw performance was really pretty good .\nMm - hmm .\nSo  And , uh , it  it doesn't appear that there 's strong evidence that even though things were somewhat tuned on those three or four languages , that  that going to a different language really hurt you . And the noises were not exactly the same . Right ? Because it was taken from a different , uh  I mean they were different drives .\nDifferent cars . Yeah .\nI mean , it was  it was actual different cars and so on .\nYeah .\nSo . Um , it 's somewhat tuned . It 's tuned more than , you know , a  a  a  a\nMm - hmm .\nYou 'd really like to have something that needed no particular noise at all , maybe just some white noise or something like that a at most .\nMm - hmm .\nBut that 's not really what this contest is . So . Um , I guess it 's OK .\nMm - hmm .\nThat 's something I 'd like to understand before we actually use something from it ,\nI think it 's\nbecause it would\nit 's probably something that , mmm , the  you know , the , uh , experiment designers didn't really think about , because I think most people aren't doing trained systems , or , you know , uh , systems that are like ours , where you actually use the data to build models . I mean , they just  doing signal - processing .\nYeah .\nWell , it 's true ,\nSo .\nexcept that , uh , that 's what we used in Aurora one , and then they designed the things for Aurora - two knowing that we were doing that .\nYeah . That 's true .\nUm .\nAnd they didn't forbid us  right ?  to build models on the data ?\nNo . But , I think  I think that it  it  it probably would be the case that if , say , we trained on Italian , uh , data and then , uh , we tested on Danish data and it did terribly , uh , that  that it would look bad . And I think someone would notice and would say \" Well , look . This is not generalizing . \" I would hope tha I would hope they would .\nMm - hmm .\nUm . But , uh , it 's true . You know , maybe there 's parameters that other people have used  you know , th that they have tuned in some way for other things . So it 's  it 's , uh  We should  we should  Maybe  that 's maybe a topic  Especially if you talk with him when I 'm not here , that 's a topic you should discuss with Hynek\nMm - hmm .\nto , you know , double check it 's OK .\nDo we know anything about  the speakers for each of the , uh , training utterances ?\nWhat do you mean ? We  we\nDo you have speaker information ?\nSocial security number\nThat would be good .\nLike , we have  male , female ,\nHmm .\nBank PIN .\nat least .\nJust male f female ?\nMmm .\nWhat kind of information do you mean ?\nWell , I was thinking about things like , you know , gender , uh  you know , gender - specific nets and , uh , vocal tract length normalization .\nMm - hmm .\nThings like that . I d I don't  I didn't know what information we have about the speakers that we could try to take advantage of .\nMm - hmm .\nHmm . Uh . Right . I mean , again , i if you had the whole system you were optimizing , that would be easy to see . But if you 're  supposedly just using a fixed back - end and you 're just coming up with a feature vector , w w I 'm not sure  I mean , having the two nets  Suppose you detected that it was male , it was female  you come up with different\nWell , you could put them both in as separate streams or something . Uh .\nMm - hmm .\nMaybe .", "topic_id": 1, "keywords": "spectrum, voicing, fft, voice, processing", "dialogue_id": 58}, {"text": "I don't know . I was just wondering if there was other information we could exploit .\nMm - hmm .\nHmm . Yeah , it 's an interesting thought . Maybe having something along the  I mean , you can't really do vocal tract normalization . But something that had some of that effect\nYeah .\nbeing applied to the data in some way .\nMm - hmm .\nUm .\nDo you have something simple in mind for  I mean , vocal tract length normalization ?\nUh no . I hadn't  I hadn't thought  it was  thought too much about it , really . It just  something that popped into my head just now . And so I  I  I mean , you could maybe use the ideas  a similar  idea to what they do in vocal tract length normalization . You know , you have some sort of a , uh , general speech model , you know , maybe just a mixture of Gaussians that you evaluate every utterance against , and then you see where each , you know , utterance  like , the likelihood of each utterance . You divide the  the range of the likelihoods up into discrete bins and then each bin 's got some knob  uh , setting .\nYeah . But just listen to yourself . I mean , that uh really doesn't sound like a real - time thing with less than two hundred milliseconds , uh , latency that  and where you 're not adjusting the statistical engine at all .\nYeah . Yeah .\nMm - hmm .\nYeah . That 's true .\nYou know , that just\nRight .\nHmm .\nI mean  Yeah .\nCould be expensive .\nNo . Well not just expensive . I  I  I don't see how you could possibly do it . You can't look at the whole utterance and do anything . You know , you can only  Right ?\nOh ,\nEach frame comes in and it 's gotta go out the other end .\nright .\nSo , uh\nRight . So whatever it was , it would have to be uh sort of on a per frame basis .\nYeah .\nMm - hmm .\nYeah . I mean , you can do , um  Fairly quickly you can do male female  f male female stuff .\nYeah . Yeah .\nBut as far as , I mean  Like I thought BBN did a thing with , uh , uh , vocal tract normalization a ways back . Maybe other people did too . With  with , uh , uh , l trying to identify third formant  average third formant   using that as an indicator of\nI don't know .\nSo . You know , third formant  I if you imagine that to first order what happens with , uh , changing vocal tract is that , uh , the formants get moved out by some proportion\nMm - hmm .\nSo , if you had a first formant that was one hundred hertz before , if the fifty  if the vocal tract is fifty percent shorter , then it would be out at seven fifty hertz , and so on . So , that 's a move of two hundred fifty hertz . Whereas the third formant which might have started off at twenty - five hundred hertz , you know , might be out to thirty - seven fifty , you know so it 's at  So , although , you frequently get less distinct higher formants , it 's still  third formant 's kind of a reasonable compromise , and\nMm - hmm .\nSo , I think , eh , if I recall correctly , they did something like that . And  and\nHmm .\nBut  Um , that doesn't work for just having one frame or something .\nYeah .\nMm - hmm .\nYou know ? That 's more like looking at third formant over  over a turn or something like that ,\nMm - hmm .\nand\nRight .\nUm . So . But on the other hand , male female is a  is a  is a much simpler categorization than figuring out a  a factor to , uh , squish or expand the  the spectrum .\nMm - hmm .\nSo , um . Y you could imagine that  I mean , just like we 're saying voiced - unvoiced is good to know  uh , male female is good to know also . Um .\nMm - hmm .\nBut , you 'd have to figure out a way to  to  to , uh , incorporate it on the fly . Uh , I mean , I guess , as you say , one thing you could do is simply , uh , have the  the male and female output vectors  you know , tr nets trained only on males and n trained only on females or  or , uh , you know . But  Um . I don't know if that would really help , because you already have males and females and it 's mm - hmm putting into one net . So is it  ?\nIs it balanced , um , in terms of gender  the data ?\nMmm .\nDo you know ?\nAlmost , yeah .\nHmm .\nMm - hmm .\nHmm . OK . Y you 're  you were saying before  ?\nUh . Yeah . So , this noise , um  Yeah . The MSG  Um . Mmm . There is something  perhaps , I could spend some days to look at this thing , cuz it seems that when we train networks on  let 's say , on TIMIT with MSG features , they  they look as good as networks trained on PLP . But , um , when they are used on  on the SpeechDat - Car data , it 's not the case  oh , well . The MSG features are much worse , and so maybe they 're , um , less  more sensitive to different recording conditions , or  Shou\nShouldn't be . They should be less so .\nYeah . But\nR right ?\nMmm .\nWh - ? But let me ask you this . What  what 's the , um  ? Do you kno recall if the insertions were  were higher with MSG ?\nI don't know . I cannot tell . But  It 's  it  the  the error rate is higher . So , I don\nYeah . But you should always look at insertions , deletions , and substitutions .\nYeah . Mm - hmm .\nSo\nMm - hmm .\nso , uh  MSG is very , very dif Eh , PLP is very much like mel cepstrum . MSG is very different from both of them .\nMm - hmm .\nSo , if it 's very different , then this is the sort of thing  I mean I 'm really glad Andreas brought this point up . I  sort of had forgotten to discuss it . Um . You always have to look at how this  uh , these adjustments , uh , affect things . And even though we 're not allowed to do that , again we maybe could reflect that back to our use of the features .\nMm - hmm .\nSo if it  if in fact , uh  The problem might be that the range of the MSG features is quite different than the range of the PLP or mel cepstrum .\nMm - hmm . Mm - hmm .\nAnd you might wanna change that .\nBut  Yeah . But , it 's d it 's after  Well , it 's tandem features , so  Mmm .\nYeah .\nYeah . We  we have estimation of post posteriors with PLP and with MSG as input ,\nYeah .\nso I don Well . I don't know .\nThat means they 're between zero and one .\nMm - hmm .\nBut i it  it  it  it doesn't necessarily  You know , they could be , um  Do - doesn't tell you what the variance of the things is .\nMmm . Mm - hmm .\nRight ? Cuz if you 're taking the log of these things , it could be , uh  Knowing what the sum of the probabilities are , doesn't tell you what the sum of the logs are .\nMm - hmm . Yeah .\nSo .\nYeah . So we should look at the likelihood , or  or what ? Or  well , at the log , perhaps , and\nYeah . Yeah .\nMm - hmm .\nOr what  you know , what you 're uh  the thing you 're actually looking at .\nMm - hmm .\nSo your  your  the values that are  are actually being fed into HTK .\nMm - hmm . But\nWhat do they look like ?\nNo And so th the , uh  for the tandem system , the values that come out of the net don't go through the sigmoid . Right ? They 're sort of the pre - nonlinearity values ?\nYes .\nRight . So they 're  kinda like log probabilities is what I was saying .\nAnd those  OK . And tho that 's what goes  into  HTK ?\nUh , almost . But then you actually do a KLT on them .\nOK .\nUm . They aren't normalized after that , are they ?\nMmm . No , they are not  no .\nNo . OK . So , um . Right . So the question is  Yeah . Whatever they are at that point , um , are they something for which taking a square root or cube root or fourth root or something like that is  is gonna be a good or a bad thing ? So .\nMm - hmm .\nUh , and that 's something that nothing  nothing else after that is gonna  Uh , things are gonna scale it  Uh , you know , subtract things from it , scale it from it , but nothing will have that same effect . Um . So . Um . Anyway , eh\nYeah . Cuz if  if the log probs that are coming out of the MSG are really big , the standard  insertion penalty is gonna have very little effect\nWell , the  Right .\ncompared to , you know , a smaller set of log probs .\nYeah . No . Again you don't really  look at that . It 's something  that , and then it 's going through this transformation that 's probably pretty close to  It 's , eh , whatever the KLT is doing . But it 's probably pretty close to what a  a  a discrete cosine transformation is doing .\nYeah .\nBut still it 's  it 's not gonna probably radically change the scale of things . I would think . And , uh  Yeah . It may be entirely off and  and it may be  at the very least it may be quite different for MSG than it is for mel cepstrum or PLP . So that would be  So the first thing I 'd look at without adjusting anything would just be to go back to the experiment and look at the , uh , substitutions , insertions , and deletions . And if the  if the , uh  i if there 's a fairly large effect of the difference , say , uh , uh , the r ratio between insertions and deletions for the two cases then that would be , uh , an indicator that it might  might be in that direction .\nMm - hmm . Mm - hmm . Yeah . But ,\nAnything else ?\nmy  my point was more that it  it works sometimes and  but sometimes it doesn't work .\nYeah .\nSo .\nWell .\nAnd it works on TI - digits and on SpeechDat - Car it doesn't work , and\nYeah .\nMm - hmm . Yeah . Well .\nBut , you know , some problems are harder than others ,\nMm - hmm . Yeah .\nand  And , uh , sometimes , you know , there 's enough evidence for something to work and then it 's harder , it breaks . You know ,\nMm - hmm .\nso it 's  But it  but , um , i it  it could be that when you say it works maybe we could be doing much better , even in TI - digits . Right ?\nYeah . Yeah , sure .\nSo .\nUh .\nHmm ? Yeah .\nYeah . Well , there is also the spectral subtraction , which , um  I think maybe we should , uh , try to integrate it in  in our system .\nYeah .\nMmm . Mm - hmm .\nRight .\nBut ,\nO\nI think that would involve to   to mmm  use a big  a  al already a big bunch of the system of Ericsson . Because he has spectral subtraction , then it 's followed by ,  um , other kind of processing that 's  are dependent on the  uh , if it 's speech or noi or silence .\nMm - hmm .\nAnd there is this kind of spectral flattening after  if it 's silence , and  and s I  I think it 's important , um ,  to reduce this musical noise and this  this increase of variance during silence portions . So . Well . This was in this would involve to take almost everything from  from the  this proposal and  and then just add some kind of on - line normalization in  in the neural network . Mmm .\nOK . Well , this 'll be , I think , something for discussion with Hynek next week .\nYeah . Mm - hmm .", "topic_id": 2, "keywords": "speechdat, normalization, utterance, normalized, voiced", "dialogue_id": 58}, {"text": "Yeah . OK . Right . So . How are , uh , uh  how are things going with what you 're doing ?\nOh . Well , um , I took a lot of time just getting my taxes out of the way  multi - national taxes . So , I 'm  I 'm starting to write code now for my work but I don't have any results yet . Um , i it would be good for me to talk to Hynek , I think , when he 's here .\nYeah .\nDo you know what his schedule will be like ?\nUh , he 'll be around for three days .\nOK . So , y\nUh , we 'll have a lot of time .\nOK .\nSo , uh  Um . I 'll , uh  You know , he 's  he 'll  he 'll be talking with everybody in this room So .\nBut you said you won't  you won't be here next Thursday ?\nNot Thursday and Friday . Yeah . Cuz I will be at faculty retreat .\nHmm .\nSo . I 'll try to  connect with him and people as  as I can on  on Wednesday . But  Um . Oh , how 'd taxes go ? Taxes go OK ?\nMmm . Yeah .\nYeah . Oh , good . Yeah . Yeah . That 's just  that 's  that 's one of the big advantages of not making much money is  the taxes are easier . Yeah .\nUnless you 're getting money in two countries .\nI think you are . Aren't you ?\nThey both want their cut .\nHmm .\nHmm . Yeah .\nRight ?\nYeah . Yeah . Huh . Canada w Canada wants a cut ?\nMm - hmm .\nHave to do  So you  you have to do two returns ?\nMmm . W uh , for two thousand I did . Yeah .\nOh , oh . Yeah . For tw That 's right , ju\nBut not for this next year ?\nTwo thousand . Yeah . Probably not this next year , I guess .\nYe\nYeah .\nUm .\nYeah .\nUh , I 'll  I 'll still have a bit of Canadian income but it 'll be less complicated because I will not be a  considered a resident of Canada anymore , so I won't have to declare my American income on my Canadian return .", "topic_id": 3, "keywords": "talking, talk, taxes, friday, doing", "dialogue_id": 58}, {"text": "OK . Alright . Uh . Barry , do you wanna  say something about your stuff here ?\nOh , um . Right . I  just , um , continuing looking at , uh , ph uh , phonetic events , and , uh , this Tuesday gonna be , uh , meeting with John Ohala with Chuck to talk some more about these , uh , ph um , phonetic events . Um , came up with , uh , a plan of attack , uh , gonna execute , and um  Yeah . It 's  that 's pretty much it .\nOh , well . No Um , why don't you say something about what it is ?\nOh , you  oh , you want  you want details . Hmm . OK .\nWell , we 're all gathered here together . I thought we 'd , you know\nI was hoping I could wave my hands . Um . So , um . So , once wa I  I was thinking getting  getting us a set of acoustic events to  um , to be able to distinguish between , uh , phones and words and stuff . And  um , once we  we would figure out a set of these events that can be , you know , um , hand - labeled or  or derived , uh , from h the hand - labeled phone targets . Um , we could take these events and , um ,  do some cheating experiments , um , where we feed , um , these events into  an SRI system , um , eh , and evaluate its performance on a Switchboard task . Uh , yeah .\nHey , Barry ? Can you give an example of an event ?\nYeah . Sure . Um , I  I can give you an example of  twenty - odd events . Um  So , he In this paper , um , it 's talking about phoneme recognition using acoustic events . So , things like frication or , uh , nasality .\nWhose paper is it ?\nUm , this is a paper by Hubener and Cardson  Benson  Bernds - Berndsen .\nYeah . Huh . From , uh , University of Hamburg and Bielefeld .\nMm - hmm .\nOK .\nUm .\nYeah . I think the  just to expand a little bit on the idea of acoustic event .\nMm - hmm .\nThere 's , um  in my mind , anyways , there 's a difference between , um , acoustic features and acoustic events . And I think of acoustic features as being , um , things that linguists talk about , like , um\nSo , stuff that 's not based on data .\nStuff that 's not based on data , necessarily .\nYeah . Oh , OK . Yeah . Yeah , OK .\nRight . That 's not based on , you know , acoustic data . So they talk about features for phones , like , uh , its height ,\nYeah .\nits tenseness , laxness , things like that ,\nMm - hmm .\nwhich may or may not be all that easy to measure in the acoustic signal . Versus an acoustic event , which is just {nonvocalsound} some {nonvocalsound} something in the acoustic signal {nonvocalsound} that is fairly easy to measure . Um . So it 's , um  it 's a little different , in  at least in my mind .\nI mean , when we did the SPAM work  I mean , there we had  we had this notion of an , uh , auditory  @ @  auditory event .\nGood . That 's great .\nAnd , uh , um , called them \" avents \" , uh , uh , uh , with an A at the front .\nMm - hmm .\nUh . And the  the  the idea was something that occurred that is important to a bunch of neurons somewhere . So .\nMm - hmm .\nUm . A sudden change or a relatively rapid change in some spectral characteristic will  will do sort of this . I mean , there 's certainly a bunch of  a bunch of places where you know that neurons are gonna fire because something novel has happened . That was  that was the main thing that we were focusing on there . But there 's certainly other things beyond what we talked about there that aren't just sort of rapid changes , but\nIt 's kinda like the difference between top - down and bottom - up .\nYeah .\nI think of the acoustic  you know , phonetic features as being top - down . You know , you look at the phone and you say this phone is supposed to be  you know , have this feature , this feature , and this feature . Whether tha those features show up in the acoustic signal is sort of irrelevant . Whereas , an acoustic event goes the other way . Here 's the signal . Here 's some event .\nMm - hmm .\nWhat  ? And then that  you know , that may map to this phone sometimes , and sometimes it may not . It just depen maybe depends on the context , things like that .\nMm - hmm .\nAnd so it 's sort of a different way of looking .\nMm - hmm .\nYeah . So . Yeah .\nOK .\nMm - hmm . Um  Using these  these events , um , you know , we can  we can perform these  these , uh , cheating experiments . See how  how  how good they are , um , in , um  in terms of phoneme recognition or word recognition . And , um  and then from that point on , I would , uh , s design robust event detectors , um , in a similar , um , wa spirit that Saul has done w uh , with his graphical models , and this  this probabilistic AND - OR model that he uses . Um , eh , try to extend it to , um  to account for other  other phenomena like , um , CMR co - modulation release . And , um  and maybe also investigate ways to  to modify the structure of these models , um , in a data - driven way , uh , similar to the way that , uh , Jeff  Jeff , uh , Bilmes did his work . Um , and while I 'm  I 'm doing these , um , event detectors , you know , I can ma mea measure my progress by comparing , um , the error rates in clean and noisy conditions to something like , uh , neural nets . Um , and  So  so , once we have these  these , uh , event detectors , um , we could put them together and  and feed the outputs of the event detectors into  into the SRI , um , HMM  HMM system , and , um  and test it on  on Switchboard or , um , maybe even Aurora stuff . And , that 's pretty much the  the big picture of  of um , the plan .\nBy the way , um , there 's , uh , a couple people who are gonna be here  I forget if I already told you this , but , a couple people who are gonna be here for six months .\nMm - hmm .\nUh  uh , there 's a Professor Kollmeier , uh , from Germany who 's , uh , uh , quite big in the , uh , hearing - aid signal - processing area and , um , Michael Kleinschmidt , who 's worked with him , who also looks at  auditory properties inspired by various , uh , brain function things .\nHmm .\nSo , um , um , I think they 'll be interesting to talk to , in this sort of issue as these detectors are  are , uh , developing .\nHmm . OK .\nSo , he looks at interesting  interesting things in  in the   different ways of looking at spectra in order to  to get various speech properties out . So .\nOK .\nOK . Well , short meeting , but that 's OK . And , uh , we might as well do our digits . And like I say , I  I encourage you to go ahead and meet , uh , next week with , uh , uh , Hynek . Alright , I 'll  I 'll start . It 's , uh , one thirty - five . seventeen OK", "topic_id": 4, "keywords": "phonetic, auditory, acoustic, hearing, speech", "dialogue_id": 58}]}